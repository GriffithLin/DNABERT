WARNING:__main__:Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
INFO:transformers.configuration_utils:loading configuration file /data3/linming/DNABERT/examples/model/6-new-12w-0/config.json
INFO:transformers.configuration_utils:Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "do_sample": false,
  "eos_token_ids": 0,
  "finetuning_task": "dnaprom",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "num_return_sequences": 1,
  "num_rnn_layer": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "rnn": "lstm",
  "rnn_dropout": 0.0,
  "rnn_hidden": 768,
  "split": 10,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 4101
}

DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): raw.githubusercontent.com:443
INFO:transformers.tokenization_utils:loading file https://raw.githubusercontent.com/jerryji1993/DNABERT/master/src/transformers/dnabert-config/bert-config-6/vocab.txt from cache at /data3/linming/.cache/torch/transformers/ea1474aad40c1c8ed4e1cb7c11345ddda6df27a857fb29e1d4c901d9b900d32d.26f8bd5a32e49c2a8271a46950754a4a767726709b7741c68723bc1db840a87e
INFO:transformers.modeling_utils:loading weights file /data3/linming/DNABERT/examples/model/6-new-12w-0/pytorch_model.bin
INFO:transformers.modeling_utils:Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
INFO:transformers.modeling_utils:Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']
INFO:__main__:finish loading model
INFO:__main__:Training/evaluation parameters Namespace(adam_epsilon=1e-08, attention_probs_dropout_prob=0.1, beta1=0.9, beta2=0.999, cache_dir='', config_name='', data_dir='/data3/linming/DNABERT/examples/data/fold5_100_13944/0/after/', device=device(type='cuda'), do_ensemble_pred=False, do_eval=True, do_lower_case=False, do_predict=False, do_train=True, do_visualize=False, early_stop=0, eval_all_checkpoints=False, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, hidden_dropout_prob=0.1, learning_rate=0.0001, local_rank=-1, logging_steps=100, max_grad_norm=1.0, max_seq_length=300, max_steps=-1, model_name='mutant_bert_fold_100_0_13944', model_name_or_path='/data3/linming/DNABERT/examples/model/6-new-12w-0/', model_num=3, model_type='dna', n_gpu=1, n_process=8, no_cuda=False, num_rnn_layer=2, num_train_epochs=15.0, output_dir='/data3/linming/DNABERT/examples/output/fold5_100_13944/0/', output_mode='classification', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=48, per_gpu_pred_batch_size=8, per_gpu_train_batch_size=48, predict_dir=None, predict_scan_size=1, result_dir=None, rnn='lstm', rnn_dropout=0.0, rnn_hidden=768, save_steps=4000, save_total_limit=None, seed=47, server_ip='', server_port='', should_continue=False, task_name='dnaprom', tokenizer_name='dna6', visualize_data_dir=None, visualize_models=None, visualize_train=False, warmup_percent=0.1, warmup_steps=0, weight_decay=0.01)
INFO:__main__:Creating features from dataset file at /data3/linming/DNABERT/examples/data/fold5_100_13944/0/after/
INFO:transformers.data.processors.glue:LOOKING AT /data3/linming/DNABERT/examples/data/fold5_100_13944/0/after/train.tsv
INFO:transformers.data.processors.glue:Writing example 0/1394
INFO:transformers.data.processors.glue:*** Example ***
INFO:transformers.data.processors.glue:guid: train-1
INFO:transformers.data.processors.glue:input_ids: 2 1829 3208 532 2113 245 965 3848 3090 59 223 878 3498 1692 2659 2430 1514 1946 3675 2398 1385 1431 1613 2343 1165 549 2183 526 2092 164 642 2555 2013 3943 3469 1573 2181 519 2062 43 157 614 2444 1572 2177 504 2001 3895 3280 819 3261 742 2953 3607 2126 300 1185 631 2511 1837 3239 654 2603 2208 625 2488 1748 2882 3324 994 3964 3553 1912 3539 1853 3304 916 3652 2307 1024 4084 4036 3844 3073 4088 4052 3905 3317 968 3858 3132 228 900 3585 2039 4045 3877 3205 520 2068 67 255 1006 4011 3743 2670 2476 1697 2677 2502 1801 3094 76 291 1150 492 1955 3709 2533 1927 3597 2087 141 552 2193 568 2257 821 3272 787 3133 232 913 3639 2253 808 3218 572 2275 893 3558 1931 3613 2152 402 1595 2269 872 3473 1592 2259 829 3304 915 3648 2289 952 3793 2869 3272 788 3139 253 997 3974 3594 2075 95 367 1453 1703 2701 2600 2193 567 2256 820 3266 764 3041 3959 3535 1840 3252 706 2812 3042 3962 3546 1883 3421 1384 1425 1592 2257 824 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:label: 1 (id = 1)
INFO:transformers.data.processors.glue:Writing example 0/1394
INFO:transformers.data.processors.glue:*** Example ***
INFO:transformers.data.processors.glue:guid: train-2
INFO:transformers.data.processors.glue:input_ids: 2 1694 2667 2461 1638 2443 1567 2160 434 1721 2773 2887 3342 1068 162 636 2529 1909 3527 1806 3116 161 632 2515 1853 3304 916 3649 2294 971 3870 3177 406 1612 2340 1155 509 2023 3982 3628 2211 637 2534 1932 3618 2170 473 1879 3406 1324 1187 639 2541 1959 3727 2605 2215 653 2597 2181 519 2061 38 139 542 2155 414 1644 2466 1658 2524 1890 3450 1499 1887 3438 1451 1693 2662 2443 1568 2162 441 1751 2893 3366 1162 539 2143 366 1451 1693 2664 2449 1592 2258 827 3295 878 3499 1693 2662 2443 1567 2157 424 1683 2621 2278 905 3606 2124 291 1150 489 1943 3663 2350 1194 666 2650 2396 1379 1405 1512 1940 3651 2303 1005 4005 3717 2568 2068 65 248 977 3893 3271 782 3116 164 642 2556 2020 3971 3581 2024 3986 3641 2263 845 3367 1167 559 2221 677 2696 2580 2113 245 968 3860 3137 248 977 3894 3273 790 3148 291 1150 490 1947 3679 2413 1447 1677 2599 2191 557 2215 653 2600 2193 565 2245 774 3082 26 90 345 1367 1359 1326 1195 669 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:label: 0 (id = 0)
INFO:transformers.data.processors.glue:*** Example ***
INFO:transformers.data.processors.glue:guid: train-1395
INFO:transformers.data.processors.glue:input_ids: 2 2540 1955 3710 2539 1951 3695 2478 1705 2711 2639 2350 1193 663 2639 2350 1194 667 2654 2412 1444 1665 2550 1996 3874 3193 469 1863 3343 1071 175 687 2733 2725 2693 2565 2054 12 35 125 486 1931 3613 2150 396 1570 2170 476 1892 3457 1527 1997 3877 3205 520 2067 63 238 938 3739 2654 2410 1435 1630 2410 1435 1631 2416 1460 1732 2819 3071 4078 4011 3741 2662 2443 1567 2158 427 1693 2664 2451 1599 2286 938 3739 2655 2414 1451 1695 2670 2476 1698 2682 2523 1886 3435 1439 1646 2475 1695 2670 2475 1694 2667 2464 1650 2491 1760 2929 3512 1747 2879 3311 942 3755 2718 2667 2462 1642 2459 1631 2414 1452 1697 2678 2506 1818 3161 343 1357 1320 1171 573 2280 916 3652 2305 1016 4052 3905 3317 968 3857 3125 197 776 3091 61 229 901 3590 2058 25 88 340 1348 1284 1025 4085 4037 3848 3092 65 246 970 3868 3172 385 1525 1989 3847 3087 47 174 684 2721 2678 2506 1819 3166 364 1444 1668 2563 2046 4076 4001 3701 2504 1811 3134 234 924 3682 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:*** Example ***
INFO:transformers.data.processors.glue:guid: train-3
INFO:transformers.data.processors.glue:input_ids: 2 580 2305 1016 4052 3908 3332 1025 4085 4040 3860 3137 248 979 3903 3310 939 3743 2671 2479 1712 2740 2755 2814 3052 4002 3708 2532 1921 3575 1997 3879 3215 557 2214 652 2596 2180 516 2052 4097 4087 4045 3879 3216 563 2237 744 2964 3652 2308 1027 4095 4079 4014 3755 2717 2663 2447 1584 2225 696 2772 2882 3324 995 3967 3566 1962 3739 2655 2415 1455 1709 2728 2705 2616 2258 827 3296 883 3518 1769 2968 3665 2358 1228 803 3199 496 1969 3768 2772 2884 3332 1027 4094 4075 3998 3691 2462 1644 2467 1664 2545 1973 3784 2834 3131 221 872 3474 1596 2276 899 3584 2035 4031 3823 2992 3763 2752 2804 3011 3838 3052 4001 3704 2514 1850 3292 866 3449 1496 1876 3396 1284 1026 4091 4061 3943 3471 1582 2220 676 2691 2557 2024 3988 3652 2307 1024 4084 4033 3832 3027 3902 3308 932 3716 2564 2051 4095 4079 4013 3751 2701 2600 2193 568 2259 832 3316 963 3839 3056 4020 3778 2812 3041 3960 3540 1860 3331 1023 4078 4010 3739 2655 2415 1455 1712 2740 2756 2820 3076 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:label: 0 (id = 0)
INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:label: 1 (id = 1)
INFO:transformers.data.processors.glue:*** Example ***
INFO:transformers.data.processors.glue:guid: train-4
INFO:transformers.data.processors.glue:input_ids: 2 175 685 2727 2704 2610 2234 731 2911 3438 1450 1691 2654 2411 1439 1646 2475 1694 2667 2464 1652 2499 1790 3052 4003 3711 2543 1967 3759 2735 2733 2728 2705 2615 2255 815 3245 679 2701 2598 2187 543 2157 424 1681 2613 2247 782 3115 157 615 2446 1578 2204 611 2430 1516 1956 3713 2549 1990 3850 3099 93 358 1419 1568 2162 444 1762 2937 3543 1871 3375 1200 692 2753 2808 3028 3908 3329 1015 4045 3879 3214 555 2205 616 2452 1604 2305 1014 4044 3875 3197 487 1934 3626 2204 610 2426 1500 1890 3452 1505 1909 3526 1804 3105 119 464 1842 3257 727 2894 3372 1188 642 2556 2020 3971 3581 2024 3987 3647 2287 942 3756 2723 2687 2542 1963 3743 2672 2483 1728 2801 3000 3794 2874 3291 862 3434 1436 1635 2429 1510 1930 3610 2140 354 1404 1508 1922 3580 2019 3965 3560 1940 3650 2299 991 3950 3500 1700 2691 2557 2024 3985 3637 2248 787 3134 236 929 3701 2504 1810 3130 219 861 3431 1421 1575 2189 552 2195 576 2291 959 3821 2984 3730 2619 2271 878 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:label: 1 (id = 1)
INFO:transformers.data.processors.glue:*** Example ***
INFO:transformers.data.processors.glue:guid: train-1396
INFO:transformers.data.processors.glue:input_ids: 2 2373 1285 1031 13 38 138 540 2146 380 1506 1915 3551 1901 3493 1669 2568 2067 61 230 905 3605 2117 261 1031 15 45 165 645 2568 2067 62 236 932 3713 2549 1990 3850 3097 85 325 1286 1036 36 129 501 1989 3845 3079 13 37 135 525 2087 142 555 2205 613 2438 1545 2071 79 302 1194 665 2645 2373 1285 1032 20 66 251 990 3946 3481 1623 2382 1323 1182 618 2460 1634 2428 1506 1914 3546 1883 3424 1396 1474 1788 3044 3970 3578 2010 3931 3423 1389 1445 1671 2575 2094 171 669 2661 2437 1542 2060 36 130 506 2010 3932 3426 1404 1505 1912 3538 1849 3285 838 3338 1049 86 332 1314 1147 478 1898 3482 1626 2395 1374 1387 1438 1644 2467 1664 2546 1977 3800 2898 3385 1238 841 3349 1094 266 1051 94 364 1443 1661 2535 1936 3633 2229 709 2821 3077 5 5 8 18 57 216 850 3385 1240 850 3388 1250 892 3556 1924 3586 2042 4057 3925 3399 1293 1064 145 567 2254 810 3226 601 2389 1349 1288 1042 58 218 857 3415 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:label: 0 (id = 0)
INFO:transformers.data.processors.glue:*** Example ***
INFO:transformers.data.processors.glue:guid: train-5
INFO:transformers.data.processors.glue:input_ids: 2 1855 3311 941 3752 2707 2621 2278 907 3614 2156 420 1666 2556 2019 3965 3560 1940 3650 2298 987 3934 3436 1443 1664 2545 1974 3788 2849 3191 461 1830 3210 540 2147 384 1522 1980 3812 2945 3574 1996 3873 3191 463 1840 3252 708 2817 3064 4052 3907 3328 1012 4035 3839 3055 4013 3752 2707 2623 2287 943 3758 2729 2711 2638 2348 1188 643 2560 2036 4035 3838 3052 4001 3703 2511 1838 3244 676 2689 2552 2004 3908 3330 1020 4068 3970 3579 2013 3944 3474 1595 2271 879 3503 1710 2732 2723 2686 2540 1955 3710 2540 1955 3710 2540 1953 3703 2511 1837 3238 651 2590 2154 410 1628 2402 1404 1508 1923 3582 2026 3993 3671 2381 1318 1163 541 2150 395 1567 2158 427 1695 2670 2476 1698 2682 2523 1886 3436 1444 1665 2549 1992 3859 3135 237 935 3726 2604 2209 632 2513 1846 3273 791 3149 293 1160 532 2115 255 1006 4012 3748 2689 2549 1991 3855 3119 175 685 2725 2693 2566 2057 23 80 306 1209 728 2900 3394 1275 991 3950 3498 1691 2655 2416 1460 1730 2812 3044 3972 3585 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:label: 0 (id = 0)
INFO:transformers.data.processors.glue:*** Example ***
INFO:transformers.data.processors.glue:guid: train-1397
INFO:transformers.data.processors.glue:input_ids: 2 3874 3196 484 1922 3580 2019 3968 3571 1982 3819 2975 3695 2477 1701 2693 2567 2062 44 164 641 2550 1996 3875 3199 495 1967 3759 2735 2733 2727 2704 2611 2239 749 2983 3726 2603 2207 622 2473 1688 2644 2369 1272 980 3907 3327 1008 4019 3774 2796 2977 3704 2516 1860 3330 1020 4065 3960 3539 1856 3316 964 3841 3063 4046 3881 3222 587 2335 1133 421 1669 2568 2067 61 232 916 3652 2307 1023 4077 4008 3732 2627 2304 1011 4031 3823 2991 3759 2735 2734 2732 2723 2688 2547 1983 3824 2995 3775 2800 2995 3775 2800 2995 3775 2800 2995 3775 2800 2995 3775 2800 2995 3775 2799 2991 3759 2736 2740 2756 2819 3072 4081 4024 3795 2879 3311 941 3752 2707 2622 2283 928 3700 2499 1792 3059 4031 3824 2995 3773 2791 2959 3632 2228 705 2808 3027 3901 3302 907 3615 2158 427 1694 2668 2468 1666 2553 2007 3917 3366 1164 548 2179 512 2036 4036 3844 3075 4096 4083 4031 3823 2992 3763 2751 2800 2993 3768 2772 2884 3332 1027 4093 4072 3987 3647 2288 947 3775 2800 2995 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:label: 0 (id = 0)
INFO:transformers.data.processors.glue:Writing example 0/1394
INFO:transformers.data.processors.glue:*** Example ***
INFO:transformers.data.processors.glue:guid: train-1398
INFO:transformers.data.processors.glue:input_ids: 2 1289 1045 70 266 1049 87 335 1326 1193 663 2639 2350 1194 666 2651 2398 1388 1442 1660 2530 1915 3550 1900 3492 1668 2563 2047 4077 4006 3722 2586 2138 346 1372 1380 1411 1534 2025 3990 3657 2325 1094 267 1053 102 395 1566 2154 410 1625 2389 1350 1290 1050 90 347 1375 1390 1449 1688 2642 2363 1247 878 3499 1695 2671 2477 1703 2701 2600 2196 578 2300 995 3966 3563 1950 3692 2466 1659 2526 1900 3490 1660 2531 1919 3567 1968 3762 2746 2780 2914 3449 1493 1861 3336 1041 56 210 827 3294 874 3482 1626 2395 1374 1388 1442 1658 2523 1885 3430 1419 1566 2156 418 1657 2517 1861 3334 1036 33 117 454 1804 3105 117 455 1808 3121 182 714 2842 3163 351 1391 1453 1704 2705 2613 2247 782 3115 159 623 2478 1705 2709 2630 2316 1057 120 465 1845 3269 773 3077 5 6 9 23 77 293 1158 521 2071 78 300 1188 642 2554 2010 3931 3421 1384 1426 1594 2266 860 3428 1411 1533 2022 3978 3611 2141 358 1418 1561 2134 332 1313 1143 462 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:label: 1 (id = 1)
INFO:transformers.data.processors.glue:*** Example ***
INFO:transformers.data.processors.glue:guid: train-2789
INFO:transformers.data.processors.glue:input_ids: 2 2476 1699 2685 2535 1935 3629 2216 659 2624 2289 952 3794 2873 3287 848 3379 1216 755 3007 3824 2994 3770 2780 2916 3459 1535 2031 4013 3752 2707 2623 2288 946 3770 2779 2909 3431 1424 1586 2236 739 2944 3570 1980 3810 2937 3543 1872 3378 1212 738 2939 3551 1901 3496 1684 2627 2304 1011 4030 3820 2980 3715 2559 2031 4013 3751 2704 2611 2239 751 2989 3751 2703 2608 2228 705 2807 3022 3884 3235 638 2540 1956 3715 2560 2036 4035 3837 3048 3987 3648 2292 963 3838 3052 4003 3712 2548 1987 3837 3048 3987 3648 2292 963 3840 3060 4035 3840 3060 4035 3840 3060 4035 3839 3056 4019 3776 2804 3011 3837 3047 3983 3632 2228 708 2817 3064 4052 3907 3325 1000 3988 3649 2296 980 3907 3327 1008 4019 3774 2796 2980 3716 2563 2045 4072 3988 3652 2305 1016 4050 3897 3287 846 3370 1177 598 2379 1310 1130 410 1627 2398 1386 1436 1633 2424 1491 1853 3304 915 3648 2290 955 3806 2922 3484 1636 2434 1531 2014 3946 3484 1635 2432 1524 1987 3840 3059 4032 3828 3010 3835 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:label: 0 (id = 0)
INFO:transformers.data.processors.glue:*** Example ***
INFO:transformers.data.processors.glue:guid: train-1399
INFO:transformers.data.processors.glue:input_ids: 2 2020 3969 3576 2001 3895 3280 820 3268 772 3075 4095 4077 4008 3732 2625 2295 973 3878 3212 548 2179 511 2029 4008 3730 2618 2266 860 3425 1398 1484 1825 3191 461 1832 3218 572 2276 897 3576 2001 3893 3272 787 3134 236 931 3710 2540 1955 3711 2541 1960 3730 2618 2267 862 3436 1442 1660 2532 1924 3588 2051 4096 4083 4029 3816 2963 3647 2287 941 3751 2703 2606 2218 667 2654 2411 1439 1646 2475 1693 2663 2448 1588 2243 767 3055 4014 3755 2717 2664 2452 1602 2300 993 3957 3528 1809 3125 200 786 3129 216 851 3392 1268 963 3837 3048 3988 3652 2307 1024 4082 4028 3812 2945 3576 2002 3899 3296 881 3510 1740 2850 3193 472 1875 3389 1256 914 3641 2263 846 3372 1188 644 2562 2044 4067 3965 3558 1930 3612 2147 381 1512 1940 3650 2299 990 3947 3487 1645 2470 1673 2582 2124 289 1143 463 1838 3244 673 2680 2516 1860 3329 1016 4052 3907 3325 997 3973 3592 2065 55 205 807 3216 562 2234 731 2910 3433 1429 1605 2309 1032 20 67 255 1005 4007 3727 2606 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:label: 0 (id = 0)
INFO:transformers.data.processors.glue:*** Example ***
INFO:transformers.data.processors.glue:guid: train-2790
INFO:transformers.data.processors.glue:Writing example 0/1394
INFO:transformers.data.processors.glue:input_ids: 2 3417 1367 1357 1318 1161 534 2122 283 1118 362 1434 1625 2390 1353 1302 1099 285 1127 397 1575 2189 551 2191 558 2217 661 2629 2311 1038 42 154 602 2394 1370 1370 1370 1370 1370 1370 1371 1375 1389 1447 1678 2602 2201 600 2385 1336 1233 824 3281 821 3269 775 3086 43 159 621 2469 1672 2577 2101 199 781 3109 135 525 2087 143 559 2221 680 2705 2614 2252 804 3201 501 1989 3846 3082 26 90 348 1380 1409 1528 2003 3901 3301 902 3596 2082 124 484 1922 3578 2010 3930 3418 1370 1372 1380 1411 1534 2028 4003 3709 2536 1940 3651 2301 998 3977 3605 2120 276 1089 246 969 3864 3156 324 1281 1014 4042 3865 3158 331 1310 1129 406 1610 2331 1117 360 1428 1602 2297 982 3914 3356 1122 377 1495 1869 3365 1158 522 2075 95 365 1448 1682 2617 2262 842 3356 1122 377 1495 1870 3371 1181 613 2439 1551 2093 167 654 2604 2209 632 2514 1852 3298 889 3543 1869 3365 1158 522 2075 94 361 1429 1606 2314 1051 94 363 1437 1640 2449 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:label: 1 (id = 1)
INFO:transformers.data.processors.glue:*** Example ***
INFO:transformers.data.processors.glue:guid: train-4183
INFO:transformers.data.processors.glue:input_ids: 2 2652 2404 1412 1539 2047 4078 4010 3738 2652 2404 1411 1536 2036 4033 3831 3022 3883 3231 621 2471 1679 2607 2223 686 2729 2709 2631 2319 1071 175 687 2736 2737 2742 2763 2847 3183 431 1711 2736 2739 2751 2799 2992 3764 2755 2815 3055 4016 3763 2750 2793 2965 3655 2319 1072 179 702 2793 2966 3658 2330 1115 350 1386 1433 1622 2379 1311 1134 426 1692 2659 2432 1521 1976 3793 2871 3278 811 3231 623 2479 1711 2733 2728 2707 2623 2287 943 3758 2730 2716 2660 2435 1535 2030 4010 3739 2654 2411 1437 1639 2446 1580 2209 631 2509 1832 3219 574 2282 922 3676 2404 1410 1532 2019 3966 3562 1947 3678 2412 1443 1662 2540 1954 3708 2532 1922 3579 2015 3949 3496 1683 2621 2278 906 3612 2147 381 1510 1929 3607 2125 296 1171 573 2279 910 3628 2212 643 2560 2034 4027 3806 2924 3492 1668 2564 2052 4097 4088 4052 3908 3332 1027 4096 4083 4029 3815 2957 3623 2189 550 2187 541 2152 402 1595 2269 871 3471 1584 2225 696 2771 2880 3313 951 3790 2860 3236 644 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:label: 1 (id = 1)
INFO:transformers.data.processors.glue:*** Example ***
INFO:transformers.data.processors.glue:guid: train-2791
INFO:transformers.data.processors.glue:input_ids: 2 3827 3007 3823 2989 3751 2703 2605 2216 657 2613 2248 785 3128 211 832 3315 960 3827 3008 3828 3011 3837 3047 3983 3632 2228 707 2815 3056 4019 3775 2799 2989 3752 2707 2621 2279 911 3632 2227 704 2803 3006 3820 2979 3709 2536 1940 3651 2301 999 3981 3623 2190 555 2208 627 2495 1775 2992 3763 2752 2803 3006 3820 2979 3711 2543 1968 3763 2751 2799 2991 3760 2739 2749 2791 2960 3635 2240 755 3005 3815 2960 3635 2240 755 3007 3823 2992 3763 2752 2803 3006 3819 2976 3699 2495 1776 2995 3775 2800 2995 3775 2800 2995 3775 2800 2995 3775 2800 2995 3775 2800 2995 3775 2800 2995 3775 2800 2995 3775 2800 2995 3776 2803 3005 3815 2959 3629 2215 655 2606 2220 675 2687 2544 1972 3779 2815 3053 4006 3724 2596 2178 508 2019 3966 3564 1954 3708 2529 1912 3539 1856 3315 960 3827 3007 3823 2992 3763 2752 2803 3007 3823 2991 3759 2736 2739 2751 2800 2996 3780 2819 3071 4079 4015 3760 2739 2752 2803 3008 3827 3006 3819 2975 3694 2476 1700 2692 2562 2043 4063 3951 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:label: 0 (id = 0)
INFO:transformers.data.processors.glue:*** Example ***
INFO:transformers.data.processors.glue:guid: train-4184
INFO:transformers.data.processors.glue:input_ids: 2 3487 1645 2471 1677 2599 2190 554 2204 611 2430 1515 1951 3695 2477 1703 2703 2606 2220 675 2685 2535 1935 3630 2219 671 2671 2478 1706 2716 2658 2426 1499 1887 3439 1454 1708 2724 2692 2562 2042 4059 3933 3432 1428 1601 2293 968 3857 3128 209 824 3283 832 3313 950 3788 2850 3194 474 1883 3421 1384 1425 1589 2248 785 3126 203 800 3186 444 1764 2945 3574 1996 3873 3192 466 1851 3295 877 3493 1672 2577 2101 199 782 3113 151 591 2349 1192 660 2625 2295 973 3877 3208 529 2104 211 830 3308 932 3716 2562 2044 4068 3969 3576 2002 3897 3287 847 3374 1196 674 2683 2527 1903 3502 1708 2724 2689 2552 2001 3895 3280 817 3255 719 2863 3248 692 2753 2805 3016 3860 3137 248 977 3894 3275 800 3186 443 1757 2918 3468 1570 2172 481 1912 3539 1856 3315 960 3828 3012 3843 3072 4084 4033 3832 3028 3908 3332 1028 4099 4093 4071 3984 3633 2232 724 2884 3332 1026 4091 4063 3950 3498 1691 2655 2415 1454 1707 2720 2675 2493 1768 2964 3652 2305 1015 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:label: 0 (id = 0)
INFO:transformers.data.processors.glue:*** Example ***
INFO:transformers.data.processors.glue:guid: train-2792
INFO:transformers.data.processors.glue:input_ids: 2 3631 2221 679 2703 2606 2219 669 2663 2448 1586 2235 733 2918 3466 1564 2147 383 1520 1971 3775 2800 2994 3772 2785 2936 3539 1853 3301 901 3592 2068 65 247 975 3887 3248 689 2741 2757 2823 3085 40 148 579 2304 1012 4034 3836 3041 3960 3540 1857 3319 975 3886 3244 675 2685 2536 1940 3649 2293 965 3846 3084 36 129 501 1991 3853 3112 148 577 2296 980 3906 3324 993 3957 3527 1807 3118 171 672 2676 2500 1794 3068 4067 3968 3570 1979 3807 2926 3498 1691 2654 2411 1439 1646 2474 1691 2654 2411 1439 1646 2475 1695 2670 2475 1694 2668 2467 1661 2536 1940 3652 2306 1019 4063 3950 3499 1694 2667 2464 1651 2496 1780 3011 3838 3052 4004 3714 2555 2013 3944 3476 1604 2306 1019 4064 3956 3523 1791 3053 4008 3731 2622 2283 927 3696 2481 1719 2768 2867 3263 749 2984 3731 2622 2282 923 3677 2406 1419 1566 2155 415 1645 2471 1680 2611 2239 752 2995 3775 2799 2990 3755 2719 2670 2475 1695 2672 2483 1727 2798 2987 3744 2673 2486 1739 2846 3179 415 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:label: 0 (id = 0)
INFO:transformers.data.processors.glue:*** Example ***
INFO:transformers.data.processors.glue:guid: train-4185
INFO:transformers.data.processors.glue:input_ids: 2 4059 3933 3432 1428 1602 2299 991 3951 3503 1709 2728 2706 2619 2272 882 3515 1757 2918 3467 1566 2156 419 1663 2544 1971 3773 2790 2954 3610 2139 352 1396 1475 1789 3046 3980 3617 2165 455 1805 3112 147 573 2280 915 3647 2285 935 3725 2600 2195 573 2280 915 3648 2289 952 3795 2879 3311 941 3752 2705 2613 2248 788 3137 245 967 3856 3124 195 767 3054 4011 3743 2670 2475 1695 2670 2475 1694 2668 2467 1664 2545 1976 3793 2872 3283 832 3314 955 3807 2928 3506 1723 2782 2924 3492 1667 2558 2027 3998 3692 2468 1667 2558 2027 3998 3692 2468 1667 2558 2027 3998 3692 2468 1667 2558 2027 3998 3692 2468 1665 2552 2001 3894 3276 804 3203 512 2034 4028 3812 2946 3577 2008 3924 3396 1284 1028 4099 4094 4076 4003 3709 2533 1928 3604 2116 260 1026 4090 4060 3939 3455 1517 1959 3727 2607 2223 685 2725 2695 2576 2100 195 767 3055 4013 3751 2701 2598 2187 544 2164 449 1781 3015 3856 3122 188 740 2947 3583 2031 4013 3750 2699 2591 2157 422 1675 2589 2150 396 1571 2175 494 1964 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:label: 0 (id = 0)
INFO:transformers.data.processors.glue:Writing example 0/1394
INFO:transformers.data.processors.glue:*** Example ***
INFO:transformers.data.processors.glue:guid: train-4186
INFO:transformers.data.processors.glue:input_ids: 2 449 1784 3026 3900 3297 885 3525 1800 3089 56 209 821 3272 785 3127 205 806 3210 539 2144 369 1464 1747 2877 3301 903 3598 2090 155 605 2407 1421 1573 2184 529 2101 197 774 3084 34 123 478 1897 3480 1617 2357 1221 773 3080 17 53 197 776 3090 58 219 862 3434 1434 1625 2390 1356 1314 1148 484 1921 3575 1999 3887 3246 684 2721 2680 2514 1850 3291 863 3439 1453 1703 2703 2608 2228 705 2806 3020 3873 3192 465 1847 3279 814 3243 670 2667 2461 1638 2441 1560 2131 319 1261 936 3729 2613 2248 786 3130 219 863 3439 1455 1709 2726 2699 2591 2157 424 1682 2618 2267 864 3442 1467 1758 2924 3492 1665 2549 1992 3857 3128 209 823 3279 814 3243 671 2672 2484 1730 2812 3041 3960 3538 1849 3288 851 3390 1258 923 3679 2414 1452 1699 2686 2538 1948 3683 2430 1516 1956 3715 2558 2028 4004 3716 2562 2042 4058 3930 3419 1375 1391 1455 1711 2735 2733 2727 2704 2612 2241 760 3028 3905 3320 978 3899 3295 878 3499 1694 2667 2461 1639 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:label: 0 (id = 0)
INFO:transformers.data.processors.glue:*** Example ***
INFO:transformers.data.processors.glue:guid: train-2793
INFO:transformers.data.processors.glue:input_ids: 2 2655 2414 1449 1686 2636 2337 1143 461 1830 3212 545 2165 455 1806 3114 153 597 2375 1295 1069 166 649 2584 2129 309 1221 773 3080 17 53 200 788 3140 260 1025 4085 4037 3848 3089 53 197 773 3079 13 38 139 541 2149 392 1555 2112 242 955 3807 2927 3501 1702 2697 2584 2129 311 1230 811 3229 615 2447 1583 2222 684 2721 2677 2504 1810 3130 219 862 3435 1437 1640 2452 1601 2294 971 3871 3181 423 1680 2610 2236 739 2941 3560 1939 3646 2282 924 3682 2427 1501 1895 3469 1576 2194 572 2275 893 3560 1939 3646 2283 928 3698 2491 1757 2919 3469 1576 2194 572 2275 893 3560 1939 3646 2283 925 3687 2446 1579 2205 616 2450 1596 2274 892 3556 1923 3581 2021 3973 3592 2068 66 252 995 3967 3567 1966 3754 2716 2657 2424 1492 1858 3322 988 3938 3451 1503 1901 3496 1684 2626 2300 993 3960 3539 1855 3309 936 3732 2627 2303 1005 4006 3723 2589 2151 398 1577 2197 581 2312 1044 67 253 999 3983 3632 2225 696 2771 2877 3303 910 3626 2202 603 2398 1386 1436 1635 2431 1517 1958 3724 2593 2168 467 1855 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:label: 1 (id = 1)
INFO:transformers.data.processors.glue:*** Example ***
INFO:transformers.data.processors.glue:guid: train-5577
INFO:transformers.data.processors.glue:input_ids: 2 2264 852 3393 1270 970 3866 3163 351 1390 1450 1690 2650 2394 1370 1370 1370 1370 1372 1378 1402 1498 1882 3419 1374 1387 1437 1639 2447 1582 2220 674 2684 2529 1911 3535 1840 3250 697 2774 2892 3363 1150 492 1954 3707 2526 1899 3487 1646 2476 1698 2683 2525 1896 3474 1596 2276 898 3580 2018 3963 3549 1896 3474 1596 2274 892 3556 1921 3574 1996 3873 3192 465 1847 3279 814 3242 666 2651 2399 1391 1453 1701 2695 2575 2094 172 675 2687 2542 1964 3745 2678 2507 1822 3177 407 1614 2347 1182 618 2458 1625 2389 1350 1292 1057 119 464 1843 3263 752 2994 3770 2778 2908 3425 1398 1482 1818 3163 350 1387 1437 1640 2452 1604 2305 1015 4045 3879 3214 555 2207 621 2472 1683 2622 2283 925 3688 2449 1590 2252 803 3197 488 1937 3640 2259 831 3309 935 3726 2604 2211 637 2535 1934 3626 2201 600 2388 1348 1283 1022 4076 4002 3708 2529 1910 3532 1827 3198 490 1948 3684 2434 1532 2020 3971 3581 2024 3988 3649 2294 972 3875 3198 491 1950 3691 2463 1648 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:label: 0 (id = 0)
INFO:transformers.data.processors.glue:*** Example ***
INFO:transformers.data.processors.glue:guid: train-4187
INFO:transformers.data.processors.glue:input_ids: 2 1950 3690 2457 1623 2382 1324 1185 630 2507 1824 3185 438 1738 2841 3159 334 1321 1175 590 2346 1178 602 2395 1375 1391 1454 1707 2719 2671 2479 1709 2726 2697 2584 2130 314 1241 855 3407 1328 1202 697 2775 2893 3367 1168 561 2232 721 2869 3272 785 3125 197 774 3082 27 93 360 1428 1601 2293 968 3858 3129 213 840 3345 1077 200 786 3129 213 840 3345 1080 210 828 3297 887 3535 1839 3246 681 2710 2634 2329 1110 332 1315 1150 490 1947 3678 2411 1437 1637 2440 1556 2113 247 973 3880 3220 577 2294 972 3876 3202 508 2017 3957 3528 1812 3137 247 973 3880 3220 577 2294 972 3876 3202 508 2017 3957 3527 1805 3112 147 573 2277 902 3595 2078 106 412 1635 2431 1517 1960 3730 2620 2274 892 3556 1921 3573 1992 3857 3125 199 782 3113 149 581 2312 1044 66 249 983 3917 3368 1170 571 2269 871 3470 1578 2204 610 2426 1499 1885 3430 1420 1572 2178 508 2020 3970 3578 2010 3932 3425 1397 1480 1812 3138 250 988 3940 3459 1534 2026 3994 3673 2389 1349 1285 1032 18 58 220 867 3455 1517 1959 3727 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:label: 1 (id = 1)
INFO:transformers.data.processors.glue:*** Example ***
INFO:transformers.data.processors.glue:guid: train-5578
INFO:transformers.data.processors.glue:input_ids: 2 1697 2680 2513 1845 3269 774 3082 26 90 346 1372 1379 1407 1517 1957 3719 2573 2085 136 529 2101 200 785 3125 197 773 3078 9 22 73 279 1103 302 1196 673 2678 2507 1823 3181 422 1676 2594 2169 469 1863 3343 1070 172 674 2682 2522 1883 3422 1388 1442 1660 2529 1910 3529 1813 3144 275 1086 235 926 3691 2463 1646 2476 1697 2678 2506 1818 3164 354 1401 1493 1863 3341 1063 141 549 2181 518 2060 34 122 475 1887 3437 1445 1670 2570 2074 91 351 1390 1449 1685 2630 2313 1045 69 261 1030 12 33 117 453 1797 3080 19 61 232 913 3640 2257 823 3277 805 3205 517 2053 6 10 26 91 350 1387 1437 1639 2446 1580 2210 633 2517 1862 3337 1045 72 273 1077 197 773 3078 10 25 88 338 1340 1251 893 3557 1925 3590 2058 27 96 369 1461 1733 2822 3084 33 118 457 1816 3153 309 1223 781 3110 137 534 2121 277 1093 261 1029 8 17 53 199 782 3116 163 637 2533 1926 3594 2074 91 352 1393 1462 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:label: 1 (id = 1)
INFO:transformers.data.processors.glue:*** Example ***
INFO:transformers.data.processors.glue:guid: train-5579
INFO:transformers.data.processors.glue:input_ids: 2 2564 2051 4094 4075 3999 3694 2475 1695 2671 2477 1701 2694 2571 2078 107 415 1647 2478 1708 2721 2677 2504 1811 3134 236 932 3713 2551 1999 3886 3244 673 2680 2515 1855 3311 941 3752 2706 2617 2264 852 3396 1281 1015 4045 3879 3213 551 2189 552 2196 580 2306 1019 4063 3949 3496 1683 2623 2285 936 3731 2624 2290 955 3807 2926 3500 1700 2691 2558 2026 3995 3679 2414 1451 1695 2669 2472 1684 2628 2306 1019 4061 3942 3466 1562 2139 349 1382 1419 1566 2153 407 1613 2341 1158 524 2082 123 478 1899 3485 1640 2449 1592 2260 833 3319 975 3886 3243 671 2671 2479 1711 2734 2731 2719 2671 2479 1709 2727 2703 2606 2218 667 2654 2411 1440 1651 2495 1775 2989 3751 2701 2599 2190 556 2211 638 2540 1956 3716 2564 2052 4097 4087 4046 3883 3231 623 2480 1715 2749 2790 2956 3619 2174 492 1954 3705 2519 1870 3370 1179 606 2412 1444 1666 2554 2011 3934 3435 1438 1644 2465 1656 2515 1856 3313 952 3794 2875 3294 874 3483 1631 2413 1447 1678 2603 2208 627 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:label: 0 (id = 0)
INFO:transformers.data.processors.glue:Writing example 0/1394
INFO:transformers.data.processors.glue:*** Example ***
INFO:transformers.data.processors.glue:guid: train-5580
INFO:transformers.data.processors.glue:input_ids: 2 2348 1185 629 2504 1810 3130 218 858 3419 1375 1391 1456 1716 2755 2814 3051 3998 3690 2458 1628 2401 1397 1478 1802 3099 94 362 1434 1628 2401 1399 1487 1840 3251 701 2791 2957 3624 2193 568 2257 823 3277 805 3208 532 2113 247 975 3885 3237 647 2574 2089 151 591 2351 1199 685 2725 2694 2569 2070 76 290 1146 475 1885 3432 1428 1601 2294 970 3868 3172 388 1537 2037 4039 3854 3114 156 612 2434 1531 2014 3946 3484 1634 2425 1495 1869 3366 1162 539 2142 363 1437 1638 2443 1565 2150 395 1567 2157 423 1678 2604 2212 641 2549 1990 3852 3107 127 494 1964 3747 2685 2534 1931 3614 2153 407 1614 2346 1178 604 2403 1407 1517 1958 3722 2586 2139 351 1389 1445 1672 2578 2106 219 861 3430 1418 1564 2148 386 1530 2010 3930 3420 1380 1412 1537 2039 4045 3880 3217 567 2254 811 3231 622 2476 1700 2692 2562 2043 4062 3945 3479 1615 2351 1197 677 2693 2567 2061 38 139 542 2155 413 1637 2438 1547 2079 111 429 1704 2705 2616 2259 829 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:label: 1 (id = 1)
INFO:transformers.data.processors.glue:*** Example ***
INFO:transformers.data.processors.glue:guid: train-6971
INFO:transformers.data.processors.glue:input_ids: 2 3191 463 1837 3238 652 2593 2168 468 1857 3319 973 3880 3218 571 2269 872 3476 1603 2302 1004 4004 3716 2564 2050 4091 4061 3941 3462 1548 2082 121 469 1863 3341 1063 142 556 2211 639 2541 1960 3730 2618 2265 855 3405 1319 1168 564 2244 770 3067 4063 3950 3499 1693 2663 2446 1579 2206 618 2459 1629 2408 1428 1604 2308 1025 4085 4040 3859 3133 231 909 3622 2185 536 2129 309 1222 777 3094 76 289 1142 460 1828 3203 511 2032 4018 3772 2785 2934 3532 1825 3191 461 1829 3207 527 2093 167 656 2612 2241 759 3023 3887 3247 685 2728 2708 2628 2307 1021 4070 3979 3614 2155 415 1647 2477 1702 2699 2589 2151 397 1574 2188 547 2173 485 1925 3589 2056 18 57 215 845 3367 1167 558 2220 675 2687 2541 1960 3732 2625 2293 968 3857 3125 197 776 3089 55 206 809 3223 590 2348 1187 637 2536 1939 3645 2279 909 3624 2193 566 2252 803 3197 485 1925 3590 2059 30 108 420 1665 2549 1992 3859 3135 237 935 3728 2610 2236 737 2935 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:label: 1 (id = 1)
INFO:transformers.data.processors.glue:*** Example ***
INFO:transformers.data.processors.glue:guid: train-5581
INFO:transformers.data.processors.glue:input_ids: 2 4076 4004 3714 2556 2018 3962 3548 1892 3460 1537 2040 4049 3895 3278 810 3227 605 2407 1421 1575 2192 564 2242 764 3041 3958 3532 1828 3202 508 2020 3970 3579 2014 3947 3488 1652 2499 1791 3055 4013 3750 2699 2591 2157 422 1675 2591 2159 430 1708 2723 2685 2536 1939 3647 2287 943 3759 2733 2725 2696 2577 2103 208 818 3260 739 2942 3563 1951 3695 2477 1704 2708 2625 2295 976 3889 3256 722 2874 3290 859 3424 1395 1470 1772 2979 3711 2541 1959 3728 2609 2230 713 2837 3144 274 1084 227 893 3558 1931 3614 2155 414 1643 2464 1652 2499 1789 3048 3986 3642 2267 864 3442 1467 1758 2924 3490 1660 2529 1911 3534 1835 3229 616 2449 1591 2255 816 3252 708 2817 3063 4046 3884 3235 638 2538 1948 3684 2433 1527 2000 3892 3267 766 3051 3997 3688 2449 1591 2256 817 3256 724 2883 3327 1006 4011 3743 2670 2476 1699 2687 2543 1968 3764 2754 2812 3043 3966 3563 1949 3687 2447 1582 2220 674 2684 2532 1922 3579 2015 3951 3504 1715 2751 2797 2984 3731 2622 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:label: 1 (id = 1)
INFO:transformers.data.processors.glue:*** Example ***
INFO:transformers.data.processors.glue:guid: train-6972
INFO:transformers.data.processors.glue:input_ids: 2 2304 1011 4029 3814 2954 3611 2143 365 1446 1675 2590 2156 418 1659 2527 1904 3506 1723 2783 2927 3502 1707 2717 2663 2445 1576 2195 575 2285 936 3731 2623 2286 939 3742 2668 2468 1668 2562 2044 4065 3959 3533 1830 3211 543 2157 422 1676 2593 2168 465 1847 3277 807 3215 559 2222 683 2718 2668 2467 1663 2541 1959 3727 2607 2221 679 2703 2606 2220 676 2689 2551 1999 3885 3240 658 2617 2263 847 3374 1196 674 2681 2519 1871 3373 1192 659 2622 2284 931 3712 2547 1983 3821 2982 3723 2589 2151 399 1582 2220 673 2680 2515 1855 3309 933 3717 2566 2059 29 103 398 1580 2209 632 2516 1859 3326 1004 4003 3711 2543 1966 3756 2724 2691 2559 2031 4014 3756 2721 2677 2504 1811 3134 235 928 3700 2499 1791 3053 4007 3725 2600 2194 572 2273 888 3539 1854 3307 927 3695 2478 1708 2723 2685 2536 1939 3646 2283 926 3692 2468 1665 2552 2003 3901 3304 916 3651 2304 1012 4033 3832 3028 3905 3319 974 3884 3236 643 2558 2027 3999 3694 2476 1699 2688 2546 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:label: 1 (id = 1)
INFO:transformers.data.processors.glue:Writing example 0/1394
INFO:transformers.data.processors.glue:*** Example ***
INFO:transformers.data.processors.glue:guid: train-6973
INFO:transformers.data.processors.glue:input_ids: 2 2735 2735 2735 2736 2738 2748 2787 2943 3568 1971 3775 2799 2989 3751 2704 2612 2244 770 3068 4065 3959 3534 1835 3231 624 2484 1732 2820 3075 4095 4079 4015 3759 2735 2735 2735 2736 2738 2748 2787 2943 3568 1971 3775 2799 2989 3751 2704 2612 2244 770 3068 4065 3959 3534 1835 3231 624 2484 1732 2820 3075 4095 4079 4015 3759 2735 2735 2735 2736 2738 2748 2787 2943 3568 1971 3775 2799 2989 3751 2704 2612 2244 770 3068 4065 3959 3534 1835 3231 624 2484 1732 2820 3075 4095 4079 4015 3759 2735 2735 2735 2736 2738 2748 2787 2943 3568 1971 3775 2799 2989 3751 2704 2612 2244 770 3068 4065 3959 3534 1835 3231 624 2484 1731 2816 3059 4031 3823 2991 3759 2735 2735 2735 2736 2738 2748 2787 2943 3568 1971 3775 2799 2989 3751 2704 2612 2244 770 3068 4065 3959 3534 1835 3231 624 2484 1732 2820 3075 4095 4079 4015 3759 2735 2735 2735 2736 2738 2748 2785 2935 3535 1839 3247 687 2733 2727 2704 2612 2244 770 3068 4065 3959 3534 1835 3231 624 2481 1720 2769 2871 3279 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:label: 0 (id = 0)
INFO:transformers.data.processors.glue:*** Example ***
INFO:transformers.data.processors.glue:guid: train-8365
INFO:transformers.data.processors.glue:input_ids: 2 3557 1928 3603 2109 230 906 3611 2143 365 1448 1681 2615 2255 815 3247 686 2732 2724 2691 2559 2032 4017 3765 2757 2824 3091 64 243 960 3827 3006 3818 2971 3678 2411 1439 1647 2477 1701 2696 2579 2109 230 906 3611 2141 359 1421 1575 2192 564 2243 767 3054 4011 3743 2671 2478 1706 2715 2654 2410 1436 1634 2425 1496 1873 3382 1228 804 3203 510 2028 4003 3712 2547 1981 3815 2959 3629 2214 651 2590 2155 414 1644 2466 1660 2529 1910 3531 1823 3182 428 1698 2682 2523 1885 3429 1415 1549 2085 136 531 2109 229 904 3601 2102 203 798 3180 419 1662 2539 1952 3699 2494 1772 2977 3704 2513 1845 3269 776 3090 59 223 878 3498 1692 2659 2430 1516 1956 3716 2561 2037 4037 3846 3083 32 113 437 1736 2833 3126 202 796 3169 376 1492 1857 3319 974 3881 3223 590 2346 1178 603 2399 1389 1448 1681 2613 2246 778 3098 92 355 1406 1515 1952 3699 2494 1769 2967 3661 2343 1166 553 2199 590 2347 1183 622 2476 1697 2680 2516 1857 3318 972 3876 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:label: 1 (id = 1)
INFO:transformers.data.processors.glue:*** Example ***
INFO:transformers.data.processors.glue:guid: train-6974
INFO:transformers.data.processors.glue:input_ids: 2 2501 1800 3090 59 223 879 3504 1716 2754 2811 3039 3949 3495 1678 2602 2202 604 2404 1410 1532 2020 3971 3582 2028 4001 3704 2515 1854 3308 930 3708 2529 1910 3529 1813 3143 271 1071 174 684 2723 2687 2541 1957 3717 2568 2065 55 205 808 3217 565 2246 779 3102 105 407 1614 2347 1183 621 2471 1678 2604 2209 632 2516 1859 3328 1012 4033 3830 3020 3876 3204 515 2046 4076 4004 3716 2564 2051 4094 4074 3995 3679 2414 1452 1697 2679 2511 1837 3240 658 2619 2270 876 3490 1658 2524 1890 3450 1499 1885 3430 1419 1568 2162 444 1763 2944 3571 1981 3813 2951 3598 2091 158 620 2465 1654 2508 1826 3196 482 1916 3556 1923 3581 2024 3988 3652 2306 1017 4053 3911 3342 1066 156 612 2436 1537 2039 4046 3883 3229 615 2446 1579 2207 621 2472 1681 2614 2250 795 3167 365 1448 1684 2625 2293 966 3852 3108 132 515 2046 4076 4002 3707 2526 1897 3480 1620 2369 1271 974 3881 3224 593 2360 1234 828 3297 887 3535 1838 3243 670 2666 2460 1633 2421 1477 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:label: 0 (id = 0)
INFO:transformers.data.processors.glue:*** Example ***
INFO:transformers.data.processors.glue:guid: train-6975
INFO:transformers.data.processors.glue:input_ids: 2 1384 1425 1590 2251 799 3181 423 1678 2604 2210 636 2531 1917 3557 1925 3589 2055 15 46 171 670 2667 2462 1642 2457 1622 2378 1306 1114 347 1376 1394 1465 1752 2900 3394 1275 989 3941 3462 1545 2069 71 269 1061 135 528 2100 193 760 3026 3898 3292 866 3450 1498 1883 3423 1390 1450 1691 2653 2405 1414 1548 2082 124 483 1918 3561 1944 3666 2364 1249 888 3539 1855 3309 936 3730 2618 2267 861 3431 1424 1587 2239 749 2984 3729 2613 2246 779 3103 110 427 1695 2671 2478 1708 2721 2679 2509 1832 3217 566 2252 804 3204 513 2040 4049 3896 3283 831 3310 938 3739 2656 2418 1467 1760 2931 3519 1775 2991 3757 2726 2698 2586 2138 348 1380 1412 1539 2045 4072 3985 3638 2252 802 3196 483 1917 3559 1933 3621 2182 524 2084 129 501 1990 3850 3099 96 369 1464 1748 2883 3328 1009 4024 3793 2870 3275 798 3177 406 1610 2329 1111 333 1320 1169 568 2257 824 3281 823 3279 813 3238 652 2596 2177 504 2003 3903 3310 940 3747 2687 2541 1958 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:label: 1 (id = 1)
INFO:transformers.data.processors.glue:*** Example ***
INFO:transformers.data.processors.glue:guid: train-8366
INFO:transformers.data.processors.glue:Writing example 0/1396
INFO:transformers.data.processors.glue:input_ids: 2 1662 2539 1950 3692 2468 1668 2563 2047 4079 4014 3755 2718 2668 2468 1666 2555 2013 3943 3470 1580 2210 636 2532 1923 3582 2028 4004 3715 2557 2024 3986 3644 2273 887 3535 1838 3243 671 2671 2478 1707 2720 2675 2493 1767 2959 3631 2223 685 2726 2700 2595 2173 488 1940 3650 2300 996 3970 3580 2017 3959 3533 1829 3206 524 2083 127 493 1960 3729 2616 2258 825 3287 847 3374 1196 673 2680 2516 1857 3317 968 3859 3136 244 962 3834 3034 3932 3428 1409 1528 2004 3907 3327 1005 4008 3732 2626 2299 990 3945 3479 1615 2350 1194 666 2651 2399 1391 1454 1706 2715 2654 2412 1442 1659 2527 1903 3502 1708 2723 2686 2540 1955 3710 2539 1950 3689 2455 1613 2342 1162 538 2138 347 1373 1383 1423 1581 2213 648 2577 2102 203 798 3179 416 1652 2498 1788 3041 3960 3538 1851 3295 877 3495 1678 2604 2211 639 2543 1967 3757 2728 2705 2616 2260 836 3331 1022 4076 4004 3716 2563 2046 4076 4002 3707 2526 1899 3485 1640 2449 1589 2248 787 3134 236 931 3711 2541 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:label: 0 (id = 0)
INFO:transformers.data.processors.glue:*** Example ***
INFO:transformers.data.processors.glue:guid: train-8367
INFO:transformers.data.processors.glue:input_ids: 2 3546 1884 3426 1401 1494 1868 3362 1145 470 1866 3354 1113 342 1354 1307 1118 362 1434 1626 2394 1371 1374 1386 1434 1625 2389 1352 1299 1085 232 916 3650 2298 988 3940 3459 1533 2021 3975 3597 2086 138 540 2146 377 1495 1869 3365 1160 530 2107 221 871 3471 1583 2221 680 2707 2623 2285 936 3729 2613 2248 788 3137 245 966 3852 3107 125 487 1933 3624 2194 569 2263 846 3372 1186 634 2522 1883 3421 1381 1413 1542 2059 29 101 389 1544 2066 59 221 870 3466 1561 2134 330 1306 1116 353 1398 1482 1817 3160 337 1336 1234 828 3300 900 3585 2038 4042 3866 3162 348 1377 1398 1481 1814 3146 284 1121 374 1484 1828 3204 515 2048 4084 4034 3833 3029 3910 3338 1049 86 331 1310 1129 405 1605 2312 1041 56 209 824 3281 821 3270 778 3098 89 343 1357 1317 1159 526 2090 156 611 2430 1514 1947 3678 2412 1442 1659 2525 1893 3463 1550 2090 155 606 2412 1442 1657 2520 1876 3395 1277 1000 3987 3645 2277 904 3603 2109 230 905 3606 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:label: 1 (id = 1)
INFO:transformers.data.processors.glue:*** Example ***
INFO:transformers.data.processors.glue:guid: train-9759
INFO:transformers.data.processors.glue:*** Example ***
INFO:transformers.data.processors.glue:guid: train-8368
INFO:transformers.data.processors.glue:input_ids: 2 3128 209 821 3272 786 3129 216 849 3381 1223 783 3117 165 648 2577 2101 200 787 3134 234 921 3670 2378 1308 1124 387 1536 2033 4024 3795 2878 3307 925 3688 2452 1601 2294 970 3867 3166 362 1435 1629 2406 1419 1567 2157 422 1676 2593 2167 461 1830 3211 542 2153 408 1617 2357 1222 777 3094 74 284 1123 382 1515 1949 3688 2449 1589 2248 785 3125 198 778 3098 90 348 1377 1397 1477 1800 3090 60 228 900 3585 2039 4048 3891 3262 747 2973 3686 2443 1566 2154 410 1627 2398 1385 1429 1605 2309 1031 15 45 165 645 2568 2065 53 197 773 3077 8 18 57 213 837 3336 1042 60 226 890 3545 1880 3409 1336 1234 828 3300 899 3582 2025 3992 3665 2357 1222 779 3103 109 424 1681 2613 2246 778 3099 93 357 1416 1556 2116 257 1013 4037 3846 3084 35 125 485 1926 3596 2081 120 466 1849 3285 840 3347 1085 232 915 3645 2277 901 3590 2060 34 122 474 1881 3414 1354 1305 1109 325 1286 1033 22 73 278 1100 291 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:input_ids: 2 2725 2696 2578 2107 223 878 3499 1696 2674 2490 1755 2909 3432 1427 1597 2278 907 3613 2149 391 1549 2088 147 575 2286 940 3748 2690 2556 2019 3967 3567 1968 3761 2744 2772 2883 3328 1012 4034 3835 3039 3949 3496 1681 2613 2247 784 3121 183 717 2853 3207 527 2093 167 655 2605 2215 656 2611 2240 753 3000 3795 2879 3309 935 3728 2612 2243 767 3053 4007 3727 2605 2215 653 2597 2183 525 2088 147 575 2285 935 3727 2605 2215 655 2607 2223 687 2733 2728 2707 2621 2279 911 3629 2215 655 2605 2215 655 2605 2215 655 2605 2215 655 2605 2215 655 2605 2215 655 2605 2215 655 2605 2215 655 2605 2214 651 2589 2151 399 1581 2215 655 2605 2215 655 2607 2224 691 2751 2800 2995 3775 2800 2995 3775 2799 2992 3763 2751 2799 2991 3760 2739 2749 2789 2951 3599 2096 179 703 2800 2995 3775 2800 2995 3775 2800 2995 3775 2800 2995 3773 2792 2963 3645 2280 915 3645 2280 915 3645 2280 915 3647 2288 947 3775 2800 2995 3775 2800 2995 3775 2800 2995 3775 2800 2995 3775 2799 2991 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:label: 0 (id = 0)
INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:label: 1 (id = 1)
INFO:transformers.data.processors.glue:*** Example ***
INFO:transformers.data.processors.glue:guid: train-8369
INFO:transformers.data.processors.glue:input_ids: 2 2720 2676 2499 1792 3059 4032 3825 2999 3789 2856 3219 575 2287 943 3759 2735 2734 2731 2719 2671 2480 1715 2752 2801 3000 3795 2879 3311 941 3751 2701 2600 2193 567 2256 819 3264 755 3008 3827 3005 3815 2957 3624 2195 575 2288 947 3773 2792 2964 3650 2300 996 3969 3576 2003 3904 3316 961 3831 3022 3883 3229 616 2451 1599 2286 938 3738 2649 2390 1354 1307 1119 368 1459 1728 2803 3007 3822 2987 3744 2676 2499 1789 3048 3988 3651 2304 1012 4036 3844 3076 4098 4092 4068 3972 3588 2052 4099 4096 4084 4036 3844 3075 4096 4084 4035 3838 3051 3997 3688 2451 1597 2280 916 3652 2307 1024 4083 4031 3823 2989 3752 2707 2621 2278 907 3614 2155 415 1646 2475 1696 2675 2493 1767 2957 3622 2188 548 2179 510 2025 3992 3668 2371 1277 999 3983 3632 2227 704 2804 3011 3837 3047 3984 3634 2236 740 2945 3573 1992 3859 3133 232 915 3647 2286 940 3747 2688 2548 1988 3842 3065 4056 3921 3384 1236 835 3328 1012 4036 3843 3069 4072 3988 3650 2297 984 3922 3388 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:label: 0 (id = 0)
INFO:transformers.data.processors.glue:*** Example ***
INFO:transformers.data.processors.glue:guid: train-9760
INFO:transformers.data.processors.glue:input_ids: 2 1381 1416 1555 2111 238 940 3746 2683 2526 1898 3483 1629 2406 1417 1560 2130 316 1249 886 3532 1825 3191 461 1829 3207 525 2087 141 550 2186 538 2137 341 1351 1293 1062 138 538 2140 354 1402 1498 1882 3420 1377 1398 1482 1818 3163 349 1383 1423 1583 2222 683 2718 2667 2463 1646 2475 1694 2667 2462 1643 2463 1647 2479 1709 2727 2702 2603 2206 619 2461 1640 2450 1595 2270 876 3491 1661 2536 1939 3647 2285 936 3732 2625 2296 977 3896 3283 829 3304 916 3652 2305 1013 4039 3854 3116 162 635 2525 1896 3473 1591 2255 813 3239 655 2605 2215 653 2597 2183 527 2093 167 653 2599 2190 555 2206 620 2468 1665 2552 2004 3905 3320 980 3905 3317 966 3852 3107 127 493 1957 3718 2572 2084 132 516 2049 4087 4047 3887 3246 684 2722 2683 2526 1900 3491 1661 2533 1926 3596 2083 127 494 1964 3746 2684 2532 1924 3587 2046 4075 3998 3689 2455 1614 2345 1175 589 2341 1160 531 2110 234 923 3677 2407 1421 1573 2182 524 2082 121 469 1864 3346 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:label: 1 (id = 1)
INFO:transformers.data.processors.glue:*** Example ***
INFO:transformers.data.processors.glue:guid: train-9761
INFO:transformers.data.processors.glue:input_ids: 2 2705 2614 2249 789 3142 266 1050 90 348 1378 1402 1498 1883 3422 1385 1429 1605 2310 1033 22 73 277 1093 262 1034 26 90 348 1377 1397 1478 1801 3096 82 314 1241 854 3404 1314 1146 473 1877 3397 1285 1029 8 18 59 222 873 3477 1605 2309 1032 19 62 235 925 3687 2445 1576 2193 565 2245 773 3077 6 11 29 103 398 1580 2210 635 2528 1906 3514 1756 2914 3451 1501 1896 3474 1594 2266 859 3421 1381 1414 1548 2082 122 473 1877 3398 1289 1046 74 284 1122 378 1498 1882 3419 1374 1386 1435 1629 2408 1427 1598 2282 923 3677 2405 1414 1546 2074 91 350 1387 1438 1641 2456 1618 2362 1241 853 3399 1294 1068 162 634 2523 1886 3434 1435 1630 2410 1435 1629 2408 1427 1597 2277 902 3593 2072 83 317 1255 910 3625 2200 595 2365 1253 902 3596 2084 131 510 2026 3995 3678 2410 1435 1629 2406 1418 1564 2148 387 1535 2030 4010 3738 2650 2395 1374 1385 1432 1617 2359 1232 817 3254 715 2846 3180 419 1662 2537 1944 3667 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:label: 0 (id = 0)
INFO:transformers.data.processors.glue:*** Example ***
INFO:transformers.data.processors.glue:guid: train-9762
INFO:transformers.data.processors.glue:input_ids: 2 1122 379 1502 1898 3481 1621 2374 1290 1050 90 348 1378 1402 1498 1882 3418 1372 1378 1401 1494 1868 3362 1148 482 1913 3542 1868 3362 1146 473 1879 3407 1325 1191 653 2598 2186 538 2138 345 1366 1356 1314 1148 481 1910 3532 1828 3204 513 2037 4037 3846 3082 26 91 349 1382 1420 1570 2169 469 1862 3338 1049 86 332 1314 1148 483 1918 3562 1947 3677 2408 1428 1602 2299 990 3948 3491 1661 2533 1927 3599 2093 165 645 2568 2065 54 202 795 3165 358 1418 1561 2133 326 1291 1053 102 393 1560 2129 310 1228 801 3189 454 1802 3100 100 388 1537 2037 4040 3857 3128 212 833 3317 967 3854 3114 155 606 2409 1431 1615 2350 1193 663 2640 2353 1206 716 2852 3201 502 1994 3866 3164 356 1412 1538 2042 4057 3928 3411 1341 1254 908 3620 2180 515 2046 4073 3990 3657 2326 1099 285 1128 401 1589 2246 777 3095 77 294 1162 540 2147 381 1509 1927 3597 2085 133 520 2065 54 202 796 3172 386 1532 2019 3966 3562 1946 3674 2394 1372 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:label: 1 (id = 1)
INFO:transformers.data.processors.glue:*** Example ***
INFO:transformers.data.processors.glue:guid: train-9763
INFO:transformers.data.processors.glue:input_ids: 2 1119 365 1448 1684 2626 2299 991 3950 3499 1695 2670 2476 1700 2689 2549 1989 3846 3081 21 72 276 1089 246 971 3870 3178 410 1628 2402 1402 1498 1882 3417 1367 1358 1322 1180 612 2435 1536 2034 4028 3809 2936 3538 1850 3290 858 3419 1374 1388 1441 1655 2510 1834 3226 601 2390 1354 1307 1120 369 1464 1746 2876 3299 893 3557 1927 3598 2089 149 582 2314 1050 91 350 1388 1444 1665 2551 1999 3886 3243 671 2670 2476 1699 2686 2537 1941 3653 2311 1038 42 155 606 2410 1433 1622 2377 1304 1105 311 1230 812 3236 643 2559 2029 4008 3729 2613 2247 782 3113 149 581 2312 1044 65 248 980 3906 3321 981 3912 3346 1083 221 871 3470 1578 2203 605 2406 1420 1570 2171 478 1898 3483 1629 2407 1422 1580 2209 629 2501 1800 3089 53 198 778 3098 89 341 1350 1289 1046 75 285 1126 393 1558 2124 292 1155 510 2026 3993 3670 2378 1305 1111 334 1322 1178 603 2397 1384 1425 1590 2250 796 3170 379 1501 1896 3474 1596 2273 885 3526 1803 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:label: 0 (id = 0)
INFO:__main__:Saving features into cached file /data3/linming/DNABERT/examples/data/fold5_100_13944/0/after/cached_train_6-new-12w-0_300_dnaprom
INFO:__main__:***** Running training *****
INFO:__main__:  Num examples = 11154
INFO:__main__:  Num Epochs = 15
INFO:__main__:  Instantaneous batch size per GPU = 48
INFO:__main__:  Total train batch size (w. parallel, distributed & accumulation) = 48
INFO:__main__:  Gradient Accumulation steps = 1
INFO:__main__:  Total optimization steps = 3495
INFO:__main__:  Continuing training from checkpoint, will skip to saved global_step
INFO:__main__:  Continuing training from epoch 0
INFO:__main__:  Continuing training from global step 0
INFO:__main__:  Will skip the first 0 steps in the first epoch
INFO:__main__:Creating features from dataset file at /data3/linming/DNABERT/examples/data/fold5_100_13944/0/after/
INFO:transformers.data.processors.glue:Writing example 0/1395
INFO:transformers.data.processors.glue:*** Example ***
INFO:transformers.data.processors.glue:guid: dev-1
INFO:transformers.data.processors.glue:input_ids: 2 104 402 1593 2263 847 3373 1192 660 2626 2297 983 3919 3373 1189 646 2572 2081 117 453 1798 3081 23 78 300 1187 638 2537 1943 3662 2347 1182 619 2462 1641 2455 1613 2344 1169 566 2251 798 3178 410 1627 2397 1384 1426 1594 2266 860 3427 1405 1509 1925 3589 2055 15 47 174 682 2714 2651 2398 1387 1439 1645 2471 1678 2602 2201 597 2375 1293 1062 140 545 2168 465 1846 3275 798 3178 410 1628 2404 1412 1540 2050 4091 4062 3946 3483 1629 2408 1427 1597 2278 906 3609 2136 337 1335 1229 807 3214 554 2202 601 2389 1351 1294 1068 162 634 2522 1883 3422 1385 1432 1618 2362 1242 859 3422 1387 1438 1642 2459 1630 2410 1434 1626 2394 1371 1374 1386 1435 1630 2411 1438 1642 2460 1636 2433 1525 1992 3860 3139 254 1001 3992 3668 2369 1270 970 3868 3169 375 1485 1829 3205 518 2058 27 94 362 1434 1625 2389 1352 1298 1082 219 861 3431 1422 1580 2212 642 2553 2006 3914 3354 1116 353 1397 1479 1805 3111 142 554 2201 600 2386 1337 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:label: 0 (id = 0)
INFO:transformers.data.processors.glue:*** Example ***
INFO:transformers.data.processors.glue:guid: dev-2
INFO:transformers.data.processors.glue:input_ids: 2 2273 888 3539 1855 3310 939 3743 2670 2475 1694 2668 2468 1668 2563 2045 4070 3979 3614 2154 411 1630 2411 1439 1646 2475 1694 2666 2458 1628 2403 1405 1512 1937 3639 2256 819 3262 748 2979 3710 2540 1955 3710 2539 1949 3685 2440 1554 2107 223 878 3500 1700 2692 2564 2051 4094 4075 3997 3688 2452 1604 2308 1028 4100 4099 4094 4076 4004 3714 2556 2020 3972 3588 2050 4091 4063 3950 3499 1696 2676 2497 1784 3027 3902 3307 926 3691 2464 1652 2500 1795 3070 4075 3997 3688 2452 1602 2300 996 3972 3588 2052 4099 4093 4072 3988 3652 2308 1026 4092 4068 3972 3585 2040 4051 3901 3304 914 3644 2276 899 3581 2023 3984 3636 2244 772 3076 4099 4095 4078 4010 3738 2652 2404 1412 1540 2049 4087 4046 3883 3230 620 2465 1656 2514 1852 3300 898 3580 2020 3970 3580 2017 3958 3532 1828 3202 508 2020 3970 3580 2020 3970 3580 2019 3966 3563 1951 3694 2474 1691 2654 2410 1436 1636 2436 1540 2052 4100 4098 4092 4065 3960 3540 1857 3320 980 3907 3328 1011 4030 3820 2979 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:label: 0 (id = 0)
INFO:transformers.data.processors.glue:Writing example 0/1395
INFO:transformers.data.processors.glue:*** Example ***
INFO:transformers.data.processors.glue:guid: dev-3
INFO:transformers.data.processors.glue:input_ids: 2 3249 696 2769 2871 3277 808 3219 576 2292 963 3837 3048 3987 3648 2289 952 3795 2877 3304 916 3652 2306 1020 4068 3970 3580 2019 3968 3572 1987 3840 3059 4030 3820 2980 3716 2562 2042 4059 3936 3444 1476 1795 3072 4084 4035 3838 3051 3999 3695 2478 1708 2724 2692 2564 2051 4093 4071 3983 3631 2223 688 2740 2755 2814 3051 4000 3700 2500 1795 3070 4075 3997 3688 2452 1603 2302 1003 3999 3696 2484 1731 2816 3060 4036 3844 3076 4099 4096 4084 4034 3836 3044 3970 3580 2020 3971 3584 2036 4035 3840 3060 4035 3840 3060 4035 3837 3048 3986 3644 2276 899 3584 2036 4035 3840 3060 4035 3840 3060 4035 3840 3060 4035 3840 3060 4036 3844 3075 4095 4079 4015 3757 2728 2708 2628 2308 1028 4100 4099 4094 4076 4003 3709 2536 1939 3645 2279 912 3633 2232 721 2871 3280 819 3261 744 2964 3649 2296 979 3902 3308 932 3715 2559 2030 4011 3743 2669 2469 1672 2579 2112 244 964 3842 3068 4068 3969 3575 1997 3878 3211 543 2157 424 1681 2613 2247 781 3109 136 531 2112 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:label: 0 (id = 0)
INFO:transformers.data.processors.glue:*** Example ***
INFO:transformers.data.processors.glue:guid: dev-1396
INFO:transformers.data.processors.glue:input_ids: 2 3579 2015 3952 3507 1725 2790 2955 3615 2159 429 1704 2705 2614 2251 798 3180 419 1661 2536 1940 3652 2306 1020 4065 3960 3539 1855 3312 947 3776 2803 3008 3828 3012 3844 3073 4086 4043 3870 3178 412 1634 2425 1495 1870 3371 1184 628 2498 1787 3038 3947 3488 1650 2491 1759 2927 3501 1704 2708 2625 2296 977 3893 3271 781 3110 140 548 2177 503 1998 3883 3231 622 2474 1691 2654 2410 1436 1636 2433 1528 2001 3894 3276 801 3191 464 1841 3254 715 2846 3178 411 1630 2411 1439 1648 2483 1727 2800 2995 3775 2797 2984 3732 2626 2297 984 3922 3387 1248 881 3509 1736 2836 3140 260 1025 4085 4039 3853 3112 148 578 2297 984 3923 3392 1267 959 3821 2984 3730 2618 2268 865 3445 1480 1810 3130 220 867 3455 1519 1966 3755 2720 2675 2495 1773 2984 3730 2620 2273 888 3540 1860 3329 1016 4050 3900 3300 898 3577 2008 3922 3388 1252 897 3575 2000 3890 3259 734 2924 3490 1660 2530 1915 3551 1902 3500 1699 2686 2538 1948 3682 2427 1503 1902 3499 1695 2670 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:label: 1 (id = 1)
INFO:transformers.data.processors.glue:*** Example ***
INFO:transformers.data.processors.glue:guid: dev-4
INFO:transformers.data.processors.glue:input_ids: 2 3049 3991 3662 2346 1179 607 2414 1452 1699 2686 2540 1956 3714 2556 2020 3969 3573 1989 3848 3089 53 199 781 3109 135 525 2087 142 554 2204 609 2421 1477 1797 3078 11 30 108 417 1656 2515 1853 3304 915 3645 2279 911 3630 2219 670 2667 2461 1638 2444 1570 2172 481 1910 3532 1826 3195 479 1901 3496 1684 2625 2296 978 3898 3292 868 3460 1540 2052 4098 4092 4066 3964 3556 1921 3574 1996 3875 3198 490 1947 3679 2414 1450 1690 2650 2393 1365 1349 1287 1037 40 148 577 2296 977 3896 3283 830 3307 925 3688 2450 1596 2274 892 3556 1922 3579 2015 3951 3503 1712 2737 2744 2770 2875 3293 872 3476 1603 2302 1004 4004 3713 2552 2001 3893 3270 779 3102 108 420 1668 2563 2046 4076 4002 3708 2531 1918 3561 1943 3663 2352 1204 706 2810 3034 3932 3427 1405 1511 1934 3627 2207 621 2469 1670 2571 2078 107 414 1641 2454 1611 2333 1128 403 1598 2282 922 3673 2389 1349 1285 1032 18 58 219 862 3436 1443 1662 2538 1947 3679 2414 1451 1693 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:label: 0 (id = 0)
INFO:transformers.data.processors.glue:*** Example ***
INFO:transformers.data.processors.glue:guid: dev-1397
INFO:transformers.data.processors.glue:input_ids: 2 2399 1390 1451 1695 2671 2480 1715 2749 2792 2963 3646 2281 920 3666 2364 1252 897 3576 2001 3893 3272 787 3136 243 959 3822 2987 3743 2670 2473 1687 2639 2351 1198 682 2716 2657 2421 1480 1812 3137 248 977 3893 3269 775 3085 40 147 573 2278 908 3619 2176 497 1976 3796 2884 3331 1021 4072 3987 3647 2287 943 3758 2729 2712 2642 2363 1248 882 3516 1764 2947 3581 2023 3981 3624 2195 575 2287 944 3764 2754 2810 3036 3940 3457 1527 1998 3883 3229 613 2440 1554 2106 219 862 3433 1429 1608 2322 1082 218 860 3427 1405 1512 1939 3646 2284 932 3715 2559 2029 4005 3720 2580 2113 248 979 3901 3304 913 3640 2257 824 3281 824 3281 823 3280 818 3259 735 2927 3502 1708 2721 2679 2511 1839 3247 687 2733 2725 2695 2573 2085 136 532 2116 260 1026 4090 4060 3940 3459 1533 2022 3980 3620 2177 501 1989 3847 3087 46 172 675 2687 2543 1965 3751 2703 2607 2223 685 2728 2705 2615 2256 817 3255 718 2860 3235 639 2543 1968 3764 2756 2817 3063 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:label: 0 (id = 0)
INFO:transformers.data.processors.glue:*** Example ***
INFO:transformers.data.processors.glue:guid: dev-5
INFO:transformers.data.processors.glue:input_ids: 2 2552 2003 3902 3307 925 3686 2442 1561 2135 334 1322 1178 604 2403 1405 1511 1935 3630 2217 663 2639 2352 1204 705 2806 3019 3871 3181 421 1671 2574 2090 155 606 2410 1435 1631 2414 1451 1693 2662 2442 1561 2136 339 1341 1255 910 3626 2203 605 2405 1413 1544 2066 57 216 850 3388 1251 894 3562 1946 3674 2394 1369 1366 1356 1315 1149 488 1939 3645 2277 901 3590 2059 29 101 389 1542 2057 22 76 290 1145 470 1868 3362 1147 477 1894 3467 1566 2155 416 1650 2489 1751 2895 3374 1194 667 2655 2413 1445 1670 2572 2083 127 493 1960 3730 2620 2273 888 3540 1857 3320 979 3903 3312 946 3769 2775 2895 3374 1196 674 2684 2529 1909 3528 1810 3132 228 900 3585 2040 4052 3905 3319 973 3880 3219 574 2283 928 3699 2493 1766 2955 3613 2152 403 1597 2278 907 3613 2151 399 1582 2220 676 2689 2552 2002 3899 3294 876 3492 1665 2552 2002 3898 3291 862 3435 1438 1644 2465 1656 2515 1855 3309 936 3729 2615 2253 805 3207 526 2089 151 591 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:label: 0 (id = 0)
INFO:transformers.data.processors.glue:*** Example ***
INFO:transformers.data.processors.glue:guid: dev-1398
INFO:transformers.data.processors.glue:input_ids: 2 915 3648 2289 951 3789 2856 3219 573 2280 914 3644 2273 886 3529 1816 3155 317 1256 914 3644 2273 887 3533 1832 3219 573 2280 915 3645 2277 903 3597 2088 147 573 2280 914 3644 2273 887 3533 1832 3219 573 2280 914 3644 2273 887 3533 1832 3219 573 2280 914 3644 2273 885 3525 1800 3091 61 232 915 3648 2289 951 3789 2856 3219 573 2280 914 3644 2273 887 3533 1832 3219 573 2280 915 3648 2289 951 3789 2856 3219 573 2280 914 3644 2273 887 3533 1832 3219 573 2280 915 3648 2289 951 3789 2856 3219 573 2280 915 3648 2289 951 3789 2856 3219 573 2280 915 3648 2289 950 3785 2840 3155 317 1256 914 3644 2273 887 3533 1832 3219 573 2280 915 3645 2277 902 3593 2072 83 317 1256 914 3644 2273 886 3529 1816 3155 317 1256 915 3648 2289 951 3789 2856 3219 573 2280 914 3644 2273 886 3529 1816 3155 317 1256 914 3644 2273 887 3533 1832 3219 573 2280 915 3648 2289 951 3789 2856 3219 573 2280 915 3648 2289 950 3785 2840 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:label: 0 (id = 0)
INFO:transformers.data.processors.glue:*** Example ***
INFO:transformers.data.processors.glue:guid: dev-1399
INFO:transformers.data.processors.glue:input_ids: 2 773 3077 5 5 5 5 5 6 11 30 108 418 1657 2519 1870 3370 1178 602 2394 1369 1365 1352 1300 1092 258 1018 4060 3938 3452 1508 1924 3585 2039 4047 3886 3244 674 2682 2521 1877 3398 1290 1049 86 329 1302 1098 284 1121 373 1477 1798 3084 35 126 490 1946 3675 2398 1386 1434 1626 2395 1374 1385 1432 1620 2370 1275 989 3942 3467 1567 2157 422 1676 2595 2175 494 1964 3748 2691 2558 2026 3993 3670 2378 1305 1110 329 1302 1099 285 1126 395 1566 2154 409 1622 2379 1310 1129 406 1610 2332 1122 378 1500 1891 3454 1516 1954 3706 2523 1886 3434 1434 1626 2394 1370 1370 1371 1373 1382 1418 1563 2141 358 1418 1562 2137 343 1358 1322 1180 612 2436 1540 2050 4089 4053 3912 3346 1082 220 866 3452 1505 1909 3525 1798 3082 26 90 346 1372 1380 1410 1531 2014 3948 3490 1659 2526 1898 3482 1627 2397 1384 1425 1589 2246 778 3097 85 327 1294 1065 151 591 2350 1194 666 2652 2402 1404 1507 1918 3564 1954 3708 2530 1913 3544 1875 3390 1257 918 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:label: 1 (id = 1)
INFO:transformers.data.processors.glue:*** Example ***
INFO:transformers.data.processors.glue:guid: dev-1400
INFO:transformers.data.processors.glue:input_ids: 2 1876 3396 1283 1022 4074 3995 3677 2408 1426 1594 2268 867 3454 1516 1955 3711 2544 1971 3773 2789 2952 3603 2111 239 942 3755 2719 2669 2469 1669 2566 2058 27 95 365 1448 1683 2623 2287 941 3751 2703 2605 2216 659 2622 2283 928 3698 2492 1763 2944 3571 1983 3822 2987 3742 2668 2467 1663 2541 1958 3724 2594 2169 472 1876 3396 1283 1022 4076 4004 3713 2552 2004 3907 3328 1009 4024 3795 2879 3310 938 3739 2653 2407 1423 1582 2219 671 2670 2475 1695 2669 2469 1671 2574 2091 159 622 2476 1699 2685 2536 1939 3646 2284 931 3711 2544 1971 3775 2800 2995 3773 2790 2956 3619 2175 495 1965 3751 2703 2608 2228 708 2818 3067 4063 3950 3500 1698 2684 2532 1924 3585 2040 4051 3903 3312 945 3768 2772 2881 3320 979 3903 3310 939 3744 2675 2494 1771 2975 3695 2477 1703 2702 2603 2205 616 2449 1592 2260 835 3327 1006 4011 3741 2664 2451 1598 2282 922 3674 2395 1375 1389 1448 1684 2625 2293 967 3854 3114 156 610 2426 1499 1885 3430 1417 1558 2122 284 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
INFO:transformers.data.processors.glue:label: 1 (id = 1)
INFO:__main__:Saving features into cached file /data3/linming/DNABERT/examples/data/fold5_100_13944/0/after/cached_dev_6-new-12w-0_300_dnaprom
INFO:__main__:***** Running evaluation  *****
INFO:__main__:  Num examples = 2790
INFO:__main__:  Batch size = 48
INFO:__main__:***** Eval results  *****
INFO:__main__:  acc = 0.6745519713261648
INFO:__main__:  auc = 0.7244411135498426
INFO:__main__:  f1 = 0.6684663802201116
INFO:__main__:  mcc = 0.3764625486314831
INFO:__main__:  precision = 0.6973858290519876
INFO:__main__:  recall = 0.679501298551661
INFO:__main__:{"eval_acc": 0.6745519713261648, "eval_f1": 0.6684663802201116, "eval_mcc": 0.3764625486314831, "eval_auc": 0.7244411135498426, "eval_precision": 0.6973858290519876, "eval_recall": 0.679501298551661, "learning_rate": 2.8653295128939826e-05, "loss": 0.6570072835683822, "step": 100}
INFO:__main__:Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_13944/0/after/cached_dev_6-new-12w-0_300_dnaprom
INFO:__main__:***** Running evaluation  *****
INFO:__main__:  Num examples = 2790
INFO:__main__:  Batch size = 48
INFO:__main__:***** Eval results  *****
INFO:__main__:  acc = 0.6695340501792114
INFO:__main__:  auc = 0.7247096197756379
INFO:__main__:  f1 = 0.656573483485921
INFO:__main__:  mcc = 0.3884259837014003
INFO:__main__:  precision = 0.713904465724756
INFO:__main__:  recall = 0.6763342624746089
INFO:__main__:{"eval_acc": 0.6695340501792114, "eval_f1": 0.656573483485921, "eval_mcc": 0.3884259837014003, "eval_auc": 0.7247096197756379, "eval_precision": 0.713904465724756, "eval_recall": 0.6763342624746089, "learning_rate": 5.730659025787965e-05, "loss": 0.6085408428311347, "step": 200}
INFO:__main__:Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_13944/0/after/cached_dev_6-new-12w-0_300_dnaprom
INFO:__main__:***** Running evaluation  *****
INFO:__main__:  Num examples = 2790
INFO:__main__:  Batch size = 48
INFO:__main__:***** Eval results  *****
INFO:__main__:  acc = 0.6867383512544802
INFO:__main__:  auc = 0.7342873705884864
INFO:__main__:  f1 = 0.6807536249492026
INFO:__main__:  mcc = 0.4025273868676482
INFO:__main__:  precision = 0.7112548305544363
INFO:__main__:  recall = 0.6917450795719744
INFO:__main__:{"eval_acc": 0.6867383512544802, "eval_f1": 0.6807536249492026, "eval_mcc": 0.4025273868676482, "eval_auc": 0.7342873705884864, "eval_precision": 0.7112548305544363, "eval_recall": 0.6917450795719744, "learning_rate": 8.595988538681948e-05, "loss": 0.5892354959249496, "step": 300}
INFO:__main__:Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_13944/0/after/cached_dev_6-new-12w-0_300_dnaprom
INFO:__main__:***** Running evaluation  *****
INFO:__main__:  Num examples = 2790
INFO:__main__:  Batch size = 48
INFO:__main__:***** Eval results  *****
INFO:__main__:  acc = 0.656989247311828
INFO:__main__:  auc = 0.7519671167317956
INFO:__main__:  f1 = 0.6324428961026858
INFO:__main__:  mcc = 0.39635308131139535
INFO:__main__:  precision = 0.7368716931216931
INFO:__main__:  recall = 0.6658025944285473
INFO:__main__:{"eval_acc": 0.656989247311828, "eval_f1": 0.6324428961026858, "eval_mcc": 0.39635308131139535, "eval_auc": 0.7519671167317956, "eval_precision": 0.7368716931216931, "eval_recall": 0.6658025944285473, "learning_rate": 9.837889383343928e-05, "loss": 0.5951860538125038, "step": 400}
INFO:__main__:Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_13944/0/after/cached_dev_6-new-12w-0_300_dnaprom
INFO:__main__:***** Running evaluation  *****
INFO:__main__:  Num examples = 2790
INFO:__main__:  Batch size = 48
INFO:__main__:***** Eval results  *****
INFO:__main__:  acc = 0.6867383512544802
INFO:__main__:  auc = 0.7625365916889607
INFO:__main__:  f1 = 0.6775888512798816
INFO:__main__:  mcc = 0.41444897852012275
INFO:__main__:  precision = 0.7227964317418715
INFO:__main__:  recall = 0.6927409187542339
INFO:__main__:{"eval_acc": 0.6867383512544802, "eval_f1": 0.6775888512798816, "eval_mcc": 0.41444897852012275, "eval_auc": 0.7625365916889607, "eval_precision": 0.7227964317418715, "eval_recall": 0.6927409187542339, "learning_rate": 9.520025429116339e-05, "loss": 0.5756206631660461, "step": 500}
INFO:__main__:Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_13944/0/after/cached_dev_6-new-12w-0_300_dnaprom
INFO:__main__:***** Running evaluation  *****
INFO:__main__:  Num examples = 2790
INFO:__main__:  Batch size = 48
INFO:__main__:***** Eval results  *****
INFO:__main__:  acc = 0.6229390681003584
INFO:__main__:  auc = 0.739043325691365
INFO:__main__:  f1 = 0.5966721065207341
INFO:__main__:  mcc = 0.2630034193650604
INFO:__main__:  precision = 0.6497175291922062
INFO:__main__:  recall = 0.6155021709397049
INFO:__main__:{"eval_acc": 0.6229390681003584, "eval_f1": 0.5966721065207341, "eval_mcc": 0.2630034193650604, "eval_auc": 0.739043325691365, "eval_precision": 0.6497175291922062, "eval_recall": 0.6155021709397049, "learning_rate": 9.202161474888749e-05, "loss": 0.5504018452763557, "step": 600}
INFO:__main__:Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_13944/0/after/cached_dev_6-new-12w-0_300_dnaprom
INFO:__main__:***** Running evaluation  *****
INFO:__main__:  Num examples = 2790
INFO:__main__:  Batch size = 48
INFO:__main__:***** Eval results  *****
INFO:__main__:  acc = 0.7
INFO:__main__:  auc = 0.7584873943528305
INFO:__main__:  f1 = 0.6997080060505128
INFO:__main__:  mcc = 0.4049520142550775
INFO:__main__:  precision = 0.7032735330225459
INFO:__main__:  recall = 0.7016816102554975
INFO:__main__:{"eval_acc": 0.7, "eval_f1": 0.6997080060505128, "eval_mcc": 0.4049520142550775, "eval_auc": 0.7584873943528305, "eval_precision": 0.7032735330225459, "eval_recall": 0.7016816102554975, "learning_rate": 8.884297520661158e-05, "loss": 0.5390756511688233, "step": 700}
INFO:__main__:Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_13944/0/after/cached_dev_6-new-12w-0_300_dnaprom
INFO:__main__:***** Running evaluation  *****
INFO:__main__:  Num examples = 2790
INFO:__main__:  Batch size = 48
INFO:__main__:***** Eval results  *****
INFO:__main__:  acc = 0.7017921146953405
INFO:__main__:  auc = 0.7675363627899752
INFO:__main__:  f1 = 0.698758062213686
INFO:__main__:  mcc = 0.42267280731643164
INFO:__main__:  precision = 0.7171699395290403
INFO:__main__:  recall = 0.7056595659972358
INFO:__main__:{"eval_acc": 0.7017921146953405, "eval_f1": 0.698758062213686, "eval_mcc": 0.42267280731643164, "eval_auc": 0.7675363627899752, "eval_precision": 0.7171699395290403, "eval_recall": 0.7056595659972358, "learning_rate": 8.566433566433567e-05, "loss": 0.4586741730570793, "step": 800}
INFO:__main__:Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_13944/0/after/cached_dev_6-new-12w-0_300_dnaprom
INFO:__main__:***** Running evaluation  *****
INFO:__main__:  Num examples = 2790
INFO:__main__:  Batch size = 48
INFO:__main__:***** Eval results  *****
INFO:__main__:  acc = 0.7125448028673835
INFO:__main__:  auc = 0.7806813371198542
INFO:__main__:  f1 = 0.7125115633672525
INFO:__main__:  mcc = 0.4256393491178384
INFO:__main__:  precision = 0.7127244994292921
INFO:__main__:  recall = 0.7129148922708786
INFO:__main__:{"eval_acc": 0.7125448028673835, "eval_f1": 0.7125115633672525, "eval_mcc": 0.4256393491178384, "eval_auc": 0.7806813371198542, "eval_precision": 0.7127244994292921, "eval_recall": 0.7129148922708786, "learning_rate": 8.248569612205977e-05, "loss": 0.43938493728637695, "step": 900}
INFO:__main__:Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_13944/0/after/cached_dev_6-new-12w-0_300_dnaprom
INFO:__main__:***** Running evaluation  *****
INFO:__main__:  Num examples = 2790
INFO:__main__:  Batch size = 48
INFO:__main__:***** Eval results  *****
INFO:__main__:  acc = 0.7121863799283155
INFO:__main__:  auc = 0.771694094251858
INFO:__main__:  f1 = 0.7120487318162778
INFO:__main__:  mcc = 0.42817387258918366
INFO:__main__:  precision = 0.7145891472868218
INFO:__main__:  recall = 0.7135859006454951
INFO:__main__:{"eval_acc": 0.7121863799283155, "eval_f1": 0.7120487318162778, "eval_mcc": 0.42817387258918366, "eval_auc": 0.771694094251858, "eval_precision": 0.7145891472868218, "eval_recall": 0.7135859006454951, "learning_rate": 7.930705657978386e-05, "loss": 0.3601484943181276, "step": 1000}
INFO:__main__:Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_13944/0/after/cached_dev_6-new-12w-0_300_dnaprom
INFO:__main__:***** Running evaluation  *****
INFO:__main__:  Num examples = 2790
INFO:__main__:  Batch size = 48
INFO:__main__:***** Eval results  *****
INFO:__main__:  acc = 0.714336917562724
INFO:__main__:  auc = 0.7803891694258852
INFO:__main__:  f1 = 0.7139912055668836
INFO:__main__:  mcc = 0.42799729940297815
INFO:__main__:  precision = 0.7140467143127681
INFO:__main__:  recall = 0.7139505958832131
INFO:__main__:{"eval_acc": 0.714336917562724, "eval_f1": 0.7139912055668836, "eval_mcc": 0.42799729940297815, "eval_auc": 0.7803891694258852, "eval_precision": 0.7140467143127681, "eval_recall": 0.7139505958832131, "learning_rate": 7.612841703750795e-05, "loss": 0.31316260814666746, "step": 1100}
INFO:__main__:Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_13944/0/after/cached_dev_6-new-12w-0_300_dnaprom
INFO:__main__:***** Running evaluation  *****
INFO:__main__:  Num examples = 2790
INFO:__main__:  Batch size = 48
INFO:__main__:***** Eval results  *****
INFO:__main__:  acc = 0.714336917562724
INFO:__main__:  auc = 0.7856301846263212
INFO:__main__:  f1 = 0.7139620671686112
INFO:__main__:  mcc = 0.4345210104159989
INFO:__main__:  precision = 0.7183350649350649
INFO:__main__:  recall = 0.7161912340432974
INFO:__main__:{"eval_acc": 0.714336917562724, "eval_f1": 0.7139620671686112, "eval_mcc": 0.4345210104159989, "eval_auc": 0.7856301846263212, "eval_precision": 0.7183350649350649, "eval_recall": 0.7161912340432974, "learning_rate": 7.294977749523204e-05, "loss": 0.2868866170197725, "step": 1200}
INFO:__main__:Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_13944/0/after/cached_dev_6-new-12w-0_300_dnaprom
INFO:__main__:***** Running evaluation  *****
INFO:__main__:  Num examples = 2790
INFO:__main__:  Batch size = 48
INFO:__main__:***** Eval results  *****
INFO:__main__:  acc = 0.6867383512544802
INFO:__main__:  auc = 0.768832085362347
INFO:__main__:  f1 = 0.6793324429627143
INFO:__main__:  mcc = 0.37941452356056693
INFO:__main__:  precision = 0.6970651495177964
INFO:__main__:  recall = 0.6826240979708234
INFO:__main__:{"eval_acc": 0.6867383512544802, "eval_f1": 0.6793324429627143, "eval_mcc": 0.37941452356056693, "eval_auc": 0.768832085362347, "eval_precision": 0.6970651495177964, "eval_recall": 0.6826240979708234, "learning_rate": 6.977113795295614e-05, "loss": 0.21712356694042684, "step": 1300}
INFO:__main__:Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_13944/0/after/cached_dev_6-new-12w-0_300_dnaprom
INFO:__main__:***** Running evaluation  *****
INFO:__main__:  Num examples = 2790
INFO:__main__:  Batch size = 48
INFO:__main__:***** Eval results  *****
INFO:__main__:  acc = 0.7118279569892473
INFO:__main__:  auc = 0.7835996705912125
INFO:__main__:  f1 = 0.709532908363975
INFO:__main__:  mcc = 0.44022438094016175
INFO:__main__:  precision = 0.7249867124257225
INFO:__main__:  recall = 0.7153432790371224
INFO:__main__:{"eval_acc": 0.7118279569892473, "eval_f1": 0.709532908363975, "eval_mcc": 0.44022438094016175, "eval_auc": 0.7835996705912125, "eval_precision": 0.7249867124257225, "eval_recall": 0.7153432790371224, "learning_rate": 6.659249841068024e-05, "loss": 0.23010051488876343, "step": 1400}
INFO:__main__:Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_13944/0/after/cached_dev_6-new-12w-0_300_dnaprom
INFO:__main__:***** Running evaluation  *****
INFO:__main__:  Num examples = 2790
INFO:__main__:  Batch size = 48
INFO:__main__:***** Eval results  *****
INFO:__main__:  acc = 0.7053763440860215
INFO:__main__:  auc = 0.7866761758335138
INFO:__main__:  f1 = 0.701976376217367
INFO:__main__:  mcc = 0.4318734768426764
INFO:__main__:  precision = 0.7226232476664256
INFO:__main__:  recall = 0.7094510590821717
INFO:__main__:{"eval_acc": 0.7053763440860215, "eval_f1": 0.701976376217367, "eval_mcc": 0.4318734768426764, "eval_auc": 0.7866761758335138, "eval_precision": 0.7226232476664256, "eval_recall": 0.7094510590821717, "learning_rate": 6.341385886840433e-05, "loss": 0.1530994220636785, "step": 1500}
INFO:__main__:Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_13944/0/after/cached_dev_6-new-12w-0_300_dnaprom
INFO:__main__:***** Running evaluation  *****
INFO:__main__:  Num examples = 2790
INFO:__main__:  Batch size = 48
INFO:__main__:***** Eval results  *****
INFO:__main__:  acc = 0.7057347670250896
INFO:__main__:  auc = 0.7657535226010743
INFO:__main__:  f1 = 0.7056935933920689
INFO:__main__:  mcc = 0.4119360046208792
INFO:__main__:  precision = 0.7058719237948018
INFO:__main__:  recall = 0.7060641256650287
INFO:__main__:{"eval_acc": 0.7057347670250896, "eval_f1": 0.7056935933920689, "eval_mcc": 0.4119360046208792, "eval_auc": 0.7657535226010743, "eval_precision": 0.7058719237948018, "eval_recall": 0.7060641256650287, "learning_rate": 6.023521932612842e-05, "loss": 0.1573674076795578, "step": 1600}
INFO:__main__:Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_13944/0/after/cached_dev_6-new-12w-0_300_dnaprom
INFO:__main__:***** Running evaluation  *****
INFO:__main__:  Num examples = 2790
INFO:__main__:  Batch size = 48
INFO:__main__:***** Eval results  *****
INFO:__main__:  acc = 0.7078853046594982
INFO:__main__:  auc = 0.7589400485265849
INFO:__main__:  f1 = 0.7061402516840865
INFO:__main__:  mcc = 0.41524082598234463
INFO:__main__:  precision = 0.7090939824205544
INFO:__main__:  recall = 0.7061572283984942
INFO:__main__:{"eval_acc": 0.7078853046594982, "eval_f1": 0.7061402516840865, "eval_mcc": 0.41524082598234463, "eval_auc": 0.7589400485265849, "eval_precision": 0.7090939824205544, "eval_recall": 0.7061572283984942, "learning_rate": 5.705657978385252e-05, "loss": 0.11597006631083787, "step": 1700}
INFO:__main__:Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_13944/0/after/cached_dev_6-new-12w-0_300_dnaprom
INFO:__main__:***** Running evaluation  *****
INFO:__main__:  Num examples = 2790
INFO:__main__:  Batch size = 48
INFO:__main__:***** Eval results  *****
INFO:__main__:  acc = 0.7136200716845879
INFO:__main__:  auc = 0.7694498554335731
INFO:__main__:  f1 = 0.7132442806370394
INFO:__main__:  mcc = 0.43307879290322737
INFO:__main__:  precision = 0.7176103896103896
INFO:__main__:  recall = 0.7154736743019481
INFO:__main__:{"eval_acc": 0.7136200716845879, "eval_f1": 0.7132442806370394, "eval_mcc": 0.43307879290322737, "eval_auc": 0.7694498554335731, "eval_precision": 0.7176103896103896, "eval_recall": 0.7154736743019481, "learning_rate": 5.3877940241576606e-05, "loss": 0.10336436172015966, "step": 1800}
INFO:__main__:Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_13944/0/after/cached_dev_6-new-12w-0_300_dnaprom
INFO:__main__:***** Running evaluation  *****
INFO:__main__:  Num examples = 2790
INFO:__main__:  Batch size = 48
INFO:__main__:***** Eval results  *****
INFO:__main__:  acc = 0.7103942652329749
INFO:__main__:  auc = 0.7652432578961147
INFO:__main__:  f1 = 0.7103869729123072
INFO:__main__:  mcc = 0.42267552862375896
INFO:__main__:  precision = 0.7114154245130777
INFO:__main__:  recall = 0.7112601326379605
INFO:__main__:{"eval_acc": 0.7103942652329749, "eval_f1": 0.7103869729123072, "eval_mcc": 0.42267552862375896, "eval_auc": 0.7652432578961147, "eval_precision": 0.7114154245130777, "eval_recall": 0.7112601326379605, "learning_rate": 5.06993006993007e-05, "loss": 0.10198059297399595, "step": 1900}
INFO:__main__:Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_13944/0/after/cached_dev_6-new-12w-0_300_dnaprom
INFO:__main__:***** Running evaluation  *****
INFO:__main__:  Num examples = 2790
INFO:__main__:  Batch size = 48
INFO:__main__:***** Eval results  *****
INFO:__main__:  acc = 0.7121863799283155
INFO:__main__:  auc = 0.7775366765616183
INFO:__main__:  f1 = 0.7120824809147994
INFO:__main__:  mcc = 0.4278137808090069
INFO:__main__:  precision = 0.7143192042201448
INFO:__main__:  recall = 0.7134953698107442
INFO:__main__:{"eval_acc": 0.7121863799283155, "eval_f1": 0.7120824809147994, "eval_mcc": 0.4278137808090069, "eval_auc": 0.7775366765616183, "eval_precision": 0.7143192042201448, "eval_recall": 0.7134953698107442, "learning_rate": 4.75206611570248e-05, "loss": 0.0925803121831268, "step": 2000}
INFO:__main__:Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_13944/0/after/cached_dev_6-new-12w-0_300_dnaprom
INFO:__main__:***** Running evaluation  *****
INFO:__main__:  Num examples = 2790
INFO:__main__:  Batch size = 48
INFO:__main__:***** Eval results  *****
INFO:__main__:  acc = 0.7114695340501792
INFO:__main__:  auc = 0.7731065810258687
INFO:__main__:  f1 = 0.7103558845942397
INFO:__main__:  mcc = 0.4220398025879982
INFO:__main__:  precision = 0.7118225298851861
INFO:__main__:  recall = 0.7102203139876826
INFO:__main__:{"eval_acc": 0.7114695340501792, "eval_f1": 0.7103558845942397, "eval_mcc": 0.4220398025879982, "eval_auc": 0.7731065810258687, "eval_precision": 0.7118225298851861, "eval_recall": 0.7102203139876826, "learning_rate": 4.4342021614748894e-05, "loss": 0.08015543885529042, "step": 2100}
INFO:__main__:Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_13944/0/after/cached_dev_6-new-12w-0_300_dnaprom
INFO:__main__:***** Running evaluation  *****
INFO:__main__:  Num examples = 2790
INFO:__main__:  Batch size = 48
INFO:__main__:***** Eval results  *****
INFO:__main__:  acc = 0.7154121863799283
INFO:__main__:  auc = 0.780050450365184
INFO:__main__:  f1 = 0.7151895804791351
INFO:__main__:  mcc = 0.4354671644379371
INFO:__main__:  precision = 0.7184622976779014
INFO:__main__:  recall = 0.7170072975054126
INFO:__main__:{"eval_acc": 0.7154121863799283, "eval_f1": 0.7151895804791351, "eval_mcc": 0.4354671644379371, "eval_auc": 0.780050450365184, "eval_precision": 0.7184622976779014, "eval_recall": 0.7170072975054126, "learning_rate": 4.116338207247298e-05, "loss": 0.0671506562049035, "step": 2200}
INFO:__main__:Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_13944/0/after/cached_dev_6-new-12w-0_300_dnaprom
INFO:__main__:***** Running evaluation  *****
INFO:__main__:  Num examples = 2790
INFO:__main__:  Batch size = 48
INFO:__main__:***** Eval results  *****
INFO:__main__:  acc = 0.7118279569892473
INFO:__main__:  auc = 0.7620499884521748
INFO:__main__:  f1 = 0.7091442266848333
INFO:__main__:  mcc = 0.4243054379729656
INFO:__main__:  precision = 0.7148348840018377
INFO:__main__:  recall = 0.7095040401956907
INFO:__main__:{"eval_acc": 0.7118279569892473, "eval_f1": 0.7091442266848333, "eval_mcc": 0.4243054379729656, "eval_auc": 0.7620499884521748, "eval_precision": 0.7148348840018377, "eval_recall": 0.7095040401956907, "learning_rate": 3.798474253019708e-05, "loss": 0.08091610293835401, "step": 2300}
INFO:__main__:Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_13944/0/after/cached_dev_6-new-12w-0_300_dnaprom
INFO:__main__:***** Running evaluation  *****
INFO:__main__:  Num examples = 2790
INFO:__main__:  Batch size = 48
INFO:__main__:***** Eval results  *****
INFO:__main__:  acc = 0.7164874551971326
INFO:__main__:  auc = 0.7614000696470172
INFO:__main__:  f1 = 0.7164200949057027
INFO:__main__:  mcc = 0.4360072534043274
INFO:__main__:  precision = 0.7183201475813741
INFO:__main__:  recall = 0.7176875647154014
INFO:__main__:{"eval_acc": 0.7164874551971326, "eval_f1": 0.7164200949057027, "eval_mcc": 0.4360072534043274, "eval_auc": 0.7614000696470172, "eval_precision": 0.7183201475813741, "eval_recall": 0.7176875647154014, "learning_rate": 3.480610298792117e-05, "loss": 0.06551154937478713, "step": 2400}
INFO:__main__:Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_13944/0/after/cached_dev_6-new-12w-0_300_dnaprom
INFO:__main__:***** Running evaluation  *****
INFO:__main__:  Num examples = 2790
INFO:__main__:  Batch size = 48
INFO:__main__:***** Eval results  *****
INFO:__main__:  acc = 0.7172043010752688
INFO:__main__:  auc = 0.7763795793299587
INFO:__main__:  f1 = 0.7171737443145603
INFO:__main__:  mcc = 0.434989318123463
INFO:__main__:  precision = 0.7173990132593278
INFO:__main__:  recall = 0.7175903469439928
INFO:__main__:{"eval_acc": 0.7172043010752688, "eval_f1": 0.7171737443145603, "eval_mcc": 0.434989318123463, "eval_auc": 0.7763795793299587, "eval_precision": 0.7173990132593278, "eval_recall": 0.7175903469439928, "learning_rate": 3.1627463445645264e-05, "loss": 0.03629687737557106, "step": 2500}
INFO:__main__:Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_13944/0/after/cached_dev_6-new-12w-0_300_dnaprom
INFO:__main__:***** Running evaluation  *****
INFO:__main__:  Num examples = 2790
INFO:__main__:  Batch size = 48
INFO:__main__:***** Eval results  *****
INFO:__main__:  acc = 0.7218637992831541
INFO:__main__:  auc = 0.7760984708004623
INFO:__main__:  f1 = 0.7218396428101566
INFO:__main__:  mcc = 0.44439266604020805
INFO:__main__:  precision = 0.7221042698749705
INFO:__main__:  recall = 0.7222884343257947
INFO:__main__:{"eval_acc": 0.7218637992831541, "eval_f1": 0.7218396428101566, "eval_mcc": 0.44439266604020805, "eval_auc": 0.7760984708004623, "eval_precision": 0.7221042698749705, "eval_recall": 0.7222884343257947, "learning_rate": 2.844882390336936e-05, "loss": 0.045752248162752945, "step": 2600}
INFO:__main__:Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_13944/0/after/cached_dev_6-new-12w-0_300_dnaprom
INFO:__main__:***** Running evaluation  *****
INFO:__main__:  Num examples = 2790
INFO:__main__:  Batch size = 48
INFO:__main__:***** Eval results  *****
INFO:__main__:  acc = 0.7293906810035843
INFO:__main__:  auc = 0.7768353197821705
INFO:__main__:  f1 = 0.7293722894028976
INFO:__main__:  mcc = 0.4595368639024571
INFO:__main__:  precision = 0.7296801371721807
INFO:__main__:  recall = 0.7298567606729939
INFO:__main__:{"eval_acc": 0.7293906810035843, "eval_f1": 0.7293722894028976, "eval_mcc": 0.4595368639024571, "eval_auc": 0.7768353197821705, "eval_precision": 0.7296801371721807, "eval_recall": 0.7298567606729939, "learning_rate": 2.5270184361093453e-05, "loss": 0.04429211599053815, "step": 2700}
INFO:__main__:Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_13944/0/after/cached_dev_6-new-12w-0_300_dnaprom
INFO:__main__:***** Running evaluation  *****
INFO:__main__:  Num examples = 2790
INFO:__main__:  Batch size = 48
INFO:__main__:***** Eval results  *****
INFO:__main__:  acc = 0.7207885304659498
INFO:__main__:  auc = 0.7796633796086495
INFO:__main__:  f1 = 0.7205529924054384
INFO:__main__:  mcc = 0.44642036550885933
INFO:__main__:  precision = 0.7240002072109407
INFO:__main__:  recall = 0.7224229446285638
INFO:__main__:{"eval_acc": 0.7207885304659498, "eval_f1": 0.7205529924054384, "eval_mcc": 0.44642036550885933, "eval_auc": 0.7796633796086495, "eval_precision": 0.7240002072109407, "eval_recall": 0.7224229446285638, "learning_rate": 2.209154481881755e-05, "loss": 0.036033070481207685, "step": 2800}
INFO:__main__:Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_13944/0/after/cached_dev_6-new-12w-0_300_dnaprom
INFO:__main__:***** Running evaluation  *****
INFO:__main__:  Num examples = 2790
INFO:__main__:  Batch size = 48
INFO:__main__:***** Eval results  *****
INFO:__main__:  acc = 0.7211469534050179
INFO:__main__:  auc = 0.7797927461139896
INFO:__main__:  f1 = 0.721143371017472
INFO:__main__:  mcc = 0.44406846650400295
INFO:__main__:  precision = 0.7220902172755106
INFO:__main__:  recall = 0.7219782633408245
INFO:__main__:{"eval_acc": 0.7211469534050179, "eval_f1": 0.721143371017472, "eval_mcc": 0.44406846650400295, "eval_auc": 0.7797927461139896, "eval_precision": 0.7220902172755106, "eval_recall": 0.7219782633408245, "learning_rate": 1.891290527654164e-05, "loss": 0.02780245529545937, "step": 2900}
INFO:__main__:Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_13944/0/after/cached_dev_6-new-12w-0_300_dnaprom
INFO:__main__:***** Running evaluation  *****
INFO:__main__:  Num examples = 2790
INFO:__main__:  Batch size = 48
INFO:__main__:***** Eval results  *****
INFO:__main__:  acc = 0.7207885304659498
INFO:__main__:  auc = 0.7740738721323972
INFO:__main__:  f1 = 0.7206274195457845
INFO:__main__:  mcc = 0.4413365724908094
INFO:__main__:  precision = 0.7205884771801124
INFO:__main__:  recall = 0.7207481241856726
INFO:__main__:{"eval_acc": 0.7207885304659498, "eval_f1": 0.7206274195457845, "eval_mcc": 0.4413365724908094, "eval_auc": 0.7740738721323972, "eval_precision": 0.7205884771801124, "eval_recall": 0.7207481241856726, "learning_rate": 1.5734265734265734e-05, "loss": 0.027621386001992505, "step": 3000}
INFO:__main__:Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_13944/0/after/cached_dev_6-new-12w-0_300_dnaprom
INFO:__main__:***** Running evaluation  *****
INFO:__main__:  Num examples = 2790
INFO:__main__:  Batch size = 48
INFO:__main__:***** Eval results  *****
INFO:__main__:  acc = 0.7243727598566309
INFO:__main__:  auc = 0.7835181414019625
INFO:__main__:  f1 = 0.7243647926000867
INFO:__main__:  mcc = 0.45070685562636714
INFO:__main__:  precision = 0.7254430272879275
INFO:__main__:  recall = 0.7252638639486155
INFO:__main__:{"eval_acc": 0.7243727598566309, "eval_f1": 0.7243647926000867, "eval_mcc": 0.45070685562636714, "eval_auc": 0.7835181414019625, "eval_precision": 0.7254430272879275, "eval_recall": 0.7252638639486155, "learning_rate": 1.2555626191989828e-05, "loss": 0.03385697258723667, "step": 3100}
INFO:__main__:Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_13944/0/after/cached_dev_6-new-12w-0_300_dnaprom
INFO:__main__:***** Running evaluation  *****
INFO:__main__:  Num examples = 2790
INFO:__main__:  Batch size = 48
INFO:__main__:***** Eval results  *****
INFO:__main__:  acc = 0.7222222222222222
INFO:__main__:  auc = 0.7802333123637859
INFO:__main__:  f1 = 0.7221733604823293
INFO:__main__:  mcc = 0.44482963744495324
INFO:__main__:  precision = 0.7223069554814654
INFO:__main__:  recall = 0.7225227342986869
INFO:__main__:{"eval_acc": 0.7222222222222222, "eval_f1": 0.7221733604823293, "eval_mcc": 0.44482963744495324, "eval_auc": 0.7802333123637859, "eval_precision": 0.7223069554814654, "eval_recall": 0.7225227342986869, "learning_rate": 9.376986649713924e-06, "loss": 0.027246813336678315, "step": 3200}
INFO:__main__:Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_13944/0/after/cached_dev_6-new-12w-0_300_dnaprom
INFO:__main__:***** Running evaluation  *****
INFO:__main__:  Num examples = 2790
INFO:__main__:  Batch size = 48
INFO:__main__:***** Eval results  *****
INFO:__main__:  acc = 0.7229390681003585
INFO:__main__:  auc = 0.7832789548215128
INFO:__main__:  f1 = 0.7228313568497926
INFO:__main__:  mcc = 0.4458651182121807
INFO:__main__:  precision = 0.7228285670824459
INFO:__main__:  recall = 0.7230365996618467
INFO:__main__:{"eval_acc": 0.7229390681003585, "eval_f1": 0.7228313568497926, "eval_mcc": 0.4458651182121807, "eval_auc": 0.7832789548215128, "eval_precision": 0.7228285670824459, "eval_recall": 0.7230365996618467, "learning_rate": 6.198347107438017e-06, "loss": 0.015108718189439969, "step": 3300}
INFO:__main__:Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_13944/0/after/cached_dev_6-new-12w-0_300_dnaprom
INFO:__main__:***** Running evaluation  *****
INFO:__main__:  Num examples = 2790
INFO:__main__:  Batch size = 48
INFO:__main__:***** Eval results  *****
INFO:__main__:  acc = 0.7247311827956989
INFO:__main__:  auc = 0.7833314215552889
INFO:__main__:  f1 = 0.7247276464542651
INFO:__main__:  mcc = 0.4512458731827087
INFO:__main__:  precision = 0.7256798254755652
INFO:__main__:  recall = 0.7255660620475708
INFO:__main__:{"eval_acc": 0.7247311827956989, "eval_f1": 0.7247276464542651, "eval_mcc": 0.4512458731827087, "eval_auc": 0.7833314215552889, "eval_precision": 0.7256798254755652, "eval_recall": 0.7255660620475708, "learning_rate": 3.0197075651621106e-06, "loss": 0.015996842345921324, "step": 3400}
INFO:__main__: global_step = 3495, average loss = 0.22216879329182812
INFO:__main__:Saving model checkpoint to /data3/linming/DNABERT/examples/output/fold5_100_13944/0/
INFO:transformers.configuration_utils:Configuration saved in /data3/linming/DNABERT/examples/output/fold5_100_13944/0/config.json
INFO:transformers.modeling_utils:Model weights saved in /data3/linming/DNABERT/examples/output/fold5_100_13944/0/pytorch_model.bin
INFO:transformers.configuration_utils:loading configuration file /data3/linming/DNABERT/examples/output/fold5_100_13944/0/config.json
INFO:transformers.configuration_utils:Model config BertConfig {
  "architectures": [
    "BertForSequenceClassification"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "do_sample": false,
  "eos_token_ids": 0,
  "finetuning_task": "dnaprom",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "num_return_sequences": 1,
  "num_rnn_layer": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "rnn": "lstm",
  "rnn_dropout": 0.0,
  "rnn_hidden": 768,
  "split": 0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 4101
}

INFO:transformers.modeling_utils:loading weights file /data3/linming/DNABERT/examples/output/fold5_100_13944/0/pytorch_model.bin
INFO:transformers.tokenization_utils:Model name '/data3/linming/DNABERT/examples/output/fold5_100_13944/0/' not found in model shortcut name list (dna3, dna4, dna5, dna6). Assuming '/data3/linming/DNABERT/examples/output/fold5_100_13944/0/' is a path, a model identifier, or url to a directory containing tokenizer files.
INFO:transformers.tokenization_utils:Didn't find file /data3/linming/DNABERT/examples/output/fold5_100_13944/0/added_tokens.json. We won't load it.
INFO:transformers.tokenization_utils:loading file /data3/linming/DNABERT/examples/output/fold5_100_13944/0/vocab.txt
INFO:transformers.tokenization_utils:loading file None
INFO:transformers.tokenization_utils:loading file /data3/linming/DNABERT/examples/output/fold5_100_13944/0/special_tokens_map.json
INFO:transformers.tokenization_utils:loading file /data3/linming/DNABERT/examples/output/fold5_100_13944/0/tokenizer_config.json
INFO:transformers.tokenization_utils:Model name '/data3/linming/DNABERT/examples/output/fold5_100_13944/0/' not found in model shortcut name list (dna3, dna4, dna5, dna6). Assuming '/data3/linming/DNABERT/examples/output/fold5_100_13944/0/' is a path, a model identifier, or url to a directory containing tokenizer files.
INFO:transformers.tokenization_utils:Didn't find file /data3/linming/DNABERT/examples/output/fold5_100_13944/0/added_tokens.json. We won't load it.
INFO:transformers.tokenization_utils:loading file /data3/linming/DNABERT/examples/output/fold5_100_13944/0/vocab.txt
INFO:transformers.tokenization_utils:loading file None
INFO:transformers.tokenization_utils:loading file /data3/linming/DNABERT/examples/output/fold5_100_13944/0/special_tokens_map.json
INFO:transformers.tokenization_utils:loading file /data3/linming/DNABERT/examples/output/fold5_100_13944/0/tokenizer_config.json
INFO:__main__:Evaluate the following checkpoints: ['/data3/linming/DNABERT/examples/output/fold5_100_13944/0/']
INFO:transformers.configuration_utils:loading configuration file /data3/linming/DNABERT/examples/output/fold5_100_13944/0/config.json
INFO:transformers.configuration_utils:Model config BertConfig {
  "architectures": [
    "BertForSequenceClassification"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "do_sample": false,
  "eos_token_ids": 0,
  "finetuning_task": "dnaprom",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "num_return_sequences": 1,
  "num_rnn_layer": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "rnn": "lstm",
  "rnn_dropout": 0.0,
  "rnn_hidden": 768,
  "split": 0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 4101
}

INFO:transformers.modeling_utils:loading weights file /data3/linming/DNABERT/examples/output/fold5_100_13944/0/pytorch_model.bin
INFO:__main__:Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_13944/0/after/cached_dev_6-new-12w-0_300_dnaprom
INFO:__main__:***** Running evaluation  *****
INFO:__main__:  Num examples = 2790
INFO:__main__:  Batch size = 48
INFO:__main__:***** Eval results  *****
INFO:__main__:  acc = 0.7225806451612903
INFO:__main__:  auc = 0.7835366590727071
INFO:__main__:  f1 = 0.722498508056495
INFO:__main__:  mcc = 0.4452942344867953
INFO:__main__:  precision = 0.7225372544525746
INFO:__main__:  recall = 0.7227570342715791
06/19/2023 10:08:20 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
06/19/2023 10:08:20 - INFO - transformers.configuration_utils -   loading configuration file /data3/linming/DNABERT/examples/model/6-new-12w-0/config.json
06/19/2023 10:08:20 - INFO - transformers.configuration_utils -   Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "do_sample": false,
  "eos_token_ids": 0,
  "finetuning_task": "dnaprom",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "num_return_sequences": 1,
  "num_rnn_layer": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "rnn": "lstm",
  "rnn_dropout": 0.0,
  "rnn_hidden": 768,
  "split": 10,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 4101
}

06/19/2023 10:08:21 - INFO - transformers.tokenization_utils -   loading file https://raw.githubusercontent.com/jerryji1993/DNABERT/master/src/transformers/dnabert-config/bert-config-6/vocab.txt from cache at /data3/linming/.cache/torch/transformers/ea1474aad40c1c8ed4e1cb7c11345ddda6df27a857fb29e1d4c901d9b900d32d.26f8bd5a32e49c2a8271a46950754a4a767726709b7741c68723bc1db840a87e
06/19/2023 10:08:21 - INFO - transformers.modeling_utils -   loading weights file /data3/linming/DNABERT/examples/model/6-new-12w-0/pytorch_model.bin
06/19/2023 10:08:27 - INFO - transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
06/19/2023 10:08:27 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']
06/19/2023 10:08:27 - INFO - __main__ -   finish loading model
06/19/2023 10:08:39 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, attention_probs_dropout_prob=0.1, beta1=0.9, beta2=0.999, cache_dir='', config_name='', data_dir='/data3/linming/DNABERT/examples/data/fold5_100_13944/0/after/', device=device(type='cuda'), do_ensemble_pred=False, do_eval=True, do_lower_case=False, do_predict=False, do_train=True, do_visualize=False, early_stop=0, eval_all_checkpoints=False, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, hidden_dropout_prob=0.1, learning_rate=0.0001, local_rank=-1, logging_steps=100, max_grad_norm=1.0, max_seq_length=300, max_steps=-1, model_name='mutant_bert_fold_100_0_13944', model_name_or_path='/data3/linming/DNABERT/examples/model/6-new-12w-0/', model_num=3, model_type='dna', n_gpu=1, n_process=8, no_cuda=False, num_rnn_layer=2, num_train_epochs=15.0, output_dir='/data3/linming/DNABERT/examples/output/fold5_100_13944/0/', output_mode='classification', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=48, per_gpu_pred_batch_size=8, per_gpu_train_batch_size=48, predict_dir=None, predict_scan_size=1, result_dir=None, rnn='lstm', rnn_dropout=0.0, rnn_hidden=768, save_steps=4000, save_total_limit=None, seed=47, server_ip='', server_port='', should_continue=False, task_name='dnaprom', tokenizer_name='dna6', visualize_data_dir=None, visualize_models=None, visualize_train=False, warmup_percent=0.1, warmup_steps=0, weight_decay=0.01)
06/19/2023 10:08:39 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_13944/0/after/cached_train_6-new-12w-0_300_dnaprom
06/19/2023 10:08:45 - INFO - __main__ -   ***** Running training *****
06/19/2023 10:08:45 - INFO - __main__ -     Num examples = 11154
06/19/2023 10:08:45 - INFO - __main__ -     Num Epochs = 15
06/19/2023 10:08:45 - INFO - __main__ -     Instantaneous batch size per GPU = 48
06/19/2023 10:08:45 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 48
06/19/2023 10:08:45 - INFO - __main__ -     Gradient Accumulation steps = 1
06/19/2023 10:08:45 - INFO - __main__ -     Total optimization steps = 3495
06/19/2023 10:08:45 - INFO - __main__ -     Continuing training from checkpoint, will skip to saved global_step
06/19/2023 10:08:45 - INFO - __main__ -     Continuing training from epoch 0
06/19/2023 10:08:45 - INFO - __main__ -     Continuing training from global step 0
06/19/2023 10:08:45 - INFO - __main__ -     Will skip the first 0 steps in the first epoch
06/19/2023 10:20:31 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
06/19/2023 10:20:31 - INFO - transformers.configuration_utils -   loading configuration file /data3/linming/DNABERT/examples/model/6-new-12w-0/config.json
06/19/2023 10:20:31 - INFO - transformers.configuration_utils -   Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "do_sample": false,
  "eos_token_ids": 0,
  "finetuning_task": "dnaprom",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "num_return_sequences": 1,
  "num_rnn_layer": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "rnn": "lstm",
  "rnn_dropout": 0.0,
  "rnn_hidden": 768,
  "split": 10,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 4101
}

06/19/2023 10:20:41 - INFO - transformers.tokenization_utils -   loading file https://raw.githubusercontent.com/jerryji1993/DNABERT/master/src/transformers/dnabert-config/bert-config-6/vocab.txt from cache at /data3/linming/.cache/torch/transformers/ea1474aad40c1c8ed4e1cb7c11345ddda6df27a857fb29e1d4c901d9b900d32d.26f8bd5a32e49c2a8271a46950754a4a767726709b7741c68723bc1db840a87e
06/19/2023 10:20:41 - INFO - transformers.modeling_utils -   loading weights file /data3/linming/DNABERT/examples/model/6-new-12w-0/pytorch_model.bin
06/19/2023 10:20:47 - INFO - transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
06/19/2023 10:20:47 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']
06/19/2023 10:20:47 - INFO - __main__ -   finish loading model
06/19/2023 10:20:55 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, attention_probs_dropout_prob=0.1, beta1=0.9, beta2=0.999, cache_dir='', config_name='', data_dir='/data3/linming/DNABERT/examples/data/fold5_100_13944/0/after/', device=device(type='cuda'), do_ensemble_pred=False, do_eval=True, do_lower_case=False, do_predict=False, do_train=True, do_visualize=False, early_stop=0, eval_all_checkpoints=False, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, hidden_dropout_prob=0.1, learning_rate=0.0001, local_rank=-1, logging_steps=100, max_grad_norm=1.0, max_seq_length=300, max_steps=-1, model_name='mutant_bert_fold_100_0_13944', model_name_or_path='/data3/linming/DNABERT/examples/model/6-new-12w-0/', model_num=3, model_type='dna', n_gpu=1, n_process=8, no_cuda=False, num_rnn_layer=2, num_train_epochs=15.0, output_dir='/data3/linming/DNABERT/examples/output/fold5_100_13944/0/', output_mode='classification', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=48, per_gpu_pred_batch_size=8, per_gpu_train_batch_size=48, predict_dir=None, predict_scan_size=1, result_dir=None, rnn='lstm', rnn_dropout=0.0, rnn_hidden=768, save_steps=4000, save_total_limit=None, seed=47, server_ip='', server_port='', should_continue=False, task_name='dnaprom', tokenizer_name='dna6', visualize_data_dir=None, visualize_models=None, visualize_train=False, warmup_percent=0.1, warmup_steps=0, weight_decay=0.01)
06/19/2023 10:20:55 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_13944/0/after/cached_train_6-new-12w-0_300_dnaprom
06/19/2023 10:21:00 - INFO - __main__ -   ***** Running training *****
06/19/2023 10:21:00 - INFO - __main__ -     Num examples = 11154
06/19/2023 10:21:00 - INFO - __main__ -     Num Epochs = 15
06/19/2023 10:21:00 - INFO - __main__ -     Instantaneous batch size per GPU = 48
06/19/2023 10:21:00 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 48
06/19/2023 10:21:00 - INFO - __main__ -     Gradient Accumulation steps = 1
06/19/2023 10:21:00 - INFO - __main__ -     Total optimization steps = 3495
06/19/2023 10:21:00 - INFO - __main__ -     Continuing training from checkpoint, will skip to saved global_step
06/19/2023 10:21:00 - INFO - __main__ -     Continuing training from epoch 0
06/19/2023 10:21:00 - INFO - __main__ -     Continuing training from global step 0
06/19/2023 10:21:00 - INFO - __main__ -     Will skip the first 0 steps in the first epoch
06/19/2023 10:21:37 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
06/19/2023 10:21:37 - INFO - transformers.configuration_utils -   loading configuration file /data3/linming/DNABERT/examples/model/6-new-12w-0/config.json
06/19/2023 10:21:37 - INFO - transformers.configuration_utils -   Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "do_sample": false,
  "eos_token_ids": 0,
  "finetuning_task": "dnaprom",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "num_return_sequences": 1,
  "num_rnn_layer": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "rnn": "lstm",
  "rnn_dropout": 0.0,
  "rnn_hidden": 768,
  "split": 10,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 4101
}

06/19/2023 10:21:58 - INFO - transformers.tokenization_utils -   loading file https://raw.githubusercontent.com/jerryji1993/DNABERT/master/src/transformers/dnabert-config/bert-config-6/vocab.txt from cache at /data3/linming/.cache/torch/transformers/ea1474aad40c1c8ed4e1cb7c11345ddda6df27a857fb29e1d4c901d9b900d32d.26f8bd5a32e49c2a8271a46950754a4a767726709b7741c68723bc1db840a87e
06/19/2023 10:21:58 - INFO - transformers.modeling_utils -   loading weights file /data3/linming/DNABERT/examples/model/6-new-12w-0/pytorch_model.bin
06/19/2023 10:22:03 - INFO - transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
06/19/2023 10:22:03 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']
06/19/2023 10:22:03 - INFO - __main__ -   finish loading model
06/19/2023 10:22:11 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, attention_probs_dropout_prob=0.1, beta1=0.9, beta2=0.999, cache_dir='', config_name='', data_dir='/data3/linming/DNABERT/examples/data/fold5_100_13944/0/after/', device=device(type='cuda'), do_ensemble_pred=False, do_eval=True, do_lower_case=False, do_predict=False, do_train=True, do_visualize=False, early_stop=0, eval_all_checkpoints=False, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, hidden_dropout_prob=0.1, learning_rate=0.0001, local_rank=-1, logging_steps=100, max_grad_norm=1.0, max_seq_length=300, max_steps=-1, model_name='mutant_bert_fold_100_0_13944', model_name_or_path='/data3/linming/DNABERT/examples/model/6-new-12w-0/', model_num=3, model_type='dna', n_gpu=1, n_process=8, no_cuda=False, num_rnn_layer=2, num_train_epochs=15.0, output_dir='/data3/linming/DNABERT/examples/output/fold5_100_13944/0/', output_mode='classification', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=48, per_gpu_pred_batch_size=8, per_gpu_train_batch_size=48, predict_dir=None, predict_scan_size=1, result_dir=None, rnn='lstm', rnn_dropout=0.0, rnn_hidden=768, save_steps=4000, save_total_limit=None, seed=47, server_ip='', server_port='', should_continue=False, task_name='dnaprom', tokenizer_name='dna6', visualize_data_dir=None, visualize_models=None, visualize_train=False, warmup_percent=0.1, warmup_steps=0, weight_decay=0.01)
06/19/2023 10:22:11 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_13944/0/after/cached_train_6-new-12w-0_300_dnaprom
06/19/2023 10:22:16 - INFO - __main__ -   ***** Running training *****
06/19/2023 10:22:16 - INFO - __main__ -     Num examples = 11154
06/19/2023 10:22:16 - INFO - __main__ -     Num Epochs = 15
06/19/2023 10:22:16 - INFO - __main__ -     Instantaneous batch size per GPU = 48
06/19/2023 10:22:16 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 48
06/19/2023 10:22:16 - INFO - __main__ -     Gradient Accumulation steps = 1
06/19/2023 10:22:16 - INFO - __main__ -     Total optimization steps = 3495
06/19/2023 10:22:16 - INFO - __main__ -     Continuing training from checkpoint, will skip to saved global_step
06/19/2023 10:22:16 - INFO - __main__ -     Continuing training from epoch 0
06/19/2023 10:22:16 - INFO - __main__ -     Continuing training from global step 0
06/19/2023 10:22:16 - INFO - __main__ -     Will skip the first 0 steps in the first epoch
06/19/2023 10:23:17 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_13944/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/19/2023 10:23:18 - INFO - __main__ -   ***** Running evaluation  *****
06/19/2023 10:23:18 - INFO - __main__ -     Num examples = 2790
06/19/2023 10:23:18 - INFO - __main__ -     Batch size = 48
06/19/2023 10:46:31 - INFO - __main__ -   ***** Eval results  *****
06/19/2023 10:46:32 - INFO - __main__ -     acc = 0.6745519713261648
06/19/2023 10:46:34 - INFO - __main__ -     auc = 0.7244411135498426
06/19/2023 10:46:37 - INFO - __main__ -     f1 = 0.6684663802201116
06/19/2023 10:46:38 - INFO - __main__ -     mcc = 0.3764625486314831
06/19/2023 10:46:40 - INFO - __main__ -     precision = 0.6973858290519876
06/19/2023 10:47:01 - INFO - __main__ -     recall = 0.679501298551661
06/19/2023 10:47:02 - INFO - __main__ -   {"eval_acc": 0.6745519713261648, "eval_f1": 0.6684663802201116, "eval_mcc": 0.3764625486314831, "eval_auc": 0.7244411135498426, "eval_precision": 0.6973858290519876, "eval_recall": 0.679501298551661, "learning_rate": 2.8653295128939826e-05, "loss": 0.6570072835683822, "step": 100}
06/19/2023 10:48:05 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_13944/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/19/2023 10:48:07 - INFO - __main__ -   ***** Running evaluation  *****
06/19/2023 10:48:07 - INFO - __main__ -     Num examples = 2790
06/19/2023 10:48:07 - INFO - __main__ -     Batch size = 48
