06/26/2023 15:58:58 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
06/26/2023 15:58:58 - INFO - transformers.configuration_utils -   loading configuration file /data3/linming/DNABERT/examples/embeding_model/6-new-12w-0/config.json
06/26/2023 15:58:58 - INFO - transformers.configuration_utils -   Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "do_sample": false,
  "eos_token_ids": 0,
  "finetuning_task": "dnaprom",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "num_return_sequences": 1,
  "num_rnn_layer": 1,
  "output_attentions": false,
  "output_hidden_states": true,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "rnn": "lstm",
  "rnn_dropout": 0.0,
  "rnn_hidden": 768,
  "split": 10,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 4101
}

06/26/2023 15:58:58 - INFO - transformers.tokenization_utils -   loading file https://raw.githubusercontent.com/jerryji1993/DNABERT/master/src/transformers/dnabert-config/bert-config-6/vocab.txt from cache at /data3/linming/.cache/torch/transformers/ea1474aad40c1c8ed4e1cb7c11345ddda6df27a857fb29e1d4c901d9b900d32d.26f8bd5a32e49c2a8271a46950754a4a767726709b7741c68723bc1db840a87e
06/26/2023 15:58:58 - INFO - transformers.modeling_utils -   loading weights file /data3/linming/DNABERT/examples/embeding_model/6-new-12w-0/pytorch_model.bin
06/26/2023 15:59:02 - INFO - transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
06/26/2023 15:59:02 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']
06/26/2023 15:59:02 - INFO - __main__ -   finish loading model
06/26/2023 15:59:04 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, attention_probs_dropout_prob=0.1, beta1=0.9, beta2=0.999, cache_dir='', config_name='', data_dir='/data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/', device=device(type='cuda'), do_ensemble_pred=False, do_eval=True, do_lower_case=False, do_predict=False, do_train=True, do_visualize=False, early_stop=15, eval_all_checkpoints=False, evaluate_during_training=True, filter_num=128, filter_size=[2, 3, 4, 5, 6], fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, hidden_dropout_prob=0.1, learning_rate=0.0001, local_rank=-1, logging_steps=100, max_grad_norm=1.0, max_seq_length=300, max_steps=-1, model_name='mutant_Bert_fold5_100_15296_fold0', model_name_or_path='/data3/linming/DNABERT/examples/embeding_model/6-new-12w-0/', model_num=5, model_type='dna', n_gpu=1, n_process=8, no_cuda=False, num_rnn_layer=2, num_train_epochs=30.0, output_dir='/data3/linming/DNABERT/examples/output/fold5_100_15296/_fold0', output_mode='classification', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=64, per_gpu_pred_batch_size=8, per_gpu_train_batch_size=64, predict_dir=None, predict_scan_size=1, result_dir=None, rnn='lstm', rnn_dropout=0.0, rnn_hidden=768, save_steps=4000, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, task_name='dnaprom', tokenizer_name='dna6', visualize_data_dir=None, visualize_models=None, visualize_train=False, warmup_percent=0.1, warmup_steps=0, weight_decay=0.01)
06/26/2023 15:59:04 - INFO - __main__ -   Creating features from dataset file at /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/
06/26/2023 15:59:04 - INFO - transformers.data.processors.glue -   LOOKING AT /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/train.tsv
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   Writing example 0/1529
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   guid: train-1
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   input_ids: 2 2299 991 3952 3508 1731 2815 3056 4020 3780 2817 3064 4051 3901 3304 916 3652 2305 1015 4045 3877 3208 529 2103 208 820 3268 769 3063 4047 3888 3251 703 2800 2996 3777 2808 3027 3903 3311 943 3759 2736 2740 2753 2807 3022 3883 3231 622 2474 1690 2652 2404 1409 1526 1996 3876 3204 515 2047 4078 4012 3748 2690 2556 2019 3966 3564 1956 3715 2560 2035 4030 3820 2980 3715 2560 2035 4030 3820 2980 3715 2560 2035 4030 3820 2980 3715 2560 2035 4030 3820 2980 3715 2560 2035 4030 3820 2980 3715 2558 2027 3998 3692 2468 1667 2558 2027 3998 3692 2466 1659 2526 1900 3489 1655 2510 1835 3230 619 2464 1652 2500 1794 3066 4059 3934 3435 1438 1644 2468 1668 2563 2046 4075 3999 3696 2484 1731 2813 3048 3985 3640 2260 835 3326 1003 3997 3687 2447 1583 2222 683 2718 2666 2458 1627 2398 1387 1439 1647 2479 1709 2725 2696 2580 2115 255 1005 4006 3723 2591 2158 428 1699 2687 2541 1960 3732 2626 2298 985 3927 3405 1318 1163 544 2163 445 1766 2953 3608 2130 316 1251 895 3567 1967 3760 2740 2755 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   guid: train-2
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   input_ids: 2 3682 2426 1498 1883 3422 1386 1434 1626 2393 1367 1359 1325 1191 653 2600 2196 577 2295 975 3886 3242 665 2646 2380 1316 1153 502 1994 3866 3162 347 1374 1388 1441 1653 2503 1807 3119 173 677 2693 2567 2064 52 194 761 3032 3922 3388 1249 887 3534 1836 3234 633 2519 1870 3371 1182 617 2456 1618 2363 1247 878 3500 1698 2682 2522 1882 3417 1367 1357 1319 1167 559 2223 688 2738 2748 2788 2946 3580 2019 3967 3568 1971 3774 2794 2970 3674 2395 1374 1388 1443 1663 2542 1962 3738 2649 2389 1351 1294 1067 158 619 2462 1644 2467 1663 2543 1967 3760 2740 2756 2819 3069 4070 3978 3610 2139 351 1389 1448 1683 2622 2283 926 3690 2459 1629 2407 1422 1578 2202 602 2394 1372 1380 1411 1533 2023 3982 3628 2212 641 2550 1996 3875 3197 486 1931 3614 2155 413 1640 2451 1597 2279 909 3624 2195 573 2280 916 3650 2297 982 3915 3358 1130 411 1631 2413 1446 1674 2588 2148 386 1532 2020 3972 3588 2050 4090 4058 3929 3415 1360 1330 1211 735 2925 3494 1675 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   guid: train-3
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   input_ids: 2 2382 1322 1177 599 2383 1327 1198 683 2717 2662 2444 1572 2180 516 2050 4089 4055 3917 3367 1165 552 2194 569 2263 845 3367 1165 552 2196 580 2307 1023 4078 4010 3739 2653 2406 1419 1565 2152 402 1596 2276 898 3580 2018 3963 3549 1893 3461 1543 2064 49 184 724 2881 3320 977 3893 3272 788 3137 248 980 3907 3327 1007 4016 3761 2744 2769 2872 3284 833 3319 975 3885 3240 660 2625 2294 972 3876 3202 508 2017 3960 3540 1860 3331 1022 4076 4003 3710 2539 1951 3693 2472 1683 2621 2280 915 3647 2287 942 3756 2721 2680 2516 1860 3330 1020 4068 3971 3582 2027 3999 3693 2472 1684 2625 2293 968 3859 3134 236 931 3709 2536 1938 3642 2268 865 3448 1490 1852 3298 892 3554 1914 3545 1878 3403 1311 1133 424 1684 2626 2299 992 3954 3516 1764 2946 3580 2020 3972 3587 2047 4077 4007 3726 2604 2212 644 2564 2049 4085 4040 3860 3137 246 972 3873 3192 468 1859 3325 1000 3985 3640 2259 830 3308 931 3711 2541 1960 3732 2628 2308 1026 4091 4063 3949 3495 1678 2603 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   Writing example 0/1529
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   guid: train-4
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   input_ids: 2 390 1546 2075 94 364 1443 1662 2538 1948 3683 2430 1516 1955 3709 2534 1929 3606 2123 286 1132 417 1654 2506 1818 3163 351 1390 1449 1688 2641 2360 1235 831 3311 941 3751 2702 2603 2208 626 2491 1757 2917 3464 1554 2108 225 888 3540 1857 3320 977 3895 3277 806 3211 544 2162 443 1757 2920 3474 1596 2275 894 3564 1955 3709 2536 1939 3647 2288 948 3780 2820 3073 4086 4043 3872 3187 447 1773 2982 3724 2596 2177 504 2001 3895 3279 813 3240 657 2616 2260 833 3319 974 3881 3223 590 2348 1188 643 2558 2028 4001 3703 2510 1835 3231 624 2484 1732 2819 3069 4072 3988 3652 2307 1022 4075 3999 3694 2474 1691 2653 2407 1423 1584 2228 707 2815 3053 4008 3732 2628 2308 1025 4086 4043 3872 3187 447 1773 2984 3732 2626 2297 981 3911 3342 1068 161 631 2511 1837 3240 659 2623 2286 939 3741 2664 2450 1595 2271 879 3502 1705 2711 2639 2350 1194 668 2660 2435 1535 2030 4012 3748 2692 2564 2052 4097 4087 4045 3879 3214 556 2210 634 2524 1891 3453 1512 1937 3637 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   guid: train-5
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   input_ids: 2 2366 1259 927 3694 2474 1690 2650 2394 1371 1374 1386 1434 1628 2402 1404 1508 1921 3575 1998 3883 3231 621 2472 1684 2626 2300 996 3971 3583 2029 4006 3723 2589 2150 395 1567 2158 427 1693 2662 2443 1565 2150 395 1565 2152 403 1600 2290 955 3808 2930 3516 1764 2946 3579 2016 3954 3515 1757 2918 3466 1563 2142 364 1444 1668 2563 2045 4072 3986 3643 2270 875 3486 1644 2467 1661 2536 1939 3646 2284 931 3709 2534 1931 3614 2154 411 1631 2414 1451 1695 2670 2475 1695 2670 2475 1694 2668 2468 1667 2558 2027 3998 3692 2468 1667 2558 2027 3998 3692 2468 1667 2558 2027 3999 3694 2475 1694 2665 2453 1606 2314 1051 95 366 1452 1699 2686 2540 1955 3710 2539 1951 3694 2475 1695 2670 2475 1694 2668 2465 1655 2510 1836 3235 639 2542 1963 3742 2668 2467 1662 2539 1951 3694 2475 1694 2668 2465 1656 2513 1847 3277 807 3216 564 2244 772 3075 4094 4074 3995 3678 2411 1438 1642 2459 1630 2410 1435 1631 2414 1451 1695 2670 2475 1695 2669 2471 1679 2606 2219 669 2664 2452 1603 2302 1003 3999 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   guid: train-1530
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   input_ids: 2 3847 3085 39 143 558 2219 670 2668 2467 1662 2538 1947 3679 2414 1452 1699 2687 2542 1961 3733 2631 2318 1065 149 581 2311 1037 40 148 579 2301 1000 3986 3644 2273 886 3532 1828 3202 507 2014 3947 3486 1642 2459 1630 2411 1439 1645 2470 1675 2590 2156 420 1665 2552 2001 3893 3272 787 3134 234 924 3684 2436 1538 2042 4060 3937 3448 1491 1853 3304 913 3640 2257 822 3275 799 3181 424 1681 2616 2260 834 3323 990 3946 3483 1630 2410 1435 1629 2406 1419 1567 2158 426 1691 2654 2410 1435 1630 2410 1435 1630 2410 1435 1630 2410 1435 1630 2410 1435 1630 2410 1435 1630 2410 1435 1630 2410 1435 1630 2410 1435 1630 2410 1435 1630 2410 1435 1630 2410 1436 1634 2426 1499 1886 3434 1435 1630 2411 1438 1644 2468 1667 2558 2028 4003 3710 2540 1956 3715 2559 2031 4015 3758 2731 2718 2666 2460 1635 2431 1518 1964 3748 2690 2556 2020 3972 3587 2046 4075 3999 3693 2472 1683 2621 2280 915 3645 2277 902 3596 2084 131 509 2021 3975 3597 2088 145 566 2252 801 3189 456 1809 3128 212 833 3320 978 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   guid: train-1531
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   Writing example 0/1529
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   input_ids: 2 1896 3476 1601 2293 965 3845 3080 17 56 210 825 3285 838 3337 1045 69 264 1041 54 202 795 3166 363 1437 1640 2449 1592 2257 823 3277 806 3210 538 2140 354 1401 1494 1866 3356 1121 373 1479 1805 3109 135 527 2093 165 647 2573 2086 138 538 2139 351 1389 1445 1669 2565 2053 6 11 29 103 397 1576 2193 565 2245 774 3084 34 124 482 1916 3554 1913 3541 1861 3333 1029 6 12 33 118 458 1819 3168 371 1469 1768 2961 3640 2258 827 3296 881 3510 1740 2849 3189 456 1809 3128 212 836 3331 1021 4070 3978 3609 2133 328 1300 1090 249 984 3922 3388 1250 890 3548 1889 3447 1486 1836 3234 634 2522 1882 3417 1365 1349 1286 1034 26 89 342 1354 1306 1114 346 1371 1373 1382 1418 1561 2133 326 1292 1058 122 474 1881 3413 1349 1285 1030 9 21 72 274 1082 217 853 3397 1286 1036 34 122 474 1881 3414 1354 1308 1123 381 1511 1935 3630 2217 661 2629 2310 1036 34 122 476 1889 3446 1482 1818 3162 345 1365 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   guid: train-1532
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   input_ids: 2 634 2522 1882 3418 1371 1375 1390 1452 1697 2678 2508 1826 3196 484 1921 3575 1998 3881 3222 588 2338 1145 469 1861 3334 1034 27 94 361 1431 1614 2348 1185 629 2504 1811 3134 236 929 3701 2501 1799 3087 45 166 650 2586 2138 348 1380 1409 1526 1993 3861 3143 269 1062 139 541 2151 398 1579 2205 613 2437 1544 2067 61 231 911 3631 2221 677 2694 2571 2077 102 394 1562 2137 341 1350 1292 1057 119 462 1834 3227 605 2407 1422 1579 2208 628 2500 1794 3067 4061 3942 3466 1564 2146 378 1500 1892 3458 1532 2020 3969 3576 2001 3893 3272 785 3126 204 803 3199 493 1957 3717 2567 2063 45 168 660 2626 2299 989 3941 3462 1546 2075 95 367 1454 1706 2716 2660 2435 1533 2024 3988 3650 2297 983 3918 3370 1178 601 2390 1353 1303 1102 300 1185 630 2508 1828 3202 508 2018 3964 3554 1915 3549 1893 3461 1541 2055 14 44 164 641 2552 2003 3902 3307 925 3688 2451 1598 2284 932 3715 2557 2021 3976 3601 2103 205 807 3213 552 2196 579 2303 1005 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   guid: train-3059
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   input_ids: 2 1992 3859 3134 236 929 3704 2516 1860 3331 1021 4072 3987 3645 2278 908 3617 2165 456 1811 3133 232 916 3651 2303 1007 4014 3756 2724 2692 2562 2044 4065 3957 3527 1806 3116 163 637 2536 1940 3651 2301 999 3984 3636 2243 765 3047 3983 3631 2223 687 2733 2728 2707 2622 2284 932 3713 2552 2004 3907 3326 1004 4002 3707 2527 1902 3498 1689 2646 2380 1316 1156 515 2045 4071 3983 3631 2224 691 2751 2800 2996 3777 2807 3022 3884 3233 631 2511 1839 3247 686 2729 2711 2638 2348 1186 633 2520 1875 3391 1262 939 3742 2668 2467 1663 2543 1966 3754 2714 2651 2397 1384 1427 1599 2287 943 3757 2727 2702 2604 2209 631 2511 1839 3245 680 2708 2627 2302 1004 4004 3715 2559 2031 4016 3763 2749 2790 2954 3611 2141 358 1420 1571 2176 499 1981 3814 2955 3613 2149 391 1551 2095 173 679 2702 2604 2211 638 2540 1956 3714 2553 2005 3910 3340 1060 132 516 2049 4085 4040 3857 3128 212 836 3330 1018 4058 3929 3414 1355 1309 1127 399 1582 2218 667 2653 2408 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   Writing example 0/1529
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   guid: train-1533
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   input_ids: 2 1479 1805 3110 140 546 2171 477 1894 3467 1568 2161 438 1739 2847 3183 429 1701 2695 2574 2090 155 607 2415 1454 1707 2718 2666 2457 1621 2375 1293 1062 137 536 2132 323 1277 997 3973 3592 2066 58 220 868 3457 1527 1997 3878 3211 543 2159 429 1701 2693 2568 2065 54 204 804 3203 512 2034 4025 3800 2897 3382 1228 801 3189 455 1805 3110 140 545 2167 462 1833 3224 596 2369 1269 968 3857 3128 210 825 3288 852 3393 1272 980 3907 3327 1008 4017 3766 2761 2837 3141 263 1037 37 135 528 2099 189 744 2964 3649 2293 968 3860 3140 257 1015 4045 3878 3211 541 2150 395 1565 2149 389 1544 2067 61 229 901 3592 2065 56 211 829 3304 915 3648 2290 956 3811 2944 3572 1985 3830 3019 3871 3183 431 1710 2730 2714 2652 2403 1406 1515 1951 3694 2474 1690 2652 2401 1398 1483 1821 3176 401 1591 2256 818 3257 728 2900 3393 1270 970 3867 3168 372 1475 1791 3053 4005 3718 2571 2079 110 425 1688 2643 2365 1253 904 3601 2103 208 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   guid: train-3060
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   input_ids: 2 3482 1626 2395 1374 1386 1435 1631 2415 1454 1705 2712 2642 2361 1238 844 3362 1145 469 1864 3348 1090 251 989 3941 3462 1546 2075 94 364 1442 1658 2523 1885 3430 1418 1562 2140 355 1405 1510 1929 3608 2132 321 1272 977 3894 3273 789 3142 267 1053 102 393 1560 2132 321 1269 966 3851 3103 111 429 1701 2693 2566 2058 25 85 326 1289 1047 77 295 1166 555 2206 618 2460 1634 2428 1507 1918 3564 1953 3703 2510 1834 3225 599 2383 1325 1192 657 2614 2250 793 3157 328 1297 1078 202 794 3162 347 1374 1388 1443 1661 2534 1929 3608 2131 317 1254 906 3609 2133 326 1292 1057 119 461 1830 3210 538 2138 348 1378 1401 1495 1870 3370 1179 606 2410 1435 1629 2405 1415 1552 2099 192 753 2997 3784 2833 3128 211 829 3304 913 3638 2249 789 3141 262 1035 31 109 422 1674 2586 2139 350 1386 1434 1627 2398 1388 1442 1658 2523 1887 3437 1445 1670 2572 2081 117 455 1806 3114 154 601 2389 1351 1293 1063 141 550 2186 537 2136 337 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   guid: train-4588
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   input_ids: 2 3977 3605 2117 264 1041 53 199 781 3109 133 519 2062 41 149 583 2317 1063 141 549 2181 517 2053 5 5 6 10 26 90 345 1365 1349 1286 1033 23 79 302 1194 666 2652 2403 1406 1516 1956 3716 2562 2043 4061 3943 3469 1573 2184 532 2115 255 1008 4019 3775 2800 2996 3778 2810 3036 3937 3446 1481 1813 3141 264 1041 53 197 773 3077 7 14 44 162 635 2526 1900 3490 1659 2526 1900 3490 1658 2524 1889 3445 1479 1806 3115 159 622 2474 1690 2652 2403 1408 1522 1980 3811 2941 3558 1930 3612 2146 380 1505 1909 3525 1798 3084 33 117 453 1799 3087 46 172 673 2680 2513 1846 3276 803 3198 489 1942 3658 2331 1117 357 1415 1549 2086 138 537 2133 326 1289 1046 76 292 1154 505 2005 3912 3348 1092 259 1021 4072 3988 3649 2294 970 3867 3167 365 1448 1681 2616 2258 828 3297 885 3525 1800 3092 68 257 1014 4042 3865 3160 337 1333 1221 774 3081 23 80 305 1206 715 2845 3175 397 1574 2188 548 2179 509 2023 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   guid: train-1534
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   guid: train-4589
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   input_ids: 2 2691 2558 2028 4002 3706 2522 1883 3422 1386 1435 1631 2413 1448 1681 2613 2246 778 3099 96 370 1466 1756 2915 3453 1511 1936 3635 2237 742 2954 3612 2148 387 1534 2028 4004 3716 2561 2038 4043 3871 3182 427 1695 2671 2479 1711 2736 2739 2751 2799 2990 3755 2719 2669 2472 1683 2623 2286 939 3741 2663 2445 1576 2195 574 2281 918 3658 2331 1118 363 1438 1644 2466 1659 2527 1902 3499 1695 2671 2477 1703 2703 2605 2216 659 2622 2282 923 3677 2406 1420 1570 2169 471 1870 3372 1188 644 2564 2049 4085 4039 3854 3115 159 623 2480 1715 2751 2797 2981 3720 2577 2102 203 797 3173 392 1553 2101 197 776 3092 68 260 1028 4099 4095 4078 4012 3745 2677 2502 1804 3108 130 508 2018 3964 3556 1921 3575 1997 3878 3211 542 2153 407 1614 2347 1184 627 2494 1772 2980 3714 2556 2017 3959 3534 1836 3233 629 2501 1797 3079 13 38 138 539 2141 360 1426 1596 2276 899 3583 2031 4013 3749 2694 2572 2084 131 509 2022 3979 3613 2151 399 1583 2222 681 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   input_ids: 2 3639 2254 812 3236 644 2562 2044 4068 3971 3581 2024 3987 3646 2284 930 3708 2531 1918 3563 1950 3692 2467 1663 2543 1968 3763 2751 2799 2989 3749 2695 2575 2095 173 679 2703 2606 2218 667 2653 2408 1428 1603 2301 999 3983 3630 2220 675 2688 2546 1980 3812 2947 3583 2030 4012 3748 2690 2556 2020 3972 3588 2049 4088 4050 3900 3300 899 3583 2029 4007 3728 2611 2239 751 2989 3752 2707 2623 2287 943 3758 2731 2720 2674 2491 1759 2927 3502 1708 2724 2689 2552 2002 3899 3295 878 3499 1695 2670 2475 1695 2670 2475 1695 2670 2475 1695 2670 2475 1695 2670 2476 1699 2686 2540 1955 3710 2540 1955 3710 2540 1955 3710 2540 1953 3702 2508 1827 3198 491 1951 3694 2476 1699 2686 2540 1955 3710 2539 1951 3694 2475 1695 2671 2480 1715 2749 2792 2963 3645 2280 914 3644 2276 900 3588 2050 4091 4063 3951 3501 1703 2702 2603 2205 615 2446 1580 2211 637 2534 1931 3615 2158 428 1699 2687 2542 1964 3748 2692 2561 2040 4049 3896 3284 836 3330 1019 4063 3952 3505 1717 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   guid: train-3061
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   input_ids: 2 2502 1801 3093 69 262 1034 27 93 358 1419 1565 2149 389 1541 2054 10 26 89 341 1350 1290 1050 90 346 1370 1370 1370 1369 1365 1349 1287 1038 44 161 630 2505 1815 3149 296 1172 577 2293 966 3850 3099 93 358 1420 1569 2165 456 1809 3126 202 793 3159 335 1325 1189 647 2574 2092 163 639 2542 1962 3737 2646 2378 1305 1110 332 1313 1142 459 1822 3178 412 1634 2425 1495 1871 3374 1194 667 2654 2412 1441 1655 2511 1839 3245 678 2699 2589 2152 401 1589 2248 785 3125 197 774 3084 33 120 465 1845 3269 773 3080 18 58 220 866 3450 1498 1884 3426 1404 1505 1909 3527 1805 3112 145 565 2248 786 3130 217 853 3400 1300 1091 255 1005 4005 3717 2566 2057 22 75 287 1135 429 1701 2693 2567 2061 40 145 566 2252 804 3203 509 2024 3985 3640 2259 830 3308 930 3708 2529 1909 3528 1810 3132 225 888 3538 1849 3286 842 3354 1115 350 1386 1434 1626 2394 1372 1377 1398 1481 1814 3146 281 1112 340 1347 1277 997 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   guid: train-4590
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   input_ids: 2 2081 119 462 1834 3227 605 2408 1426 1594 2265 855 3407 1326 1196 675 2685 2534 1929 3607 2127 301 1189 647 2574 2092 163 639 2542 1964 3748 2689 2552 2003 3902 3307 926 3691 2463 1646 2474 1691 2654 2409 1431 1615 2350 1196 676 2692 2563 2046 4076 4002 3708 2529 1911 3533 1829 3208 530 2106 219 863 3439 1454 1707 2717 2662 2444 1569 2168 465 1848 3282 828 3297 888 3539 1854 3308 931 3711 2543 1967 3760 2739 2752 2801 3000 3794 2876 3300 900 3585 2040 4049 3893 3271 781 3109 136 532 2113 248 980 3907 3328 1011 4030 3820 2979 3710 2539 1949 3687 2447 1582 2218 667 2653 2406 1420 1572 2177 504 2003 3901 3304 916 3650 2300 996 3972 3588 2050 4092 4068 3971 3582 2025 3992 3668 2372 1283 1021 4069 3974 3596 2083 127 494 1964 3748 2692 2564 2049 4088 4049 3896 3284 833 3320 980 3907 3326 1004 4003 3709 2535 1933 3624 2196 579 2302 1003 3999 3694 2476 1700 2689 2550 1996 3876 3204 515 2048 4084 4036 3841 3064 4052 3908 3329 1016 4051 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   Writing example 0/1529
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   guid: train-3062
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   input_ids: 2 3725 2598 2186 539 2142 363 1440 1649 2486 1737 2837 3144 274 1081 216 850 3385 1239 847 3374 1194 668 2659 2431 1519 1967 3760 2739 2749 2792 2964 3652 2305 1016 4051 3903 3311 941 3752 2708 2627 2302 1003 3997 3687 2445 1576 2196 579 2302 1003 3999 3695 2479 1712 2739 2751 2800 2996 3779 2815 3053 4008 3731 2624 2292 964 3843 3072 4083 4032 3827 3007 3824 2993 3768 2769 2869 3272 788 3139 253 998 3977 3607 2125 295 1167 560 2225 695 2766 2860 3236 644 2563 2047 4080 4019 3775 2800 2995 3775 2800 2995 3775 2800 2995 3774 2793 2968 3667 2367 1264 945 3768 2771 2877 3304 915 3645 2279 909 3623 2189 550 2188 548 2179 512 2035 4029 3813 2950 3594 2076 98 379 1503 1901 3493 1672 2577 2101 200 787 3135 237 936 3731 2624 2292 961 3832 3027 3904 3315 959 3823 2991 3760 2737 2741 2759 2829 3109 136 531 2109 231 910 3628 2210 633 2517 1864 3348 1092 260 1025 4088 4052 3907 3327 1005 4008 3731 2621 2280 916 3651 2304 1011 4031 3822 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   guid: train-4591
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   input_ids: 2 1694 2668 2468 1668 2563 2045 4070 3979 3614 2154 411 1630 2411 1439 1646 2475 1694 2666 2458 1628 2403 1405 1512 1937 3639 2256 819 3262 748 2979 3710 2540 1955 3710 2539 1949 3685 2440 1554 2107 223 878 3500 1700 2692 2564 2051 4094 4075 3997 3688 2452 1604 2308 1028 4100 4099 4094 4076 4004 3714 2556 2020 3972 3588 2050 4091 4063 3950 3499 1696 2676 2497 1784 3027 3902 3307 926 3691 2464 1652 2500 1795 3070 4075 3997 3688 2452 1602 2300 996 3969 3576 2004 3906 3324 996 3971 3581 2024 3988 3652 2308 1026 4092 4068 3972 3585 2040 4051 3901 3304 914 3644 2276 899 3581 2023 3984 3636 2244 772 3076 4099 4095 4078 4010 3738 2652 2404 1412 1540 2049 4087 4046 3883 3230 620 2465 1656 2514 1852 3300 898 3580 2020 3970 3580 2017 3958 3532 1828 3202 508 2020 3970 3580 2020 3970 3580 2019 3966 3563 1951 3694 2474 1691 2654 2410 1436 1636 2436 1540 2052 4100 4098 4092 4065 3960 3540 1857 3320 980 3907 3328 1011 4030 3820 2979 3710 2540 1955 3710 2540 1955 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   guid: train-6117
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   guid: train-4592
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   input_ids: 2 3901 3303 912 3633 2232 724 2884 3332 1025 4087 4045 3880 3220 579 2303 1008 4018 3772 2787 2942 3564 1953 3704 2516 1860 3330 1020 4065 3958 3532 1827 3198 492 1953 3704 2516 1859 3328 1012 4036 3843 3070 4076 4004 3714 2555 2016 3956 3524 1795 3071 4078 4011 3742 2666 2460 1634 2427 1502 1899 3487 1648 2483 1725 2792 2962 3644 2274 892 3554 1913 3541 1863 3344 1075 189 744 2964 3651 2303 1006 4012 3748 2692 2563 2047 4078 4012 3747 2686 2540 1956 3716 2564 2051 4095 4080 4019 3774 2796 2980 3716 2564 2052 4097 4088 4052 3905 3319 976 3891 3263 752 2994 3772 2788 2947 3583 2030 4011 3742 2668 2466 1660 2531 1918 3564 1956 3713 2551 2000 3890 3260 737 2933 3526 1804 3106 121 472 1874 3385 1240 852 3396 1281 1015 4046 3884 3234 636 2531 1920 3572 1985 3830 3020 3875 3198 492 1955 3709 2536 1940 3651 2303 1006 4010 3739 2655 2414 1452 1699 2687 2541 1960 3729 2615 2253 806 3212 545 2165 456 1809 3128 212 835 3328 1011 4032 3828 3010 3834 3035 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   input_ids: 2 1478 1802 3100 100 387 1535 2031 4014 3753 2711 2639 2350 1196 673 2677 2504 1812 3138 251 991 3950 3498 1692 2660 2435 1535 2029 4008 3729 2615 2255 814 3242 667 2653 2406 1419 1565 2151 399 1584 2226 700 2787 2943 3566 1964 3746 2683 2528 1908 3523 1791 3053 4007 3727 2606 2220 676 2690 2555 2016 3954 3515 1759 2926 3499 1693 2661 2439 1552 2098 187 733 2920 3475 1600 2290 955 3807 2927 3504 1714 2748 2787 2943 3566 1964 3747 2686 2539 1950 3689 2454 1612 2338 1147 478 1898 3483 1630 2410 1435 1631 2416 1459 1725 2790 2956 3620 2179 509 2023 3981 3624 2195 574 2284 929 3704 2516 1857 3317 966 3850 3098 91 349 1381 1416 1556 2116 259 1021 4071 3983 3630 2217 663 2638 2348 1187 638 2537 1943 3663 2350 1194 668 2658 2428 1507 1919 3567 1966 3753 2711 2639 2350 1196 676 2690 2556 2018 3964 3555 1918 3562 1947 3677 2406 1420 1570 2172 484 1922 3580 2018 3964 3553 1912 3539 1854 3307 926 3691 2463 1648 2482 1724 2788 2946 3579 2013 3942 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   guid: train-3063
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   input_ids: 2 2040 4049 3894 3275 798 3179 413 1640 2449 1591 2254 811 3231 624 2481 1719 2768 2867 3262 748 2977 3704 2516 1857 3319 974 3883 3231 624 2483 1727 2800 2996 3779 2814 3051 4000 3700 2497 1784 3028 3907 3327 1008 4019 3775 2800 2995 3776 2801 3000 3793 2872 3283 831 3311 944 3764 2756 2817 3063 4047 3887 3245 680 2707 2624 2292 964 3842 3068 4065 3960 3539 1856 3315 957 3816 2964 3652 2307 1024 4084 4035 3838 3052 4003 3711 2544 1969 3768 2772 2883 3328 1010 4026 3804 2915 3456 1524 1987 3838 3052 4003 3710 2540 1955 3712 2548 1987 3838 3052 4003 3710 2540 1955 3712 2548 1987 3839 3056 4020 3777 2808 3027 3901 3304 916 3650 2299 991 3950 3500 1697 2677 2504 1811 3136 243 959 3822 2987 3744 2675 2496 1780 3010 3836 3042 3964 3555 1920 3570 1980 3812 2945 3575 1997 3879 3213 552 2196 578 2300 995 3968 3572 1987 3840 3060 4033 3832 3028 3908 3331 1021 4071 3984 3636 2244 771 3072 4081 4022 3785 2839 3150 299 1184 628 2500 1796 3074 4089 4056 3924 3393 1269 965 3848 3092 67 255 1006 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   guid: train-6118
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   input_ids: 2 2024 3988 3652 2305 1014 4041 3861 3144 275 1085 232 915 3647 2286 937 3736 2643 2366 1259 925 3688 2452 1601 2296 977 3893 3272 786 3132 225 888 3538 1849 3286 841 3349 1093 261 1032 19 63 239 943 3757 2728 2708 2627 2302 1004 4004 3716 2561 2040 4051 3901 3304 915 3647 2285 934 3723 2589 2151 397 1576 2193 565 2248 786 3131 223 877 3495 1678 2603 2205 614 2442 1563 2142 362 1436 1636 2435 1533 2024 3988 3649 2294 972 3876 3203 510 2026 3995 3678 2411 1440 1650 2491 1758 2924 3491 1662 2539 1951 3694 2475 1695 2670 2475 1694 2668 2467 1663 2542 1962 3740 2659 2430 1516 1956 3713 2551 1998 3884 3236 642 2553 2006 3914 3354 1116 354 1404 1506 1915 3550 1900 3489 1656 2516 1859 3326 1004 4004 3715 2559 2031 4014 3753 2711 2640 2356 1218 764 3041 3960 3538 1852 3298 890 3546 1883 3422 1388 1442 1660 2529 1911 3533 1830 3211 543 2159 429 1702 2698 2587 2143 366 1449 1687 2637 2342 1162 538 2137 341 1352 1297 1078 202 795 3165 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   Writing example 0/1529
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   guid: train-6119
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   input_ids: 2 3172 388 1537 2038 4044 3873 3190 457 1814 3148 292 1153 502 1996 3873 3191 462 1834 3226 604 2401 1398 1481 1815 3150 298 1179 606 2412 1441 1656 2513 1847 3278 810 3227 605 2405 1413 1541 2054 11 29 102 394 1562 2140 354 1402 1497 1879 3405 1319 1167 557 2215 655 2607 2223 685 2725 2693 2568 2066 59 221 871 3470 1578 2202 604 2402 1401 1493 1864 3345 1080 210 825 3285 840 3347 1085 231 910 3628 2211 638 2539 1949 3688 2449 1589 2245 774 3081 21 69 261 1032 20 68 258 1017 4053 3912 3345 1080 209 821 3269 775 3086 42 154 602 2394 1370 1369 1365 1349 1288 1043 61 231 909 3624 2195 574 2282 922 3673 2390 1353 1303 1101 293 1159 525 2085 133 519 2061 39 141 552 2194 569 2261 837 3336 1041 55 206 812 3233 630 2506 1818 3164 355 1407 1518 1963 3743 2669 2471 1679 2607 2222 683 2719 2670 2475 1694 2668 2465 1653 2501 1800 3091 64 241 952 3795 2877 3301 901 3590 2057 24 81 310 1226 794 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   guid: train-7646
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   input_ids: 2 45 166 651 2590 2155 414 1644 2466 1658 2522 1881 3416 1362 1338 1242 858 3418 1372 1377 1397 1477 1798 3084 35 126 492 1954 3707 2527 1902 3497 1687 2637 2341 1159 527 2094 171 670 2665 2454 1612 2337 1143 462 1834 3228 611 2430 1516 1953 3704 2513 1845 3269 775 3085 39 143 557 2213 646 2570 2074 91 351 1392 1457 1720 2772 2884 3332 1026 4091 4062 3947 3486 1642 2458 1628 2401 1397 1479 1807 3118 169 661 2631 2317 1063 144 561 2229 709 2824 3092 67 256 1011 4029 3813 2951 3597 2088 145 566 2252 802 3196 483 1917 3559 1934 3628 2211 637 2535 1934 3628 2211 638 2538 1946 3674 2395 1375 1390 1450 1692 2659 2432 1521 1975 3790 2859 3231 621 2472 1681 2613 2247 782 3114 153 600 2386 1337 1238 843 3357 1126 394 1563 2141 359 1422 1580 2210 636 2529 1910 3531 1822 3177 405 1605 2309 1031 15 46 172 673 2677 2501 1797 3078 9 22 75 287 1134 426 1691 2654 2410 1434 1628 2402 1401 1493 1863 3343 1071 175 685 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   guid: train-6120
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   input_ids: 2 2083 125 486 1930 3610 2140 355 1406 1513 1941 3653 2312 1042 58 218 858 3418 1369 1365 1349 1287 1039 47 174 684 2722 2682 2522 1881 3414 1353 1304 1108 322 1274 985 3925 3397 1288 1041 55 206 811 3229 616 2450 1595 2270 875 3486 1644 2465 1656 2513 1845 3269 773 3079 13 37 134 522 2076 100 385 1527 1998 3884 3233 630 2508 1827 3200 497 1973 3782 2828 3107 125 488 1938 3642 2266 858 3420 1380 1409 1525 1989 3845 3077 5 5 7 14 44 162 636 2532 1922 3580 2020 3969 3573 1992 3857 3126 201 790 3145 278 1097 279 1102 300 1186 636 2529 1911 3533 1829 3206 523 2079 109 423 1679 2605 2215 653 2598 2187 541 2152 403 1599 2286 940 3746 2684 2532 1923 3583 2029 4006 3722 2588 2145 373 1479 1806 3113 150 588 2340 1153 501 1992 3860 3138 249 981 3909 3333 1029 5 5 5 5 5 5 5 5 6 9 23 79 301 1191 654 2602 2202 602 2393 1365 1350 1290 1050 92 354 1401 1494 1868 3361 1141 454 1801 3094 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   Writing example 0/1529
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   guid: train-7647
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   input_ids: 2 3747 2688 2546 1980 3812 2945 3576 2001 3893 3271 782 3115 160 626 2491 1760 2930 3516 1763 2943 3567 1967 3757 2728 2707 2622 2283 928 3700 2500 1796 3075 4094 4076 4004 3713 2551 1997 3879 3215 557 2216 660 2627 2304 1011 4029 3816 2962 3644 2275 896 3570 1979 3805 2917 3463 1551 2093 165 647 2575 2093 168 660 2627 2303 1006 4011 3743 2669 2470 1676 2594 2171 480 1906 3514 1754 2908 3427 1405 1510 1931 3616 2164 451 1791 3054 4012 3748 2689 2549 1991 3854 3113 152 593 2360 1236 835 3326 1004 4004 3715 2560 2036 4035 3838 3050 3996 3684 2436 1539 2047 4077 4008 3731 2623 2288 947 3774 2796 2980 3716 2563 2045 4071 3984 3635 2238 747 2975 3694 2475 1696 2676 2499 1791 3053 4008 3732 2628 2307 1023 4078 4011 3742 2665 2456 1619 2367 1264 947 3774 2795 2975 3695 2477 1703 2702 2604 2212 644 2563 2046 4074 3996 3684 2433 1528 2002 3898 3291 861 3432 1427 1598 2284 931 3709 2535 1936 3636 2244 771 3069 4072 3985 3640 2260 835 3327 1006 4012 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   guid: train-6121
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   input_ids: 2 1429 1606 2315 1055 111 431 1709 2725 2693 2568 2066 59 223 878 3499 1694 2668 2465 1654 2506 1819 3165 358 1419 1566 2154 409 1624 2385 1336 1236 833 3317 968 3860 3139 256 1010 4026 3804 2915 3454 1514 1946 3674 2395 1374 1388 1442 1660 2530 1914 3547 1887 3437 1446 1674 2586 2139 350 1387 1438 1644 2465 1655 2509 1830 3211 543 2160 434 1722 2779 2910 3434 1434 1626 2395 1375 1390 1452 1698 2682 2522 1883 3422 1386 1436 1635 2431 1518 1962 3739 2653 2408 1426 1593 2261 837 3336 1044 67 255 1007 4016 3762 2745 2773 2888 3347 1085 232 913 3637 2248 785 3127 206 810 3227 607 2414 1451 1695 2670 2475 1695 2671 2477 1701 2693 2568 2066 58 218 860 3428 1409 1528 2003 3901 3303 911 3632 2227 703 2798 2987 3741 2664 2452 1601 2293 967 3853 3112 148 577 2293 967 3855 3118 170 667 2654 2411 1438 1642 2460 1635 2431 1519 1965 3749 2695 2573 2085 133 520 2066 59 223 877 3496 1684 2628 2308 1025 4086 4043 3870 3179 416 1652 2497 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   guid: train-9175
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   input_ids: 2 879 3501 1704 2705 2616 2258 825 3288 852 3395 1277 1000 3988 3652 2308 1025 4087 4046 3883 3229 615 2446 1580 2211 638 2538 1946 3675 2399 1390 1451 1695 2670 2475 1695 2671 2478 1707 2718 2668 2465 1655 2510 1836 3235 638 2538 1946 3675 2398 1387 1438 1643 2463 1646 2475 1695 2671 2478 1707 2718 2668 2465 1655 2510 1836 3235 638 2538 1946 3675 2398 1387 1438 1643 2463 1646 2475 1695 2671 2478 1707 2719 2670 2476 1699 2686 2540 1955 3709 2536 1938 3643 2270 875 3487 1646 2475 1696 2675 2495 1776 2996 3778 2812 3044 3972 3586 2044 4065 3960 3538 1849 3288 851 3391 1263 941 3749 2696 2580 2114 252 996 3969 3576 2004 3908 3331 1021 4072 3988 3650 2298 987 3934 3436 1443 1663 2542 1964 3748 2690 2555 2014 3947 3486 1644 2468 1665 2552 2003 3902 3308 929 3704 2516 1859 3326 1004 4004 3716 2564 2051 4093 4072 3985 3640 2260 836 3330 1017 4055 3917 3368 1171 574 2284 929 3701 2503 1806 3116 161 630 2507 1823 3183 430 1708 2721 2680 2513 1848 3281 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   guid: train-7648
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   input_ids: 2 3905 3320 980 3907 3327 1008 4017 3768 2771 2878 3308 931 3710 2538 1948 3684 2435 1536 2035 4031 3824 2993 3767 2765 2855 3213 551 2189 552 2196 580 2307 1022 4075 3999 3696 2481 1720 2770 2874 3291 864 3441 1464 1746 2874 3291 861 3431 1423 1584 2225 695 2766 2858 3226 601 2391 1358 1323 1182 618 2459 1631 2414 1449 1688 2643 2367 1261 936 3729 2615 2256 819 3261 744 2961 3639 2256 819 3263 751 2991 3759 2735 2736 2740 2755 2816 3060 4035 3839 3055 4015 3760 2740 2755 2816 3060 4034 3836 3044 3971 3584 2036 4035 3840 3059 4032 3828 3012 3841 3064 4052 3907 3327 1007 4016 3764 2756 2819 3072 4084 4035 3840 3059 4032 3828 3012 3843 3072 4083 4032 3828 3012 3843 3072 4083 4030 3820 2979 3712 2548 1987 3840 3060 4036 3841 3063 4045 3880 3219 574 2283 928 3697 2487 1744 2867 3264 755 3005 3816 2964 3650 2300 993 3960 3539 1856 3316 963 3837 3047 3981 3622 2188 548 2179 512 2036 4034 3836 3043 3967 3568 1972 3777 2805 3016 3859 3135 239 944 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   guid: train-9176
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   input_ids: 2 1027 4093 4072 3985 3638 2252 804 3202 508 2020 3972 3588 2049 4088 4052 3905 3318 971 3870 3177 408 1619 2365 1256 915 3647 2286 940 3748 2692 2562 2043 4063 3951 3503 1710 2731 2717 2663 2447 1583 2222 683 2717 2664 2452 1602 2300 996 3969 3575 1998 3882 3227 606 2409 1430 1612 2339 1151 494 1962 3737 2647 2384 1332 1220 771 3070 4076 4001 3704 2516 1859 3327 1006 4009 3735 2639 2350 1195 671 2669 2472 1683 2622 2283 926 3692 2466 1660 2529 1911 3534 1834 3227 606 2411 1440 1652 2499 1791 3056 4019 3775 2799 2989 3752 2705 2613 2247 783 3118 172 675 2688 2545 1973 3784 2836 3140 259 1023 4078 4009 3735 2638 2347 1181 614 2442 1561 2135 333 1320 1171 573 2280 916 3649 2295 973 3877 3207 526 2092 163 637 2533 1928 3603 2109 231 911 3630 2220 676 2689 2552 2003 3904 3315 959 3822 2987 3741 2663 2447 1582 2218 666 2652 2402 1404 1507 1918 3563 1950 3689 2455 1615 2350 1193 663 2637 2344 1172 578 2300 995 3967 3566 1964 3748 2692 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   guid: train-7649
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   input_ids: 2 2020 3972 3588 2049 4086 4044 3875 3198 492 1956 3715 2557 2024 3985 3639 2256 819 3262 746 2971 3678 2411 1439 1647 2477 1702 2697 2584 2130 315 1248 882 3515 1758 2923 3487 1647 2477 1703 2703 2608 2225 695 2766 2860 3235 638 2540 1953 3701 2502 1804 3108 132 515 2047 4078 4012 3747 2687 2543 1966 3755 2718 2668 2468 1666 2556 2018 3964 3556 1924 3588 2052 4098 4090 4058 3931 3422 1387 1438 1644 2468 1668 2564 2050 4089 4056 3921 3381 1221 776 3091 62 235 928 3699 2494 1772 2979 3710 2540 1955 3710 2540 1955 3710 2540 1955 3711 2542 1963 3743 2669 2471 1679 2605 2215 655 2606 2219 670 2668 2467 1662 2538 1947 3679 2413 1447 1678 2601 2199 590 2348 1187 639 2543 1967 3760 2740 2756 2819 3072 4083 4030 3820 2979 3710 2540 1956 3716 2563 2047 4078 4012 3748 2692 2564 2052 4098 4091 4062 3946 3484 1636 2434 1531 2014 3947 3485 1639 2447 1584 2226 698 2780 2914 3452 1508 1923 3583 2029 4008 3729 2614 2252 803 3199 494 1963 3742 2666 2459 1629 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   guid: train-9177
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   input_ids: 2 2500 1796 3076 4098 4092 4065 3960 3539 1855 3311 943 3760 2738 2746 2777 2903 3407 1325 1190 652 2593 2168 468 1860 3330 1020 4068 3970 3580 2020 3970 3580 2019 3967 3565 1960 3731 2622 2282 924 3684 2436 1539 2047 4078 4011 3744 2676 2499 1791 3053 4006 3722 2585 2136 339 1342 1259 926 3690 2460 1636 2436 1540 2049 4085 4040 3858 3132 225 886 3529 1813 3143 270 1068 164 642 2555 2014 3945 3479 1614 2346 1179 608 2420 1473 1783 3022 3884 3234 636 2530 1916 3556 1924 3588 2052 4100 4098 4092 4068 3971 3582 2028 4004 3713 2551 1999 3885 3239 655 2605 2215 653 2600 2194 572 2276 899 3583 2029 4007 3727 2605 2215 655 2608 2227 701 2792 2961 3640 2259 831 3312 948 3779 2813 3048 3985 3639 2254 811 3231 622 2476 1700 2691 2559 2031 4016 3761 2741 2760 2833 3126 204 804 3203 510 2027 3999 3695 2479 1710 2732 2722 2684 2531 1918 3564 1955 3710 2539 1949 3688 2449 1590 2251 799 3181 423 1680 2612 2243 768 3060 4035 3839 3056 4020 3780 2817 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   Writing example 0/1533
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   guid: train-7650
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   input_ids: 2 968 3857 3128 212 833 3318 970 3867 3167 365 1448 1683 2623 2286 940 3746 2682 2524 1892 3459 1535 2031 4015 3758 2732 2722 2683 2526 1898 3483 1632 2417 1463 1743 2863 3245 680 2707 2623 2287 941 3752 2707 2623 2287 943 3759 2734 2731 2718 2668 2466 1658 2524 1891 3454 1515 1950 3692 2467 1661 2534 1929 3606 2122 284 1124 387 1535 2032 4018 3771 2782 2924 3492 1668 2564 2050 4091 4063 3949 3494 1675 2590 2155 415 1647 2478 1707 2719 2670 2476 1697 2680 2515 1854 3305 920 3665 2357 1221 774 3081 24 81 309 1221 775 3087 47 173 680 2705 2616 2257 822 3276 804 3201 504 2004 3907 3326 1004 4002 3707 2526 1898 3484 1635 2430 1513 1942 3660 2340 1155 509 2024 3988 3652 2305 1016 4052 3906 3324 993 3959 3533 1832 3219 575 2286 940 3747 2686 2540 1956 3715 2557 2023 3982 3628 2210 633 2518 1865 3350 1098 282 1113 344 1362 1340 1250 891 3550 1898 3481 1623 2382 1322 1177 597 2376 1300 1089 246 970 3866 3161 342 1356 1315 1149 486 1932 3620 2177 501 1990 3850 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   guid: train-10704
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   guid: train-9178
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   input_ids: 2 3268 769 3062 4044 3876 3204 513 2038 4044 3876 3204 516 2050 4092 4065 3959 3534 1836 3234 636 2531 1920 3572 1986 3835 3040 3956 3521 1783 3021 3877 3208 532 2114 249 983 3919 3374 1196 675 2686 2539 1952 3700 2499 1791 3053 4008 3732 2628 2306 1020 4067 3968 3572 1985 3831 3024 3891 3263 749 2984 3730 2620 2275 896 3572 1985 3830 3019 3870 3179 413 1638 2444 1572 2179 511 2031 4013 3752 2707 2623 2287 944 3764 2755 2815 3053 4008 3731 2624 2291 960 3827 3006 3819 2974 3692 2467 1661 2536 1939 3646 2284 931 3711 2543 1967 3758 2732 2723 2686 2539 1951 3693 2472 1683 2621 2279 912 3636 2243 767 3055 4015 3758 2729 2711 2639 2351 1200 691 2750 2796 2979 3710 2539 1951 3693 2472 1684 2628 2307 1023 4078 4011 3743 2671 2477 1702 2700 2595 2175 493 1960 3731 2622 2284 932 3716 2563 2048 4084 4036 3843 3069 4069 3975 3598 2090 156 611 2431 1520 1969 3766 2763 2845 3175 399 1581 2216 659 2623 2288 947 3773 2792 2963 3646 2284 931 3710 2539 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   input_ids: 2 3823 2992 3763 2751 2799 2989 3750 2698 2588 2147 382 1516 1955 3711 2543 1966 3753 2711 2638 2348 1188 643 2558 2028 4003 3710 2540 1956 3714 2556 2018 3962 3547 1887 3438 1452 1700 2691 2558 2028 4003 3711 2543 1966 3755 2717 2661 2438 1548 2083 127 495 1966 3756 2723 2686 2540 1955 3709 2536 1938 3644 2276 899 3582 2028 4003 3710 2540 1955 3712 2548 1987 3839 3053 4007 3726 2604 2212 642 2556 2019 3966 3563 1950 3689 2455 1616 2355 1213 743 2959 3631 2223 686 2732 2723 2686 2540 1956 3715 2559 2032 4018 3772 2788 2947 3583 2029 4005 3719 2573 2087 143 557 2215 655 2606 2218 667 2653 2407 1423 1584 2226 699 2781 2920 3475 1597 2279 911 3632 2225 695 2765 2853 3208 532 2115 254 1003 3997 3688 2451 1600 2291 959 3821 2982 3722 2586 2139 352 1396 1475 1790 3049 3990 3660 2337 1144 467 1855 3311 943 3758 2732 2722 2682 2523 1886 3435 1440 1650 2492 1764 2948 3585 2040 4052 3905 3318 969 3864 3155 319 1264 948 3777 2807 3023 3887 3248 690 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   guid: train-10705
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   input_ids: 2 2604 2210 635 2527 1901 3494 1676 2594 2171 479 1903 3502 1708 2724 2690 2556 2019 3966 3564 1953 3704 2516 1857 3320 980 3908 3332 1027 4094 4075 3997 3687 2447 1582 2218 668 2660 2436 1537 2040 4052 3908 3331 1023 4079 4014 3756 2721 2680 2515 1853 3304 913 3640 2259 831 3309 933 3720 2577 2101 200 787 3135 239 942 3755 2719 2669 2472 1683 2623 2285 935 3725 2597 2183 527 2095 175 687 2733 2727 2701 2600 2195 576 2292 963 3839 3053 4008 3731 2621 2279 911 3629 2216 659 2621 2280 915 3645 2280 915 3645 2280 915 3645 2280 915 3645 2280 915 3645 2280 916 3649 2296 979 3901 3304 916 3651 2302 1003 3997 3687 2448 1588 2243 766 3051 3998 3691 2463 1645 2472 1683 2623 2287 943 3759 2736 2739 2749 2792 2964 3649 2296 980 3908 3331 1022 4074 3996 3684 2434 1531 2014 3946 3483 1629 2407 1423 1582 2220 676 2692 2563 2048 4082 4028 3811 2941 3558 1931 3613 2152 404 1604 2306 1019 4061 3944 3473 1589 2248 788 3140 258 1019 4061 3942 3468 1569 2168 468 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   guid: train-9179
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   input_ids: 2 1630 2410 1434 1628 2403 1407 1517 1960 3732 2625 2295 974 3883 3232 627 2495 1774 2987 3742 2668 2467 1661 2535 1933 3621 2181 520 2067 63 239 942 3755 2718 2666 2458 1626 2396 1380 1412 1538 2041 4056 3923 3390 1260 930 3708 2532 1923 3582 2028 4002 3708 2531 1918 3564 1955 3709 2536 1939 3646 2282 924 3681 2422 1484 1825 3192 468 1858 3323 989 3941 3463 1550 2090 156 610 2425 1494 1866 3355 1117 360 1427 1597 2280 916 3650 2297 983 3919 3376 1203 701 2791 2958 3626 2204 609 2421 1479 1805 3109 133 517 2055 15 46 172 675 2685 2534 1929 3607 2126 298 1178 601 2392 1361 1334 1225 792 3154 315 1246 875 3487 1648 2482 1721 2774 2889 3350 1098 283 1117 357 1414 1548 2081 119 461 1829 3208 532 2114 249 981 3912 3347 1085 229 901 3591 2062 42 154 604 2403 1407 1518 1962 3740 2657 2424 1492 1858 3322 987 3935 3438 1449 1688 2641 2358 1226 793 3159 334 1323 1181 613 2437 1542 2058 26 89 344 1362 1337 1239 846 3371 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   guid: train-10706
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   input_ids: 2 970 3868 3169 376 1489 1848 3283 829 3303 909 3624 2196 577 2293 967 3855 3117 168 657 2616 2260 834 3322 986 3931 3422 1388 1441 1653 2503 1806 3116 161 629 2501 1798 3081 23 78 300 1188 644 2564 2050 4092 4068 3971 3581 2024 3987 3646 2283 927 3694 2475 1694 2666 2459 1631 2414 1451 1695 2670 2475 1695 2670 2475 1694 2668 2467 1663 2542 1963 3743 2670 2475 1695 2670 2475 1695 2670 2475 1695 2670 2475 1694 2666 2459 1631 2414 1451 1694 2666 2459 1631 2414 1451 1694 2666 2459 1630 2410 1435 1630 2410 1435 1630 2410 1435 1631 2414 1451 1695 2670 2475 1695 2670 2475 1695 2670 2475 1695 2670 2475 1695 2670 2475 1695 2670 2476 1698 2682 2524 1891 3454 1514 1947 3678 2412 1443 1662 2540 1955 3710 2540 1955 3710 2540 1954 3706 2524 1891 3454 1516 1955 3710 2538 1947 3678 2412 1443 1662 2540 1955 3710 2540 1956 3716 2563 2046 4076 4003 3709 2535 1936 3633 2229 709 2824 3089 56 211 831 3310 940 3746 2681 2519 1870 3370 1179 606 2411 1439 1647 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   guid: train-10707
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   input_ids: 2 2326 1100 290 1147 477 1895 3469 1576 2193 565 2248 786 3132 225 886 3531 1823 3183 429 1702 2699 2589 2151 398 1578 2202 602 2393 1367 1359 1326 1194 665 2646 2377 1304 1108 322 1276 996 3972 3587 2047 4078 4011 3742 2666 2460 1636 2436 1537 2037 4040 3857 3125 199 782 3116 164 641 2550 1995 3869 3176 404 1604 2305 1013 4040 3857 3128 210 825 3287 846 3370 1178 604 2402 1402 1497 1878 3403 1309 1128 403 1598 2282 922 3674 2394 1370 1372 1377 1400 1489 1847 3278 812 3233 629 2503 1805 3111 142 556 2209 629 2504 1812 3137 248 977 3893 3269 774 3083 31 109 424 1681 2614 2251 800 3185 438 1740 2852 3202 508 2018 3964 3554 1915 3550 1898 3484 1636 2436 1537 2038 4042 3867 3165 357 1414 1545 2069 71 270 1066 154 604 2403 1405 1509 1927 3597 2088 146 572 2276 897 3576 2004 3905 3317 965 3848 3091 63 238 938 3738 2652 2404 1409 1528 2002 3900 3297 886 3529 1815 3151 301 1191 653 2600 2196 578 2300 993 3960 3539 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   guid: train-10708
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   input_ids: 2 3905 3320 980 3907 3325 1000 3985 3637 2248 785 3128 212 835 3327 1008 4019 3775 2800 2995 3776 2804 3009 3829 3015 3855 3117 168 657 2616 2258 827 3295 878 3497 1687 2639 2350 1196 676 2689 2550 1994 3866 3164 355 1407 1520 1969 3765 2760 2835 3133 229 901 3590 2058 26 91 350 1388 1441 1653 2501 1797 3077 5 7 14 41 151 591 2349 1189 648 2577 2104 212 833 3318 971 3871 3182 428 1697 2678 2508 1827 3198 491 1951 3694 2476 1698 2684 2530 1916 3553 1912 3538 1851 3296 884 3522 1788 3041 3960 3540 1859 3327 1005 4008 3732 2627 2304 1012 4036 3844 3076 4099 4094 4076 4003 3709 2536 1939 3645 2280 913 3640 2260 836 3329 1015 4046 3883 3229 615 2448 1588 2244 772 3076 4098 4092 4066 3964 3555 1917 3560 1940 3650 2298 987 3934 3436 1441 1656 2516 1859 3327 1006 4011 3742 2668 2467 1662 2540 1956 3716 2563 2047 4077 4008 3730 2620 2275 894 3561 1944 3667 2367 1262 940 3748 2689 2552 2002 3899 3293 872 3476 1601 2296 978 3900 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 15:59:05 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 15:59:09 - INFO - __main__ -   Saving features into cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_train_6-new-12w-0_300_dnaprom
06/26/2023 15:59:12 - INFO - __main__ -   ***** Running training *****
06/26/2023 15:59:12 - INFO - __main__ -     Num examples = 12236
06/26/2023 15:59:12 - INFO - __main__ -     Num Epochs = 30
06/26/2023 15:59:12 - INFO - __main__ -     Instantaneous batch size per GPU = 64
06/26/2023 15:59:12 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 64
06/26/2023 15:59:12 - INFO - __main__ -     Gradient Accumulation steps = 1
06/26/2023 15:59:12 - INFO - __main__ -     Total optimization steps = 5760
06/26/2023 15:59:12 - INFO - __main__ -     Continuing training from checkpoint, will skip to saved global_step
06/26/2023 15:59:12 - INFO - __main__ -     Continuing training from epoch 0
06/26/2023 15:59:12 - INFO - __main__ -     Continuing training from global step 0
06/26/2023 15:59:12 - INFO - __main__ -     Will skip the first 0 steps in the first epoch
06/26/2023 15:59:36 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
06/26/2023 15:59:36 - INFO - transformers.configuration_utils -   loading configuration file /data3/linming/DNABERT/examples/embeding_model/6-new-12w-0/config.json
06/26/2023 15:59:36 - INFO - transformers.configuration_utils -   Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "do_sample": false,
  "eos_token_ids": 0,
  "finetuning_task": "dnaprom",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "num_return_sequences": 1,
  "num_rnn_layer": 1,
  "output_attentions": false,
  "output_hidden_states": true,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "rnn": "lstm",
  "rnn_dropout": 0.0,
  "rnn_hidden": 768,
  "split": 10,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 4101
}

06/26/2023 15:59:37 - INFO - transformers.tokenization_utils -   loading file https://raw.githubusercontent.com/jerryji1993/DNABERT/master/src/transformers/dnabert-config/bert-config-6/vocab.txt from cache at /data3/linming/.cache/torch/transformers/ea1474aad40c1c8ed4e1cb7c11345ddda6df27a857fb29e1d4c901d9b900d32d.26f8bd5a32e49c2a8271a46950754a4a767726709b7741c68723bc1db840a87e
06/26/2023 15:59:37 - INFO - transformers.modeling_utils -   loading weights file /data3/linming/DNABERT/examples/embeding_model/6-new-12w-0/pytorch_model.bin
06/26/2023 15:59:39 - INFO - transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
06/26/2023 15:59:39 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']
06/26/2023 15:59:39 - INFO - __main__ -   finish loading model
06/26/2023 15:59:41 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, attention_probs_dropout_prob=0.1, beta1=0.9, beta2=0.999, cache_dir='', config_name='', data_dir='/data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/', device=device(type='cuda'), do_ensemble_pred=False, do_eval=True, do_lower_case=False, do_predict=False, do_train=True, do_visualize=False, early_stop=15, eval_all_checkpoints=False, evaluate_during_training=True, filter_num=128, filter_size=[2, 3, 4, 5, 6], fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, hidden_dropout_prob=0.1, learning_rate=0.0001, local_rank=-1, logging_steps=100, max_grad_norm=1.0, max_seq_length=300, max_steps=-1, model_name='mutant_Bert_fold5_100_15296_fold0', model_name_or_path='/data3/linming/DNABERT/examples/embeding_model/6-new-12w-0/', model_num=5, model_type='dna', n_gpu=1, n_process=8, no_cuda=False, num_rnn_layer=2, num_train_epochs=30.0, output_dir='/data3/linming/DNABERT/examples/output/fold5_100_15296/_fold0', output_mode='classification', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=64, per_gpu_pred_batch_size=8, per_gpu_train_batch_size=64, predict_dir=None, predict_scan_size=1, result_dir=None, rnn='lstm', rnn_dropout=0.0, rnn_hidden=768, save_steps=4000, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, task_name='dnaprom', tokenizer_name='dna6', visualize_data_dir=None, visualize_models=None, visualize_train=False, warmup_percent=0.1, warmup_steps=0, weight_decay=0.01)
06/26/2023 15:59:41 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_train_6-new-12w-0_300_dnaprom
06/26/2023 15:59:43 - INFO - __main__ -   ***** Running training *****
06/26/2023 15:59:43 - INFO - __main__ -     Num examples = 12236
06/26/2023 15:59:43 - INFO - __main__ -     Num Epochs = 30
06/26/2023 15:59:43 - INFO - __main__ -     Instantaneous batch size per GPU = 64
06/26/2023 15:59:43 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 64
06/26/2023 15:59:43 - INFO - __main__ -     Gradient Accumulation steps = 1
06/26/2023 15:59:43 - INFO - __main__ -     Total optimization steps = 5760
06/26/2023 15:59:43 - INFO - __main__ -     Continuing training from checkpoint, will skip to saved global_step
06/26/2023 15:59:43 - INFO - __main__ -     Continuing training from epoch 0
06/26/2023 15:59:43 - INFO - __main__ -     Continuing training from global step 0
06/26/2023 15:59:43 - INFO - __main__ -     Will skip the first 0 steps in the first epoch
06/26/2023 16:00:09 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
06/26/2023 16:00:09 - INFO - transformers.configuration_utils -   loading configuration file /data3/linming/DNABERT/examples/embeding_model/6-new-12w-0/config.json
06/26/2023 16:00:09 - INFO - transformers.configuration_utils -   Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "do_sample": false,
  "eos_token_ids": 0,
  "finetuning_task": "dnaprom",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "num_return_sequences": 1,
  "num_rnn_layer": 1,
  "output_attentions": false,
  "output_hidden_states": true,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "rnn": "lstm",
  "rnn_dropout": 0.0,
  "rnn_hidden": 768,
  "split": 10,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 4101
}

06/26/2023 16:00:10 - INFO - transformers.tokenization_utils -   loading file https://raw.githubusercontent.com/jerryji1993/DNABERT/master/src/transformers/dnabert-config/bert-config-6/vocab.txt from cache at /data3/linming/.cache/torch/transformers/ea1474aad40c1c8ed4e1cb7c11345ddda6df27a857fb29e1d4c901d9b900d32d.26f8bd5a32e49c2a8271a46950754a4a767726709b7741c68723bc1db840a87e
06/26/2023 16:00:10 - INFO - transformers.modeling_utils -   loading weights file /data3/linming/DNABERT/examples/embeding_model/6-new-12w-0/pytorch_model.bin
06/26/2023 16:00:12 - INFO - transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
06/26/2023 16:00:12 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']
06/26/2023 16:00:12 - INFO - __main__ -   finish loading model
06/26/2023 16:00:13 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, attention_probs_dropout_prob=0.1, beta1=0.9, beta2=0.999, cache_dir='', config_name='', data_dir='/data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/', device=device(type='cuda'), do_ensemble_pred=False, do_eval=True, do_lower_case=False, do_predict=False, do_train=True, do_visualize=False, early_stop=15, eval_all_checkpoints=False, evaluate_during_training=True, filter_num=128, filter_size=[2, 3, 4, 5, 6], fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, hidden_dropout_prob=0.1, learning_rate=0.0001, local_rank=-1, logging_steps=100, max_grad_norm=1.0, max_seq_length=300, max_steps=-1, model_name='mutant_Bert_fold5_100_15296_fold0', model_name_or_path='/data3/linming/DNABERT/examples/embeding_model/6-new-12w-0/', model_num=5, model_type='dna', n_gpu=1, n_process=8, no_cuda=False, num_rnn_layer=2, num_train_epochs=30.0, output_dir='/data3/linming/DNABERT/examples/output/fold5_100_15296/_fold0', output_mode='classification', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=48, per_gpu_pred_batch_size=8, per_gpu_train_batch_size=48, predict_dir=None, predict_scan_size=1, result_dir=None, rnn='lstm', rnn_dropout=0.0, rnn_hidden=768, save_steps=4000, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, task_name='dnaprom', tokenizer_name='dna6', visualize_data_dir=None, visualize_models=None, visualize_train=False, warmup_percent=0.1, warmup_steps=0, weight_decay=0.01)
06/26/2023 16:00:13 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_train_6-new-12w-0_300_dnaprom
06/26/2023 16:00:16 - INFO - __main__ -   ***** Running training *****
06/26/2023 16:00:16 - INFO - __main__ -     Num examples = 12236
06/26/2023 16:00:16 - INFO - __main__ -     Num Epochs = 30
06/26/2023 16:00:16 - INFO - __main__ -     Instantaneous batch size per GPU = 48
06/26/2023 16:00:16 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 48
06/26/2023 16:00:16 - INFO - __main__ -     Gradient Accumulation steps = 1
06/26/2023 16:00:16 - INFO - __main__ -     Total optimization steps = 7650
06/26/2023 16:00:16 - INFO - __main__ -     Continuing training from checkpoint, will skip to saved global_step
06/26/2023 16:00:16 - INFO - __main__ -     Continuing training from epoch 0
06/26/2023 16:00:16 - INFO - __main__ -     Continuing training from global step 0
06/26/2023 16:00:16 - INFO - __main__ -     Will skip the first 0 steps in the first epoch
06/26/2023 16:00:58 - INFO - __main__ -   Creating features from dataset file at /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   Writing example 0/1530
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   guid: dev-1
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   input_ids: 2 914 3644 2273 886 3529 1816 3154 313 1240 850 3388 1249 887 3533 1832 3219 573 2280 914 3644 2273 886 3529 1816 3154 316 1249 887 3533 1832 3219 573 2280 914 3644 2273 886 3529 1816 3154 313 1240 850 3388 1249 887 3533 1832 3219 573 2280 914 3641 2261 838 3337 1048 82 313 1237 839 3341 1064 147 573 2280 915 3648 2289 950 3785 2840 3154 316 1249 887 3533 1832 3219 573 2280 915 3645 2277 903 3597 2088 147 573 2280 915 3648 2289 950 3785 2840 3155 317 1256 914 3644 2273 887 3533 1832 3219 573 2280 914 3644 2273 886 3529 1816 3155 317 1256 914 3644 2273 887 3533 1832 3219 573 2280 915 3645 2277 903 3597 2088 147 573 2280 914 3644 2273 887 3533 1832 3218 569 2264 851 3392 1265 950 3785 2840 3155 317 1256 914 3644 2273 887 3533 1832 3219 573 2280 915 3645 2277 903 3597 2088 147 573 2280 914 3644 2273 887 3533 1832 3219 573 2280 914 3644 2273 886 3529 1816 3155 317 1256 914 3644 2273 887 3533 1832 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   guid: dev-2
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   input_ids: 2 2534 1931 3613 2150 395 1567 2158 426 1690 2650 2396 1379 1407 1518 1962 3738 2652 2403 1407 1517 1957 3719 2573 2085 135 525 2088 147 575 2285 936 3731 2622 2284 931 3709 2535 1933 3623 2189 552 2196 578 2297 981 3909 3334 1033 24 83 318 1259 925 3686 2441 1557 2117 262 1036 36 130 508 2018 3963 3550 1900 3489 1653 2501 1798 3084 35 125 485 1927 3597 2087 142 554 2201 599 2383 1326 1194 668 2657 2424 1491 1853 3302 905 3607 2126 300 1188 643 2557 2021 3976 3601 2103 205 807 3213 549 2183 527 2094 171 671 2670 2476 1697 2680 2516 1860 3331 1022 4074 3993 3672 2388 1345 1270 970 3868 3172 388 1540 2050 4091 4062 3948 3489 1656 2513 1845 3270 778 3100 98 378 1500 1892 3458 1530 2009 3928 3410 1337 1238 841 3351 1104 308 1217 758 3018 3867 3166 363 1440 1651 2494 1770 2971 3678 2409 1432 1619 2365 1254 905 3607 2127 303 1197 678 2697 2584 2129 309 1224 787 3133 229 901 3590 2060 33 120 466 1849 3288 851 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   guid: dev-3
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   input_ids: 2 1188 644 2562 2042 4060 3937 3447 1486 1835 3231 621 2469 1669 2567 2062 42 155 605 2407 1422 1579 2207 621 2470 1675 2590 2155 413 1637 2440 1555 2109 230 907 3616 2161 438 1740 2850 3195 477 1893 3463 1552 2100 196 772 3076 4099 4093 4069 3975 3599 2096 180 705 2805 3016 3857 3127 207 813 3238 651 2590 2154 412 1636 2433 1528 2004 3905 3318 972 3873 3189 453 1797 3080 17 56 212 835 3326 1004 4004 3715 2559 2031 4013 3751 2703 2607 2223 686 2730 2715 2654 2411 1439 1646 2474 1692 2660 2435 1535 2032 4018 3771 2782 2923 3487 1646 2474 1692 2660 2435 1535 2032 4018 3771 2782 2922 3482 1628 2401 1400 1492 1858 3324 994 3964 3556 1923 3582 2026 3993 3671 2384 1330 1209 727 2896 3377 1208 721 2870 3276 803 3197 485 1928 3603 2109 231 910 3626 2201 600 2388 1346 1276 996 3971 3584 2036 4033 3830 3017 3864 3153 311 1229 807 3213 552 2193 567 2254 809 3222 585 2328 1105 310 1227 797 3175 398 1579 2205 613 2440 1555 2111 237 933 3720 2577 2102 204 801 3189 455 1808 3123 189 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   guid: dev-4
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   input_ids: 2 1021 4072 3987 3648 2290 956 3810 2939 3552 1908 3524 1795 3069 4072 3985 3637 2245 776 3092 68 259 1024 4081 4024 3796 2882 3322 985 3928 3410 1340 1251 893 3560 1939 3647 2287 942 3756 2724 2692 2562 2044 4067 3966 3564 1956 3714 2556 2018 3964 3556 1924 3587 2046 4076 4004 3713 2552 2002 3900 3300 897 3576 2004 3908 3331 1021 4072 3988 3652 2308 1028 4100 4099 4095 4079 4016 3764 2755 2813 3047 3982 3627 2205 615 2447 1582 2220 676 2691 2558 2027 3998 3691 2464 1649 2488 1747 2877 3302 908 3620 2179 511 2029 4006 3724 2594 2171 479 1901 3494 1676 2593 2165 455 1805 3110 140 546 2171 480 1906 3516 1762 2937 3544 1875 3390 1259 925 3687 2448 1588 2241 758 3020 3875 3198 492 1954 3706 2523 1886 3435 1439 1645 2472 1683 2622 2282 924 3681 2422 1484 1825 3190 459 1822 3179 413 1639 2446 1580 2210 636 2531 1919 3568 1971 3776 2802 3003 3806 2923 3485 1637 2438 1547 2078 107 416 1651 2494 1771 2973 3688 2449 1592 2259 831 3310 940 3747 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   guid: dev-5
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   input_ids: 2 979 3903 3310 937 3736 2644 2371 1279 1008 4019 3773 2789 2952 3603 2111 239 942 3756 2721 2680 2515 1854 3307 928 3697 2488 1746 2874 3291 861 3432 1428 1602 2299 991 3951 3503 1711 2735 2736 2739 2752 2803 3005 3815 2959 3631 2222 682 2716 2659 2431 1518 1962 3739 2654 2412 1441 1653 2504 1812 3139 256 1009 4024 3794 2875 3296 882 3515 1759 2928 3505 1720 2772 2883 3327 1008 4019 3776 2804 3011 3840 3060 4035 3837 3048 3986 3643 2269 871 3471 1584 2227 704 2804 3010 3836 3044 3970 3579 2016 3954 3515 1760 2931 3519 1776 2995 3775 2800 2993 3767 2768 2868 3268 772 3075 4096 4084 4036 3843 3070 4076 4004 3715 2558 2028 4004 3716 2564 2049 4087 4047 3888 3251 703 2800 2995 3776 2804 3010 3834 3036 3937 3448 1490 1851 3295 880 3508 1731 2814 3051 3997 3688 2450 1596 2274 891 3552 1908 3524 1794 3066 4059 3935 3440 1460 1731 2814 3051 3999 3696 2484 1732 2818 3067 4063 3951 3504 1716 2755 2815 3055 4016 3764 2755 2816 3058 4028 3811 2942 3564 1955 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   Writing example 0/1530
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   guid: dev-1531
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   input_ids: 2 572 2273 888 3538 1851 3295 878 3500 1697 2679 2510 1836 3235 638 2540 1956 3713 2551 1999 3887 3246 683 2718 2666 2459 1631 2415 1455 1711 2733 2726 2697 2584 2132 321 1271 973 3877 3205 520 2068 65 245 965 3848 3092 65 248 979 3902 3307 926 3691 2462 1644 2468 1668 2563 2046 4074 3996 3684 2435 1533 2024 3986 3644 2275 894 3563 1950 3689 2453 1605 2312 1041 53 198 779 3103 111 430 1706 2714 2652 2404 1412 1537 2037 4038 3852 3107 126 492 1956 3715 2559 2030 4012 3747 2686 2537 1944 3668 2369 1272 977 3896 3284 835 3325 1000 3988 3651 2301 997 3973 3591 2061 40 147 574 2284 929 3704 2516 1859 3328 1012 4034 3833 3032 3924 3395 1278 1002 3993 3672 2388 1348 1283 1023 4077 4008 3729 2616 2259 831 3309 936 3732 2628 2308 1025 4088 4052 3908 3331 1021 4072 3988 3652 2306 1020 4068 3970 3580 2018 3961 3542 1868 3364 1155 509 2021 3975 3598 2089 149 583 2319 1069 168 658 2619 2269 870 3466 1563 2142 363 1439 1647 2478 1707 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   guid: dev-1532
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   input_ids: 2 1867 3358 1130 412 1634 2426 1498 1882 3418 1370 1370 1370 1369 1365 1349 1288 1041 54 203 797 3173 389 1544 2066 57 214 843 3358 1132 418 1660 2530 1915 3550 1898 3483 1629 2408 1428 1601 2296 980 3906 3324 993 3959 3534 1836 3235 637 2534 1930 3611 2144 369 1461 1735 2829 3110 137 535 2125 293 1157 519 2063 45 168 657 2613 2245 774 3083 29 101 392 1553 2101 197 776 3092 65 245 968 3858 3130 217 855 3405 1317 1158 521 2069 70 265 1046 74 284 1122 379 1501 1893 3463 1552 2098 185 725 2885 3336 1041 55 205 808 3219 574 2284 930 3706 2524 1891 3454 1516 1953 3702 2505 1813 3143 271 1070 171 671 2670 2475 1694 2666 2458 1626 2393 1366 1355 1310 1130 412 1636 2433 1525 1992 3858 3132 227 895 3565 1957 3717 2566 2058 26 92 354 1401 1493 1864 3346 1083 222 873 3477 1606 2313 1046 74 283 1117 357 1415 1550 2090 154 602 2395 1373 1382 1418 1561 2136 340 1347 1278 1004 4003 3710 2540 1954 3705 2518 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   guid: dev-1533
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   input_ids: 2 2473 1685 2632 2322 1082 219 861 3430 1417 1557 2119 270 1066 155 606 2412 1441 1654 2507 1822 3180 420 1667 2559 2029 4006 3722 2586 2140 356 1412 1538 2042 4058 3931 3422 1386 1436 1636 2433 1528 2004 3906 3322 986 3931 3423 1389 1448 1684 2626 2300 993 3958 3530 1818 3163 350 1385 1430 1610 2332 1121 374 1482 1819 3166 364 1441 1656 2515 1855 3310 940 3746 2684 2529 1911 3534 1834 3228 611 2429 1509 1926 3596 2082 122 476 1892 3457 1528 2001 3896 3282 827 3294 876 3492 1667 2557 2024 3988 3652 2307 1023 4078 4011 3743 2669 2470 1674 2588 2146 379 1503 1901 3496 1684 2627 2301 1000 3985 3638 2250 794 3162 348 1377 1399 1485 1831 3213 551 2190 553 2200 595 2366 1260 930 3708 2531 1917 3557 1927 3599 2094 171 671 2669 2470 1674 2587 2144 370 1468 1763 2941 3560 1940 3651 2302 1001 3991 3661 2341 1160 532 2116 257 1016 4049 3893 3272 786 3130 217 854 3401 1303 1102 300 1185 632 2513 1848 3282 825 3285 840 3348 1091 254 1004 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   guid: dev-1534
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   input_ids: 2 3270 777 3094 73 278 1097 279 1102 300 1188 642 2556 2017 3957 3528 1810 3131 222 874 3484 1634 2425 1493 1862 3339 1053 101 391 1550 2091 157 613 2440 1555 2109 230 906 3610 2140 354 1401 1496 1873 3384 1233 823 3277 805 3207 525 2086 140 545 2165 453 1799 3087 45 168 657 2615 2254 810 3227 606 2410 1435 1629 2405 1415 1550 2091 157 613 2438 1548 2084 129 502 1993 3862 3148 292 1154 505 2005 3911 3343 1070 171 670 2667 2463 1645 2472 1682 2620 2274 889 3543 1869 3367 1165 552 2196 577 2293 965 3848 3090 60 226 892 3556 1921 3573 1990 3851 3102 106 409 1624 2387 1341 1253 901 3589 2056 20 65 245 965 3846 3084 34 121 469 1861 3336 1043 61 231 911 3631 2223 686 2731 2717 2661 2437 1541 2054 10 25 85 327 1293 1064 148 578 2297 982 3914 3354 1114 345 1366 1354 1307 1119 365 1446 1674 2585 2135 333 1320 1170 570 2265 853 3399 1294 1066 155 605 2408 1425 1589 2247 781 3112 145 565 2245 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   guid: dev-1535
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   input_ids: 2 2015 3950 3499 1693 2663 2447 1581 2214 651 2591 2158 427 1695 2671 2479 1710 2730 2716 2660 2433 1526 1994 3867 3167 365 1448 1684 2627 2302 1004 4004 3715 2558 2026 3996 3683 2432 1523 1981 3815 2957 3623 2190 556 2211 637 2534 1932 3617 2167 461 1830 3211 544 2164 452 1795 3071 4078 4012 3745 2680 2513 1846 3275 799 3184 433 1719 2768 2868 3268 771 3071 4077 4006 3723 2590 2155 414 1644 2468 1665 2552 2001 3894 3275 798 3179 413 1639 2447 1584 2227 702 2796 2977 3704 2516 1857 3320 979 3902 3308 932 3713 2551 1997 3877 3208 532 2115 255 1005 4006 3724 2593 2165 456 1812 3137 248 980 3907 3326 1004 4002 3708 2530 1915 3551 1904 3507 1726 2796 2979 3710 2538 1947 3678 2412 1441 1653 2504 1809 3126 204 801 3191 461 1830 3211 542 2154 411 1629 2408 1428 1604 2306 1020 4068 3972 3586 2044 4068 3970 3580 2019 3967 3565 1958 3724 2596 2179 512 2035 4029 3815 2958 3627 2206 619 2464 1649 2487 1743 2863 3247 686 2729 2710 2633 2325 1093 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 16:00:58 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 16:01:02 - INFO - __main__ -   Saving features into cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:01:03 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:01:03 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:01:03 - INFO - __main__ -     Batch size = 48
06/26/2023 16:01:12 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:01:12 - INFO - __main__ -     acc = 0.6421568627450981
06/26/2023 16:01:12 - INFO - __main__ -     auc = 0.6937491990260157
06/26/2023 16:01:12 - INFO - __main__ -     f1 = 0.6202473543287008
06/26/2023 16:01:12 - INFO - __main__ -     mcc = 0.3241690807320487
06/26/2023 16:01:12 - INFO - __main__ -     precision = 0.6848056978633013
06/26/2023 16:01:12 - INFO - __main__ -     recall = 0.642156862745098
06/26/2023 16:01:12 - INFO - __main__ -   {"eval_acc": 0.6421568627450981, "eval_f1": 0.6202473543287008, "eval_mcc": 0.3241690807320487, "eval_auc": 0.6937491990260157, "eval_precision": 0.6848056978633013, "eval_recall": 0.642156862745098, "learning_rate": 1.3071895424836602e-05, "loss": 0.6856842356920242, "step": 100}
06/26/2023 16:01:55 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:01:55 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:01:55 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:01:55 - INFO - __main__ -     Batch size = 48
06/26/2023 16:02:04 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:02:04 - INFO - __main__ -     acc = 0.6888888888888889
06/26/2023 16:02:04 - INFO - __main__ -     auc = 0.7488124225725148
06/26/2023 16:02:04 - INFO - __main__ -     f1 = 0.6816958041958042
06/26/2023 16:02:04 - INFO - __main__ -     mcc = 0.3961041671679659
06/26/2023 16:02:04 - INFO - __main__ -     precision = 0.7076597942985958
06/26/2023 16:02:04 - INFO - __main__ -     recall = 0.6888888888888889
06/26/2023 16:02:04 - INFO - __main__ -   {"eval_acc": 0.6888888888888889, "eval_f1": 0.6816958041958042, "eval_mcc": 0.3961041671679659, "eval_auc": 0.7488124225725148, "eval_precision": 0.7076597942985958, "eval_recall": 0.6888888888888889, "learning_rate": 2.6143790849673204e-05, "loss": 0.6206475442647934, "step": 200}
06/26/2023 16:02:47 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:02:47 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:02:47 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:02:47 - INFO - __main__ -     Batch size = 48
06/26/2023 16:02:56 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:02:56 - INFO - __main__ -     acc = 0.6849673202614379
06/26/2023 16:02:56 - INFO - __main__ -     auc = 0.763124012132086
06/26/2023 16:02:56 - INFO - __main__ -     f1 = 0.6843977018626894
06/26/2023 16:02:56 - INFO - __main__ -     mcc = 0.3712772762165329
06/26/2023 16:02:56 - INFO - __main__ -     precision = 0.6863123924268503
06/26/2023 16:02:56 - INFO - __main__ -     recall = 0.6849673202614379
06/26/2023 16:02:56 - INFO - __main__ -   {"eval_acc": 0.6849673202614379, "eval_f1": 0.6843977018626894, "eval_mcc": 0.3712772762165329, "eval_auc": 0.763124012132086, "eval_precision": 0.6863123924268503, "eval_recall": 0.6849673202614379, "learning_rate": 3.9215686274509805e-05, "loss": 0.6059445956349373, "step": 300}
06/26/2023 16:03:39 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:03:39 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:03:39 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:03:39 - INFO - __main__ -     Batch size = 48
06/26/2023 16:03:48 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:03:48 - INFO - __main__ -     acc = 0.6908496732026144
06/26/2023 16:03:48 - INFO - __main__ -     auc = 0.7586590627536418
06/26/2023 16:03:48 - INFO - __main__ -     f1 = 0.6793291386033322
06/26/2023 16:03:48 - INFO - __main__ -     mcc = 0.4124865735511159
06/26/2023 16:03:48 - INFO - __main__ -     precision = 0.7228785233225243
06/26/2023 16:03:48 - INFO - __main__ -     recall = 0.6908496732026144
06/26/2023 16:03:48 - INFO - __main__ -   {"eval_acc": 0.6908496732026144, "eval_f1": 0.6793291386033322, "eval_mcc": 0.4124865735511159, "eval_auc": 0.7586590627536418, "eval_precision": 0.7228785233225243, "eval_recall": 0.6908496732026144, "learning_rate": 5.228758169934641e-05, "loss": 0.5831643885374069, "step": 400}
06/26/2023 16:04:31 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:04:32 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:04:32 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:04:32 - INFO - __main__ -     Batch size = 48
06/26/2023 16:04:41 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:04:41 - INFO - __main__ -     acc = 0.7091503267973857
06/26/2023 16:04:41 - INFO - __main__ -     auc = 0.7805476526122432
06/26/2023 16:04:41 - INFO - __main__ -     f1 = 0.7014318641070978
06/26/2023 16:04:41 - INFO - __main__ -     mcc = 0.4417644067992509
06/26/2023 16:04:41 - INFO - __main__ -     precision = 0.7332721565667828
06/26/2023 16:04:41 - INFO - __main__ -     recall = 0.7091503267973857
06/26/2023 16:04:41 - INFO - __main__ -   {"eval_acc": 0.7091503267973857, "eval_f1": 0.7014318641070978, "eval_mcc": 0.4417644067992509, "eval_auc": 0.7805476526122432, "eval_precision": 0.7332721565667828, "eval_recall": 0.7091503267973857, "learning_rate": 6.535947712418301e-05, "loss": 0.5838103768229485, "step": 500}
06/26/2023 16:05:24 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:05:24 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:05:24 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:05:24 - INFO - __main__ -     Batch size = 48
06/26/2023 16:05:33 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:05:33 - INFO - __main__ -     acc = 0.7052287581699347
06/26/2023 16:05:33 - INFO - __main__ -     auc = 0.7730949634755863
06/26/2023 16:05:33 - INFO - __main__ -     f1 = 0.7022118226260841
06/26/2023 16:05:33 - INFO - __main__ -     mcc = 0.41903595350419104
06/26/2023 16:05:33 - INFO - __main__ -     precision = 0.7138968386971536
06/26/2023 16:05:33 - INFO - __main__ -     recall = 0.7052287581699346
06/26/2023 16:05:33 - INFO - __main__ -   {"eval_acc": 0.7052287581699347, "eval_f1": 0.7022118226260841, "eval_mcc": 0.41903595350419104, "eval_auc": 0.7730949634755863, "eval_precision": 0.7138968386971536, "eval_recall": 0.7052287581699346, "learning_rate": 7.843137254901961e-05, "loss": 0.5536057767271996, "step": 600}
06/26/2023 16:06:16 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:06:17 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:06:17 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:06:17 - INFO - __main__ -     Batch size = 48
06/26/2023 16:06:26 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:06:26 - INFO - __main__ -     acc = 0.6813725490196079
06/26/2023 16:06:26 - INFO - __main__ -     auc = 0.7818193857063523
06/26/2023 16:06:26 - INFO - __main__ -     f1 = 0.6591703176244759
06/26/2023 16:06:26 - INFO - __main__ -     mcc = 0.42184421867865207
06/26/2023 16:06:26 - INFO - __main__ -     precision = 0.7452859401746682
06/26/2023 16:06:26 - INFO - __main__ -     recall = 0.6813725490196079
06/26/2023 16:06:26 - INFO - __main__ -   {"eval_acc": 0.6813725490196079, "eval_f1": 0.6591703176244759, "eval_mcc": 0.42184421867865207, "eval_auc": 0.7818193857063523, "eval_precision": 0.7452859401746682, "eval_recall": 0.6813725490196079, "learning_rate": 9.150326797385621e-05, "loss": 0.5537643575668335, "step": 700}
06/26/2023 16:07:08 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:07:09 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:07:09 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:07:09 - INFO - __main__ -     Batch size = 48
06/26/2023 16:07:18 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:07:18 - INFO - __main__ -     acc = 0.7209150326797386
06/26/2023 16:07:18 - INFO - __main__ -     auc = 0.7854778076808064
06/26/2023 16:07:18 - INFO - __main__ -     f1 = 0.7183503593747844
06/26/2023 16:07:18 - INFO - __main__ -     mcc = 0.4501032898802388
06/26/2023 16:07:18 - INFO - __main__ -     precision = 0.7292657148582484
06/26/2023 16:07:18 - INFO - __main__ -     recall = 0.7209150326797386
06/26/2023 16:07:18 - INFO - __main__ -   {"eval_acc": 0.7209150326797386, "eval_f1": 0.7183503593747844, "eval_mcc": 0.4501032898802388, "eval_auc": 0.7854778076808064, "eval_precision": 0.7292657148582484, "eval_recall": 0.7209150326797386, "learning_rate": 9.949164851125636e-05, "loss": 0.5382874310016632, "step": 800}
06/26/2023 16:08:01 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:08:02 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:08:02 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:08:02 - INFO - __main__ -     Batch size = 48
06/26/2023 16:08:11 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:08:11 - INFO - __main__ -     acc = 0.7006535947712418
06/26/2023 16:08:11 - INFO - __main__ -     auc = 0.7685761886453928
06/26/2023 16:08:11 - INFO - __main__ -     f1 = 0.6942748855941316
06/26/2023 16:08:11 - INFO - __main__ -     mcc = 0.41917991779672736
06/26/2023 16:08:11 - INFO - __main__ -     precision = 0.7189243154158216
06/26/2023 16:08:11 - INFO - __main__ -     recall = 0.7006535947712418
06/26/2023 16:08:11 - INFO - __main__ -   {"eval_acc": 0.7006535947712418, "eval_f1": 0.6942748855941316, "eval_mcc": 0.41917991779672736, "eval_auc": 0.7685761886453928, "eval_precision": 0.7189243154158216, "eval_recall": 0.7006535947712418, "learning_rate": 9.80392156862745e-05, "loss": 0.49896720111370085, "step": 900}
06/26/2023 16:08:53 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:08:54 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:08:54 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:08:54 - INFO - __main__ -     Batch size = 48
06/26/2023 16:09:03 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:09:03 - INFO - __main__ -     acc = 0.7254901960784313
06/26/2023 16:09:03 - INFO - __main__ -     auc = 0.7980191379383998
06/26/2023 16:09:03 - INFO - __main__ -     f1 = 0.721098107842065
06/26/2023 16:09:03 - INFO - __main__ -     mcc = 0.46589260301422486
06/26/2023 16:09:03 - INFO - __main__ -     precision = 0.7406489520589539
06/26/2023 16:09:03 - INFO - __main__ -     recall = 0.7254901960784313
06/26/2023 16:09:03 - INFO - __main__ -   {"eval_acc": 0.7254901960784313, "eval_f1": 0.721098107842065, "eval_mcc": 0.46589260301422486, "eval_auc": 0.7980191379383998, "eval_precision": 0.7406489520589539, "eval_recall": 0.7254901960784313, "learning_rate": 9.658678286129266e-05, "loss": 0.5112883794307709, "step": 1000}
06/26/2023 16:09:46 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:09:46 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:09:46 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:09:46 - INFO - __main__ -     Batch size = 48
06/26/2023 16:09:55 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:09:55 - INFO - __main__ -     acc = 0.711437908496732
06/26/2023 16:09:55 - INFO - __main__ -     auc = 0.7842214532871973
06/26/2023 16:09:55 - INFO - __main__ -     f1 = 0.7106368723962346
06/26/2023 16:09:55 - INFO - __main__ -     mcc = 0.42523671331960944
06/26/2023 16:09:55 - INFO - __main__ -     precision = 0.7138053952109285
06/26/2023 16:09:55 - INFO - __main__ -     recall = 0.7114379084967319
06/26/2023 16:09:55 - INFO - __main__ -   {"eval_acc": 0.711437908496732, "eval_f1": 0.7106368723962346, "eval_mcc": 0.42523671331960944, "eval_auc": 0.7842214532871973, "eval_precision": 0.7138053952109285, "eval_recall": 0.7114379084967319, "learning_rate": 9.513435003631082e-05, "loss": 0.39093362882733346, "step": 1100}
06/26/2023 16:10:38 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:10:39 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:10:39 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:10:39 - INFO - __main__ -     Batch size = 48
06/26/2023 16:10:48 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:10:48 - INFO - __main__ -     acc = 0.7225490196078431
06/26/2023 16:10:48 - INFO - __main__ -     auc = 0.7958975180486139
06/26/2023 16:10:48 - INFO - __main__ -     f1 = 0.722142809701611
06/26/2023 16:10:48 - INFO - __main__ -     mcc = 0.4464051861417038
06/26/2023 16:10:48 - INFO - __main__ -     precision = 0.7238580859234509
06/26/2023 16:10:48 - INFO - __main__ -     recall = 0.7225490196078431
06/26/2023 16:10:48 - INFO - __main__ -   {"eval_acc": 0.7225490196078431, "eval_f1": 0.722142809701611, "eval_mcc": 0.4464051861417038, "eval_auc": 0.7958975180486139, "eval_precision": 0.7238580859234509, "eval_recall": 0.7225490196078431, "learning_rate": 9.368191721132898e-05, "loss": 0.3806422357261181, "step": 1200}
06/26/2023 16:11:31 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:11:31 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:11:31 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:11:31 - INFO - __main__ -     Batch size = 48
06/26/2023 16:11:40 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:11:40 - INFO - __main__ -     acc = 0.719281045751634
06/26/2023 16:11:40 - INFO - __main__ -     auc = 0.7727681660899655
06/26/2023 16:11:40 - INFO - __main__ -     f1 = 0.7192807759330795
06/26/2023 16:11:40 - INFO - __main__ -     mcc = 0.4385629345700809
06/26/2023 16:11:40 - INFO - __main__ -     precision = 0.7192818888192573
06/26/2023 16:11:40 - INFO - __main__ -     recall = 0.719281045751634
06/26/2023 16:11:40 - INFO - __main__ -   {"eval_acc": 0.719281045751634, "eval_f1": 0.7192807759330795, "eval_mcc": 0.4385629345700809, "eval_auc": 0.7727681660899655, "eval_precision": 0.7192818888192573, "eval_recall": 0.719281045751634, "learning_rate": 9.222948438634713e-05, "loss": 0.3571820090711117, "step": 1300}
06/26/2023 16:12:23 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:12:23 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:12:23 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:12:23 - INFO - __main__ -     Batch size = 48
06/26/2023 16:12:32 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:12:32 - INFO - __main__ -     acc = 0.7225490196078431
06/26/2023 16:12:32 - INFO - __main__ -     auc = 0.7923785723439704
06/26/2023 16:12:32 - INFO - __main__ -     f1 = 0.7217978953171336
06/26/2023 16:12:32 - INFO - __main__ -     mcc = 0.44752114453070524
06/26/2023 16:12:32 - INFO - __main__ -     precision = 0.7249787205926363
06/26/2023 16:12:32 - INFO - __main__ -     recall = 0.7225490196078431
06/26/2023 16:12:32 - INFO - __main__ -   {"eval_acc": 0.7225490196078431, "eval_f1": 0.7217978953171336, "eval_mcc": 0.44752114453070524, "eval_auc": 0.7923785723439704, "eval_precision": 0.7249787205926363, "eval_recall": 0.7225490196078431, "learning_rate": 9.077705156136529e-05, "loss": 0.2507747048139572, "step": 1400}
06/26/2023 16:13:15 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:13:16 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:13:16 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:13:16 - INFO - __main__ -     Batch size = 48
06/26/2023 16:13:25 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:13:25 - INFO - __main__ -     acc = 0.7143790849673203
06/26/2023 16:13:25 - INFO - __main__ -     auc = 0.8076643598615917
06/26/2023 16:13:25 - INFO - __main__ -     f1 = 0.7091057332200983
06/26/2023 16:13:25 - INFO - __main__ -     mcc = 0.4452032487438489
06/26/2023 16:13:25 - INFO - __main__ -     precision = 0.7311395404107306
06/26/2023 16:13:25 - INFO - __main__ -     recall = 0.7143790849673203
06/26/2023 16:13:25 - INFO - __main__ -   {"eval_acc": 0.7143790849673203, "eval_f1": 0.7091057332200983, "eval_mcc": 0.4452032487438489, "eval_auc": 0.8076643598615917, "eval_precision": 0.7311395404107306, "eval_recall": 0.7143790849673203, "learning_rate": 8.932461873638345e-05, "loss": 0.2721372776478529, "step": 1500}
06/26/2023 16:14:07 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:14:08 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:14:08 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:14:08 - INFO - __main__ -     Batch size = 48
06/26/2023 16:14:17 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:14:17 - INFO - __main__ -     acc = 0.7238562091503268
06/26/2023 16:14:17 - INFO - __main__ -     auc = 0.7969259686445385
06/26/2023 16:14:17 - INFO - __main__ -     f1 = 0.7227761326943507
06/26/2023 16:14:17 - INFO - __main__ -     mcc = 0.45124234535139385
06/26/2023 16:14:17 - INFO - __main__ -     precision = 0.727400051813494
06/26/2023 16:14:17 - INFO - __main__ -     recall = 0.7238562091503268
06/26/2023 16:14:17 - INFO - __main__ -   {"eval_acc": 0.7238562091503268, "eval_f1": 0.7227761326943507, "eval_mcc": 0.45124234535139385, "eval_auc": 0.7969259686445385, "eval_precision": 0.727400051813494, "eval_recall": 0.7238562091503268, "learning_rate": 8.78721859114016e-05, "loss": 0.20179187094792725, "step": 1600}
06/26/2023 16:15:00 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:15:00 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:15:00 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:15:00 - INFO - __main__ -     Batch size = 48
06/26/2023 16:15:09 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:15:09 - INFO - __main__ -     acc = 0.7326797385620915
06/26/2023 16:15:09 - INFO - __main__ -     auc = 0.7946473578538168
06/26/2023 16:15:09 - INFO - __main__ -     f1 = 0.7326427340962225
06/26/2023 16:15:09 - INFO - __main__ -     mcc = 0.46548834987024923
06/26/2023 16:15:09 - INFO - __main__ -     precision = 0.7328086291526258
06/26/2023 16:15:09 - INFO - __main__ -     recall = 0.7326797385620916
06/26/2023 16:15:09 - INFO - __main__ -   {"eval_acc": 0.7326797385620915, "eval_f1": 0.7326427340962225, "eval_mcc": 0.46548834987024923, "eval_auc": 0.7946473578538168, "eval_precision": 0.7328086291526258, "eval_recall": 0.7326797385620916, "learning_rate": 8.641975308641975e-05, "loss": 0.1832216965034604, "step": 1700}
06/26/2023 16:15:52 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:15:53 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:15:53 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:15:53 - INFO - __main__ -     Batch size = 48
06/26/2023 16:16:02 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:16:02 - INFO - __main__ -     acc = 0.7258169934640523
06/26/2023 16:16:02 - INFO - __main__ -     auc = 0.8057913622965527
06/26/2023 16:16:02 - INFO - __main__ -     f1 = 0.7205269247587647
06/26/2023 16:16:02 - INFO - __main__ -     mcc = 0.4697682268741477
06/26/2023 16:16:02 - INFO - __main__ -     precision = 0.7443153010710097
06/26/2023 16:16:02 - INFO - __main__ -     recall = 0.7258169934640524
06/26/2023 16:16:02 - INFO - __main__ -   {"eval_acc": 0.7258169934640523, "eval_f1": 0.7205269247587647, "eval_mcc": 0.4697682268741477, "eval_auc": 0.8057913622965527, "eval_precision": 0.7443153010710097, "eval_recall": 0.7258169934640524, "learning_rate": 8.496732026143791e-05, "loss": 0.187685160972178, "step": 1800}
06/26/2023 16:16:44 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:16:45 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:16:45 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:16:45 - INFO - __main__ -     Batch size = 48
06/26/2023 16:16:54 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:16:54 - INFO - __main__ -     acc = 0.7215686274509804
06/26/2023 16:16:54 - INFO - __main__ -     auc = 0.7863926267674824
06/26/2023 16:16:54 - INFO - __main__ -     f1 = 0.7193511550961849
06/26/2023 16:16:54 - INFO - __main__ -     mcc = 0.45031040290603563
06/26/2023 16:16:54 - INFO - __main__ -     precision = 0.7287998320184779
06/26/2023 16:16:54 - INFO - __main__ -     recall = 0.7215686274509804
06/26/2023 16:16:54 - INFO - __main__ -   {"eval_acc": 0.7215686274509804, "eval_f1": 0.7193511550961849, "eval_mcc": 0.45031040290603563, "eval_auc": 0.7863926267674824, "eval_precision": 0.7287998320184779, "eval_recall": 0.7215686274509804, "learning_rate": 8.351488743645607e-05, "loss": 0.14512864626944066, "step": 1900}
06/26/2023 16:17:37 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:17:37 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:17:37 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:17:37 - INFO - __main__ -     Batch size = 48
06/26/2023 16:17:46 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:17:46 - INFO - __main__ -     acc = 0.7137254901960784
06/26/2023 16:17:46 - INFO - __main__ -     auc = 0.7832261096159597
06/26/2023 16:17:46 - INFO - __main__ -     f1 = 0.7102317834404819
06/26/2023 16:17:46 - INFO - __main__ -     mcc = 0.43814692211990963
06/26/2023 16:17:46 - INFO - __main__ -     precision = 0.7245552521449692
06/26/2023 16:17:46 - INFO - __main__ -     recall = 0.7137254901960783
06/26/2023 16:17:46 - INFO - __main__ -   {"eval_acc": 0.7137254901960784, "eval_f1": 0.7102317834404819, "eval_mcc": 0.43814692211990963, "eval_auc": 0.7832261096159597, "eval_precision": 0.7245552521449692, "eval_recall": 0.7137254901960783, "learning_rate": 8.206245461147423e-05, "loss": 0.14021038274280728, "step": 2000}
06/26/2023 16:18:29 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:18:29 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:18:29 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:18:29 - INFO - __main__ -     Batch size = 48
06/26/2023 16:18:38 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:18:38 - INFO - __main__ -     acc = 0.7261437908496732
06/26/2023 16:18:38 - INFO - __main__ -     auc = 0.7945565808022556
06/26/2023 16:18:38 - INFO - __main__ -     f1 = 0.7258960211802372
06/26/2023 16:18:38 - INFO - __main__ -     mcc = 0.453107474602485
06/26/2023 16:18:38 - INFO - __main__ -     precision = 0.7269644268910272
06/26/2023 16:18:38 - INFO - __main__ -     recall = 0.7261437908496732
06/26/2023 16:18:38 - INFO - __main__ -   {"eval_acc": 0.7261437908496732, "eval_f1": 0.7258960211802372, "eval_mcc": 0.453107474602485, "eval_auc": 0.7945565808022556, "eval_precision": 0.7269644268910272, "eval_recall": 0.7261437908496732, "learning_rate": 8.061002178649237e-05, "loss": 0.13731240677647294, "step": 2100}
06/26/2023 16:19:21 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:19:22 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:19:22 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:19:22 - INFO - __main__ -     Batch size = 48
06/26/2023 16:19:31 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:19:31 - INFO - __main__ -     acc = 0.7369281045751634
06/26/2023 16:19:31 - INFO - __main__ -     auc = 0.797891622880089
06/26/2023 16:19:31 - INFO - __main__ -     f1 = 0.7361040002853972
06/26/2023 16:19:31 - INFO - __main__ -     mcc = 0.4768437793122062
06/26/2023 16:19:31 - INFO - __main__ -     precision = 0.7399250927580582
06/26/2023 16:19:31 - INFO - __main__ -     recall = 0.7369281045751634
06/26/2023 16:19:31 - INFO - __main__ -   {"eval_acc": 0.7369281045751634, "eval_f1": 0.7361040002853972, "eval_mcc": 0.4768437793122062, "eval_auc": 0.797891622880089, "eval_precision": 0.7399250927580582, "eval_recall": 0.7369281045751634, "learning_rate": 7.915758896151053e-05, "loss": 0.1324319285247475, "step": 2200}
06/26/2023 16:20:13 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:20:14 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:20:14 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:20:14 - INFO - __main__ -     Batch size = 48
06/26/2023 16:20:23 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:20:23 - INFO - __main__ -     acc = 0.7258169934640523
06/26/2023 16:20:23 - INFO - __main__ -     auc = 0.7876075441069674
06/26/2023 16:20:23 - INFO - __main__ -     f1 = 0.7240480138011464
06/26/2023 16:20:23 - INFO - __main__ -     mcc = 0.45753814263970044
06/26/2023 16:20:23 - INFO - __main__ -     precision = 0.7317597413273416
06/26/2023 16:20:23 - INFO - __main__ -     recall = 0.7258169934640524
06/26/2023 16:20:23 - INFO - __main__ -   {"eval_acc": 0.7258169934640523, "eval_f1": 0.7240480138011464, "eval_mcc": 0.45753814263970044, "eval_auc": 0.7876075441069674, "eval_precision": 0.7317597413273416, "eval_recall": 0.7258169934640524, "learning_rate": 7.770515613652869e-05, "loss": 0.11620069305412471, "step": 2300}
06/26/2023 16:21:06 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:21:06 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:21:06 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:21:06 - INFO - __main__ -     Batch size = 48
06/26/2023 16:21:15 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:21:15 - INFO - __main__ -     acc = 0.7336601307189542
06/26/2023 16:21:15 - INFO - __main__ -     auc = 0.7976934085180913
06/26/2023 16:21:15 - INFO - __main__ -     f1 = 0.7333922302847995
06/26/2023 16:21:15 - INFO - __main__ -     mcc = 0.46826227431774275
06/26/2023 16:21:15 - INFO - __main__ -     precision = 0.7346030930421777
06/26/2023 16:21:15 - INFO - __main__ -     recall = 0.7336601307189542
06/26/2023 16:21:15 - INFO - __main__ -   {"eval_acc": 0.7336601307189542, "eval_f1": 0.7333922302847995, "eval_mcc": 0.46826227431774275, "eval_auc": 0.7976934085180913, "eval_precision": 0.7346030930421777, "eval_recall": 0.7336601307189542, "learning_rate": 7.625272331154685e-05, "loss": 0.10023922611959278, "step": 2400}
06/26/2023 16:21:58 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:21:58 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:21:58 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:21:58 - INFO - __main__ -     Batch size = 48
06/26/2023 16:22:07 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:22:07 - INFO - __main__ -     acc = 0.7248366013071895
06/26/2023 16:22:07 - INFO - __main__ -     auc = 0.7794506386432568
06/26/2023 16:22:07 - INFO - __main__ -     f1 = 0.7247508835892762
06/26/2023 16:22:07 - INFO - __main__ -     mcc = 0.4499535378214329
06/26/2023 16:22:07 - INFO - __main__ -     precision = 0.7251170238975118
06/26/2023 16:22:07 - INFO - __main__ -     recall = 0.7248366013071896
06/26/2023 16:22:07 - INFO - __main__ -   {"eval_acc": 0.7248366013071895, "eval_f1": 0.7247508835892762, "eval_mcc": 0.4499535378214329, "eval_auc": 0.7794506386432568, "eval_precision": 0.7251170238975118, "eval_recall": 0.7248366013071896, "learning_rate": 7.4800290486565e-05, "loss": 0.10493439556565136, "step": 2500}
06/26/2023 16:22:50 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:22:51 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:22:51 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:22:51 - INFO - __main__ -     Batch size = 48
06/26/2023 16:23:00 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:23:00 - INFO - __main__ -     acc = 0.7395424836601308
06/26/2023 16:23:00 - INFO - __main__ -     auc = 0.7888245973770772
06/26/2023 16:23:00 - INFO - __main__ -     f1 = 0.7393507184308674
06/26/2023 16:23:00 - INFO - __main__ -     mcc = 0.4797914731108799
06/26/2023 16:23:00 - INFO - __main__ -     precision = 0.740249510392196
06/26/2023 16:23:00 - INFO - __main__ -     recall = 0.7395424836601308
06/26/2023 16:23:00 - INFO - __main__ -   {"eval_acc": 0.7395424836601308, "eval_f1": 0.7393507184308674, "eval_mcc": 0.4797914731108799, "eval_auc": 0.7888245973770772, "eval_precision": 0.740249510392196, "eval_recall": 0.7395424836601308, "learning_rate": 7.334785766158315e-05, "loss": 0.08625849453732372, "step": 2600}
06/26/2023 16:23:42 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:23:43 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:23:43 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:23:43 - INFO - __main__ -     Batch size = 48
06/26/2023 16:23:52 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:23:52 - INFO - __main__ -     acc = 0.7359477124183007
06/26/2023 16:23:52 - INFO - __main__ -     auc = 0.7977087872185911
06/26/2023 16:23:52 - INFO - __main__ -     f1 = 0.7348148783731605
06/26/2023 16:23:52 - INFO - __main__ -     mcc = 0.4759795844597337
06/26/2023 16:23:52 - INFO - __main__ -     precision = 0.7400495458298927
06/26/2023 16:23:52 - INFO - __main__ -     recall = 0.7359477124183007
06/26/2023 16:23:52 - INFO - __main__ -   {"eval_acc": 0.7359477124183007, "eval_f1": 0.7348148783731605, "eval_mcc": 0.4759795844597337, "eval_auc": 0.7977087872185911, "eval_precision": 0.7400495458298927, "eval_recall": 0.7359477124183007, "learning_rate": 7.189542483660131e-05, "loss": 0.08800497326534241, "step": 2700}
06/26/2023 16:24:34 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:24:35 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:24:35 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:24:35 - INFO - __main__ -     Batch size = 48
06/26/2023 16:24:44 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:24:44 - INFO - __main__ -     acc = 0.7225490196078431
06/26/2023 16:24:44 - INFO - __main__ -     auc = 0.8022589602289719
06/26/2023 16:24:44 - INFO - __main__ -     f1 = 0.719981706773549
06/26/2023 16:24:44 - INFO - __main__ -     mcc = 0.45349126659963424
06/26/2023 16:24:44 - INFO - __main__ -     precision = 0.7310213826649596
06/26/2023 16:24:44 - INFO - __main__ -     recall = 0.7225490196078431
06/26/2023 16:24:44 - INFO - __main__ -   {"eval_acc": 0.7225490196078431, "eval_f1": 0.719981706773549, "eval_mcc": 0.45349126659963424, "eval_auc": 0.8022589602289719, "eval_precision": 0.7310213826649596, "eval_recall": 0.7225490196078431, "learning_rate": 7.044299201161947e-05, "loss": 0.10032268457114696, "step": 2800}
06/26/2023 16:25:26 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:25:27 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:25:27 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:25:27 - INFO - __main__ -     Batch size = 48
06/26/2023 16:25:36 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:25:36 - INFO - __main__ -     acc = 0.7294117647058823
06/26/2023 16:25:36 - INFO - __main__ -     auc = 0.80540198214362
06/26/2023 16:25:36 - INFO - __main__ -     f1 = 0.7280058399175542
06/26/2023 16:25:36 - INFO - __main__ -     mcc = 0.46364164705204614
06/26/2023 16:25:36 - INFO - __main__ -     precision = 0.7342551799345693
06/26/2023 16:25:36 - INFO - __main__ -     recall = 0.7294117647058824
06/26/2023 16:25:36 - INFO - __main__ -   {"eval_acc": 0.7294117647058823, "eval_f1": 0.7280058399175542, "eval_mcc": 0.46364164705204614, "eval_auc": 0.80540198214362, "eval_precision": 0.7342551799345693, "eval_recall": 0.7294117647058824, "learning_rate": 6.899055918663763e-05, "loss": 0.06646297965024132, "step": 2900}
06/26/2023 16:26:18 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:26:19 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:26:19 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:26:19 - INFO - __main__ -     Batch size = 48
06/26/2023 16:26:28 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:26:28 - INFO - __main__ -     acc = 0.7310457516339869
06/26/2023 16:26:28 - INFO - __main__ -     auc = 0.7940138408304498
06/26/2023 16:26:28 - INFO - __main__ -     f1 = 0.7286922797236698
06/26/2023 16:26:28 - INFO - __main__ -     mcc = 0.47032322310733987
06/26/2023 16:26:28 - INFO - __main__ -     precision = 0.7393507915961366
06/26/2023 16:26:28 - INFO - __main__ -     recall = 0.7310457516339869
06/26/2023 16:26:28 - INFO - __main__ -   {"eval_acc": 0.7310457516339869, "eval_f1": 0.7286922797236698, "eval_mcc": 0.47032322310733987, "eval_auc": 0.7940138408304498, "eval_precision": 0.7393507915961366, "eval_recall": 0.7310457516339869, "learning_rate": 6.753812636165577e-05, "loss": 0.07237609479110688, "step": 3000}
06/26/2023 16:27:11 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:27:11 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:27:11 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:27:11 - INFO - __main__ -     Batch size = 48
06/26/2023 16:27:20 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:27:20 - INFO - __main__ -     acc = 0.7088235294117647
06/26/2023 16:27:20 - INFO - __main__ -     auc = 0.7803026613695587
06/26/2023 16:27:20 - INFO - __main__ -     f1 = 0.6995000263967722
06/26/2023 16:27:20 - INFO - __main__ -     mcc = 0.4462557094607947
06/26/2023 16:27:20 - INFO - __main__ -     precision = 0.7384120204118361
06/26/2023 16:27:20 - INFO - __main__ -     recall = 0.7088235294117646
06/26/2023 16:27:20 - INFO - __main__ -   {"eval_acc": 0.7088235294117647, "eval_f1": 0.6995000263967722, "eval_mcc": 0.4462557094607947, "eval_auc": 0.7803026613695587, "eval_precision": 0.7384120204118361, "eval_recall": 0.7088235294117646, "learning_rate": 6.608569353667393e-05, "loss": 0.08462997691938653, "step": 3100}
06/26/2023 16:28:03 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:28:03 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:28:03 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:28:03 - INFO - __main__ -     Batch size = 48
06/26/2023 16:28:12 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:28:12 - INFO - __main__ -     acc = 0.7284313725490196
06/26/2023 16:28:12 - INFO - __main__ -     auc = 0.7689106753812636
06/26/2023 16:28:12 - INFO - __main__ -     f1 = 0.7283958397308374
06/26/2023 16:28:12 - INFO - __main__ -     mcc = 0.4569823308580384
06/26/2023 16:28:12 - INFO - __main__ -     precision = 0.7285509739600586
06/26/2023 16:28:12 - INFO - __main__ -     recall = 0.7284313725490197
06/26/2023 16:28:12 - INFO - __main__ -   {"eval_acc": 0.7284313725490196, "eval_f1": 0.7283958397308374, "eval_mcc": 0.4569823308580384, "eval_auc": 0.7689106753812636, "eval_precision": 0.7285509739600586, "eval_recall": 0.7284313725490197, "learning_rate": 6.463326071169209e-05, "loss": 0.06407347309635952, "step": 3200}
06/26/2023 16:28:55 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:28:56 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:28:56 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:28:56 - INFO - __main__ -     Batch size = 48
06/26/2023 16:29:05 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:29:05 - INFO - __main__ -     acc = 0.7245098039215686
06/26/2023 16:29:05 - INFO - __main__ -     auc = 0.7842167542398223
06/26/2023 16:29:05 - INFO - __main__ -     f1 = 0.7215212038374581
06/26/2023 16:29:05 - INFO - __main__ -     mcc = 0.458979077683543
06/26/2023 16:29:05 - INFO - __main__ -     precision = 0.7345797266662233
06/26/2023 16:29:05 - INFO - __main__ -     recall = 0.7245098039215686
06/26/2023 16:29:05 - INFO - __main__ -   {"eval_acc": 0.7245098039215686, "eval_f1": 0.7215212038374581, "eval_mcc": 0.458979077683543, "eval_auc": 0.7842167542398223, "eval_precision": 0.7345797266662233, "eval_recall": 0.7245098039215686, "learning_rate": 6.318082788671025e-05, "loss": 0.06587095387279987, "step": 3300}
06/26/2023 16:29:47 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:29:48 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:29:48 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:29:48 - INFO - __main__ -     Batch size = 48
06/26/2023 16:29:57 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:29:57 - INFO - __main__ -     acc = 0.7218954248366013
06/26/2023 16:29:57 - INFO - __main__ -     auc = 0.7870643769490369
06/26/2023 16:29:57 - INFO - __main__ -     f1 = 0.720897211190735
06/26/2023 16:29:57 - INFO - __main__ -     mcc = 0.44699976512839174
06/26/2023 16:29:57 - INFO - __main__ -     precision = 0.7251159416332851
06/26/2023 16:29:57 - INFO - __main__ -     recall = 0.7218954248366013
06/26/2023 16:29:57 - INFO - __main__ -   {"eval_acc": 0.7218954248366013, "eval_f1": 0.720897211190735, "eval_mcc": 0.44699976512839174, "eval_auc": 0.7870643769490369, "eval_precision": 0.7251159416332851, "eval_recall": 0.7218954248366013, "learning_rate": 6.17283950617284e-05, "loss": 0.056992451289552264, "step": 3400}
06/26/2023 16:30:40 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:30:40 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:30:40 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:30:40 - INFO - __main__ -     Batch size = 48
06/26/2023 16:30:49 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:30:49 - INFO - __main__ -     acc = 0.7225490196078431
06/26/2023 16:30:49 - INFO - __main__ -     auc = 0.7895839207142552
06/26/2023 16:30:49 - INFO - __main__ -     f1 = 0.7199104598393751
06/26/2023 16:30:49 - INFO - __main__ -     mcc = 0.4537287512858612
06/26/2023 16:30:49 - INFO - __main__ -     precision = 0.7312634089628804
06/26/2023 16:30:49 - INFO - __main__ -     recall = 0.7225490196078431
06/26/2023 16:30:49 - INFO - __main__ -   {"eval_acc": 0.7225490196078431, "eval_f1": 0.7199104598393751, "eval_mcc": 0.4537287512858612, "eval_auc": 0.7895839207142552, "eval_precision": 0.7312634089628804, "eval_recall": 0.7225490196078431, "learning_rate": 6.0275962236746555e-05, "loss": 0.05308971734950319, "step": 3500}
06/26/2023 16:31:32 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:31:32 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:31:32 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:31:32 - INFO - __main__ -     Batch size = 48
06/26/2023 16:31:41 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:31:41 - INFO - __main__ -     acc = 0.7303921568627451
06/26/2023 16:31:41 - INFO - __main__ -     auc = 0.7763168012302961
06/26/2023 16:31:41 - INFO - __main__ -     f1 = 0.7289526556680891
06/26/2023 16:31:41 - INFO - __main__ -     mcc = 0.46575804498785106
06/26/2023 16:31:41 - INFO - __main__ -     precision = 0.7353927314897055
06/26/2023 16:31:41 - INFO - __main__ -     recall = 0.7303921568627452
06/26/2023 16:31:41 - INFO - __main__ -   {"eval_acc": 0.7303921568627451, "eval_f1": 0.7289526556680891, "eval_mcc": 0.46575804498785106, "eval_auc": 0.7763168012302961, "eval_precision": 0.7353927314897055, "eval_recall": 0.7303921568627452, "learning_rate": 5.882352941176471e-05, "loss": 0.05568579092505388, "step": 3600}
06/26/2023 16:32:24 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:32:25 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:32:25 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:32:25 - INFO - __main__ -     Batch size = 48
06/26/2023 16:32:34 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:32:34 - INFO - __main__ -     acc = 0.7339869281045751
06/26/2023 16:32:34 - INFO - __main__ -     auc = 0.7873916015207826
06/26/2023 16:32:34 - INFO - __main__ -     f1 = 0.7339268004944516
06/26/2023 16:32:34 - INFO - __main__ -     mcc = 0.46818550653776486
06/26/2023 16:32:34 - INFO - __main__ -     precision = 0.7341986262946899
06/26/2023 16:32:34 - INFO - __main__ -     recall = 0.7339869281045752
06/26/2023 16:32:34 - INFO - __main__ -   {"eval_acc": 0.7339869281045751, "eval_f1": 0.7339268004944516, "eval_mcc": 0.46818550653776486, "eval_auc": 0.7873916015207826, "eval_precision": 0.7341986262946899, "eval_recall": 0.7339869281045752, "learning_rate": 5.7371096586782866e-05, "loss": 0.05704300788929686, "step": 3700}
06/26/2023 16:33:16 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:33:17 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:33:17 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:33:17 - INFO - __main__ -     Batch size = 48
06/26/2023 16:33:26 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:33:26 - INFO - __main__ -     acc = 0.730718954248366
06/26/2023 16:33:26 - INFO - __main__ -     auc = 0.7886308684693921
06/26/2023 16:33:26 - INFO - __main__ -     f1 = 0.7299432433544
06/26/2023 16:33:26 - INFO - __main__ -     mcc = 0.46411184052868915
06/26/2023 16:33:26 - INFO - __main__ -     precision = 0.7334006337067698
06/26/2023 16:33:26 - INFO - __main__ -     recall = 0.7307189542483661
06/26/2023 16:33:26 - INFO - __main__ -   {"eval_acc": 0.730718954248366, "eval_f1": 0.7299432433544, "eval_mcc": 0.46411184052868915, "eval_auc": 0.7886308684693921, "eval_precision": 0.7334006337067698, "eval_recall": 0.7307189542483661, "learning_rate": 5.591866376180102e-05, "loss": 0.053002432814973875, "step": 3800}
06/26/2023 16:34:08 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:34:09 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:34:09 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:34:09 - INFO - __main__ -     Batch size = 48
06/26/2023 16:34:18 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:34:18 - INFO - __main__ -     acc = 0.7287581699346405
06/26/2023 16:34:18 - INFO - __main__ -     auc = 0.7917666282199155
06/26/2023 16:34:18 - INFO - __main__ -     f1 = 0.7273488491927173
06/26/2023 16:34:18 - INFO - __main__ -     mcc = 0.46232073067867846
06/26/2023 16:34:18 - INFO - __main__ -     precision = 0.7335877862595419
06/26/2023 16:34:18 - INFO - __main__ -     recall = 0.7287581699346406
06/26/2023 16:34:18 - INFO - __main__ -   {"eval_acc": 0.7287581699346405, "eval_f1": 0.7273488491927173, "eval_mcc": 0.46232073067867846, "eval_auc": 0.7917666282199155, "eval_precision": 0.7335877862595419, "eval_recall": 0.7287581699346406, "learning_rate": 5.446623093681917e-05, "loss": 0.04060632884385996, "step": 3900}
06/26/2023 16:35:00 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:35:01 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:35:01 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:35:01 - INFO - __main__ -     Batch size = 48
06/26/2023 16:35:10 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:35:10 - INFO - __main__ -     acc = 0.726797385620915
06/26/2023 16:35:10 - INFO - __main__ -     auc = 0.772202785253535
06/26/2023 16:35:10 - INFO - __main__ -     f1 = 0.7249615636860157
06/26/2023 16:35:10 - INFO - __main__ -     mcc = 0.4597740804527587
06/26/2023 16:35:10 - INFO - __main__ -     precision = 0.7330187851123595
06/26/2023 16:35:10 - INFO - __main__ -     recall = 0.7267973856209151
06/26/2023 16:35:10 - INFO - __main__ -   {"eval_acc": 0.726797385620915, "eval_f1": 0.7249615636860157, "eval_mcc": 0.4597740804527587, "eval_auc": 0.772202785253535, "eval_precision": 0.7330187851123595, "eval_recall": 0.7267973856209151, "learning_rate": 5.301379811183733e-05, "loss": 0.04012736920092721, "step": 4000}
06/26/2023 16:35:10 - INFO - transformers.configuration_utils -   Configuration saved in /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold0/checkpoint-4000/config.json
06/26/2023 16:35:10 - INFO - transformers.modeling_utils -   Model weights saved in /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold0/checkpoint-4000/pytorch_model.bin
06/26/2023 16:35:10 - INFO - __main__ -   Saving model checkpoint to /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold0/checkpoint-4000
06/26/2023 16:35:11 - INFO - __main__ -   Saving optimizer and scheduler states to /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold0/checkpoint-4000
06/26/2023 16:35:53 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:35:54 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:35:54 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:35:54 - INFO - __main__ -     Batch size = 48
06/26/2023 16:36:03 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:36:03 - INFO - __main__ -     acc = 0.723202614379085
06/26/2023 16:36:03 - INFO - __main__ -     auc = 0.788517450553206
06/26/2023 16:36:03 - INFO - __main__ -     f1 = 0.721979050224347
06/26/2023 16:36:03 - INFO - __main__ -     mcc = 0.4503871186106809
06/26/2023 16:36:03 - INFO - __main__ -     precision = 0.7272022632605859
06/26/2023 16:36:03 - INFO - __main__ -     recall = 0.723202614379085
06/26/2023 16:36:03 - INFO - __main__ -   {"eval_acc": 0.723202614379085, "eval_f1": 0.721979050224347, "eval_mcc": 0.4503871186106809, "eval_auc": 0.788517450553206, "eval_precision": 0.7272022632605859, "eval_recall": 0.723202614379085, "learning_rate": 5.156136528685549e-05, "loss": 0.04363782866159454, "step": 4100}
06/26/2023 16:36:46 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:36:46 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:36:46 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:36:46 - INFO - __main__ -     Batch size = 48
06/26/2023 16:36:55 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:36:55 - INFO - __main__ -     acc = 0.723202614379085
06/26/2023 16:36:55 - INFO - __main__ -     auc = 0.7827771369985903
06/26/2023 16:36:55 - INFO - __main__ -     f1 = 0.7217512551854536
06/26/2023 16:36:55 - INFO - __main__ -     mcc = 0.4511363353311559
06/26/2023 16:36:55 - INFO - __main__ -     precision = 0.72795879163669
06/26/2023 16:36:55 - INFO - __main__ -     recall = 0.723202614379085
06/26/2023 16:36:55 - INFO - __main__ -   {"eval_acc": 0.723202614379085, "eval_f1": 0.7217512551854536, "eval_mcc": 0.4511363353311559, "eval_auc": 0.7827771369985903, "eval_precision": 0.72795879163669, "eval_recall": 0.723202614379085, "learning_rate": 5.0108932461873634e-05, "loss": 0.03118686609581346, "step": 4200}
06/26/2023 16:37:37 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:37:38 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:37:38 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:37:38 - INFO - __main__ -     Batch size = 48
06/26/2023 16:37:47 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:37:47 - INFO - __main__ -     acc = 0.7287581699346405
06/26/2023 16:37:47 - INFO - __main__ -     auc = 0.7695130078175061
06/26/2023 16:37:47 - INFO - __main__ -     f1 = 0.7282053850391608
06/26/2023 16:37:47 - INFO - __main__ -     mcc = 0.4593887962269488
06/26/2023 16:37:47 - INFO - __main__ -     precision = 0.7306344579508807
06/26/2023 16:37:47 - INFO - __main__ -     recall = 0.7287581699346406
06/26/2023 16:37:47 - INFO - __main__ -   {"eval_acc": 0.7287581699346405, "eval_f1": 0.7282053850391608, "eval_mcc": 0.4593887962269488, "eval_auc": 0.7695130078175061, "eval_precision": 0.7306344579508807, "eval_recall": 0.7287581699346406, "learning_rate": 4.865649963689179e-05, "loss": 0.03772203355154488, "step": 4300}
06/26/2023 16:38:29 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:38:30 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:38:30 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:38:30 - INFO - __main__ -     Batch size = 48
06/26/2023 16:38:39 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:38:39 - INFO - __main__ -     acc = 0.7179738562091503
06/26/2023 16:38:39 - INFO - __main__ -     auc = 0.7862646845230468
06/26/2023 16:38:39 - INFO - __main__ -     f1 = 0.713993262848442
06/26/2023 16:38:39 - INFO - __main__ -     mcc = 0.44861399104120386
06/26/2023 16:38:39 - INFO - __main__ -     precision = 0.730824141548436
06/26/2023 16:38:39 - INFO - __main__ -     recall = 0.7179738562091503
06/26/2023 16:38:39 - INFO - __main__ -   {"eval_acc": 0.7179738562091503, "eval_f1": 0.713993262848442, "eval_mcc": 0.44861399104120386, "eval_auc": 0.7862646845230468, "eval_precision": 0.730824141548436, "eval_recall": 0.7179738562091503, "learning_rate": 4.720406681190995e-05, "loss": 0.03472111797455, "step": 4400}
06/26/2023 16:39:21 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:39:22 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:39:22 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:39:22 - INFO - __main__ -     Batch size = 48
06/26/2023 16:39:31 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:39:31 - INFO - __main__ -     acc = 0.7271241830065359
06/26/2023 16:39:31 - INFO - __main__ -     auc = 0.7890091417830748
06/26/2023 16:39:31 - INFO - __main__ -     f1 = 0.7269687958384621
06/26/2023 16:39:31 - INFO - __main__ -     mcc = 0.45476629295950666
06/26/2023 16:39:31 - INFO - __main__ -     precision = 0.7276424052191092
06/26/2023 16:39:31 - INFO - __main__ -     recall = 0.727124183006536
06/26/2023 16:39:31 - INFO - __main__ -   {"eval_acc": 0.7271241830065359, "eval_f1": 0.7269687958384621, "eval_mcc": 0.45476629295950666, "eval_auc": 0.7890091417830748, "eval_precision": 0.7276424052191092, "eval_recall": 0.727124183006536, "learning_rate": 4.5751633986928104e-05, "loss": 0.03548350150304032, "step": 4500}
06/26/2023 16:40:13 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:40:14 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:40:14 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:40:14 - INFO - __main__ -     Batch size = 48
06/26/2023 16:40:23 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:40:23 - INFO - __main__ -     acc = 0.7303921568627451
06/26/2023 16:40:23 - INFO - __main__ -     auc = 0.782640010252467
06/26/2023 16:40:23 - INFO - __main__ -     f1 = 0.730387290727085
06/26/2023 16:40:23 - INFO - __main__ -     mcc = 0.46080094766238366
06/26/2023 16:40:23 - INFO - __main__ -     precision = 0.7304087910998744
06/26/2023 16:40:23 - INFO - __main__ -     recall = 0.7303921568627452
06/26/2023 16:40:23 - INFO - __main__ -   {"eval_acc": 0.7303921568627451, "eval_f1": 0.730387290727085, "eval_mcc": 0.46080094766238366, "eval_auc": 0.782640010252467, "eval_precision": 0.7304087910998744, "eval_recall": 0.7303921568627452, "learning_rate": 4.429920116194626e-05, "loss": 0.03105673577141715, "step": 4600}
06/26/2023 16:41:05 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:41:05 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:41:05 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:41:05 - INFO - __main__ -     Batch size = 48
06/26/2023 16:41:14 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:41:14 - INFO - __main__ -     acc = 0.7205882352941176
06/26/2023 16:41:14 - INFO - __main__ -     auc = 0.7919932504592252
06/26/2023 16:41:14 - INFO - __main__ -     f1 = 0.7182797090645492
06/26/2023 16:41:14 - INFO - __main__ -     mcc = 0.4485895589674584
06/26/2023 16:41:14 - INFO - __main__ -     precision = 0.7280636047365681
06/26/2023 16:41:14 - INFO - __main__ -     recall = 0.7205882352941176
06/26/2023 16:41:14 - INFO - __main__ -   {"eval_acc": 0.7205882352941176, "eval_f1": 0.7182797090645492, "eval_mcc": 0.4485895589674584, "eval_auc": 0.7919932504592252, "eval_precision": 0.7280636047365681, "eval_recall": 0.7205882352941176, "learning_rate": 4.2846768336964415e-05, "loss": 0.03160216083284467, "step": 4700}
06/26/2023 16:41:57 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:41:58 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:41:58 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:41:58 - INFO - __main__ -     Batch size = 48
06/26/2023 16:42:07 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:42:07 - INFO - __main__ -     acc = 0.7254901960784313
06/26/2023 16:42:07 - INFO - __main__ -     auc = 0.7906928958947413
06/26/2023 16:42:07 - INFO - __main__ -     f1 = 0.7210514960816548
06/26/2023 16:42:07 - INFO - __main__ -     mcc = 0.46605623897434817
06/26/2023 16:42:07 - INFO - __main__ -     precision = 0.7408180285267968
06/26/2023 16:42:07 - INFO - __main__ -     recall = 0.7254901960784313
06/26/2023 16:42:07 - INFO - __main__ -   {"eval_acc": 0.7254901960784313, "eval_f1": 0.7210514960816548, "eval_mcc": 0.46605623897434817, "eval_auc": 0.7906928958947413, "eval_precision": 0.7408180285267968, "eval_recall": 0.7254901960784313, "learning_rate": 4.1394335511982573e-05, "loss": 0.030726078276202315, "step": 4800}
06/26/2023 16:42:49 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:42:50 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:42:50 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:42:50 - INFO - __main__ -     Batch size = 48
06/26/2023 16:42:59 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:42:59 - INFO - __main__ -     acc = 0.7258169934640523
06/26/2023 16:42:59 - INFO - __main__ -     auc = 0.7956781579734291
06/26/2023 16:42:59 - INFO - __main__ -     f1 = 0.7258120447515446
06/26/2023 16:42:59 - INFO - __main__ -     mcc = 0.45165029054568384
06/26/2023 16:42:59 - INFO - __main__ -     precision = 0.7258332973759052
06/26/2023 16:42:59 - INFO - __main__ -     recall = 0.7258169934640523
06/26/2023 16:42:59 - INFO - __main__ -   {"eval_acc": 0.7258169934640523, "eval_f1": 0.7258120447515446, "eval_mcc": 0.45165029054568384, "eval_auc": 0.7956781579734291, "eval_precision": 0.7258332973759052, "eval_recall": 0.7258169934640523, "learning_rate": 3.9941902687000726e-05, "loss": 0.02830785311118234, "step": 4900}
06/26/2023 16:43:41 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:43:42 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:43:42 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:43:42 - INFO - __main__ -     Batch size = 48
06/26/2023 16:43:51 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:43:51 - INFO - __main__ -     acc = 0.7294117647058823
06/26/2023 16:43:51 - INFO - __main__ -     auc = 0.797316630355846
06/26/2023 16:43:51 - INFO - __main__ -     f1 = 0.72930063561486
06/26/2023 16:43:51 - INFO - __main__ -     mcc = 0.4592007118584518
06/26/2023 16:43:51 - INFO - __main__ -     precision = 0.7297891021866827
06/26/2023 16:43:51 - INFO - __main__ -     recall = 0.7294117647058824
06/26/2023 16:43:51 - INFO - __main__ -   {"eval_acc": 0.7294117647058823, "eval_f1": 0.72930063561486, "eval_mcc": 0.4592007118584518, "eval_auc": 0.797316630355846, "eval_precision": 0.7297891021866827, "eval_recall": 0.7294117647058824, "learning_rate": 3.8489469862018884e-05, "loss": 0.024857055134925757, "step": 5000}
06/26/2023 16:44:34 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:44:34 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:44:34 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:44:34 - INFO - __main__ -     Batch size = 48
06/26/2023 16:44:43 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:44:43 - INFO - __main__ -     acc = 0.7320261437908496
06/26/2023 16:44:43 - INFO - __main__ -     auc = 0.7980917595796488
06/26/2023 16:44:43 - INFO - __main__ -     f1 = 0.7317041979974261
06/26/2023 16:44:43 - INFO - __main__ -     mcc = 0.46517000664134245
06/26/2023 16:44:43 - INFO - __main__ -     precision = 0.7331452089228319
06/26/2023 16:44:43 - INFO - __main__ -     recall = 0.7320261437908497
06/26/2023 16:44:43 - INFO - __main__ -   {"eval_acc": 0.7320261437908496, "eval_f1": 0.7317041979974261, "eval_mcc": 0.46517000664134245, "eval_auc": 0.7980917595796488, "eval_precision": 0.7331452089228319, "eval_recall": 0.7320261437908497, "learning_rate": 3.7037037037037037e-05, "loss": 0.03421995468757814, "step": 5100}
06/26/2023 16:45:26 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:45:26 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:45:26 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:45:26 - INFO - __main__ -     Batch size = 48
06/26/2023 16:45:35 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:45:35 - INFO - __main__ -     acc = 0.7323529411764705
06/26/2023 16:45:35 - INFO - __main__ -     auc = 0.7932310222563971
06/26/2023 16:45:35 - INFO - __main__ -     f1 = 0.7315913377603651
06/26/2023 16:45:35 - INFO - __main__ -     mcc = 0.46736573020401434
06/26/2023 16:45:35 - INFO - __main__ -     precision = 0.7350204011440022
06/26/2023 16:45:35 - INFO - __main__ -     recall = 0.7323529411764707
06/26/2023 16:45:35 - INFO - __main__ -   {"eval_acc": 0.7323529411764705, "eval_f1": 0.7315913377603651, "eval_mcc": 0.46736573020401434, "eval_auc": 0.7932310222563971, "eval_precision": 0.7350204011440022, "eval_recall": 0.7323529411764707, "learning_rate": 3.5584604212055195e-05, "loss": 0.011152610064018518, "step": 5200}
06/26/2023 16:46:18 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:46:18 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:46:18 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:46:18 - INFO - __main__ -     Batch size = 48
06/26/2023 16:46:27 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:46:27 - INFO - __main__ -     acc = 0.7323529411764705
06/26/2023 16:46:27 - INFO - __main__ -     auc = 0.7959269938912383
06/26/2023 16:46:27 - INFO - __main__ -     f1 = 0.7314132201830941
06/26/2023 16:46:27 - INFO - __main__ -     mcc = 0.46799220684359677
06/26/2023 16:46:27 - INFO - __main__ -     precision = 0.7356508858435302
06/26/2023 16:46:27 - INFO - __main__ -     recall = 0.7323529411764707
06/26/2023 16:46:27 - INFO - __main__ -   {"eval_acc": 0.7323529411764705, "eval_f1": 0.7314132201830941, "eval_mcc": 0.46799220684359677, "eval_auc": 0.7959269938912383, "eval_precision": 0.7356508858435302, "eval_recall": 0.7323529411764707, "learning_rate": 3.413217138707335e-05, "loss": 0.027485327309623244, "step": 5300}
06/26/2023 16:47:10 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:47:11 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:47:11 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:47:11 - INFO - __main__ -     Batch size = 48
06/26/2023 16:47:20 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:47:20 - INFO - __main__ -     acc = 0.7297385620915032
06/26/2023 16:47:20 - INFO - __main__ -     auc = 0.7973100089709085
06/26/2023 16:47:20 - INFO - __main__ -     f1 = 0.7272721100378179
06/26/2023 16:47:20 - INFO - __main__ -     mcc = 0.46802030892473456
06/26/2023 16:47:20 - INFO - __main__ -     precision = 0.7383611697268748
06/26/2023 16:47:20 - INFO - __main__ -     recall = 0.7297385620915032
06/26/2023 16:47:20 - INFO - __main__ -   {"eval_acc": 0.7297385620915032, "eval_f1": 0.7272721100378179, "eval_mcc": 0.46802030892473456, "eval_auc": 0.7973100089709085, "eval_precision": 0.7383611697268748, "eval_recall": 0.7297385620915032, "learning_rate": 3.2679738562091506e-05, "loss": 0.009846124475734542, "step": 5400}
06/26/2023 16:48:03 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:48:03 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:48:03 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:48:03 - INFO - __main__ -     Batch size = 48
06/26/2023 16:48:12 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:48:12 - INFO - __main__ -     acc = 0.7356209150326798
06/26/2023 16:48:12 - INFO - __main__ -     auc = 0.7971570763381606
06/26/2023 16:48:12 - INFO - __main__ -     f1 = 0.7343336948826445
06/26/2023 16:48:12 - INFO - __main__ -     mcc = 0.4758758698683037
06/26/2023 16:48:12 - INFO - __main__ -     precision = 0.7402777396602355
06/26/2023 16:48:12 - INFO - __main__ -     recall = 0.7356209150326798
06/26/2023 16:48:12 - INFO - __main__ -   {"eval_acc": 0.7356209150326798, "eval_f1": 0.7343336948826445, "eval_mcc": 0.4758758698683037, "eval_auc": 0.7971570763381606, "eval_precision": 0.7402777396602355, "eval_recall": 0.7356209150326798, "learning_rate": 3.122730573710966e-05, "loss": 0.018705862376009463, "step": 5500}
06/26/2023 16:48:55 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:48:55 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:48:55 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:48:55 - INFO - __main__ -     Batch size = 48
06/26/2023 16:49:04 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:49:04 - INFO - __main__ -     acc = 0.7316993464052287
06/26/2023 16:49:04 - INFO - __main__ -     auc = 0.79381028664189
06/26/2023 16:49:04 - INFO - __main__ -     f1 = 0.7303432583292179
06/26/2023 16:49:04 - INFO - __main__ -     mcc = 0.46813101966947923
06/26/2023 16:49:04 - INFO - __main__ -     precision = 0.7364558370327808
06/26/2023 16:49:04 - INFO - __main__ -     recall = 0.7316993464052288
06/26/2023 16:49:04 - INFO - __main__ -   {"eval_acc": 0.7316993464052287, "eval_f1": 0.7303432583292179, "eval_mcc": 0.46813101966947923, "eval_auc": 0.79381028664189, "eval_precision": 0.7364558370327808, "eval_recall": 0.7316993464052288, "learning_rate": 2.9774872912127817e-05, "loss": 0.014473480622109491, "step": 5600}
06/26/2023 16:49:47 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:49:48 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:49:48 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:49:48 - INFO - __main__ -     Batch size = 48
06/26/2023 16:49:57 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:49:57 - INFO - __main__ -     acc = 0.7205882352941176
06/26/2023 16:49:57 - INFO - __main__ -     auc = 0.7905258661198685
06/26/2023 16:49:57 - INFO - __main__ -     f1 = 0.7166887265329893
06/26/2023 16:49:57 - INFO - __main__ -     mcc = 0.45384687177359845
06/26/2023 16:49:57 - INFO - __main__ -     precision = 0.7334405807545052
06/26/2023 16:49:57 - INFO - __main__ -     recall = 0.7205882352941176
06/26/2023 16:49:57 - INFO - __main__ -   {"eval_acc": 0.7205882352941176, "eval_f1": 0.7166887265329893, "eval_mcc": 0.45384687177359845, "eval_auc": 0.7905258661198685, "eval_precision": 0.7334405807545052, "eval_recall": 0.7205882352941176, "learning_rate": 2.832244008714597e-05, "loss": 0.008344001729565207, "step": 5700}
06/26/2023 16:50:39 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:50:40 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:50:40 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:50:40 - INFO - __main__ -     Batch size = 48
06/26/2023 16:50:49 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:50:49 - INFO - __main__ -     acc = 0.7303921568627451
06/26/2023 16:50:49 - INFO - __main__ -     auc = 0.7944937844418813
06/26/2023 16:50:49 - INFO - __main__ -     f1 = 0.7293815137505171
06/26/2023 16:50:49 - INFO - __main__ -     mcc = 0.4642650200541549
06/26/2023 16:50:49 - INFO - __main__ -     precision = 0.7338860095987261
06/26/2023 16:50:49 - INFO - __main__ -     recall = 0.7303921568627451
06/26/2023 16:50:49 - INFO - __main__ -   {"eval_acc": 0.7303921568627451, "eval_f1": 0.7293815137505171, "eval_mcc": 0.4642650200541549, "eval_auc": 0.7944937844418813, "eval_precision": 0.7338860095987261, "eval_recall": 0.7303921568627451, "learning_rate": 2.6870007262164125e-05, "loss": 0.010398505728735472, "step": 5800}
06/26/2023 16:51:32 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:51:32 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:51:32 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:51:32 - INFO - __main__ -     Batch size = 48
06/26/2023 16:51:41 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:51:41 - INFO - __main__ -     acc = 0.7310457516339869
06/26/2023 16:51:41 - INFO - __main__ -     auc = 0.8048876500491264
06/26/2023 16:51:41 - INFO - __main__ -     f1 = 0.7285226497926228
06/26/2023 16:51:41 - INFO - __main__ -     mcc = 0.47092798646092865
06/26/2023 16:51:41 - INFO - __main__ -     precision = 0.7399667239753758
06/26/2023 16:51:41 - INFO - __main__ -     recall = 0.7310457516339869
06/26/2023 16:51:41 - INFO - __main__ -   {"eval_acc": 0.7310457516339869, "eval_f1": 0.7285226497926228, "eval_mcc": 0.47092798646092865, "eval_auc": 0.8048876500491264, "eval_precision": 0.7399667239753758, "eval_recall": 0.7310457516339869, "learning_rate": 2.5417574437182277e-05, "loss": 0.015627270105833303, "step": 5900}
06/26/2023 16:52:24 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:52:24 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:52:24 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:52:24 - INFO - __main__ -     Batch size = 48
06/26/2023 16:52:33 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:52:33 - INFO - __main__ -     acc = 0.7313725490196078
06/26/2023 16:52:33 - INFO - __main__ -     auc = 0.8012604126617968
06/26/2023 16:52:33 - INFO - __main__ -     f1 = 0.7297651544321901
06/26/2023 16:52:33 - INFO - __main__ -     mcc = 0.46835026457489654
06/26/2023 16:52:33 - INFO - __main__ -     precision = 0.7370116628537321
06/26/2023 16:52:33 - INFO - __main__ -     recall = 0.7313725490196079
06/26/2023 16:52:33 - INFO - __main__ -   {"eval_acc": 0.7313725490196078, "eval_f1": 0.7297651544321901, "eval_mcc": 0.46835026457489654, "eval_auc": 0.8012604126617968, "eval_precision": 0.7370116628537321, "eval_recall": 0.7313725490196079, "learning_rate": 2.3965141612200436e-05, "loss": 0.0054030649904234455, "step": 6000}
06/26/2023 16:53:16 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:53:17 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:53:17 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:53:17 - INFO - __main__ -     Batch size = 48
06/26/2023 16:53:26 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:53:26 - INFO - __main__ -     acc = 0.7379084967320262
06/26/2023 16:53:26 - INFO - __main__ -     auc = 0.8057657311290529
06/26/2023 16:53:26 - INFO - __main__ -     f1 = 0.7371718503610658
06/26/2023 16:53:26 - INFO - __main__ -     mcc = 0.4785068412167488
06/26/2023 16:53:26 - INFO - __main__ -     precision = 0.7406059474928456
06/26/2023 16:53:26 - INFO - __main__ -     recall = 0.7379084967320262
06/26/2023 16:53:26 - INFO - __main__ -   {"eval_acc": 0.7379084967320262, "eval_f1": 0.7371718503610658, "eval_mcc": 0.4785068412167488, "eval_auc": 0.8057657311290529, "eval_precision": 0.7406059474928456, "eval_recall": 0.7379084967320262, "learning_rate": 2.251270878721859e-05, "loss": 0.006749365826217399, "step": 6100}
06/26/2023 16:54:09 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:54:09 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:54:09 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:54:09 - INFO - __main__ -     Batch size = 48
06/26/2023 16:54:18 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:54:18 - INFO - __main__ -     acc = 0.7326797385620915
06/26/2023 16:54:18 - INFO - __main__ -     auc = 0.8046652996710668
06/26/2023 16:54:18 - INFO - __main__ -     f1 = 0.7320358416032373
06/26/2023 16:54:18 - INFO - __main__ -     mcc = 0.4676121743685331
06/26/2023 16:54:18 - INFO - __main__ -     precision = 0.7349378881987578
06/26/2023 16:54:18 - INFO - __main__ -     recall = 0.7326797385620916
06/26/2023 16:54:18 - INFO - __main__ -   {"eval_acc": 0.7326797385620915, "eval_f1": 0.7320358416032373, "eval_mcc": 0.4676121743685331, "eval_auc": 0.8046652996710668, "eval_precision": 0.7349378881987578, "eval_recall": 0.7326797385620916, "learning_rate": 2.1060275962236747e-05, "loss": 0.005324505298594886, "step": 6200}
06/26/2023 16:55:01 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:55:02 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:55:02 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:55:02 - INFO - __main__ -     Batch size = 48
06/26/2023 16:55:11 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:55:11 - INFO - __main__ -     acc = 0.7359477124183007
06/26/2023 16:55:11 - INFO - __main__ -     auc = 0.8076355247981546
06/26/2023 16:55:11 - INFO - __main__ -     f1 = 0.7355273173342736
06/26/2023 16:55:11 - INFO - __main__ -     mcc = 0.47340282876073997
06/26/2023 16:55:11 - INFO - __main__ -     precision = 0.7374575239379264
06/26/2023 16:55:11 - INFO - __main__ -     recall = 0.7359477124183007
06/26/2023 16:55:11 - INFO - __main__ -   {"eval_acc": 0.7359477124183007, "eval_f1": 0.7355273173342736, "eval_mcc": 0.47340282876073997, "eval_auc": 0.8076355247981546, "eval_precision": 0.7374575239379264, "eval_recall": 0.7359477124183007, "learning_rate": 1.9607843137254903e-05, "loss": 0.0034544871308025906, "step": 6300}
06/26/2023 16:55:55 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:55:56 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:55:56 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:55:56 - INFO - __main__ -     Batch size = 48
06/26/2023 16:56:05 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:56:05 - INFO - __main__ -     acc = 0.7287581699346405
06/26/2023 16:56:05 - INFO - __main__ -     auc = 0.7958616344141143
06/26/2023 16:56:05 - INFO - __main__ -     f1 = 0.7273488491927173
06/26/2023 16:56:05 - INFO - __main__ -     mcc = 0.46232073067867846
06/26/2023 16:56:05 - INFO - __main__ -     precision = 0.7335877862595419
06/26/2023 16:56:05 - INFO - __main__ -     recall = 0.7287581699346406
06/26/2023 16:56:05 - INFO - __main__ -   {"eval_acc": 0.7287581699346405, "eval_f1": 0.7273488491927173, "eval_mcc": 0.46232073067867846, "eval_auc": 0.7958616344141143, "eval_precision": 0.7335877862595419, "eval_recall": 0.7287581699346406, "learning_rate": 1.8155410312273058e-05, "loss": 0.010526850440437557, "step": 6400}
06/26/2023 16:56:49 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:56:49 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:56:49 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:56:49 - INFO - __main__ -     Batch size = 48
06/26/2023 16:56:58 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:56:58 - INFO - __main__ -     acc = 0.7366013071895425
06/26/2023 16:56:58 - INFO - __main__ -     auc = 0.8037859370327651
06/26/2023 16:56:58 - INFO - __main__ -     f1 = 0.7352576342228209
06/26/2023 16:56:58 - INFO - __main__ -     mcc = 0.478080394896011
06/26/2023 16:56:58 - INFO - __main__ -     precision = 0.7415042278283195
06/26/2023 16:56:58 - INFO - __main__ -     recall = 0.7366013071895425
06/26/2023 16:56:58 - INFO - __main__ -   {"eval_acc": 0.7366013071895425, "eval_f1": 0.7352576342228209, "eval_mcc": 0.478080394896011, "eval_auc": 0.8037859370327651, "eval_precision": 0.7415042278283195, "eval_recall": 0.7366013071895425, "learning_rate": 1.6702977487291213e-05, "loss": 0.01224063790989021, "step": 6500}
06/26/2023 16:57:41 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:57:41 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:57:41 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:57:41 - INFO - __main__ -     Batch size = 48
06/26/2023 16:57:50 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:57:50 - INFO - __main__ -     acc = 0.7388888888888889
06/26/2023 16:57:50 - INFO - __main__ -     auc = 0.8016459481396044
06/26/2023 16:57:50 - INFO - __main__ -     f1 = 0.7385323293726513
06/26/2023 16:57:50 - INFO - __main__ -     mcc = 0.4790862097739441
06/26/2023 16:57:50 - INFO - __main__ -     precision = 0.7401991125069852
06/26/2023 16:57:50 - INFO - __main__ -     recall = 0.7388888888888889
06/26/2023 16:57:50 - INFO - __main__ -   {"eval_acc": 0.7388888888888889, "eval_f1": 0.7385323293726513, "eval_mcc": 0.4790862097739441, "eval_auc": 0.8016459481396044, "eval_precision": 0.7401991125069852, "eval_recall": 0.7388888888888889, "learning_rate": 1.5250544662309369e-05, "loss": 0.0076981676319701365, "step": 6600}
06/26/2023 16:58:33 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:58:33 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:58:33 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:58:33 - INFO - __main__ -     Batch size = 48
06/26/2023 16:58:42 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:58:42 - INFO - __main__ -     acc = 0.7297385620915032
06/26/2023 16:58:42 - INFO - __main__ -     auc = 0.8057287795292407
06/26/2023 16:58:42 - INFO - __main__ -     f1 = 0.7283214734809564
06/26/2023 16:58:42 - INFO - __main__ -     mcc = 0.4643467697478808
06/26/2023 16:58:42 - INFO - __main__ -     precision = 0.7346340124752461
06/26/2023 16:58:42 - INFO - __main__ -     recall = 0.7297385620915033
06/26/2023 16:58:42 - INFO - __main__ -   {"eval_acc": 0.7297385620915032, "eval_f1": 0.7283214734809564, "eval_mcc": 0.4643467697478808, "eval_auc": 0.8057287795292407, "eval_precision": 0.7346340124752461, "eval_recall": 0.7297385620915033, "learning_rate": 1.3798111837327524e-05, "loss": 0.011134987378354708, "step": 6700}
06/26/2023 16:59:26 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 16:59:27 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 16:59:27 - INFO - __main__ -     Num examples = 3060
06/26/2023 16:59:27 - INFO - __main__ -     Batch size = 48
06/26/2023 16:59:36 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 16:59:36 - INFO - __main__ -     acc = 0.7379084967320262
06/26/2023 16:59:36 - INFO - __main__ -     auc = 0.8071201247383485
06/26/2023 16:59:36 - INFO - __main__ -     f1 = 0.7377551312634882
06/26/2023 16:59:36 - INFO - __main__ -     mcc = 0.4763745042812189
06/26/2023 16:59:36 - INFO - __main__ -     precision = 0.7384663341645885
06/26/2023 16:59:36 - INFO - __main__ -     recall = 0.7379084967320262
06/26/2023 16:59:36 - INFO - __main__ -   {"eval_acc": 0.7379084967320262, "eval_f1": 0.7377551312634882, "eval_mcc": 0.4763745042812189, "eval_auc": 0.8071201247383485, "eval_precision": 0.7384663341645885, "eval_recall": 0.7379084967320262, "learning_rate": 1.2345679012345678e-05, "loss": 0.0034411074967647436, "step": 6800}
06/26/2023 17:00:20 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:00:20 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:00:20 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:00:20 - INFO - __main__ -     Batch size = 48
06/26/2023 17:00:30 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:00:30 - INFO - __main__ -     acc = 0.7415032679738562
06/26/2023 17:00:30 - INFO - __main__ -     auc = 0.8073595625614081
06/26/2023 17:00:30 - INFO - __main__ -     f1 = 0.7410711945635284
06/26/2023 17:00:30 - INFO - __main__ -     mcc = 0.48462663277694373
06/26/2023 17:00:30 - INFO - __main__ -     precision = 0.7431260818612853
06/26/2023 17:00:30 - INFO - __main__ -     recall = 0.7415032679738562
06/26/2023 17:00:30 - INFO - __main__ -   {"eval_acc": 0.7415032679738562, "eval_f1": 0.7410711945635284, "eval_mcc": 0.48462663277694373, "eval_auc": 0.8073595625614081, "eval_precision": 0.7431260818612853, "eval_recall": 0.7415032679738562, "learning_rate": 1.0893246187363835e-05, "loss": 0.004410464502943796, "step": 6900}
06/26/2023 17:01:13 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:01:14 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:01:14 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:01:14 - INFO - __main__ -     Batch size = 48
06/26/2023 17:01:23 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:01:23 - INFO - __main__ -     acc = 0.7395424836601308
06/26/2023 17:01:23 - INFO - __main__ -     auc = 0.8071060275962236
06/26/2023 17:01:23 - INFO - __main__ -     f1 = 0.7387456013842042
06/26/2023 17:01:23 - INFO - __main__ -     mcc = 0.4820346110870315
06/26/2023 17:01:23 - INFO - __main__ -     precision = 0.7425012076516462
06/26/2023 17:01:23 - INFO - __main__ -     recall = 0.7395424836601308
06/26/2023 17:01:23 - INFO - __main__ -   {"eval_acc": 0.7395424836601308, "eval_f1": 0.7387456013842042, "eval_mcc": 0.4820346110870315, "eval_auc": 0.8071060275962236, "eval_precision": 0.7425012076516462, "eval_recall": 0.7395424836601308, "learning_rate": 9.440813362381991e-06, "loss": 0.002156446084227355, "step": 7000}
06/26/2023 17:02:06 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:02:07 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:02:07 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:02:07 - INFO - __main__ -     Batch size = 48
06/26/2023 17:02:16 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:02:16 - INFO - __main__ -     acc = 0.7382352941176471
06/26/2023 17:02:16 - INFO - __main__ -     auc = 0.8079236618394634
06/26/2023 17:02:16 - INFO - __main__ -     f1 = 0.7371679494293917
06/26/2023 17:02:16 - INFO - __main__ -     mcc = 0.4803882162376083
06/26/2023 17:02:16 - INFO - __main__ -     precision = 0.7421690278456278
06/26/2023 17:02:16 - INFO - __main__ -     recall = 0.7382352941176471
06/26/2023 17:02:16 - INFO - __main__ -   {"eval_acc": 0.7382352941176471, "eval_f1": 0.7371679494293917, "eval_mcc": 0.4803882162376083, "eval_auc": 0.8079236618394634, "eval_precision": 0.7421690278456278, "eval_recall": 0.7382352941176471, "learning_rate": 7.988380537400146e-06, "loss": 0.0020628266035419072, "step": 7100}
06/26/2023 17:02:59 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:03:00 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:03:00 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:03:00 - INFO - __main__ -     Batch size = 48
06/26/2023 17:03:09 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:03:09 - INFO - __main__ -     acc = 0.7369281045751634
06/26/2023 17:03:09 - INFO - __main__ -     auc = 0.8068144730659149
06/26/2023 17:03:09 - INFO - __main__ -     f1 = 0.7357420822125018
06/26/2023 17:03:09 - INFO - __main__ -     mcc = 0.4781678007276995
06/26/2023 17:03:09 - INFO - __main__ -     precision = 0.7412593116198141
06/26/2023 17:03:09 - INFO - __main__ -     recall = 0.7369281045751634
06/26/2023 17:03:09 - INFO - __main__ -   {"eval_acc": 0.7369281045751634, "eval_f1": 0.7357420822125018, "eval_mcc": 0.4781678007276995, "eval_auc": 0.8068144730659149, "eval_precision": 0.7412593116198141, "eval_recall": 0.7369281045751634, "learning_rate": 6.535947712418301e-06, "loss": 0.0008410318480309798, "step": 7200}
06/26/2023 17:03:53 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:03:53 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:03:53 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:03:53 - INFO - __main__ -     Batch size = 48
06/26/2023 17:04:03 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:04:03 - INFO - __main__ -     acc = 0.7372549019607844
06/26/2023 17:04:03 - INFO - __main__ -     auc = 0.8073783587509078
06/26/2023 17:04:03 - INFO - __main__ -     f1 = 0.7365702479338844
06/26/2023 17:04:03 - INFO - __main__ -     mcc = 0.4769957057059318
06/26/2023 17:04:03 - INFO - __main__ -     precision = 0.7397473154205971
06/26/2023 17:04:03 - INFO - __main__ -     recall = 0.7372549019607844
06/26/2023 17:04:03 - INFO - __main__ -   {"eval_acc": 0.7372549019607844, "eval_f1": 0.7365702479338844, "eval_mcc": 0.4769957057059318, "eval_auc": 0.8073783587509078, "eval_precision": 0.7397473154205971, "eval_recall": 0.7372549019607844, "learning_rate": 5.083514887436457e-06, "loss": 0.0014333319477918848, "step": 7300}
06/26/2023 17:04:46 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:04:47 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:04:47 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:04:47 - INFO - __main__ -     Batch size = 48
06/26/2023 17:04:56 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:04:56 - INFO - __main__ -     acc = 0.7379084967320262
06/26/2023 17:04:56 - INFO - __main__ -     auc = 0.8072897176299716
06/26/2023 17:04:56 - INFO - __main__ -     f1 = 0.7369154534352402
06/26/2023 17:04:56 - INFO - __main__ -     mcc = 0.4794502414228982
06/26/2023 17:04:56 - INFO - __main__ -     precision = 0.7415556160856644
06/26/2023 17:04:56 - INFO - __main__ -     recall = 0.7379084967320262
06/26/2023 17:04:56 - INFO - __main__ -   {"eval_acc": 0.7379084967320262, "eval_f1": 0.7369154534352402, "eval_mcc": 0.4794502414228982, "eval_auc": 0.8072897176299716, "eval_precision": 0.7415556160856644, "eval_recall": 0.7379084967320262, "learning_rate": 3.6310820624546117e-06, "loss": 0.004444707516704512, "step": 7400}
06/26/2023 17:05:40 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:05:40 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:05:40 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:05:40 - INFO - __main__ -     Batch size = 48
06/26/2023 17:05:49 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:05:49 - INFO - __main__ -     acc = 0.7339869281045751
06/26/2023 17:05:49 - INFO - __main__ -     auc = 0.8062157717117349
06/26/2023 17:05:49 - INFO - __main__ -     f1 = 0.7326299184334693
06/26/2023 17:05:49 - INFO - __main__ -     mcc = 0.4727977385988175
06/26/2023 17:05:49 - INFO - __main__ -     precision = 0.7388356728246916
06/26/2023 17:05:49 - INFO - __main__ -     recall = 0.7339869281045752
06/26/2023 17:05:49 - INFO - __main__ -   {"eval_acc": 0.7339869281045751, "eval_f1": 0.7326299184334693, "eval_mcc": 0.4727977385988175, "eval_auc": 0.8062157717117349, "eval_precision": 0.7388356728246916, "eval_recall": 0.7339869281045752, "learning_rate": 2.178649237472767e-06, "loss": 0.005229566479101777, "step": 7500}
06/26/2023 17:06:33 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:06:34 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:06:34 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:06:34 - INFO - __main__ -     Batch size = 48
06/26/2023 17:06:43 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:06:43 - INFO - __main__ -     acc = 0.7336601307189542
06/26/2023 17:06:43 - INFO - __main__ -     auc = 0.8059024306890513
06/26/2023 17:06:43 - INFO - __main__ -     f1 = 0.7322888961240339
06/26/2023 17:06:43 - INFO - __main__ -     mcc = 0.47218239559474606
06/26/2023 17:06:43 - INFO - __main__ -     precision = 0.7385475583955787
06/26/2023 17:06:43 - INFO - __main__ -     recall = 0.7336601307189543
06/26/2023 17:06:43 - INFO - __main__ -   {"eval_acc": 0.7336601307189542, "eval_f1": 0.7322888961240339, "eval_mcc": 0.47218239559474606, "eval_auc": 0.8059024306890513, "eval_precision": 0.7385475583955787, "eval_recall": 0.7336601307189543, "learning_rate": 7.262164124909224e-07, "loss": 0.001630980925183394, "step": 7600}
06/26/2023 17:07:05 - INFO - __main__ -    global_step = 7650, average loss = 0.13579961591719658
06/26/2023 17:07:05 - INFO - __main__ -   Saving model checkpoint to /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold0
06/26/2023 17:07:05 - INFO - transformers.configuration_utils -   Configuration saved in /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold0/config.json
06/26/2023 17:07:06 - INFO - transformers.modeling_utils -   Model weights saved in /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold0/pytorch_model.bin
06/26/2023 17:07:06 - INFO - transformers.configuration_utils -   loading configuration file /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold0/config.json
06/26/2023 17:07:06 - INFO - transformers.configuration_utils -   Model config BertConfig {
  "architectures": [
    "BertForSequenceClassification"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "do_sample": false,
  "eos_token_ids": 0,
  "filter_num": 128,
  "filter_size": [
    2,
    3,
    4,
    5,
    6
  ],
  "finetuning_task": "dnaprom",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "num_return_sequences": 1,
  "num_rnn_layer": 2,
  "output_attentions": false,
  "output_hidden_states": true,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "rnn": "lstm",
  "rnn_dropout": 0.0,
  "rnn_hidden": 768,
  "split": 0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 4101
}

06/26/2023 17:07:06 - INFO - transformers.modeling_utils -   loading weights file /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold0/pytorch_model.bin
06/26/2023 17:07:08 - INFO - transformers.tokenization_utils -   Model name '/data3/linming/DNABERT/examples/output/fold5_100_15296/_fold0' not found in model shortcut name list (dna3, dna4, dna5, dna6). Assuming '/data3/linming/DNABERT/examples/output/fold5_100_15296/_fold0' is a path, a model identifier, or url to a directory containing tokenizer files.
06/26/2023 17:07:08 - INFO - transformers.tokenization_utils -   Didn't find file /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold0/added_tokens.json. We won't load it.
06/26/2023 17:07:08 - INFO - transformers.tokenization_utils -   loading file /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold0/vocab.txt
06/26/2023 17:07:08 - INFO - transformers.tokenization_utils -   loading file None
06/26/2023 17:07:08 - INFO - transformers.tokenization_utils -   loading file /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold0/special_tokens_map.json
06/26/2023 17:07:08 - INFO - transformers.tokenization_utils -   loading file /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold0/tokenizer_config.json
06/26/2023 17:07:08 - INFO - transformers.tokenization_utils -   Model name '/data3/linming/DNABERT/examples/output/fold5_100_15296/_fold0' not found in model shortcut name list (dna3, dna4, dna5, dna6). Assuming '/data3/linming/DNABERT/examples/output/fold5_100_15296/_fold0' is a path, a model identifier, or url to a directory containing tokenizer files.
06/26/2023 17:07:08 - INFO - transformers.tokenization_utils -   Didn't find file /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold0/added_tokens.json. We won't load it.
06/26/2023 17:07:08 - INFO - transformers.tokenization_utils -   loading file /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold0/vocab.txt
06/26/2023 17:07:08 - INFO - transformers.tokenization_utils -   loading file None
06/26/2023 17:07:08 - INFO - transformers.tokenization_utils -   loading file /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold0/special_tokens_map.json
06/26/2023 17:07:08 - INFO - transformers.tokenization_utils -   loading file /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold0/tokenizer_config.json
06/26/2023 17:07:08 - INFO - __main__ -   Evaluate the following checkpoints: ['/data3/linming/DNABERT/examples/output/fold5_100_15296/_fold0']
06/26/2023 17:07:08 - INFO - transformers.configuration_utils -   loading configuration file /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold0/config.json
06/26/2023 17:07:08 - INFO - transformers.configuration_utils -   Model config BertConfig {
  "architectures": [
    "BertForSequenceClassification"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "do_sample": false,
  "eos_token_ids": 0,
  "filter_num": 128,
  "filter_size": [
    2,
    3,
    4,
    5,
    6
  ],
  "finetuning_task": "dnaprom",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "num_return_sequences": 1,
  "num_rnn_layer": 2,
  "output_attentions": false,
  "output_hidden_states": true,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "rnn": "lstm",
  "rnn_dropout": 0.0,
  "rnn_hidden": 768,
  "split": 0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 4101
}

06/26/2023 17:07:08 - INFO - transformers.modeling_utils -   loading weights file /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold0/pytorch_model.bin
06/26/2023 17:07:10 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/0/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:07:11 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:07:11 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:07:11 - INFO - __main__ -     Batch size = 48
06/26/2023 17:07:20 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:07:20 - INFO - __main__ -     acc = 0.7336601307189542
06/26/2023 17:07:20 - INFO - __main__ -     auc = 0.8057981972745525
06/26/2023 17:07:20 - INFO - __main__ -     f1 = 0.7322380780236273
06/26/2023 17:07:20 - INFO - __main__ -     mcc = 0.4723645420798773
06/26/2023 17:07:20 - INFO - __main__ -     precision = 0.7387316354824673
06/26/2023 17:07:20 - INFO - __main__ -     recall = 0.7336601307189543
06/26/2023 17:07:20 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
06/26/2023 17:07:20 - INFO - transformers.configuration_utils -   loading configuration file /data3/linming/DNABERT/examples/embeding_model/6-new-12w-0/config.json
06/26/2023 17:07:20 - INFO - transformers.configuration_utils -   Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "do_sample": false,
  "eos_token_ids": 0,
  "finetuning_task": "dnaprom",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "num_return_sequences": 1,
  "num_rnn_layer": 1,
  "output_attentions": false,
  "output_hidden_states": true,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "rnn": "lstm",
  "rnn_dropout": 0.0,
  "rnn_hidden": 768,
  "split": 10,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 4101
}

06/26/2023 17:07:21 - INFO - transformers.tokenization_utils -   loading file https://raw.githubusercontent.com/jerryji1993/DNABERT/master/src/transformers/dnabert-config/bert-config-6/vocab.txt from cache at /data3/linming/.cache/torch/transformers/ea1474aad40c1c8ed4e1cb7c11345ddda6df27a857fb29e1d4c901d9b900d32d.26f8bd5a32e49c2a8271a46950754a4a767726709b7741c68723bc1db840a87e
06/26/2023 17:07:21 - INFO - transformers.modeling_utils -   loading weights file /data3/linming/DNABERT/examples/embeding_model/6-new-12w-0/pytorch_model.bin
06/26/2023 17:07:24 - INFO - transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
06/26/2023 17:07:24 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']
06/26/2023 17:07:24 - INFO - __main__ -   finish loading model
06/26/2023 17:07:24 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, attention_probs_dropout_prob=0.1, beta1=0.9, beta2=0.999, cache_dir='', config_name='', data_dir='/data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/', device=device(type='cuda'), do_ensemble_pred=False, do_eval=True, do_lower_case=False, do_predict=False, do_train=True, do_visualize=False, early_stop=15, eval_all_checkpoints=False, eval_batch_size=48, evaluate_during_training=True, filter_num=128, filter_size=[2, 3, 4, 5, 6], fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, hidden_dropout_prob=0.1, learning_rate=0.0001, local_rank=-1, logging_steps=100, max_grad_norm=1.0, max_seq_length=300, max_steps=-1, model_name='mutant_Bert_fold5_100_15296_fold1', model_name_or_path='/data3/linming/DNABERT/examples/embeding_model/6-new-12w-0/', model_num=5, model_type='dna', n_gpu=1, n_process=8, no_cuda=False, num_rnn_layer=2, num_train_epochs=30.0, output_dir='/data3/linming/DNABERT/examples/output/fold5_100_15296/_fold1', output_mode='classification', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=48, per_gpu_pred_batch_size=8, per_gpu_train_batch_size=48, predict_dir=None, predict_scan_size=1, result_dir=None, rnn='lstm', rnn_dropout=0.0, rnn_hidden=768, save_steps=4000, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, task_name='dnaprom', tokenizer_name='dna6', train_batch_size=48, visualize_data_dir=None, visualize_models=None, visualize_train=False, warmup_percent=0.1, warmup_steps=0, weight_decay=0.01)
06/26/2023 17:07:24 - INFO - __main__ -   Creating features from dataset file at /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   LOOKING AT /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/train.tsv
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   Writing example 0/1529
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   guid: train-1
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   input_ids: 2 3760 2739 2750 2793 2967 3664 2356 1217 760 3027 3904 3314 955 3805 2919 3470 1579 2207 624 2483 1727 2797 2984 3729 2616 2259 830 3308 931 3711 2543 1967 3757 2728 2708 2626 2299 991 3952 3508 1731 2815 3056 4020 3780 2817 3064 4051 3901 3304 916 3652 2305 1015 4045 3877 3208 529 2103 208 820 3268 769 3063 4047 3888 3251 703 2800 2996 3777 2808 3027 3903 3311 943 3759 2736 2740 2753 2807 3022 3883 3231 622 2474 1690 2652 2404 1409 1526 1996 3876 3204 515 2047 4078 4012 3748 2691 2560 2035 4030 3820 2980 3715 2560 2035 4030 3820 2980 3715 2560 2035 4030 3820 2980 3715 2560 2035 4030 3820 2980 3715 2558 2027 3998 3692 2466 1659 2526 1900 3489 1655 2510 1835 3230 619 2464 1652 2500 1794 3066 4059 3934 3435 1438 1644 2468 1668 2563 2046 4075 3999 3696 2484 1731 2813 3048 3985 3640 2260 835 3326 1003 3997 3687 2447 1583 2222 683 2718 2666 2458 1627 2398 1387 1439 1647 2479 1709 2725 2696 2580 2115 255 1005 4006 3723 2591 2158 428 1699 2687 2541 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   guid: train-2
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   input_ids: 2 3105 117 454 1801 3093 69 261 1030 9 21 69 262 1033 22 73 278 1097 277 1093 262 1036 34 121 470 1865 3349 1093 262 1033 21 69 262 1036 35 126 491 1950 3689 2455 1614 2346 1178 603 2397 1381 1415 1551 2093 167 654 2601 2199 590 2347 1182 620 2466 1658 2522 1882 3418 1371 1374 1386 1434 1626 2393 1368 1361 1333 1221 773 3077 7 13 37 134 524 2082 124 484 1922 3580 2017 3960 3538 1852 3298 891 3549 1893 3463 1549 2085 136 532 2113 248 979 3903 3310 940 3745 2679 2509 1830 3211 541 2150 396 1572 2179 511 2029 4007 3725 2597 2181 518 2060 36 131 512 2034 4028 3812 2946 3579 2015 3949 3494 1676 2594 2171 477 1894 3467 1565 2151 399 1581 2213 646 2572 2082 122 475 1886 3436 1443 1661 2536 1939 3647 2286 939 3743 2669 2472 1684 2626 2297 981 3912 3346 1084 226 891 3552 1907 3517 1766 2955 3615 2159 431 1709 2727 2702 2604 2209 631 2510 1835 3230 620 2467 1661 2536 1939 3647 2285 936 3730 2619 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   Writing example 0/1529
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   guid: train-3
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   input_ids: 2 3548 1890 3449 1493 1864 3345 1078 204 802 3194 475 1887 3439 1453 1704 2707 2621 2278 906 3610 2140 354 1401 1493 1863 3341 1061 133 517 2053 7 15 45 167 656 2612 2244 771 3069 4071 3983 3631 2224 691 2749 2792 2963 3646 2284 931 3711 2543 1967 3758 2732 2724 2692 2561 2040 4050 3898 3291 861 3431 1423 1581 2216 659 2623 2286 938 3739 2656 2420 1473 1781 3016 3860 3139 254 1002 3994 3675 2397 1384 1425 1592 2259 829 3304 915 3645 2280 916 3652 2305 1014 4043 3869 3174 395 1565 2151 398 1579 2206 620 2466 1660 2532 1923 3583 2031 4015 3760 2739 2749 2791 2957 3621 2184 531 2109 231 910 3627 2207 621 2470 1675 2592 2161 438 1740 2850 3195 479 1901 3493 1671 2573 2088 148 577 2293 967 3855 3119 173 677 2693 2568 2068 66 252 996 3972 3586 2044 4068 3972 3587 2046 4075 3998 3692 2467 1661 2536 1937 3640 2257 822 3276 804 3202 505 2005 3912 3345 1078 201 789 3142 266 1049 87 335 1325 1192 658 2617 2263 848 3378 1212 737 2936 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   guid: train-4
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   input_ids: 2 3854 3113 150 588 2340 1153 501 1991 3853 3112 148 578 2299 990 3947 3486 1643 2462 1644 2468 1667 2559 2030 4009 3733 2630 2314 1049 88 338 1339 1245 872 3476 1602 2297 982 3913 3351 1103 303 1197 679 2702 2604 2209 630 2508 1826 3195 477 1895 3470 1578 2202 603 2399 1390 1450 1691 2655 2413 1448 1684 2626 2300 994 3963 3549 1896 3475 1598 2284 929 3703 2509 1832 3220 580 2308 1027 4094 4075 3998 3692 2468 1667 2559 2029 4007 3725 2600 2195 574 2282 924 3684 2436 1537 2038 4044 3873 3191 464 1843 3264 753 2998 3787 2847 3184 435 1728 2802 3004 3810 2938 3546 1883 3421 1384 1428 1601 2296 980 3905 3318 971 3871 3183 429 1701 2695 2574 2091 160 628 2497 1782 3019 3871 3181 423 1677 2600 2195 573 2280 915 3647 2287 941 3751 2703 2606 2218 667 2654 2411 1439 1647 2478 1708 2721 2679 2509 1832 3219 575 2287 941 3751 2702 2602 2204 611 2429 1510 1931 3613 2152 404 1603 2303 1007 4013 3750 2698 2587 2143 367 1453 1704 2708 2625 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   guid: train-1530
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   input_ids: 2 1834 3226 601 2392 1364 1346 1274 987 3934 3436 1441 1653 2501 1800 3091 63 238 939 3741 2664 2449 1591 2253 807 3213 551 2189 550 2188 546 2170 476 1889 3448 1490 1852 3299 894 3562 1945 3671 2382 1323 1184 627 2493 1767 2957 3623 2189 550 2188 548 2180 514 2042 4060 3937 3446 1482 1820 3169 374 1482 1817 3158 330 1308 1124 385 1525 1990 3850 3099 95 368 1458 1722 2778 2906 3418 1370 1369 1366 1354 1306 1114 346 1369 1368 1364 1345 1271 974 3882 3225 597 2376 1299 1086 233 919 3661 2343 1165 549 2183 527 2094 171 669 2663 2447 1581 2215 655 2608 2228 707 2813 3047 3982 3627 2207 621 2472 1683 2624 2291 960 3828 3010 3833 3030 3916 3361 1144 468 1858 3324 993 3960 3537 1848 3282 828 3300 897 3574 1994 3866 3161 343 1357 1320 1169 567 2254 812 3235 639 2541 1957 3718 2572 2081 117 454 1803 3102 108 419 1663 2542 1961 3734 2636 2339 1150 489 1942 3657 2326 1097 278 1100 289 1142 458 1818 3163 350 1386 1435 1631 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   guid: train-5
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   input_ids: 2 2606 2219 671 2669 2471 1680 2612 2243 768 3060 4035 3840 3059 4031 3821 2984 3731 2624 2290 955 3807 2927 3503 1711 2735 2736 2740 2756 2820 3076 4100 4099 4095 4078 4012 3748 2692 2563 2048 4084 4035 3840 3060 4035 3840 3060 4035 3840 3060 4035 3840 3060 4036 3844 3076 4098 4089 4056 3923 3389 1256 915 3645 2280 915 3648 2292 962 3833 3032 3923 3389 1256 914 3644 2276 899 3584 2036 4035 3840 3060 4034 3836 3044 3971 3584 2036 4034 3833 3032 3923 3392 1268 962 3833 3032 3923 3392 1268 963 3837 3048 3987 3648 2292 963 3837 3048 3987 3648 2292 963 3840 3060 4035 3837 3048 3987 3645 2280 915 3645 2280 915 3645 2280 915 3645 2280 915 3645 2280 915 3645 2280 915 3645 2280 915 3645 2280 915 3645 2277 904 3601 2101 197 774 3083 31 109 421 1669 2568 2065 56 211 829 3301 901 3589 2056 20 67 256 1011 4030 3820 2979 3712 2548 1987 3838 3050 3993 3669 2375 1293 1062 139 541 2149 390 1548 2083 127 495 1968 3761 2744 2769 2872 3283 832 3315 959 3824 2996 3779 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   guid: train-1531
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   input_ids: 2 3254 713 2838 3145 277 1093 262 1034 27 93 360 1426 1596 2273 886 3532 1825 3189 453 1798 3084 34 122 474 1884 3427 1407 1517 1960 3729 2613 2245 773 3078 10 27 93 360 1427 1598 2283 927 3694 2474 1690 2649 2389 1350 1291 1056 113 437 1734 2826 3098 92 355 1405 1509 1925 3590 2060 34 124 482 1915 3551 1903 3501 1704 2708 2628 2306 1017 4054 3914 3354 1114 345 1366 1354 1305 1111 334 1322 1179 606 2411 1437 1638 2444 1570 2170 473 1877 3397 1285 1031 13 38 138 538 2140 353 1397 1480 1809 3125 198 779 3102 106 410 1628 2402 1404 1508 1921 3574 1994 3866 3162 347 1374 1388 1441 1654 2505 1816 3156 322 1273 981 3912 3348 1090 250 985 3927 3405 1318 1161 533 2120 275 1085 232 914 3644 2273 888 3537 1848 3281 821 3269 773 3077 5 7 14 42 155 605 2407 1422 1579 2206 620 2466 1658 2523 1885 3429 1413 1542 2057 21 70 265 1045 69 262 1033 22 74 282 1116 356 1412 1539 2046 4076 4004 3716 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   guid: train-1532
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   input_ids: 2 2139 349 1384 1426 1594 2266 858 3418 1371 1374 1386 1436 1633 2422 1483 1821 3174 396 1569 2165 453 1797 3079 16 51 191 749 2981 3719 2573 2085 133 517 2054 10 27 94 364 1441 1653 2502 1803 3104 116 451 1791 3053 4005 3717 2568 2065 56 212 834 3321 982 3913 3349 1094 266 1051 93 360 1428 1602 2297 981 3909 3334 1034 28 100 385 1525 1992 3857 3128 210 826 3290 860 3426 1402 1499 1885 3429 1416 1556 2116 257 1013 4039 3855 3118 170 668 2657 2421 1478 1804 3106 121 470 1868 3364 1153 501 1992 3857 3125 197 773 3080 18 60 226 889 3544 1874 3386 1242 858 3420 1377 1397 1480 1809 3125 200 787 3133 231 912 3633 2232 721 2869 3272 786 3130 218 858 3418 1372 1377 1397 1477 1797 3079 13 39 142 556 2209 629 2501 1800 3089 53 199 781 3112 146 572 2273 888 3538 1849 3286 842 3354 1115 351 1389 1447 1677 2598 2185 533 2118 265 1047 79 303 1198 682 2715 2653 2408 1425 1590 2252 803 3197 488 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   Writing example 0/1529
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   guid: train-1533
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   input_ids: 2 571 2271 878 3498 1690 2649 2391 1357 1317 1158 521 2071 78 300 1185 629 2501 1798 3083 31 110 428 1700 2690 2554 2011 3935 3437 1445 1670 2570 2074 90 348 1379 1406 1515 1950 3692 2468 1665 2552 2002 3898 3289 855 3408 1330 1210 730 2907 3422 1387 1437 1640 2451 1599 2285 934 3722 2588 2145 376 1489 1845 3269 773 3077 6 11 30 106 412 1636 2436 1537 2039 4045 3878 3211 543 2158 427 1696 2673 2488 1746 2874 3290 858 3419 1375 1389 1447 1677 2598 2187 542 2154 409 1624 2388 1345 1272 977 3894 3275 797 3173 390 1547 2077 101 389 1543 2064 49 184 721 2870 3273 789 3142 268 1058 123 477 1894 3465 1558 2121 277 1094 266 1049 86 331 1310 1129 408 1617 2357 1221 775 3085 37 133 518 2057 21 70 265 1047 78 298 1179 605 2408 1425 1590 2249 790 3148 292 1156 515 2045 4071 3983 3629 2214 650 2586 2138 345 1366 1353 1303 1102 300 1186 634 2522 1883 3422 1386 1434 1626 2396 1378 1402 1500 1892 3458 1530 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   guid: train-3059
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   input_ids: 2 1016 4049 3895 3278 812 3236 644 2564 2050 4092 4068 3971 3582 2026 3993 3671 2383 1328 1202 700 2785 2934 3532 1825 3190 460 1827 3198 492 1954 3708 2532 1923 3582 2028 4002 3705 2519 1870 3372 1187 637 2534 1931 3615 2159 430 1707 2720 2673 2486 1739 2847 3183 429 1704 2708 2625 2296 979 3903 3310 937 3736 2643 2367 1264 947 3773 2791 2957 3623 2190 555 2206 620 2467 1662 2539 1951 3695 2477 1704 2705 2613 2247 782 3114 156 612 2433 1528 2003 3903 3311 943 3757 2728 2708 2627 2303 1006 4011 3742 2668 2465 1656 2516 1859 3325 997 3973 3592 2065 56 211 829 3302 908 3620 2178 508 2018 3962 3548 1892 3460 1540 2049 4085 4039 3853 3112 148 579 2304 1012 4034 3836 3042 3964 3554 1915 3550 1899 3487 1647 2479 1710 2729 2712 2644 2372 1282 1020 4068 3971 3582 2026 3994 3676 2404 1411 1534 2028 4004 3713 2552 2003 3903 3309 936 3729 2613 2245 776 3090 59 223 877 3496 1684 2626 2297 983 3919 3373 1189 646 2572 2082 121 471 1869 3368 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   Writing example 0/1529
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   guid: train-3060
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   input_ids: 2 158 618 2458 1627 2399 1389 1448 1681 2613 2246 780 3106 122 476 1890 3450 1497 1877 3400 1298 1083 222 874 3481 1624 2386 1339 1245 870 3466 1561 2136 340 1348 1281 1016 4049 3894 3273 791 3149 294 1161 534 2124 292 1153 502 1993 3863 3149 295 1166 555 2205 615 2445 1573 2181 518 2058 27 94 362 1435 1630 2412 1444 1668 2564 2050 4091 4061 3944 3476 1603 2303 1005 4008 3729 2615 2253 807 3215 557 2215 655 2605 2214 652 2596 2177 503 1997 3878 3210 538 2138 348 1378 1402 1500 1889 3447 1487 1839 3246 682 2714 2651 2398 1388 1442 1658 2524 1889 3445 1480 1811 3134 236 930 3707 2525 1893 3462 1546 2075 94 364 1444 1667 2558 2026 3995 3678 2411 1439 1647 2478 1708 2723 2686 2539 1949 3687 2445 1575 2190 554 2202 603 2398 1386 1435 1631 2413 1446 1674 2588 2147 381 1510 1930 3609 2134 329 1303 1103 303 1197 680 2707 2621 2280 914 3641 2262 843 3357 1128 402 1593 2264 850 3385 1238 844 3361 1144 467 1853 3304 915 3645 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   guid: train-1534
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   input_ids: 2 851 3392 1267 960 3827 3005 3816 2961 3639 2255 815 3248 691 2750 2796 2980 3716 2564 2051 4095 4080 4019 3776 2804 3011 3839 3056 4019 3775 2799 2992 3763 2751 2800 2995 3773 2792 2964 3651 2301 1000 3987 3645 2280 915 3645 2280 915 3645 2277 903 3597 2088 147 573 2280 915 3645 2280 915 3645 2280 915 3645 2280 915 3645 2277 903 3597 2088 147 573 2280 915 3645 2277 903 3597 2088 147 573 2280 915 3645 2280 915 3645 2280 915 3645 2280 915 3645 2277 903 3597 2088 147 573 2280 915 3645 2280 915 3645 2280 915 3645 2280 915 3645 2280 915 3645 2280 915 3645 2280 915 3645 2280 915 3645 2280 915 3645 2280 914 3643 2271 878 3499 1693 2663 2447 1583 2222 683 2718 2668 2467 1663 2542 1963 3743 2669 2471 1678 2604 2211 639 2543 1965 3752 2705 2615 2254 812 3235 639 2543 1965 3752 2707 2622 2284 931 3709 2536 1939 3647 2288 945 3765 2759 2831 3118 172 676 2690 2553 2006 3915 3358 1132 419 1662 2538 1947 3679 2416 1459 1728 2804 3011 3839 3056 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   guid: train-3061
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   input_ids: 2 161 631 2510 1836 3233 631 2509 1830 3210 539 2142 363 1438 1642 2458 1627 2398 1387 1438 1643 2462 1643 2462 1643 2462 1642 2458 1627 2398 1387 1437 1640 2451 1600 2291 959 3823 2992 3763 2750 2793 2966 3660 2340 1156 515 2045 4071 3982 3628 2212 643 2557 2022 3977 3605 2120 273 1077 199 781 3109 136 532 2115 255 1007 4015 3757 2728 2708 2627 2304 1009 4024 3794 2873 3287 847 3376 1203 701 2792 2962 3644 2276 899 3583 2031 4015 3759 2736 2739 2751 2798 2987 3741 2662 2442 1562 2138 347 1373 1382 1419 1567 2158 426 1692 2660 2436 1540 2052 4098 4092 4066 3964 3553 1912 3539 1855 3310 940 3745 2677 2502 1804 3105 120 465 1846 3276 803 3200 499 1982 3820 2979 3712 2547 1983 3822 2985 3735 2640 2353 1208 724 2882 3324 993 3959 3535 1839 3245 680 2708 2627 2303 1005 4005 3719 2576 2100 193 757 3013 3848 3090 60 228 900 3585 2040 4052 3906 3324 995 3966 3564 1953 3702 2505 1816 3156 322 1276 993 3960 3538 1852 3300 899 3583 2032 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   guid: train-4588
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   input_ids: 2 877 3496 1683 2622 2283 928 3698 2491 1760 2931 3518 1771 2974 3692 2468 1665 2552 2004 3905 3319 975 3886 3244 676 2690 2553 2008 3921 3384 1236 833 3317 968 3858 3131 224 881 3510 1740 2850 3193 471 1871 3374 1196 676 2691 2559 2032 4019 3775 2797 2984 3731 2622 2282 924 3681 2424 1492 1860 3330 1019 4062 3948 3489 1653 2502 1803 3102 106 412 1635 2430 1515 1949 3688 2451 1598 2282 924 3682 2427 1503 1904 3505 1720 2772 2884 3331 1021 4072 3987 3648 2290 956 3812 2947 3584 2033 4021 3783 2832 3123 191 750 2987 3744 2674 2490 1755 2909 3432 1427 1600 2289 951 3790 2860 3236 644 2562 2044 4067 3968 3571 1982 3820 2980 3715 2560 2035 4030 3819 2975 3695 2480 1715 2749 2791 2960 3634 2234 732 2916 3459 1535 2029 4006 3724 2593 2167 463 1839 3248 691 2750 2796 2979 3712 2546 1979 3806 2924 3491 1661 2536 1939 3646 2283 927 3694 2475 1696 2674 2489 1749 2888 3345 1079 206 812 3235 640 2548 1985 3831 3022 3883 3231 623 2480 1715 2751 2800 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   guid: train-3062
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   input_ids: 2 3544 1876 3393 1272 980 3906 3322 987 3934 3436 1444 1668 2564 2051 4094 4075 3998 3690 2459 1631 2415 1455 1710 2731 2717 2664 2452 1601 2295 973 3880 3218 571 2269 872 3473 1591 2255 815 3247 685 2728 2708 2625 2295 975 3886 3242 668 2658 2427 1502 1899 3485 1639 2447 1581 2215 654 2601 2198 587 2333 1127 397 1574 2188 548 2178 507 2014 3947 3486 1642 2459 1631 2415 1455 1711 2734 2732 2723 2687 2543 1967 3757 2727 2701 2600 2193 568 2260 833 3318 969 3861 3144 273 1077 200 785 3125 200 785 3125 200 785 3125 200 785 3125 200 785 3125 200 785 3125 200 788 3137 247 973 3880 3218 572 2274 892 3556 1921 3575 1997 3879 3213 552 2194 572 2276 899 3583 2029 4006 3723 2589 2149 389 1544 2066 57 216 849 3384 1236 833 3320 980 3905 3318 972 3873 3192 465 1845 3272 785 3125 198 780 3105 120 468 1859 3327 1005 4005 3720 2577 2101 200 785 3125 200 785 3125 197 776 3092 65 248 977 3896 3281 821 3269 774 3084 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   guid: train-4589
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   input_ids: 2 1263 943 3758 2732 2723 2686 2539 1952 3700 2499 1791 3054 4010 3739 2656 2417 1464 1746 2874 3291 863 3437 1447 1678 2604 2211 639 2542 1961 3733 2632 2322 1084 228 899 3584 2033 4024 3794 2876 3299 893 3558 1931 3615 2157 423 1678 2603 2207 621 2472 1683 2622 2284 932 3715 2560 2035 4030 3820 2978 3708 2529 1910 3532 1828 3202 508 2020 3971 3583 2031 4015 3760 2737 2743 2766 2860 3235 637 2533 1928 3604 2113 247 973 3877 3205 518 2059 30 108 417 1655 2512 1844 3266 761 3030 3916 3364 1156 515 2048 4084 4036 3844 3075 4095 4077 4008 3732 2628 2306 1020 4068 3972 3588 2052 4099 4096 4084 4036 3844 3075 4096 4082 4027 3807 2926 3497 1686 2635 2333 1127 399 1582 2220 674 2683 2527 1903 3502 1708 2724 2692 2563 2046 4075 3999 3695 2479 1711 2733 2728 2708 2626 2300 994 3964 3556 1924 3585 2039 4045 3878 3212 547 2173 488 1938 3644 2273 886 3530 1818 3161 344 1364 1346 1276 995 3967 3568 1969 3765 2760 2834 3132 228 897 3574 1994 3866 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   Writing example 0/1529
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   guid: train-3063
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   input_ids: 2 3172 388 1540 2050 4092 4066 3964 3556 1922 3579 2013 3944 3473 1591 2253 806 3211 542 2156 420 1667 2559 2029 4008 3732 2626 2299 991 3949 3494 1675 2590 2155 414 1644 2465 1655 2511 1840 3252 707 2814 3051 3999 3694 2476 1700 2690 2555 2013 3941 3463 1551 2095 175 687 2733 2728 2708 2628 2305 1016 4051 3902 3308 932 3713 2549 1992 3857 3128 210 828 3299 895 3565 1960 3731 2624 2289 949 3781 2823 3087 45 167 656 2609 2232 724 2884 3330 1020 4065 3958 3532 1825 3191 464 1841 3255 717 2856 3219 575 2285 935 3728 2610 2235 735 2928 3508 1732 2819 3071 4079 4013 3752 2707 2621 2280 916 3651 2303 1006 4012 3747 2685 2534 1930 3612 2145 376 1492 1859 3327 1005 4005 3720 2579 2109 231 912 3634 2236 737 2936 3540 1860 3330 1020 4067 3967 3567 1967 3759 2735 2733 2727 2703 2607 2221 679 2701 2598 2188 546 2172 484 1924 3586 2043 4062 3948 3490 1660 2530 1916 3554 1916 3554 1916 3555 1917 3559 1936 3634 2236 740 2947 3584 2034 4028 3812 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   guid: train-4590
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   input_ids: 2 2797 2981 3719 2575 2093 167 655 2608 2227 702 2796 2980 3715 2558 2028 4004 3716 2561 2040 4052 3905 3320 978 3899 3296 884 3521 1784 3025 3895 3278 812 3233 632 2513 1847 3279 814 3241 663 2637 2343 1165 552 2193 568 2260 834 3324 996 3970 3580 2017 3959 3533 1832 3217 568 2258 826 3290 860 3428 1412 1537 2039 4047 3888 3249 696 2772 2882 3324 996 3969 3576 2003 3903 3311 944 3761 2744 2770 2874 3290 860 3428 1412 1537 2039 4047 3885 3237 648 2580 2114 252 996 3969 3576 2003 3903 3310 940 3745 2680 2514 1850 3290 860 3425 1400 1489 1847 3279 815 3245 680 2707 2622 2284 932 3713 2549 1991 3855 3119 176 689 2744 2770 2874 3290 860 3425 1400 1492 1857 3317 968 3857 3128 212 833 3320 980 3905 3320 980 3905 3320 980 3905 3320 977 3893 3269 776 3089 56 212 833 3320 980 3905 3320 977 3894 3273 792 3155 319 1261 935 3726 2604 2212 643 2559 2029 4008 3732 2627 2301 998 3978 3611 2143 367 1455 1710 2730 2715 2653 2407 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   guid: train-6117
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   input_ids: 2 4006 3724 2596 2178 508 2017 3960 3540 1858 3323 991 3951 3503 1712 2737 2742 2761 2840 3153 312 1234 827 3294 875 3487 1647 2477 1704 2707 2621 2280 916 3649 2294 972 3873 3191 461 1830 3210 540 2148 386 1530 2010 3930 3420 1379 1407 1519 1966 3755 2717 2661 2440 1554 2106 220 867 3454 1516 1956 3713 2549 1992 3858 3129 213 839 3343 1069 168 657 2616 2258 826 3291 862 3435 1437 1639 2445 1575 2192 563 2237 744 2961 3640 2259 830 3308 930 3706 2523 1886 3434 1436 1634 2425 1494 1868 3362 1148 482 1916 3554 1913 3542 1868 3361 1144 467 1854 3308 932 3715 2559 2031 4014 3754 2713 2645 2373 1286 1035 31 111 430 1708 2724 2689 2552 2001 3893 3269 773 3079 15 47 174 681 2709 2629 2310 1033 21 70 268 1057 117 456 1809 3127 205 805 3208 529 2104 209 823 3277 808 3217 566 2252 804 3201 501 1992 3860 3140 259 1022 4076 4003 3709 2536 1940 3652 2305 1015 4047 3887 3245 678 2700 2594 2172 484 1923 3581 2023 3983 3629 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   guid: train-4591
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   input_ids: 2 2028 4002 3705 2520 1874 3388 1252 899 3581 2024 3986 3644 2274 890 3548 1892 3458 1532 2020 3970 3580 2019 3967 3567 1968 3762 2747 2782 2923 3488 1650 2492 1764 2948 3586 2043 4062 3947 3488 1651 2493 1768 2964 3652 2306 1020 4068 3972 3586 2042 4058 3932 3425 1400 1491 1853 3304 915 3647 2285 934 3724 2595 2174 492 1955 3711 2543 1968 3764 2755 2815 3053 4006 3724 2594 2170 476 1892 3457 1528 2004 3906 3324 996 3971 3584 2036 4034 3836 3044 3970 3580 2020 3971 3584 2035 4031 3823 2992 3762 2747 2782 2923 3488 1650 2492 1764 2948 3586 2043 4062 3947 3488 1651 2493 1768 2964 3652 2307 1024 4084 4036 3842 3066 4059 3936 3441 1461 1735 2829 3112 145 567 2254 811 3232 628 2497 1783 3023 3885 3239 656 2611 2238 745 2967 3663 2349 1190 650 2587 2142 364 1443 1662 2540 1956 3715 2559 2031 4013 3751 2701 2600 2194 571 2272 881 3512 1748 2882 3323 989 3943 3469 1573 2184 529 2104 209 821 3272 787 3133 232 915 3646 2284 931 3711 2542 1963 3743 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   guid: train-6118
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   input_ids: 2 1371 1374 1386 1434 1626 2394 1370 1371 1373 1382 1417 1560 2130 316 1250 891 3551 1901 3494 1676 2596 2180 515 2046 4073 3990 3658 2331 1119 366 1451 1693 2661 2437 1541 2054 9 23 77 293 1158 521 2070 75 286 1130 412 1634 2426 1499 1886 3434 1434 1628 2404 1411 1534 2028 4001 3702 2508 1826 3193 469 1862 3340 1057 120 466 1852 3297 885 3527 1805 3112 147 574 2284 932 3715 2559 2029 4005 3717 2568 2065 53 198 778 3100 99 381 1512 1938 3642 2265 856 3409 1333 1224 785 3125 200 787 3134 236 931 3711 2544 1970 3770 2778 2906 3418 1371 1375 1390 1452 1697 2677 2504 1810 3130 220 867 3456 1522 1977 3797 2888 3346 1081 213 837 3333 1030 10 27 93 359 1421 1573 2181 518 2057 23 78 298 1178 601 2390 1355 1310 1129 408 1619 2365 1253 903 3598 2090 153 598 2377 1304 1107 317 1256 913 3640 2258 826 3290 858 3417 1368 1364 1345 1270 970 3866 3164 353 1398 1484 1825 3192 466 1849 3285 838 3338 1052 98 379 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   guid: train-4592
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   input_ids: 2 1894 3467 1565 2151 399 1584 2228 707 2814 3050 3995 3678 2410 1434 1625 2391 1359 1328 1202 700 2785 2935 3535 1837 3240 659 2622 2281 919 3663 2350 1196 673 2680 2515 1855 3310 940 3745 2680 2515 1853 3303 911 3631 2221 678 2700 2595 2173 488 1937 3640 2259 831 3311 942 3753 2711 2637 2343 1168 563 2240 755 3005 3816 2964 3652 2307 1023 4079 4014 3756 2724 2691 2559 2029 4007 3727 2608 2225 696 2772 2882 3323 989 3943 3471 1584 2227 703 2800 2996 3779 2815 3054 4009 3734 2635 2336 1139 446 1772 2979 3710 2540 1955 3711 2543 1966 3755 2719 2669 2470 1676 2595 2175 495 1966 3754 2716 2657 2421 1478 1802 3100 100 387 1535 2031 4014 3753 2711 2639 2350 1196 673 2677 2504 1812 3138 251 991 3950 3498 1692 2660 2435 1535 2029 4008 3729 2615 2255 814 3242 667 2653 2406 1419 1565 2151 399 1584 2226 700 2787 2943 3566 1964 3746 2683 2528 1908 3523 1791 3053 4007 3727 2606 2220 676 2690 2555 2016 3954 3515 1759 2926 3499 1693 2661 2439 1552 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   guid: train-6119
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   input_ids: 2 2721 2677 2504 1811 3134 234 923 3677 2407 1422 1579 2206 620 2465 1656 2515 1853 3302 905 3605 2119 269 1061 136 531 2109 232 913 3640 2258 827 3295 879 3502 1707 2718 2668 2468 1666 2555 2015 3951 3501 1704 2705 2615 2253 806 3211 541 2150 394 1563 2142 362 1433 1623 2383 1326 1196 676 2690 2555 2015 3951 3503 1709 2728 2708 2625 2295 973 3877 3205 520 2066 60 226 892 3556 1923 3583 2029 4008 3732 2625 2296 978 3900 3298 891 3549 1893 3461 1543 2063 48 180 705 2806 3017 3863 3151 303 1199 688 2740 2753 2808 3027 3903 3312 946 3772 2787 2944 3570 1977 3798 2890 3355 1117 357 1414 1548 2081 119 463 1838 3243 671 2670 2474 1691 2653 2407 1421 1574 2187 543 2158 428 1698 2684 2531 1918 3564 1954 3708 2530 1913 3544 1873 3382 1228 802 3196 484 1924 3586 2044 4065 3959 3533 1832 3220 580 2306 1018 4060 3938 3449 1496 1876 3393 1271 975 3887 3247 686 2732 2721 2677 2501 1800 3092 67 253 999 3981 3621 2184 529 2103 205 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   guid: train-6120
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   input_ids: 2 2085 133 517 2055 14 42 153 597 2374 1290 1050 90 346 1372 1377 1399 1485 1831 3213 551 2191 558 2219 670 2665 2453 1606 2313 1045 71 269 1062 139 541 2151 398 1578 2202 602 2395 1374 1388 1442 1658 2522 1882 3420 1380 1409 1525 1992 3857 3126 203 797 3173 389 1544 2067 63 237 934 3723 2592 2164 451 1791 3053 4008 3729 2615 2253 808 3217 568 2258 826 3292 865 3445 1478 1804 3107 125 485 1928 3603 2109 229 902 3595 2079 109 424 1681 2613 2247 781 3112 147 574 2284 932 3715 2557 2024 3987 3648 2291 957 3816 2961 3640 2257 821 3272 788 3137 245 965 3845 3077 5 5 5 8 18 58 218 859 3422 1387 1439 1645 2469 1672 2579 2109 229 902 3596 2084 131 509 2021 3973 3589 2055 14 42 154 601 2391 1358 1322 1178 602 2393 1365 1352 1299 1085 232 914 3642 2265 853 3397 1286 1034 26 90 346 1370 1370 1369 1365 1351 1294 1066 154 602 2393 1366 1354 1306 1114 346 1370 1369 1365 1349 1287 1037 37 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   Writing example 0/1529
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   guid: train-6121
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   input_ids: 2 1877 3397 1286 1036 33 117 454 1801 3094 74 282 1114 346 1372 1378 1404 1506 1913 3541 1864 3347 1086 234 923 3678 2409 1429 1606 2314 1052 99 381 1511 1933 3621 2181 518 2057 23 77 294 1161 534 2121 278 1098 283 1119 366 1452 1698 2684 2530 1916 3554 1914 3546 1882 3419 1376 1394 1465 1752 2900 3394 1276 993 3957 3528 1812 3138 252 993 3958 3529 1813 3141 264 1042 57 213 837 3336 1042 60 227 894 3562 1946 3675 2397 1383 1422 1580 2210 636 2532 1921 3576 2004 3908 3331 1022 4073 3989 3655 2318 1068 161 630 2506 1820 3172 385 1525 1992 3859 3135 239 941 3752 2706 2620 2273 885 3528 1809 3127 207 815 3246 682 2716 2660 2436 1537 2037 4039 3853 3109 135 525 2086 140 547 2174 489 1941 3653 2310 1036 36 130 505 2006 3915 3359 1133 424 1684 2628 2306 1017 4053 3912 3345 1078 201 790 3146 282 1113 341 1350 1290 1052 98 378 1499 1885 3430 1418 1564 2146 377 1495 1869 3368 1172 579 2301 997 3976 3602 2106 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   guid: train-7646
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   input_ids: 2 435 1728 2802 3001 3800 2900 3394 1276 994 3963 3549 1893 3461 1544 2066 60 228 898 3579 2016 3954 3514 1755 2910 3435 1439 1647 2479 1711 2734 2730 2715 2654 2411 1438 1644 2467 1663 2541 1957 3720 2578 2105 215 845 3367 1167 557 2216 660 2625 2293 967 3856 3121 184 724 2883 3327 1005 4008 3732 2625 2294 972 3873 3192 465 1847 3277 805 3205 520 2068 65 245 968 3859 3135 240 945 3766 2764 2850 3193 471 1871 3373 1192 660 2627 2301 1000 3986 3644 2273 887 3535 1837 3239 655 2605 2216 659 2622 2283 927 3694 2476 1697 2680 2513 1848 3284 835 3325 1000 3985 3639 2256 820 3267 765 3047 3983 3629 2215 655 2605 2214 651 2589 2150 396 1569 2167 463 1837 3239 655 2605 2214 651 2589 2151 399 1581 2216 657 2613 2248 787 3133 230 907 3613 2151 399 1581 2214 651 2589 2151 399 1581 2215 655 2605 2215 655 2605 2213 647 2573 2087 143 557 2215 655 2605 2215 655 2605 2214 651 2589 2151 397 1574 2187 541 2149 391 1549 2087 143 557 2214 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   guid: train-7647
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   input_ids: 2 3747 2688 2546 1980 3812 2945 3576 2001 3893 3271 782 3115 160 626 2491 1760 2930 3516 1763 2943 3567 1967 3757 2728 2707 2622 2283 928 3700 2500 1796 3075 4094 4076 4004 3713 2551 1997 3879 3215 557 2216 660 2627 2304 1011 4029 3816 2962 3644 2275 896 3570 1979 3805 2917 3463 1551 2093 165 647 2575 2093 168 660 2627 2303 1006 4011 3743 2669 2470 1676 2594 2171 480 1906 3514 1754 2908 3427 1405 1510 1931 3616 2164 451 1791 3054 4012 3748 2689 2549 1991 3854 3113 152 593 2360 1236 835 3326 1004 4004 3715 2560 2036 4035 3838 3050 3996 3684 2436 1539 2047 4077 4008 3731 2623 2288 947 3774 2796 2980 3716 2563 2045 4071 3984 3635 2238 747 2975 3694 2475 1696 2676 2499 1791 3053 4008 3732 2628 2307 1023 4078 4011 3742 2665 2456 1619 2367 1264 947 3774 2795 2975 3695 2477 1703 2702 2604 2212 644 2563 2046 4074 3996 3684 2433 1528 2002 3898 3291 861 3432 1427 1598 2284 931 3709 2535 1936 3636 2244 771 3069 4072 3985 3640 2260 835 3327 1006 4012 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   Writing example 0/1529
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   guid: train-7648
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   input_ids: 2 3759 2736 2740 2756 2820 3075 4096 4083 4031 3823 2992 3763 2751 2799 2990 3755 2718 2668 2467 1662 2539 1950 3692 2468 1667 2557 2024 3988 3652 2308 1028 4100 4097 4085 4040 3860 3137 248 978 3900 3300 900 3588 2051 4096 4083 4031 3824 2996 3780 2818 3065 4055 3918 3371 1181 615 2448 1588 2244 771 3070 4075 3999 3694 2476 1697 2678 2507 1823 3184 436 1731 2814 3051 4000 3699 2496 1780 3011 3840 3059 4031 3823 2991 3760 2737 2744 2772 2881 3319 976 3891 3261 744 2961 3640 2259 829 3304 915 3645 2280 915 3645 2280 916 3652 2308 1027 4093 4072 3987 3645 2277 903 3600 2100 195 768 3060 4035 3840 3060 4035 3839 3056 4019 3775 2800 2995 3776 2803 3008 3828 3009 3830 3018 3868 3172 388 1539 2048 4084 4035 3840 3060 4036 3844 3075 4095 4079 4015 3760 2740 2755 2816 3060 4035 3839 3056 4020 3779 2816 3060 4036 3843 3069 4070 3980 3620 2180 516 2051 4095 4080 4020 3779 2816 3059 4030 3820 2979 3711 2544 1972 3780 2820 3076 4099 4096 4083 4032 3827 3008 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   guid: train-9175
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   input_ids: 2 2515 1854 3307 925 3685 2440 1556 2115 255 1008 4019 3776 2804 3011 3839 3054 4012 3748 2692 2564 2051 4096 4084 4033 3832 3027 3903 3310 939 3743 2671 2479 1710 2731 2717 2663 2447 1581 2216 660 2626 2300 996 3972 3587 2045 4072 3988 3649 2293 968 3858 3132 225 888 3538 1851 3295 877 3496 1681 2614 2252 802 3194 476 1889 3447 1487 1840 3250 699 2782 2923 3488 1650 2490 1756 2916 3458 1531 2013 3942 3467 1566 2156 420 1665 2549 1992 3860 3137 248 979 3902 3308 929 3703 2509 1831 3213 552 2194 571 2271 877 3493 1669 2568 2067 63 240 945 3768 2771 2878 3308 932 3714 2556 2020 3972 3588 2051 4096 4084 4035 3840 3060 4034 3833 3032 3923 3391 1261 936 3729 2615 2253 806 3212 545 2166 460 1827 3199 493 1958 3723 2590 2154 411 1631 2415 1453 1704 2705 2613 2247 781 3111 143 558 2217 664 2644 2372 1282 1017 4056 3922 3388 1252 898 3580 2020 3972 3585 2040 4049 3896 3284 833 3317 968 3860 3140 259 1024 4082 4027 3805 2919 3470 1580 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   guid: train-7649
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   input_ids: 2 1673 2583 2127 302 1193 664 2644 2372 1284 1026 4090 4060 3937 3445 1477 1800 3091 61 229 904 3603 2111 237 936 3731 2621 2278 906 3609 2136 339 1341 1256 916 3651 2302 1004 4003 3710 2537 1944 3668 2371 1278 1004 4001 3701 2504 1812 3140 260 1025 4088 4052 3905 3317 968 3859 3135 237 936 3729 2616 2260 836 3331 1023 4080 4019 3774 2796 2980 3716 2564 2049 4087 4046 3883 3229 615 2447 1581 2216 660 2626 2299 989 3943 3472 1585 2230 716 2850 3193 471 1870 3372 1187 637 2536 1937 3638 2252 803 3197 488 1937 3638 2252 803 3198 491 1952 3698 2490 1755 2911 3438 1451 1693 2664 2449 1592 2258 825 3285 839 3342 1067 158 620 2468 1666 2554 2010 3932 3427 1407 1519 1966 3755 2719 2669 2469 1670 2572 2084 132 514 2043 4063 3950 3499 1695 2669 2472 1684 2628 2305 1015 4046 3884 3234 636 2531 1918 3563 1950 3691 2462 1644 2466 1660 2532 1921 3576 2001 3895 3277 808 3219 573 2280 913 3639 2254 811 3229 613 2440 1554 2107 223 877 3495 1679 2607 2223 687 2734 2729 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   Writing example 0/1533
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   guid: train-7650
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   input_ids: 2 4077 4007 3725 2599 2190 555 2207 622 2476 1699 2685 2535 1935 3630 2220 676 2691 2558 2027 3999 3695 2477 1703 2703 2605 2214 651 2591 2157 423 1679 2607 2223 685 2728 2707 2622 2284 931 3710 2539 1949 3688 2449 1591 2255 815 3246 684 2722 2681 2519 1870 3371 1181 615 2447 1583 2221 680 2707 2621 2279 911 3631 2221 680 2705 2613 2248 785 3127 208 820 3267 767 3056 4017 3768 2771 2879 3311 944 3763 2749 2791 2959 3629 2216 659 2623 2285 936 3731 2623 2285 936 3729 2613 2248 788 3140 260 1025 4085 4040 3860 3137 248 977 3894 3276 803 3199 494 1963 3743 2669 2472 1683 2623 2285 936 3729 2616 2259 829 3302 905 3607 2126 300 1185 630 2508 1827 3200 499 1982 3820 2980 3716 2563 2046 4075 3997 3687 2447 1582 2219 670 2667 2464 1652 2499 1791 3054 4012 3748 2692 2564 2052 4099 4093 4072 3985 3638 2252 804 3203 509 2022 3978 3612 2148 388 1540 2050 4092 4067 3966 3564 1954 3706 2523 1887 3440 1457 1719 2766 2859 3230 619 2463 1645 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   guid: train-9176
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   input_ids: 2 2701 2600 2193 566 2252 804 3203 511 2031 4013 3752 2707 2622 2283 925 3686 2441 1560 2131 317 1256 915 3646 2282 924 3684 2436 1537 2039 4047 3887 3245 679 2702 2604 2210 636 2530 1915 3552 1906 3516 1763 2941 3560 1940 3651 2301 1000 3986 3642 2267 863 3437 1448 1681 2613 2248 788 3139 253 1000 3985 3640 2257 821 3271 783 3117 167 654 2602 2203 606 2411 1439 1645 2471 1680 2612 2243 767 3053 4006 3723 2591 2160 436 1731 2813 3047 3981 3621 2183 527 2095 175 687 2733 2728 2706 2617 2263 846 3369 1175 591 2350 1196 674 2681 2519 1871 3376 1204 708 2819 3071 4077 4005 3720 2577 2104 211 831 3312 948 3779 2813 3048 3987 3646 2284 931 3710 2540 1955 3709 2536 1937 3637 2247 781 3110 138 538 2138 346 1372 1380 1412 1540 2051 4095 4079 4016 3763 2751 2797 2984 3732 2625 2294 972 3874 3196 484 1923 3583 2029 4007 3726 2604 2210 635 2527 1902 3500 1699 2686 2539 1951 3694 2475 1693 2661 2439 1551 2095 175 685 2725 2696 2579 2109 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   guid: train-9177
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   input_ids: 2 878 3500 1699 2685 2535 1935 3629 2215 655 2608 2227 703 2797 2984 3731 2622 2283 927 3694 2475 1695 2671 2478 1708 2724 2691 2559 2029 4005 3720 2580 2113 247 973 3879 3214 554 2203 605 2406 1419 1568 2162 444 1761 2936 3540 1857 3320 979 3902 3308 930 3706 2524 1892 3460 1538 2044 4066 3963 3550 1898 3484 1635 2431 1518 1963 3742 2665 2456 1617 2360 1236 835 3326 1002 3994 3676 2401 1400 1489 1845 3272 787 3134 235 925 3688 2451 1598 2284 931 3711 2542 1962 3739 2655 2414 1452 1700 2692 2561 2040 4051 3903 3309 935 3726 2604 2212 644 2561 2040 4052 3908 3332 1028 4097 4087 4047 3887 3248 690 2748 2788 2945 3576 2001 3893 3270 778 3100 100 387 1535 2029 4008 3729 2616 2259 831 3310 940 3746 2684 2532 1923 3583 2031 4015 3760 2737 2744 2772 2883 3326 1004 4004 3716 2561 2039 4045 3879 3214 556 2210 636 2530 1916 3556 1923 3583 2031 4014 3756 2724 2689 2551 1997 3877 3208 531 2111 237 935 3725 2600 2195 575 2287 943 3758 2732 2723 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   guid: train-10704
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   input_ids: 2 585 2328 1106 315 1247 877 3494 1676 2593 2165 453 1798 3081 24 81 310 1228 801 3189 456 1809 3127 205 808 3218 571 2271 878 3498 1690 2649 2390 1353 1302 1100 289 1142 458 1818 3164 353 1400 1490 1849 3285 837 3335 1037 40 148 577 2295 973 3878 3210 540 2145 375 1485 1829 3207 528 2099 189 744 2961 3639 2254 810 3226 604 2401 1397 1477 1798 3083 32 114 444 1764 2946 3579 2013 3942 3465 1559 2126 300 1188 641 2549 1992 3860 3139 253 998 3980 3620 2177 501 1992 3859 3135 237 935 3726 2604 2211 639 2541 1958 3724 2593 2167 464 1841 3255 717 2855 3213 552 2194 572 2275 895 3568 1970 3769 2776 2899 3390 1259 926 3690 2457 1622 2379 1310 1129 408 1619 2365 1253 901 3590 2060 33 117 453 1798 3083 31 110 428 1698 2684 2532 1924 3588 2051 4095 4077 4007 3727 2608 2227 702 2793 2966 3660 2337 1144 467 1855 3310 940 3746 2684 2531 1918 3563 1950 3690 2458 1628 2401 1397 1480 1809 3128 209 821 3272 787 3133 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   guid: train-9178
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   input_ids: 2 1000 3985 3640 2257 824 3284 833 3320 980 3907 3327 1005 4008 3732 2625 2295 973 3877 3207 527 2095 175 685 2728 2708 2626 2297 984 3924 3396 1281 1013 4040 3857 3128 212 835 3327 1005 4008 3732 2628 2307 1021 4069 3974 3594 2074 90 345 1368 1361 1334 1228 804 3204 516 2049 4088 4052 3905 3317 968 3859 3135 237 936 3732 2625 2295 973 3877 3206 523 2078 107 413 1640 2452 1603 2304 1012 4036 3844 3073 4088 4052 3905 3320 980 3907 3326 1004 4001 3704 2513 1847 3277 808 3219 575 2286 939 3741 2664 2452 1603 2304 1012 4036 3844 3073 4088 4052 3905 3320 980 3907 3326 1004 4001 3701 2501 1799 3085 40 147 575 2286 939 3741 2664 2452 1603 2304 1012 4036 3844 3073 4088 4052 3905 3320 980 3907 3326 1004 4001 3701 2501 1799 3085 40 147 575 2286 939 3741 2664 2452 1603 2304 1012 4036 3844 3073 4088 4052 3905 3320 980 3907 3327 1008 4020 3780 2817 3063 4045 3880 3219 575 2286 939 3744 2676 2500 1793 3064 4052 3908 3332 1025 4088 4052 3905 3320 980 3907 3327 1008 4020 3780 2817 3062 4041 3864 3155 319 1262 939 3741 2664 2452 1603 2304 1012 4036 3844 3073 4088 4052 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   guid: train-10705
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   input_ids: 2 2605 2216 659 2621 2279 910 3625 2197 581 2309 1031 13 39 144 564 2241 757 3013 3845 3079 13 40 146 569 2264 849 3382 1228 801 3191 463 1837 3240 660 2628 2305 1016 4052 3907 3326 1004 4004 3716 2563 2046 4076 4002 3707 2527 1901 3493 1672 2580 2115 253 997 3976 3602 2108 228 899 3583 2032 4017 3768 2772 2884 3332 1027 4096 4084 4036 3843 3072 4084 4035 3837 3047 3983 3631 2221 679 2703 2608 2226 699 2782 2924 3492 1666 2554 2012 3940 3458 1532 2020 3971 3583 2032 4019 3775 2798 2987 3743 2670 2475 1695 2670 2474 1692 2659 2432 1524 1987 3839 3056 4020 3779 2815 3054 4010 3739 2655 2413 1447 1677 2599 2192 564 2242 763 3037 3944 3476 1603 2302 1004 4001 3701 2504 1812 3138 252 994 3961 3543 1870 3371 1183 621 2471 1680 2611 2239 749 2984 3731 2623 2288 947 3775 2797 2984 3731 2623 2288 947 3774 2795 2975 3695 2480 1714 2748 2788 2945 3573 1990 3852 3108 130 508 2017 3959 3535 1840 3250 700 2787 2942 3564 1955 3710 2539 1951 3695 2480 1715 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   guid: train-9179
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   input_ids: 2 2466 1658 2521 1878 3402 1306 1114 346 1371 1374 1386 1434 1626 2393 1368 1364 1347 1277 998 3979 3613 2152 404 1602 2297 983 3917 3366 1164 545 2165 453 1797 3077 8 17 53 200 785 3125 198 778 3099 93 357 1416 1556 2115 254 1002 3994 3676 2401 1397 1477 1797 3079 16 50 186 729 2901 3400 1298 1081 214 842 3354 1114 347 1374 1385 1431 1615 2349 1189 648 2579 2110 236 932 3716 2561 2039 4046 3882 3227 607 2413 1445 1669 2568 2067 62 236 932 3716 2561 2040 4052 3906 3321 981 3912 3345 1077 197 774 3081 23 78 297 1174 588 2338 1146 474 1882 3420 1380 1412 1538 2043 4062 3947 3486 1642 2457 1621 2375 1293 1064 145 565 2246 778 3098 90 346 1370 1369 1365 1349 1286 1034 25 86 329 1304 1107 317 1253 901 3590 2057 22 73 280 1105 312 1233 824 3281 822 3276 804 3203 509 2021 3976 3602 2106 218 860 3428 1410 1530 2010 3930 3418 1371 1375 1391 1453 1704 2706 2618 2268 865 3447 1486 1834 3225 597 2375 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   guid: train-10706
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   input_ids: 2 680 2705 2615 2254 812 3234 634 2524 1892 3458 1530 2010 3930 3419 1374 1388 1443 1661 2536 1939 3646 2283 926 3689 2454 1612 2338 1146 475 1887 3439 1453 1702 2700 2596 2177 501 1992 3857 3128 212 834 3323 989 3942 3467 1566 2156 417 1653 2503 1807 3117 165 647 2575 2095 173 677 2693 2567 2064 51 189 744 2962 3643 2271 879 3503 1711 2735 2734 2731 2717 2663 2447 1582 2220 673 2678 2507 1821 3174 395 1566 2154 411 1631 2414 1451 1693 2662 2443 1566 2154 411 1631 2414 1451 1695 2670 2475 1695 2670 2475 1694 2666 2459 1629 2406 1419 1567 2158 428 1697 2679 2510 1833 3222 587 2333 1126 395 1567 2158 427 1693 2662 2443 1567 2158 427 1696 2674 2490 1753 2903 3406 1324 1187 639 2541 1959 3726 2604 2211 638 2540 1954 3707 2527 1902 3499 1694 2666 2459 1631 2414 1452 1697 2680 2514 1852 3298 892 3555 1918 3563 1951 3694 2475 1695 2670 2475 1693 2662 2443 1567 2158 427 1693 2664 2452 1604 2306 1019 4063 3949 3496 1684 2625 2294 969 3862 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   guid: train-10707
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   input_ids: 2 2445 1573 2184 531 2111 237 933 3720 2577 2102 203 800 3185 437 1734 2828 3106 124 481 1911 3536 1841 3255 717 2853 3208 532 2116 260 1028 4097 4086 4044 3876 3203 510 2027 3999 3694 2476 1699 2688 2545 1974 3788 2850 3196 483 1920 3572 1986 3833 3031 3918 3372 1188 643 2559 2031 4013 3751 2704 2612 2241 760 3027 3903 3310 940 3748 2692 2564 2049 4088 4050 3897 3287 848 3379 1214 748 2978 3708 2531 1917 3559 1936 3634 2235 733 2918 3467 1566 2156 418 1660 2529 1910 3532 1825 3192 468 1857 3319 973 3878 3211 543 2160 433 1720 2769 2871 3278 811 3229 615 2447 1583 2222 682 2715 2653 2406 1418 1564 2147 383 1519 1965 3751 2701 2598 2187 543 2158 428 1699 2687 2543 1968 3763 2751 2799 2991 3757 2727 2703 2606 2220 673 2679 2510 1836 3235 638 2538 1947 3679 2415 1453 1704 2705 2614 2249 789 3144 276 1090 252 994 3964 3556 1922 3579 2015 3951 3501 1704 2707 2622 2283 925 3687 2445 1575 2189 551 2189 551 2191 558 2220 675 2687 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   guid: train-10708
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   input_ids: 2 1839 3247 685 2727 2703 2607 2224 691 2751 2798 2986 3737 2647 2383 1328 1203 704 2802 3003 3807 2925 3496 1683 2622 2282 923 3677 2407 1423 1581 2214 652 2596 2178 507 2014 3947 3487 1645 2472 1682 2618 2266 859 3422 1386 1436 1633 2422 1484 1828 3204 514 2041 4055 3919 3374 1195 670 2668 2468 1667 2558 2027 3999 3693 2470 1673 2584 2130 315 1245 871 3471 1581 2215 653 2597 2183 527 2094 171 671 2671 2479 1710 2732 2722 2684 2532 1921 3576 2002 3900 3297 888 3537 1848 3284 833 3320 979 3903 3311 943 3759 2733 2726 2698 2588 2147 381 1511 1933 3624 2195 573 2279 909 3623 2192 564 2243 765 3048 3987 3648 2291 959 3824 2996 3777 2808 3025 3893 3272 787 3135 238 940 3745 2679 2510 1836 3236 641 2551 1997 3880 3217 566 2252 804 3201 502 1993 3864 3153 310 1228 804 3201 503 1997 3880 3217 567 2253 808 3220 579 2301 1000 3985 3640 2260 833 3317 968 3860 3137 248 979 3901 3301 904 3601 2104 212 833 3317 967 3853 3112 146 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:07:24 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 17:07:29 - INFO - __main__ -   Saving features into cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_train_6-new-12w-0_300_dnaprom
06/26/2023 17:07:33 - INFO - __main__ -   ***** Running training *****
06/26/2023 17:07:33 - INFO - __main__ -     Num examples = 12236
06/26/2023 17:07:33 - INFO - __main__ -     Num Epochs = 30
06/26/2023 17:07:33 - INFO - __main__ -     Instantaneous batch size per GPU = 48
06/26/2023 17:07:33 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 48
06/26/2023 17:07:33 - INFO - __main__ -     Gradient Accumulation steps = 1
06/26/2023 17:07:33 - INFO - __main__ -     Total optimization steps = 7650
06/26/2023 17:07:33 - INFO - __main__ -     Continuing training from checkpoint, will skip to saved global_step
06/26/2023 17:07:33 - INFO - __main__ -     Continuing training from epoch 0
06/26/2023 17:07:33 - INFO - __main__ -     Continuing training from global step 0
06/26/2023 17:07:33 - INFO - __main__ -     Will skip the first 0 steps in the first epoch
06/26/2023 17:08:16 - INFO - __main__ -   Creating features from dataset file at /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   Writing example 0/1530
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   guid: dev-1
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   input_ids: 2 914 3644 2273 887 3533 1832 3219 573 2280 914 3644 2273 886 3529 1816 3155 317 1256 915 3645 2277 903 3597 2088 147 573 2280 914 3644 2273 886 3529 1816 3155 317 1256 914 3644 2273 885 3525 1800 3091 61 232 914 3641 2261 838 3337 1048 82 313 1240 850 3388 1249 887 3533 1829 3207 525 2088 147 573 2277 902 3593 2072 83 317 1256 914 3644 2273 887 3533 1832 3219 573 2280 915 3645 2277 903 3597 2088 147 573 2280 914 3644 2273 887 3533 1832 3219 573 2280 914 3644 2273 887 3533 1832 3219 573 2280 914 3641 2261 838 3337 1048 82 313 1240 850 3388 1249 887 3533 1832 3219 573 2280 915 3645 2277 902 3593 2072 83 317 1256 914 3644 2273 887 3533 1832 3219 573 2280 915 3645 2277 903 3597 2088 147 573 2280 914 3644 2273 887 3533 1832 3219 573 2280 914 3644 2273 886 3529 1816 3155 317 1253 902 3593 2072 83 317 1256 915 3648 2289 951 3789 2856 3219 573 2280 914 3644 2273 887 3533 1832 3219 573 2280 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   guid: dev-2
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   input_ids: 2 623 2477 1702 2699 2590 2155 413 1639 2446 1580 2211 639 2541 1960 3732 2626 2300 995 3966 3562 1946 3674 2393 1368 1361 1335 1229 807 3215 559 2223 687 2736 2738 2748 2786 2939 3551 1901 3495 1679 2607 2222 682 2714 2650 2396 1377 1399 1486 1835 3231 623 2478 1708 2722 2682 2523 1887 3440 1459 1727 2798 2987 3743 2669 2471 1677 2600 2193 566 2251 799 3182 428 1699 2685 2535 1935 3631 2222 684 2721 2680 2516 1857 3317 966 3852 3107 125 486 1932 3618 2169 470 1868 3362 1148 484 1924 3587 2047 4077 4008 3732 2626 2297 983 3917 3367 1166 554 2204 609 2423 1487 1837 3240 660 2628 2305 1013 4040 3859 3135 237 935 3725 2598 2188 548 2178 508 2017 3959 3533 1830 3209 534 2124 291 1151 494 1962 3739 2655 2415 1454 1706 2714 2652 2402 1402 1499 1886 3435 1437 1637 2439 1551 2093 165 648 2577 2101 200 787 3134 234 924 3682 2427 1502 1899 3485 1639 2445 1573 2183 527 2094 170 667 2654 2412 1443 1661 2534 1931 3614 2156 419 1662 2538 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   guid: dev-3
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   input_ids: 2 1370 1370 1370 1370 1370 1370 1369 1365 1352 1300 1089 248 979 3901 3301 901 3592 2065 53 198 779 3102 108 419 1661 2536 1937 3640 2258 828 3298 890 3548 1890 3452 1507 1918 3562 1945 3672 2386 1337 1237 837 3333 1030 12 33 117 454 1802 3098 90 348 1377 1397 1478 1803 3102 106 410 1626 2396 1378 1401 1493 1861 3333 1032 17 54 203 798 3178 411 1630 2410 1435 1630 2412 1444 1666 2554 2011 3936 3442 1467 1757 2920 3474 1593 2262 841 3352 1105 312 1234 826 3290 857 3414 1353 1301 1096 273 1077 198 777 3096 81 312 1235 830 3308 932 3713 2549 1989 3846 3081 21 72 276 1091 253 998 3979 3615 2157 421 1672 2580 2113 248 977 3893 3270 780 3105 118 458 1820 3172 386 1529 2006 3914 3354 1116 356 1411 1533 2022 3977 3606 2121 277 1096 276 1090 249 981 3910 3338 1049 86 331 1310 1130 411 1631 2414 1450 1690 2650 2394 1369 1365 1350 1290 1050 89 343 1358 1322 1177 598 2378 1306 1114 346 1370 1370 1369 1365 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   guid: dev-4
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   input_ids: 2 3311 944 3763 2751 2799 2989 3752 2707 2623 2286 939 3742 2667 2462 1643 2461 1639 2446 1580 2209 632 2515 1854 3306 923 3678 2410 1434 1626 2395 1374 1385 1431 1614 2346 1180 612 2435 1534 2027 3999 3695 2478 1706 2715 2655 2415 1454 1707 2718 2668 2467 1661 2536 1940 3652 2308 1027 4095 4077 4008 3732 2627 2303 1007 4016 3764 2753 2808 3026 3899 3296 884 3521 1784 3026 3898 3292 868 3457 1528 2004 3907 3325 998 3978 3611 2143 366 1449 1687 2638 2346 1177 599 2384 1331 1214 748 2980 3716 2564 2052 4099 4094 4074 3994 3675 2399 1391 1456 1716 2755 2814 3050 3994 3676 2404 1410 1532 2018 3963 3552 1908 3521 1784 3026 3899 3296 884 3521 1784 3028 3906 3321 982 3915 3359 1135 430 1708 2724 2689 2552 2002 3899 3296 883 3517 1768 2964 3650 2300 994 3963 3551 1903 3502 1708 2724 2690 2556 2018 3963 3552 1908 3521 1784 3028 3906 3324 994 3962 3547 1887 3439 1456 1716 2753 2808 3026 3899 3296 884 3521 1784 3028 3906 3324 994 3963 3551 1903 3504 1716 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   guid: dev-5
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   input_ids: 2 3988 3650 2300 996 3972 3588 2052 4098 4090 4060 3937 3447 1485 1832 3219 575 2287 942 3754 2714 2651 2398 1388 1444 1668 2563 2046 4076 4004 3713 2552 2001 3896 3281 821 3269 776 3091 62 233 919 3662 2346 1178 602 2396 1377 1399 1487 1837 3238 649 2581 2120 275 1086 235 927 3694 2475 1694 2667 2462 1644 2467 1661 2536 1937 3637 2245 776 3092 67 255 1007 4014 3756 2724 2689 2552 2001 3893 3272 788 3137 247 973 3877 3208 529 2104 212 836 3332 1027 4095 4078 4010 3739 2654 2410 1435 1631 2415 1454 1707 2718 2668 2467 1661 2535 1935 3630 2219 672 2674 2491 1757 2920 3476 1603 2302 1004 4001 3704 2516 1860 3331 1022 4076 4001 3702 2508 1825 3191 463 1838 3243 669 2663 2446 1578 2204 610 2428 1506 1915 3550 1900 3489 1654 2505 1814 3148 289 1143 461 1831 3214 553 2200 593 2359 1231 813 3237 648 2580 2116 259 1022 4073 3992 3666 2362 1242 858 3420 1378 1403 1502 1900 3490 1659 2525 1895 3471 1584 2226 700 2788 2946 3580 2017 3958 3531 1822 3179 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   Writing example 0/1530
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   guid: dev-1531
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   input_ids: 2 2212 644 2561 2040 4052 3908 3332 1028 4099 4093 4072 3988 3652 2306 1017 4056 3924 3393 1271 974 3881 3224 596 2369 1271 975 3885 3239 654 2603 2205 616 2449 1592 2257 822 3276 804 3204 513 2037 4038 3852 3108 132 516 2049 4087 4048 3892 3265 758 3018 3868 3169 376 1490 1852 3299 893 3560 1939 3647 2288 946 3772 2788 2948 3586 2043 4062 3946 3481 1623 2383 1327 1200 692 2756 2817 3063 4047 3885 3240 657 2613 2246 777 3093 72 276 1090 252 993 3958 3532 1825 3191 463 1837 3239 655 2605 2216 657 2614 2252 803 3200 499 1983 3821 2984 3732 2625 2296 979 3904 3314 955 3805 2920 3476 1601 2293 968 3859 3136 241 952 3793 2872 3284 836 3331 1021 4071 3981 3621 2184 531 2111 239 942 3756 2721 2680 2513 1847 3279 815 3248 692 2755 2815 3055 4013 3750 2700 2596 2179 511 2031 4014 3755 2720 2676 2500 1796 3073 4087 4045 3877 3208 532 2116 259 1024 4084 4035 3840 3060 4034 3835 3038 3947 3486 1644 2465 1656 2516 1859 3326 1004 4004 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   guid: dev-1532
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   input_ids: 2 521 2069 69 263 1040 51 190 746 2970 3675 2399 1390 1451 1694 2667 2461 1640 2449 1590 2250 795 3165 359 1422 1578 2202 603 2398 1385 1430 1610 2330 1116 354 1402 1498 1881 3413 1350 1289 1048 83 317 1253 903 3597 2086 139 542 2154 410 1626 2396 1379 1406 1515 1950 3691 2463 1645 2471 1678 2602 2201 600 2387 1342 1258 922 3676 2403 1405 1509 1925 3591 2061 37 135 526 2091 159 621 2469 1669 2568 2068 67 254 1003 3999 3694 2475 1694 2666 2459 1631 2413 1445 1671 2575 2094 172 673 2680 2514 1850 3289 853 3397 1287 1037 37 133 519 2061 37 133 519 2061 37 133 517 2053 5 7 13 37 133 519 2061 37 133 517 2053 5 7 13 39 143 557 2215 653 2597 2184 529 2101 198 779 3104 116 449 1781 3014 3851 3101 101 389 1542 2057 24 81 310 1227 797 3176 403 1599 2287 941 3749 2694 2569 2070 73 277 1093 261 1029 5 7 14 41 149 581 2312 1042 59 221 869 3462 1547 2078 106 410 1625 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   guid: dev-1533
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   input_ids: 2 56 212 835 3325 1000 3985 3640 2258 826 3292 865 3447 1485 1830 3212 547 2174 492 1956 3713 2552 2001 3896 3281 823 3278 810 3225 600 2385 1333 1223 782 3116 161 630 2507 1822 3178 410 1627 2399 1391 1455 1710 2730 2714 2650 2395 1375 1391 1454 1707 2717 2661 2438 1545 2072 83 317 1255 909 3622 2186 539 2144 370 1468 1762 2938 3548 1892 3457 1526 1996 3876 3204 513 2040 4051 3902 3308 931 3710 2540 1955 3710 2540 1953 3703 2509 1829 3207 527 2093 166 651 2591 2158 428 1697 2679 2512 1841 3256 721 2872 3281 822 3276 803 3200 497 1973 3784 2836 3140 259 1021 4070 3979 3613 2151 399 1583 2221 680 2708 2625 2296 979 3901 3304 913 3638 2252 801 3189 454 1804 3105 120 466 1850 3291 861 3432 1425 1592 2259 831 3310 939 3743 2670 2474 1691 2653 2405 1415 1551 2093 167 654 2602 2202 604 2401 1399 1485 1832 3220 580 2306 1017 4055 3919 3373 1191 654 2603 2206 619 2462 1641 2455 1614 2346 1177 598 2378 1306 1116 353 1397 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   guid: dev-1534
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   input_ids: 2 2276 899 3582 2026 3995 3679 2415 1455 1709 2726 2699 2589 2152 402 1594 2265 855 3407 1326 1194 667 2653 2407 1421 1576 2196 579 2302 1002 3994 3675 2399 1391 1456 1714 2747 2781 2920 3475 1597 2279 910 3628 2212 644 2563 2045 4071 3984 3633 2229 712 2835 3135 239 941 3750 2700 2594 2171 480 1907 3517 1766 2954 3611 2141 359 1421 1576 2195 576 2292 962 3833 3030 3915 3359 1134 427 1695 2670 2476 1700 2690 2556 2019 3965 3558 1930 3612 2145 376 1492 1859 3326 1004 4003 3711 2541 1959 3725 2600 2193 568 2257 822 3274 795 3165 360 1428 1602 2298 987 3934 3435 1437 1640 2449 1592 2259 829 3303 910 3627 2205 614 2443 1565 2149 392 1556 2114 251 990 3945 3479 1613 2344 1171 575 2285 936 3729 2613 2245 776 3089 53 197 775 3085 39 141 551 2192 562 2234 729 2903 3406 1323 1182 618 2459 1631 2414 1451 1696 2676 2498 1786 3033 3928 3412 1348 1284 1027 4094 4074 3994 3675 2398 1385 1429 1606 2314 1051 95 366 1451 1693 2664 2452 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   guid: dev-1535
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   input_ids: 2 4005 3720 2577 2101 200 787 3136 244 964 3843 3071 4080 4017 3767 2767 2862 3244 676 2690 2556 2020 3969 3576 2001 3893 3272 788 3138 252 995 3968 3572 1987 3840 3059 4032 3825 3000 3796 2883 3327 1008 4017 3768 2771 2877 3304 915 3648 2291 960 3827 3008 3827 3008 3827 3008 3825 2997 3784 2833 3125 197 773 3080 20 65 248 979 3904 3315 960 3825 3000 3795 2880 3315 960 3825 3000 3795 2880 3316 964 3841 3061 4039 3856 3123 192 753 3000 3793 2869 3269 776 3089 56 211 832 3315 960 3825 3000 3795 2880 3315 960 3825 3000 3793 2869 3272 788 3137 248 979 3904 3315 960 3825 3000 3795 2880 3315 960 3825 3000 3793 2869 3272 788 3137 248 979 3904 3315 960 3825 3000 3795 2880 3315 960 3825 3000 3793 2869 3272 788 3137 248 979 3904 3315 960 3825 3000 3795 2878 3306 924 3681 2421 1479 1808 3123 189 744 2963 3648 2290 956 3812 2946 3580 2017 3960 3538 1852 3299 896 3570 1979 3805 2919 3470 1580 2211 639 2542 1964 3747 2688 2547 1983 3821 2983 3727 2608 2227 703 2798 2986 3739 2654 2410 1434 1627 2399 1391 1454 1707 2718 2666 2458 1627 2399 1390 1450 1691 2655 2414 1450 1691 2655 2415 1454 1707 2718 2668 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 17:08:16 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 17:08:21 - INFO - __main__ -   Saving features into cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:08:22 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:08:22 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:08:22 - INFO - __main__ -     Batch size = 48
06/26/2023 17:08:31 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:08:31 - INFO - __main__ -     acc = 0.6369281045751634
06/26/2023 17:08:31 - INFO - __main__ -     auc = 0.6939638600538255
06/26/2023 17:08:31 - INFO - __main__ -     f1 = 0.6307757471429773
06/26/2023 17:08:31 - INFO - __main__ -     mcc = 0.28346583674153153
06/26/2023 17:08:31 - INFO - __main__ -     precision = 0.6467063333142629
06/26/2023 17:08:31 - INFO - __main__ -     recall = 0.6369281045751634
06/26/2023 17:08:31 - INFO - __main__ -   {"eval_acc": 0.6369281045751634, "eval_f1": 0.6307757471429773, "eval_mcc": 0.28346583674153153, "eval_auc": 0.6939638600538255, "eval_precision": 0.6467063333142629, "eval_recall": 0.6369281045751634, "learning_rate": 1.3071895424836602e-05, "loss": 0.6807468813657761, "step": 100}
06/26/2023 17:09:15 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:09:15 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:09:15 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:09:15 - INFO - __main__ -     Batch size = 48
06/26/2023 17:09:24 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:09:24 - INFO - __main__ -     acc = 0.6712418300653594
06/26/2023 17:09:24 - INFO - __main__ -     auc = 0.7319447648340383
06/26/2023 17:09:24 - INFO - __main__ -     f1 = 0.6683853742950512
06/26/2023 17:09:24 - INFO - __main__ -     mcc = 0.3485408006180178
06/26/2023 17:09:24 - INFO - __main__ -     precision = 0.6773525336202639
06/26/2023 17:09:24 - INFO - __main__ -     recall = 0.6712418300653595
06/26/2023 17:09:24 - INFO - __main__ -   {"eval_acc": 0.6712418300653594, "eval_f1": 0.6683853742950512, "eval_mcc": 0.3485408006180178, "eval_auc": 0.7319447648340383, "eval_precision": 0.6773525336202639, "eval_recall": 0.6712418300653595, "learning_rate": 2.6143790849673204e-05, "loss": 0.6084511041641235, "step": 200}
06/26/2023 17:10:08 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:10:08 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:10:08 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:10:08 - INFO - __main__ -     Batch size = 48
06/26/2023 17:10:17 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:10:17 - INFO - __main__ -     acc = 0.6761437908496732
06/26/2023 17:10:17 - INFO - __main__ -     auc = 0.7442261523345722
06/26/2023 17:10:17 - INFO - __main__ -     f1 = 0.6547934146122951
06/26/2023 17:10:17 - INFO - __main__ -     mcc = 0.40608135605994494
06/26/2023 17:10:17 - INFO - __main__ -     precision = 0.7340446787026069
06/26/2023 17:10:17 - INFO - __main__ -     recall = 0.6761437908496732
06/26/2023 17:10:17 - INFO - __main__ -   {"eval_acc": 0.6761437908496732, "eval_f1": 0.6547934146122951, "eval_mcc": 0.40608135605994494, "eval_auc": 0.7442261523345722, "eval_precision": 0.7340446787026069, "eval_recall": 0.6761437908496732, "learning_rate": 3.9215686274509805e-05, "loss": 0.5952002939581871, "step": 300}
06/26/2023 17:11:00 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:11:01 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:11:01 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:11:01 - INFO - __main__ -     Batch size = 48
06/26/2023 17:11:10 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:11:10 - INFO - __main__ -     acc = 0.6944444444444444
06/26/2023 17:11:10 - INFO - __main__ -     auc = 0.749448929898757
06/26/2023 17:11:10 - INFO - __main__ -     f1 = 0.6830985564486304
06/26/2023 17:11:10 - INFO - __main__ -     mcc = 0.4201345692836747
06/26/2023 17:11:10 - INFO - __main__ -     precision = 0.72694535810923
06/26/2023 17:11:10 - INFO - __main__ -     recall = 0.6944444444444444
06/26/2023 17:11:10 - INFO - __main__ -   {"eval_acc": 0.6944444444444444, "eval_f1": 0.6830985564486304, "eval_mcc": 0.4201345692836747, "eval_auc": 0.749448929898757, "eval_precision": 0.72694535810923, "eval_recall": 0.6944444444444444, "learning_rate": 5.228758169934641e-05, "loss": 0.5817703139781952, "step": 400}
06/26/2023 17:11:53 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:11:54 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:11:54 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:11:54 - INFO - __main__ -     Batch size = 48
06/26/2023 17:12:03 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:12:03 - INFO - __main__ -     acc = 0.6526143790849673
06/26/2023 17:12:03 - INFO - __main__ -     auc = 0.7680838566363366
06/26/2023 17:12:03 - INFO - __main__ -     f1 = 0.6163323491920789
06/26/2023 17:12:03 - INFO - __main__ -     mcc = 0.38709972293224193
06/26/2023 17:12:03 - INFO - __main__ -     precision = 0.7454653951886021
06/26/2023 17:12:03 - INFO - __main__ -     recall = 0.6526143790849673
06/26/2023 17:12:03 - INFO - __main__ -   {"eval_acc": 0.6526143790849673, "eval_f1": 0.6163323491920789, "eval_mcc": 0.38709972293224193, "eval_auc": 0.7680838566363366, "eval_precision": 0.7454653951886021, "eval_recall": 0.6526143790849673, "learning_rate": 6.535947712418301e-05, "loss": 0.5865933412313461, "step": 500}
06/26/2023 17:12:46 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:12:47 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:12:47 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:12:47 - INFO - __main__ -     Batch size = 48
06/26/2023 17:12:56 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:12:56 - INFO - __main__ -     acc = 0.711437908496732
06/26/2023 17:12:56 - INFO - __main__ -     auc = 0.7693938228886327
06/26/2023 17:12:56 - INFO - __main__ -     f1 = 0.7067965221165715
06/26/2023 17:12:56 - INFO - __main__ -     mcc = 0.4369353154967952
06/26/2023 17:12:56 - INFO - __main__ -     precision = 0.7257311275040761
06/26/2023 17:12:56 - INFO - __main__ -     recall = 0.711437908496732
06/26/2023 17:12:56 - INFO - __main__ -   {"eval_acc": 0.711437908496732, "eval_f1": 0.7067965221165715, "eval_mcc": 0.4369353154967952, "eval_auc": 0.7693938228886327, "eval_precision": 0.7257311275040761, "eval_recall": 0.711437908496732, "learning_rate": 7.843137254901961e-05, "loss": 0.5527094459533691, "step": 600}
06/26/2023 17:13:38 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:13:39 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:13:39 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:13:39 - INFO - __main__ -     Batch size = 48
06/26/2023 17:13:48 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:13:48 - INFO - __main__ -     acc = 0.7081699346405229
06/26/2023 17:13:48 - INFO - __main__ -     auc = 0.7807005852449912
06/26/2023 17:13:48 - INFO - __main__ -     f1 = 0.6970206666325907
06/26/2023 17:13:48 - INFO - __main__ -     mcc = 0.45084074311849887
06/26/2023 17:13:48 - INFO - __main__ -     precision = 0.7441003020040264
06/26/2023 17:13:48 - INFO - __main__ -     recall = 0.7081699346405229
06/26/2023 17:13:48 - INFO - __main__ -   {"eval_acc": 0.7081699346405229, "eval_f1": 0.6970206666325907, "eval_mcc": 0.45084074311849887, "eval_auc": 0.7807005852449912, "eval_precision": 0.7441003020040264, "eval_recall": 0.7081699346405229, "learning_rate": 9.150326797385621e-05, "loss": 0.5626918926835061, "step": 700}
06/26/2023 17:14:31 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:14:31 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:14:31 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:14:31 - INFO - __main__ -     Batch size = 48
06/26/2023 17:14:40 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:14:40 - INFO - __main__ -     acc = 0.7075163398692811
06/26/2023 17:14:40 - INFO - __main__ -     auc = 0.7743564441026954
06/26/2023 17:14:40 - INFO - __main__ -     f1 = 0.7055031775053333
06/26/2023 17:14:40 - INFO - __main__ -     mcc = 0.42082603970072163
06/26/2023 17:14:40 - INFO - __main__ -     precision = 0.7133501340204691
06/26/2023 17:14:40 - INFO - __main__ -     recall = 0.707516339869281
06/26/2023 17:14:40 - INFO - __main__ -   {"eval_acc": 0.7075163398692811, "eval_f1": 0.7055031775053333, "eval_mcc": 0.42082603970072163, "eval_auc": 0.7743564441026954, "eval_precision": 0.7133501340204691, "eval_recall": 0.707516339869281, "learning_rate": 9.949164851125636e-05, "loss": 0.5364140152931214, "step": 800}
06/26/2023 17:15:23 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:15:24 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:15:24 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:15:24 - INFO - __main__ -     Batch size = 48
06/26/2023 17:15:33 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:15:33 - INFO - __main__ -     acc = 0.7075163398692811
06/26/2023 17:15:33 - INFO - __main__ -     auc = 0.7856480413516169
06/26/2023 17:15:33 - INFO - __main__ -     f1 = 0.6985759538078409
06/26/2023 17:15:33 - INFO - __main__ -     mcc = 0.4420853394268618
06/26/2023 17:15:33 - INFO - __main__ -     precision = 0.7354506727750633
06/26/2023 17:15:33 - INFO - __main__ -     recall = 0.707516339869281
06/26/2023 17:15:33 - INFO - __main__ -   {"eval_acc": 0.7075163398692811, "eval_f1": 0.6985759538078409, "eval_mcc": 0.4420853394268618, "eval_auc": 0.7856480413516169, "eval_precision": 0.7354506727750633, "eval_recall": 0.707516339869281, "learning_rate": 9.80392156862745e-05, "loss": 0.4841049537062645, "step": 900}
06/26/2023 17:16:15 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:16:16 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:16:16 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:16:16 - INFO - __main__ -     Batch size = 48
06/26/2023 17:16:25 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:16:25 - INFO - __main__ -     acc = 0.6993464052287581
06/26/2023 17:16:25 - INFO - __main__ -     auc = 0.7852445640565594
06/26/2023 17:16:25 - INFO - __main__ -     f1 = 0.6971260541738982
06/26/2023 17:16:25 - INFO - __main__ -     mcc = 0.40467018280314704
06/26/2023 17:16:25 - INFO - __main__ -     precision = 0.7053685852298333
06/26/2023 17:16:25 - INFO - __main__ -     recall = 0.6993464052287581
06/26/2023 17:16:25 - INFO - __main__ -   {"eval_acc": 0.6993464052287581, "eval_f1": 0.6971260541738982, "eval_mcc": 0.40467018280314704, "eval_auc": 0.7852445640565594, "eval_precision": 0.7053685852298333, "eval_recall": 0.6993464052287581, "learning_rate": 9.658678286129266e-05, "loss": 0.4867179429531097, "step": 1000}
06/26/2023 17:17:08 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:17:09 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:17:09 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:17:09 - INFO - __main__ -     Batch size = 48
06/26/2023 17:17:18 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:17:18 - INFO - __main__ -     acc = 0.7127450980392157
06/26/2023 17:17:18 - INFO - __main__ -     auc = 0.7790016660258876
06/26/2023 17:17:18 - INFO - __main__ -     f1 = 0.7122176692107015
06/26/2023 17:17:18 - INFO - __main__ -     mcc = 0.42705844570580875
06/26/2023 17:17:18 - INFO - __main__ -     precision = 0.714316237753035
06/26/2023 17:17:18 - INFO - __main__ -     recall = 0.7127450980392156
06/26/2023 17:17:18 - INFO - __main__ -   {"eval_acc": 0.7127450980392157, "eval_f1": 0.7122176692107015, "eval_mcc": 0.42705844570580875, "eval_auc": 0.7790016660258876, "eval_precision": 0.714316237753035, "eval_recall": 0.7127450980392156, "learning_rate": 9.513435003631082e-05, "loss": 0.3766468068957329, "step": 1100}
06/26/2023 17:18:01 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:18:01 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:18:01 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:18:01 - INFO - __main__ -     Batch size = 48
06/26/2023 17:18:10 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:18:10 - INFO - __main__ -     acc = 0.7150326797385621
06/26/2023 17:18:10 - INFO - __main__ -     auc = 0.7806014780639925
06/26/2023 17:18:10 - INFO - __main__ -     f1 = 0.7149974942440244
06/26/2023 17:18:10 - INFO - __main__ -     mcc = 0.4301715878002157
06/26/2023 17:18:10 - INFO - __main__ -     precision = 0.7151389211811208
06/26/2023 17:18:10 - INFO - __main__ -     recall = 0.7150326797385621
06/26/2023 17:18:10 - INFO - __main__ -   {"eval_acc": 0.7150326797385621, "eval_f1": 0.7149974942440244, "eval_mcc": 0.4301715878002157, "eval_auc": 0.7806014780639925, "eval_precision": 0.7151389211811208, "eval_recall": 0.7150326797385621, "learning_rate": 9.368191721132898e-05, "loss": 0.37546486020088193, "step": 1200}
06/26/2023 17:18:53 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:18:54 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:18:54 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:18:54 - INFO - __main__ -     Batch size = 48
06/26/2023 17:19:03 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:19:03 - INFO - __main__ -     acc = 0.719281045751634
06/26/2023 17:19:03 - INFO - __main__ -     auc = 0.7881336238198983
06/26/2023 17:19:03 - INFO - __main__ -     f1 = 0.7188118282301783
06/26/2023 17:19:03 - INFO - __main__ -     mcc = 0.440033113116819
06/26/2023 17:19:03 - INFO - __main__ -     precision = 0.7207545344099084
06/26/2023 17:19:03 - INFO - __main__ -     recall = 0.719281045751634
06/26/2023 17:19:03 - INFO - __main__ -   {"eval_acc": 0.719281045751634, "eval_f1": 0.7188118282301783, "eval_mcc": 0.440033113116819, "eval_auc": 0.7881336238198983, "eval_precision": 0.7207545344099084, "eval_recall": 0.719281045751634, "learning_rate": 9.222948438634713e-05, "loss": 0.35142699360847474, "step": 1300}
06/26/2023 17:19:45 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:19:46 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:19:46 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:19:46 - INFO - __main__ -     Batch size = 48
06/26/2023 17:19:55 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:19:55 - INFO - __main__ -     acc = 0.6715686274509803
06/26/2023 17:19:55 - INFO - __main__ -     auc = 0.7700098252808749
06/26/2023 17:19:55 - INFO - __main__ -     f1 = 0.6608090706799425
06/26/2023 17:19:55 - INFO - __main__ -     mcc = 0.36722491386292033
06/26/2023 17:19:55 - INFO - __main__ -     precision = 0.6965017430126598
06/26/2023 17:19:55 - INFO - __main__ -     recall = 0.6715686274509804
06/26/2023 17:19:55 - INFO - __main__ -   {"eval_acc": 0.6715686274509803, "eval_f1": 0.6608090706799425, "eval_mcc": 0.36722491386292033, "eval_auc": 0.7700098252808749, "eval_precision": 0.6965017430126598, "eval_recall": 0.6715686274509804, "learning_rate": 9.077705156136529e-05, "loss": 0.23994894206523895, "step": 1400}
06/26/2023 17:20:37 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:20:38 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:20:38 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:20:38 - INFO - __main__ -     Batch size = 48
06/26/2023 17:20:47 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:20:47 - INFO - __main__ -     acc = 0.7183006535947712
06/26/2023 17:20:47 - INFO - __main__ -     auc = 0.7907217309581784
06/26/2023 17:20:47 - INFO - __main__ -     f1 = 0.7140287371998555
06/26/2023 17:20:47 - INFO - __main__ -     mcc = 0.4502607323638567
06/26/2023 17:20:47 - INFO - __main__ -     precision = 0.7321737518536826
06/26/2023 17:20:47 - INFO - __main__ -     recall = 0.7183006535947712
06/26/2023 17:20:47 - INFO - __main__ -   {"eval_acc": 0.7183006535947712, "eval_f1": 0.7140287371998555, "eval_mcc": 0.4502607323638567, "eval_auc": 0.7907217309581784, "eval_precision": 0.7321737518536826, "eval_recall": 0.7183006535947712, "learning_rate": 8.932461873638345e-05, "loss": 0.26310724526643753, "step": 1500}
06/26/2023 17:21:29 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:21:30 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:21:30 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:21:30 - INFO - __main__ -     Batch size = 48
06/26/2023 17:21:39 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:21:39 - INFO - __main__ -     acc = 0.719281045751634
06/26/2023 17:21:39 - INFO - __main__ -     auc = 0.7783008671878338
06/26/2023 17:21:39 - INFO - __main__ -     f1 = 0.7165749839959225
06/26/2023 17:21:39 - INFO - __main__ -     mcc = 0.447184396044498
06/26/2023 17:21:39 - INFO - __main__ -     precision = 0.7279881092552117
06/26/2023 17:21:39 - INFO - __main__ -     recall = 0.719281045751634
06/26/2023 17:21:39 - INFO - __main__ -   {"eval_acc": 0.719281045751634, "eval_f1": 0.7165749839959225, "eval_mcc": 0.447184396044498, "eval_auc": 0.7783008671878338, "eval_precision": 0.7279881092552117, "eval_recall": 0.719281045751634, "learning_rate": 8.78721859114016e-05, "loss": 0.18847106819972395, "step": 1600}
06/26/2023 17:22:22 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:22:23 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:22:23 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:22:23 - INFO - __main__ -     Batch size = 48
06/26/2023 17:22:32 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:22:32 - INFO - __main__ -     acc = 0.7127450980392157
06/26/2023 17:22:32 - INFO - __main__ -     auc = 0.7821923191934725
06/26/2023 17:22:32 - INFO - __main__ -     f1 = 0.7126652828400045
06/26/2023 17:22:32 - INFO - __main__ -     mcc = 0.4257267766894712
06/26/2023 17:22:32 - INFO - __main__ -     precision = 0.7129817444219066
06/26/2023 17:22:32 - INFO - __main__ -     recall = 0.7127450980392156
06/26/2023 17:22:32 - INFO - __main__ -   {"eval_acc": 0.7127450980392157, "eval_f1": 0.7126652828400045, "eval_mcc": 0.4257267766894712, "eval_auc": 0.7821923191934725, "eval_precision": 0.7129817444219066, "eval_recall": 0.7127450980392156, "learning_rate": 8.641975308641975e-05, "loss": 0.1850198132172227, "step": 1700}
06/26/2023 17:23:16 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:23:16 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:23:16 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:23:16 - INFO - __main__ -     Batch size = 48
06/26/2023 17:23:25 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:23:25 - INFO - __main__ -     acc = 0.711437908496732
06/26/2023 17:23:25 - INFO - __main__ -     auc = 0.784997009697125
06/26/2023 17:23:25 - INFO - __main__ -     f1 = 0.7059776961430018
06/26/2023 17:23:25 - INFO - __main__ -     mcc = 0.4395150215026151
06/26/2023 17:23:25 - INFO - __main__ -     precision = 0.728404470489536
06/26/2023 17:23:25 - INFO - __main__ -     recall = 0.7114379084967319
06/26/2023 17:23:25 - INFO - __main__ -   {"eval_acc": 0.711437908496732, "eval_f1": 0.7059776961430018, "eval_mcc": 0.4395150215026151, "eval_auc": 0.784997009697125, "eval_precision": 0.728404470489536, "eval_recall": 0.7114379084967319, "learning_rate": 8.496732026143791e-05, "loss": 0.17173757654614746, "step": 1800}
06/26/2023 17:24:08 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:24:08 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:24:08 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:24:08 - INFO - __main__ -     Batch size = 48
06/26/2023 17:24:17 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:24:17 - INFO - __main__ -     acc = 0.7140522875816994
06/26/2023 17:24:17 - INFO - __main__ -     auc = 0.7839183647315136
06/26/2023 17:24:17 - INFO - __main__ -     f1 = 0.7140058313970647
06/26/2023 17:24:17 - INFO - __main__ -     mcc = 0.428243723470221
06/26/2023 17:24:17 - INFO - __main__ -     precision = 0.7141914585024487
06/26/2023 17:24:17 - INFO - __main__ -     recall = 0.7140522875816993
06/26/2023 17:24:17 - INFO - __main__ -   {"eval_acc": 0.7140522875816994, "eval_f1": 0.7140058313970647, "eval_mcc": 0.428243723470221, "eval_auc": 0.7839183647315136, "eval_precision": 0.7141914585024487, "eval_recall": 0.7140522875816993, "learning_rate": 8.351488743645607e-05, "loss": 0.14451359268277883, "step": 1900}
06/26/2023 17:25:00 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:25:01 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:25:01 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:25:01 - INFO - __main__ -     Batch size = 48
06/26/2023 17:25:10 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:25:10 - INFO - __main__ -     acc = 0.719281045751634
06/26/2023 17:25:10 - INFO - __main__ -     auc = 0.7834664018112693
06/26/2023 17:25:10 - INFO - __main__ -     f1 = 0.7169278246398598
06/26/2023 17:25:10 - INFO - __main__ -     mcc = 0.44604079570286415
06/26/2023 17:25:10 - INFO - __main__ -     precision = 0.726823516311329
06/26/2023 17:25:10 - INFO - __main__ -     recall = 0.719281045751634
06/26/2023 17:25:10 - INFO - __main__ -   {"eval_acc": 0.719281045751634, "eval_f1": 0.7169278246398598, "eval_mcc": 0.44604079570286415, "eval_auc": 0.7834664018112693, "eval_precision": 0.726823516311329, "eval_recall": 0.719281045751634, "learning_rate": 8.206245461147423e-05, "loss": 0.14091575008817017, "step": 2000}
06/26/2023 17:25:53 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:25:53 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:25:53 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:25:53 - INFO - __main__ -     Batch size = 48
06/26/2023 17:26:02 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:26:02 - INFO - __main__ -     acc = 0.7264705882352941
06/26/2023 17:26:02 - INFO - __main__ -     auc = 0.7885947712418301
06/26/2023 17:26:02 - INFO - __main__ -     f1 = 0.7263471118530884
06/26/2023 17:26:02 - INFO - __main__ -     mcc = 0.4533504786222116
06/26/2023 17:26:02 - INFO - __main__ -     precision = 0.7268800753207014
06/26/2023 17:26:02 - INFO - __main__ -     recall = 0.7264705882352942
06/26/2023 17:26:02 - INFO - __main__ -   {"eval_acc": 0.7264705882352941, "eval_f1": 0.7263471118530884, "eval_mcc": 0.4533504786222116, "eval_auc": 0.7885947712418301, "eval_precision": 0.7268800753207014, "eval_recall": 0.7264705882352942, "learning_rate": 8.061002178649237e-05, "loss": 0.11979725645389408, "step": 2100}
06/26/2023 17:26:45 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:26:45 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:26:45 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:26:45 - INFO - __main__ -     Batch size = 48
06/26/2023 17:26:54 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:26:54 - INFO - __main__ -     acc = 0.7225490196078431
06/26/2023 17:26:54 - INFO - __main__ -     auc = 0.7836197616301422
06/26/2023 17:26:54 - INFO - __main__ -     f1 = 0.7223347717465365
06/26/2023 17:26:54 - INFO - __main__ -     mcc = 0.44578651300569594
06/26/2023 17:26:54 - INFO - __main__ -     precision = 0.7232380258604989
06/26/2023 17:26:54 - INFO - __main__ -     recall = 0.7225490196078431
06/26/2023 17:26:54 - INFO - __main__ -   {"eval_acc": 0.7225490196078431, "eval_f1": 0.7223347717465365, "eval_mcc": 0.44578651300569594, "eval_auc": 0.7836197616301422, "eval_precision": 0.7232380258604989, "eval_recall": 0.7225490196078431, "learning_rate": 7.915758896151053e-05, "loss": 0.12416954654734581, "step": 2200}
06/26/2023 17:27:38 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:27:39 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:27:39 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:27:39 - INFO - __main__ -     Batch size = 48
06/26/2023 17:27:48 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:27:48 - INFO - __main__ -     acc = 0.7183006535947712
06/26/2023 17:27:48 - INFO - __main__ -     auc = 0.7944907941390064
06/26/2023 17:27:48 - INFO - __main__ -     f1 = 0.7117875874125874
06/26/2023 17:27:48 - INFO - __main__ -     mcc = 0.45778128662318557
06/26/2023 17:27:48 - INFO - __main__ -     precision = 0.7399943643450899
06/26/2023 17:27:48 - INFO - __main__ -     recall = 0.7183006535947712
06/26/2023 17:27:48 - INFO - __main__ -   {"eval_acc": 0.7183006535947712, "eval_f1": 0.7117875874125874, "eval_mcc": 0.45778128662318557, "eval_auc": 0.7944907941390064, "eval_precision": 0.7399943643450899, "eval_recall": 0.7183006535947712, "learning_rate": 7.770515613652869e-05, "loss": 0.10688709624111653, "step": 2300}
06/26/2023 17:28:31 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:28:32 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:28:32 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:28:32 - INFO - __main__ -     Batch size = 48
06/26/2023 17:28:41 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:28:41 - INFO - __main__ -     acc = 0.7254901960784313
06/26/2023 17:28:41 - INFO - __main__ -     auc = 0.7876094664445299
06/26/2023 17:28:41 - INFO - __main__ -     f1 = 0.7237911025145068
06/26/2023 17:28:41 - INFO - __main__ -     mcc = 0.4566333243478906
06/26/2023 17:28:41 - INFO - __main__ -     precision = 0.7311785573512022
06/26/2023 17:28:41 - INFO - __main__ -     recall = 0.7254901960784315
06/26/2023 17:28:41 - INFO - __main__ -   {"eval_acc": 0.7254901960784313, "eval_f1": 0.7237911025145068, "eval_mcc": 0.4566333243478906, "eval_auc": 0.7876094664445299, "eval_precision": 0.7311785573512022, "eval_recall": 0.7254901960784315, "learning_rate": 7.625272331154685e-05, "loss": 0.0939760095544625, "step": 2400}
06/26/2023 17:29:25 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:29:25 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:29:25 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:29:25 - INFO - __main__ -     Batch size = 48
06/26/2023 17:29:34 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:29:34 - INFO - __main__ -     acc = 0.7258169934640523
06/26/2023 17:29:34 - INFO - __main__ -     auc = 0.7992874535435089
06/26/2023 17:29:34 - INFO - __main__ -     f1 = 0.7225708687849706
06/26/2023 17:29:34 - INFO - __main__ -     mcc = 0.4625889657881945
06/26/2023 17:29:34 - INFO - __main__ -     precision = 0.7369048360648023
06/26/2023 17:29:34 - INFO - __main__ -     recall = 0.7258169934640524
06/26/2023 17:29:34 - INFO - __main__ -   {"eval_acc": 0.7258169934640523, "eval_f1": 0.7225708687849706, "eval_mcc": 0.4625889657881945, "eval_auc": 0.7992874535435089, "eval_precision": 0.7369048360648023, "eval_recall": 0.7258169934640524, "learning_rate": 7.4800290486565e-05, "loss": 0.0988186920620501, "step": 2500}
06/26/2023 17:30:18 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:30:18 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:30:18 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:30:18 - INFO - __main__ -     Batch size = 48
06/26/2023 17:30:27 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:30:27 - INFO - __main__ -     acc = 0.7199346405228758
06/26/2023 17:30:27 - INFO - __main__ -     auc = 0.7939489085394507
06/26/2023 17:30:27 - INFO - __main__ -     f1 = 0.7165372714866709
06/26/2023 17:30:27 - INFO - __main__ -     mcc = 0.4508080821228066
06/26/2023 17:30:27 - INFO - __main__ -     precision = 0.7310094562912941
06/26/2023 17:30:27 - INFO - __main__ -     recall = 0.7199346405228759
06/26/2023 17:30:27 - INFO - __main__ -   {"eval_acc": 0.7199346405228758, "eval_f1": 0.7165372714866709, "eval_mcc": 0.4508080821228066, "eval_auc": 0.7939489085394507, "eval_precision": 0.7310094562912941, "eval_recall": 0.7199346405228759, "learning_rate": 7.334785766158315e-05, "loss": 0.08892373517388479, "step": 2600}
06/26/2023 17:31:10 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:31:11 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:31:11 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:31:11 - INFO - __main__ -     Batch size = 48
06/26/2023 17:31:20 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:31:20 - INFO - __main__ -     acc = 0.7323529411764705
06/26/2023 17:31:20 - INFO - __main__ -     auc = 0.786565423555043
06/26/2023 17:31:20 - INFO - __main__ -     f1 = 0.7316996115642784
06/26/2023 17:31:20 - INFO - __main__ -     mcc = 0.46698573127373666
06/26/2023 17:31:20 - INFO - __main__ -     precision = 0.7346383825712361
06/26/2023 17:31:20 - INFO - __main__ -     recall = 0.7323529411764707
06/26/2023 17:31:20 - INFO - __main__ -   {"eval_acc": 0.7323529411764705, "eval_f1": 0.7316996115642784, "eval_mcc": 0.46698573127373666, "eval_auc": 0.786565423555043, "eval_precision": 0.7346383825712361, "eval_recall": 0.7323529411764707, "learning_rate": 7.189542483660131e-05, "loss": 0.08608149025938473, "step": 2700}
06/26/2023 17:32:03 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:32:04 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:32:04 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:32:04 - INFO - __main__ -     Batch size = 48
06/26/2023 17:32:13 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:32:13 - INFO - __main__ -     acc = 0.7284313725490196
06/26/2023 17:32:13 - INFO - __main__ -     auc = 0.7935452176513307
06/26/2023 17:32:13 - INFO - __main__ -     f1 = 0.7283672907156639
06/26/2023 17:32:13 - INFO - __main__ -     mcc = 0.4570784579915477
06/26/2023 17:32:13 - INFO - __main__ -     precision = 0.7286471363681649
06/26/2023 17:32:13 - INFO - __main__ -     recall = 0.7284313725490197
06/26/2023 17:32:13 - INFO - __main__ -   {"eval_acc": 0.7284313725490196, "eval_f1": 0.7283672907156639, "eval_mcc": 0.4570784579915477, "eval_auc": 0.7935452176513307, "eval_precision": 0.7286471363681649, "eval_recall": 0.7284313725490197, "learning_rate": 7.044299201161947e-05, "loss": 0.08215040612965822, "step": 2800}
06/26/2023 17:32:57 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:32:57 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:32:57 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:32:57 - INFO - __main__ -     Batch size = 48
06/26/2023 17:33:06 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:33:06 - INFO - __main__ -     acc = 0.7294117647058823
06/26/2023 17:33:06 - INFO - __main__ -     auc = 0.8000489128113119
06/26/2023 17:33:06 - INFO - __main__ -     f1 = 0.7293783546262067
06/26/2023 17:33:06 - INFO - __main__ -     mcc = 0.4589368611485584
06/26/2023 17:33:06 - INFO - __main__ -     precision = 0.7295251104394327
06/26/2023 17:33:06 - INFO - __main__ -     recall = 0.7294117647058824
06/26/2023 17:33:06 - INFO - __main__ -   {"eval_acc": 0.7294117647058823, "eval_f1": 0.7293783546262067, "eval_mcc": 0.4589368611485584, "eval_auc": 0.8000489128113119, "eval_precision": 0.7295251104394327, "eval_recall": 0.7294117647058824, "learning_rate": 6.899055918663763e-05, "loss": 0.07454075556714088, "step": 2900}
06/26/2023 17:33:50 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:33:51 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:33:51 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:33:51 - INFO - __main__ -     Batch size = 48
06/26/2023 17:34:00 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:34:00 - INFO - __main__ -     acc = 0.7205882352941176
06/26/2023 17:34:00 - INFO - __main__ -     auc = 0.7825799906019053
06/26/2023 17:34:00 - INFO - __main__ -     f1 = 0.7192020284683187
06/26/2023 17:34:00 - INFO - __main__ -     mcc = 0.4455979465094435
06/26/2023 17:34:00 - INFO - __main__ -     precision = 0.7250318672578906
06/26/2023 17:34:00 - INFO - __main__ -     recall = 0.7205882352941176
06/26/2023 17:34:00 - INFO - __main__ -   {"eval_acc": 0.7205882352941176, "eval_f1": 0.7192020284683187, "eval_mcc": 0.4455979465094435, "eval_auc": 0.7825799906019053, "eval_precision": 0.7250318672578906, "eval_recall": 0.7205882352941176, "learning_rate": 6.753812636165577e-05, "loss": 0.06928834191407077, "step": 3000}
06/26/2023 17:34:43 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:34:44 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:34:44 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:34:44 - INFO - __main__ -     Batch size = 48
06/26/2023 17:34:53 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:34:53 - INFO - __main__ -     acc = 0.7251633986928104
06/26/2023 17:34:53 - INFO - __main__ -     auc = 0.7892124823785723
06/26/2023 17:34:53 - INFO - __main__ -     f1 = 0.7251631345281954
06/26/2023 17:34:53 - INFO - __main__ -     mcc = 0.4503276630682351
06/26/2023 17:34:53 - INFO - __main__ -     precision = 0.7251642643762568
06/26/2023 17:34:53 - INFO - __main__ -     recall = 0.7251633986928104
06/26/2023 17:34:53 - INFO - __main__ -   {"eval_acc": 0.7251633986928104, "eval_f1": 0.7251631345281954, "eval_mcc": 0.4503276630682351, "eval_auc": 0.7892124823785723, "eval_precision": 0.7251642643762568, "eval_recall": 0.7251633986928104, "learning_rate": 6.608569353667393e-05, "loss": 0.07678597273887135, "step": 3100}
06/26/2023 17:35:36 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:35:36 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:35:36 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:35:36 - INFO - __main__ -     Batch size = 48
06/26/2023 17:35:45 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:35:45 - INFO - __main__ -     acc = 0.7290849673202614
06/26/2023 17:35:45 - INFO - __main__ -     auc = 0.7990008116536375
06/26/2023 17:35:45 - INFO - __main__ -     f1 = 0.7281125594325726
06/26/2023 17:35:45 - INFO - __main__ -     mcc = 0.4614828208468374
06/26/2023 17:35:45 - INFO - __main__ -     precision = 0.7324098307583694
06/26/2023 17:35:45 - INFO - __main__ -     recall = 0.7290849673202614
06/26/2023 17:35:45 - INFO - __main__ -   {"eval_acc": 0.7290849673202614, "eval_f1": 0.7281125594325726, "eval_mcc": 0.4614828208468374, "eval_auc": 0.7990008116536375, "eval_precision": 0.7324098307583694, "eval_recall": 0.7290849673202614, "learning_rate": 6.463326071169209e-05, "loss": 0.0698445967643056, "step": 3200}
06/26/2023 17:36:28 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:36:28 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:36:28 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:36:28 - INFO - __main__ -     Batch size = 48
06/26/2023 17:36:37 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:36:37 - INFO - __main__ -     acc = 0.719281045751634
06/26/2023 17:36:37 - INFO - __main__ -     auc = 0.7846351830492546
06/26/2023 17:36:37 - INFO - __main__ -     f1 = 0.7187497291596293
06/26/2023 17:36:37 - INFO - __main__ -     mcc = 0.44022853805061013
06/26/2023 17:36:37 - INFO - __main__ -     precision = 0.7209506583775644
06/26/2023 17:36:37 - INFO - __main__ -     recall = 0.719281045751634
06/26/2023 17:36:37 - INFO - __main__ -   {"eval_acc": 0.719281045751634, "eval_f1": 0.7187497291596293, "eval_mcc": 0.44022853805061013, "eval_auc": 0.7846351830492546, "eval_precision": 0.7209506583775644, "eval_recall": 0.719281045751634, "learning_rate": 6.318082788671025e-05, "loss": 0.061872720078681595, "step": 3300}
06/26/2023 17:37:20 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:37:21 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:37:21 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:37:21 - INFO - __main__ -     Batch size = 48
06/26/2023 17:37:30 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:37:30 - INFO - __main__ -     acc = 0.730718954248366
06/26/2023 17:37:30 - INFO - __main__ -     auc = 0.7846063479858175
06/26/2023 17:37:30 - INFO - __main__ -     f1 = 0.7292941317430073
06/26/2023 17:37:30 - INFO - __main__ -     mcc = 0.4663734064820435
06/26/2023 17:37:30 - INFO - __main__ -     precision = 0.7356808470529094
06/26/2023 17:37:30 - INFO - __main__ -     recall = 0.7307189542483661
06/26/2023 17:37:30 - INFO - __main__ -   {"eval_acc": 0.730718954248366, "eval_f1": 0.7292941317430073, "eval_mcc": 0.4663734064820435, "eval_auc": 0.7846063479858175, "eval_precision": 0.7356808470529094, "eval_recall": 0.7307189542483661, "learning_rate": 6.17283950617284e-05, "loss": 0.05371397003531456, "step": 3400}
06/26/2023 17:38:13 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:38:13 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:38:13 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:38:13 - INFO - __main__ -     Batch size = 48
06/26/2023 17:38:22 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:38:22 - INFO - __main__ -     acc = 0.7186274509803922
06/26/2023 17:38:22 - INFO - __main__ -     auc = 0.7798005040796274
06/26/2023 17:38:22 - INFO - __main__ -     f1 = 0.7165971478141442
06/26/2023 17:38:22 - INFO - __main__ -     mcc = 0.4436578520001059
06/26/2023 17:38:22 - INFO - __main__ -     precision = 0.7250772818768776
06/26/2023 17:38:22 - INFO - __main__ -     recall = 0.7186274509803922
06/26/2023 17:38:22 - INFO - __main__ -   {"eval_acc": 0.7186274509803922, "eval_f1": 0.7165971478141442, "eval_mcc": 0.4436578520001059, "eval_auc": 0.7798005040796274, "eval_precision": 0.7250772818768776, "eval_recall": 0.7186274509803922, "learning_rate": 6.0275962236746555e-05, "loss": 0.05239410251611844, "step": 3500}
06/26/2023 17:39:05 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:39:05 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:39:05 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:39:05 - INFO - __main__ -     Batch size = 48
06/26/2023 17:39:14 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:39:14 - INFO - __main__ -     acc = 0.734313725490196
06/26/2023 17:39:14 - INFO - __main__ -     auc = 0.7970906488957239
06/26/2023 17:39:14 - INFO - __main__ -     f1 = 0.733937943665361
06/26/2023 17:39:14 - INFO - __main__ -     mcc = 0.46995685045329477
06/26/2023 17:39:14 - INFO - __main__ -     precision = 0.735645010579226
06/26/2023 17:39:14 - INFO - __main__ -     recall = 0.7343137254901961
06/26/2023 17:39:14 - INFO - __main__ -   {"eval_acc": 0.734313725490196, "eval_f1": 0.733937943665361, "eval_mcc": 0.46995685045329477, "eval_auc": 0.7970906488957239, "eval_precision": 0.735645010579226, "eval_recall": 0.7343137254901961, "learning_rate": 5.882352941176471e-05, "loss": 0.05894232730846852, "step": 3600}
06/26/2023 17:39:57 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:39:57 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:39:57 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:39:57 - INFO - __main__ -     Batch size = 48
06/26/2023 17:40:06 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:40:06 - INFO - __main__ -     acc = 0.7313725490196078
06/26/2023 17:40:06 - INFO - __main__ -     auc = 0.7875065145884061
06/26/2023 17:40:06 - INFO - __main__ -     f1 = 0.7307080908765444
06/26/2023 17:40:06 - INFO - __main__ -     mcc = 0.46504572152904927
06/26/2023 17:40:06 - INFO - __main__ -     precision = 0.7336788914986478
06/26/2023 17:40:06 - INFO - __main__ -     recall = 0.7313725490196079
06/26/2023 17:40:06 - INFO - __main__ -   {"eval_acc": 0.7313725490196078, "eval_f1": 0.7307080908765444, "eval_mcc": 0.46504572152904927, "eval_auc": 0.7875065145884061, "eval_precision": 0.7336788914986478, "eval_recall": 0.7313725490196079, "learning_rate": 5.7371096586782866e-05, "loss": 0.03723477919265861, "step": 3700}
06/26/2023 17:40:50 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:40:51 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:40:51 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:40:51 - INFO - __main__ -     Batch size = 48
06/26/2023 17:41:00 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:41:00 - INFO - __main__ -     acc = 0.7183006535947712
06/26/2023 17:41:00 - INFO - __main__ -     auc = 0.7869682600709129
06/26/2023 17:41:00 - INFO - __main__ -     f1 = 0.7100560339369382
06/26/2023 17:41:00 - INFO - __main__ -     mcc = 0.46377215538122235
06/26/2023 17:41:00 - INFO - __main__ -     precision = 0.7463169584757674
06/26/2023 17:41:00 - INFO - __main__ -     recall = 0.7183006535947712
06/26/2023 17:41:00 - INFO - __main__ -   {"eval_acc": 0.7183006535947712, "eval_f1": 0.7100560339369382, "eval_mcc": 0.46377215538122235, "eval_auc": 0.7869682600709129, "eval_precision": 0.7463169584757674, "eval_recall": 0.7183006535947712, "learning_rate": 5.591866376180102e-05, "loss": 0.049576292185811326, "step": 3800}
06/26/2023 17:41:43 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:41:44 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:41:44 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:41:44 - INFO - __main__ -     Batch size = 48
06/26/2023 17:41:53 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:41:53 - INFO - __main__ -     acc = 0.7261437908496732
06/26/2023 17:41:53 - INFO - __main__ -     auc = 0.793874364560639
06/26/2023 17:41:53 - INFO - __main__ -     f1 = 0.7245878397972225
06/26/2023 17:41:53 - INFO - __main__ -     mcc = 0.4574862908259725
06/26/2023 17:41:53 - INFO - __main__ -     precision = 0.7313723776223776
06/26/2023 17:41:53 - INFO - __main__ -     recall = 0.7261437908496733
06/26/2023 17:41:53 - INFO - __main__ -   {"eval_acc": 0.7261437908496732, "eval_f1": 0.7245878397972225, "eval_mcc": 0.4574862908259725, "eval_auc": 0.793874364560639, "eval_precision": 0.7313723776223776, "eval_recall": 0.7261437908496733, "learning_rate": 5.446623093681917e-05, "loss": 0.04536885859677568, "step": 3900}
06/26/2023 17:42:35 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:42:36 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:42:36 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:42:36 - INFO - __main__ -     Batch size = 48
06/26/2023 17:42:45 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:42:45 - INFO - __main__ -     acc = 0.7248366013071895
06/26/2023 17:42:45 - INFO - __main__ -     auc = 0.7954241958221197
06/26/2023 17:42:45 - INFO - __main__ -     f1 = 0.7210611740088411
06/26/2023 17:42:45 - INFO - __main__ -     mcc = 0.4623635031756784
06/26/2023 17:42:45 - INFO - __main__ -     precision = 0.7377059693861883
06/26/2023 17:42:45 - INFO - __main__ -     recall = 0.7248366013071895
06/26/2023 17:42:45 - INFO - __main__ -   {"eval_acc": 0.7248366013071895, "eval_f1": 0.7210611740088411, "eval_mcc": 0.4623635031756784, "eval_auc": 0.7954241958221197, "eval_precision": 0.7377059693861883, "eval_recall": 0.7248366013071895, "learning_rate": 5.301379811183733e-05, "loss": 0.04750929814123083, "step": 4000}
06/26/2023 17:42:45 - INFO - transformers.configuration_utils -   Configuration saved in /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold1/checkpoint-4000/config.json
06/26/2023 17:42:46 - INFO - transformers.modeling_utils -   Model weights saved in /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold1/checkpoint-4000/pytorch_model.bin
06/26/2023 17:42:46 - INFO - __main__ -   Saving model checkpoint to /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold1/checkpoint-4000
06/26/2023 17:42:47 - INFO - __main__ -   Saving optimizer and scheduler states to /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold1/checkpoint-4000
06/26/2023 17:43:29 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:43:30 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:43:30 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:43:30 - INFO - __main__ -     Batch size = 48
06/26/2023 17:43:39 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:43:39 - INFO - __main__ -     acc = 0.7290849673202614
06/26/2023 17:43:39 - INFO - __main__ -     auc = 0.7887931991968902
06/26/2023 17:43:39 - INFO - __main__ -     f1 = 0.7279109884922546
06/26/2023 17:43:39 - INFO - __main__ -     mcc = 0.46217557856650565
06/26/2023 17:43:39 - INFO - __main__ -     precision = 0.7331081213249822
06/26/2023 17:43:39 - INFO - __main__ -     recall = 0.7290849673202614
06/26/2023 17:43:39 - INFO - __main__ -   {"eval_acc": 0.7290849673202614, "eval_f1": 0.7279109884922546, "eval_mcc": 0.46217557856650565, "eval_auc": 0.7887931991968902, "eval_precision": 0.7331081213249822, "eval_recall": 0.7290849673202614, "learning_rate": 5.156136528685549e-05, "loss": 0.052021002817782575, "step": 4100}
06/26/2023 17:44:21 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:44:22 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:44:22 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:44:22 - INFO - __main__ -     Batch size = 48
06/26/2023 17:44:31 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:44:31 - INFO - __main__ -     acc = 0.7369281045751634
06/26/2023 17:44:31 - INFO - __main__ -     auc = 0.7847678243410654
06/26/2023 17:44:31 - INFO - __main__ -     f1 = 0.7363360743692182
06/26/2023 17:44:31 - INFO - __main__ -     mcc = 0.475998642528518
06/26/2023 17:44:31 - INFO - __main__ -     precision = 0.7390753812166604
06/26/2023 17:44:31 - INFO - __main__ -     recall = 0.7369281045751634
06/26/2023 17:44:31 - INFO - __main__ -   {"eval_acc": 0.7369281045751634, "eval_f1": 0.7363360743692182, "eval_mcc": 0.475998642528518, "eval_auc": 0.7847678243410654, "eval_precision": 0.7390753812166604, "eval_recall": 0.7369281045751634, "learning_rate": 5.0108932461873634e-05, "loss": 0.040180013871286065, "step": 4200}
06/26/2023 17:45:15 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:45:16 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:45:16 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:45:16 - INFO - __main__ -     Batch size = 48
06/26/2023 17:45:25 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:45:25 - INFO - __main__ -     acc = 0.7163398692810458
06/26/2023 17:45:25 - INFO - __main__ -     auc = 0.7766391131616045
06/26/2023 17:45:25 - INFO - __main__ -     f1 = 0.7163277511961723
06/26/2023 17:45:25 - INFO - __main__ -     mcc = 0.43271671025647346
06/26/2023 17:45:25 - INFO - __main__ -     precision = 0.7163768425550097
06/26/2023 17:45:25 - INFO - __main__ -     recall = 0.7163398692810458
06/26/2023 17:45:25 - INFO - __main__ -   {"eval_acc": 0.7163398692810458, "eval_f1": 0.7163277511961723, "eval_mcc": 0.43271671025647346, "eval_auc": 0.7766391131616045, "eval_precision": 0.7163768425550097, "eval_recall": 0.7163398692810458, "learning_rate": 4.865649963689179e-05, "loss": 0.0375512245669961, "step": 4300}
06/26/2023 17:46:09 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:46:10 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:46:10 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:46:10 - INFO - __main__ -     Batch size = 48
06/26/2023 17:46:19 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:46:19 - INFO - __main__ -     acc = 0.7225490196078431
06/26/2023 17:46:19 - INFO - __main__ -     auc = 0.7827500106796532
06/26/2023 17:46:19 - INFO - __main__ -     f1 = 0.7183643376406084
06/26/2023 17:46:19 - INFO - __main__ -     mcc = 0.4589454179677931
06/26/2023 17:46:19 - INFO - __main__ -     precision = 0.7366118002280891
06/26/2023 17:46:19 - INFO - __main__ -     recall = 0.7225490196078431
06/26/2023 17:46:19 - INFO - __main__ -   {"eval_acc": 0.7225490196078431, "eval_f1": 0.7183643376406084, "eval_mcc": 0.4589454179677931, "eval_auc": 0.7827500106796532, "eval_precision": 0.7366118002280891, "eval_recall": 0.7225490196078431, "learning_rate": 4.720406681190995e-05, "loss": 0.027940051376644987, "step": 4400}
06/26/2023 17:47:03 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:47:03 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:47:03 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:47:03 - INFO - __main__ -     Batch size = 48
06/26/2023 17:47:12 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:47:12 - INFO - __main__ -     acc = 0.7369281045751634
06/26/2023 17:47:12 - INFO - __main__ -     auc = 0.7964635396642317
06/26/2023 17:47:12 - INFO - __main__ -     f1 = 0.7350298536473706
06/26/2023 17:47:12 - INFO - __main__ -     mcc = 0.4807951310912956
06/26/2023 17:47:12 - INFO - __main__ -     precision = 0.743917831630398
06/26/2023 17:47:12 - INFO - __main__ -     recall = 0.7369281045751634
06/26/2023 17:47:12 - INFO - __main__ -   {"eval_acc": 0.7369281045751634, "eval_f1": 0.7350298536473706, "eval_mcc": 0.4807951310912956, "eval_auc": 0.7964635396642317, "eval_precision": 0.743917831630398, "eval_recall": 0.7369281045751634, "learning_rate": 4.5751633986928104e-05, "loss": 0.034500829953467475, "step": 4500}
06/26/2023 17:47:56 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:47:56 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:47:56 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:47:56 - INFO - __main__ -     Batch size = 48
06/26/2023 17:48:06 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:48:06 - INFO - __main__ -     acc = 0.7359477124183007
06/26/2023 17:48:06 - INFO - __main__ -     auc = 0.795434661882182
06/26/2023 17:48:06 - INFO - __main__ -     f1 = 0.734837516553351
06/26/2023 17:48:06 - INFO - __main__ -     mcc = 0.47589727287035016
06/26/2023 17:48:06 - INFO - __main__ -     precision = 0.739966529029029
06/26/2023 17:48:06 - INFO - __main__ -     recall = 0.7359477124183007
06/26/2023 17:48:06 - INFO - __main__ -   {"eval_acc": 0.7359477124183007, "eval_f1": 0.734837516553351, "eval_mcc": 0.47589727287035016, "eval_auc": 0.795434661882182, "eval_precision": 0.739966529029029, "eval_recall": 0.7359477124183007, "learning_rate": 4.429920116194626e-05, "loss": 0.030270069701218746, "step": 4600}
06/26/2023 17:48:48 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:48:49 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:48:49 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:48:49 - INFO - __main__ -     Batch size = 48
06/26/2023 17:48:58 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:48:58 - INFO - __main__ -     acc = 0.7362745098039216
06/26/2023 17:48:58 - INFO - __main__ -     auc = 0.7961519073860481
06/26/2023 17:48:58 - INFO - __main__ -     f1 = 0.7362400032043153
06/26/2023 17:48:58 - INFO - __main__ -     mcc = 0.4726727113166835
06/26/2023 17:48:58 - INFO - __main__ -     precision = 0.7363982177011765
06/26/2023 17:48:58 - INFO - __main__ -     recall = 0.7362745098039216
06/26/2023 17:48:58 - INFO - __main__ -   {"eval_acc": 0.7362745098039216, "eval_f1": 0.7362400032043153, "eval_mcc": 0.4726727113166835, "eval_auc": 0.7961519073860481, "eval_precision": 0.7363982177011765, "eval_recall": 0.7362745098039216, "learning_rate": 4.2846768336964415e-05, "loss": 0.018471842897706665, "step": 4700}
06/26/2023 17:49:41 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:49:42 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:49:42 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:49:42 - INFO - __main__ -     Batch size = 48
06/26/2023 17:49:51 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:49:51 - INFO - __main__ -     acc = 0.7339869281045751
06/26/2023 17:49:51 - INFO - __main__ -     auc = 0.7881957794010851
06/26/2023 17:49:51 - INFO - __main__ -     f1 = 0.7336910292481842
06/26/2023 17:49:51 - INFO - __main__ -     mcc = 0.46901727747376437
06/26/2023 17:49:51 - INFO - __main__ -     precision = 0.735031512605042
06/26/2023 17:49:51 - INFO - __main__ -     recall = 0.7339869281045752
06/26/2023 17:49:51 - INFO - __main__ -   {"eval_acc": 0.7339869281045751, "eval_f1": 0.7336910292481842, "eval_mcc": 0.46901727747376437, "eval_auc": 0.7881957794010851, "eval_precision": 0.735031512605042, "eval_recall": 0.7339869281045752, "learning_rate": 4.1394335511982573e-05, "loss": 0.028111226058099417, "step": 4800}
06/26/2023 17:50:33 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:50:34 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:50:34 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:50:34 - INFO - __main__ -     Batch size = 48
06/26/2023 17:50:43 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:50:43 - INFO - __main__ -     acc = 0.7339869281045751
06/26/2023 17:50:43 - INFO - __main__ -     auc = 0.7971472510572857
06/26/2023 17:50:43 - INFO - __main__ -     f1 = 0.7335772044666924
06/26/2023 17:50:43 - INFO - __main__ -     mcc = 0.4694198970637004
06/26/2023 17:50:43 - INFO - __main__ -     precision = 0.7354352030947775
06/26/2023 17:50:43 - INFO - __main__ -     recall = 0.7339869281045752
06/26/2023 17:50:43 - INFO - __main__ -   {"eval_acc": 0.7339869281045751, "eval_f1": 0.7335772044666924, "eval_mcc": 0.4694198970637004, "eval_auc": 0.7971472510572857, "eval_precision": 0.7354352030947775, "eval_recall": 0.7339869281045752, "learning_rate": 3.9941902687000726e-05, "loss": 0.027442260355092004, "step": 4900}
06/26/2023 17:51:26 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:51:26 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:51:26 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:51:26 - INFO - __main__ -     Batch size = 48
06/26/2023 17:51:35 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:51:35 - INFO - __main__ -     acc = 0.7326797385620915
06/26/2023 17:51:35 - INFO - __main__ -     auc = 0.8024744756290315
06/26/2023 17:51:35 - INFO - __main__ -     f1 = 0.7315097316298672
06/26/2023 17:51:35 - INFO - __main__ -     mcc = 0.46946909954404376
06/26/2023 17:51:35 - INFO - __main__ -     precision = 0.7368075071649183
06/26/2023 17:51:35 - INFO - __main__ -     recall = 0.7326797385620916
06/26/2023 17:51:35 - INFO - __main__ -   {"eval_acc": 0.7326797385620915, "eval_f1": 0.7315097316298672, "eval_mcc": 0.46946909954404376, "eval_auc": 0.8024744756290315, "eval_precision": 0.7368075071649183, "eval_recall": 0.7326797385620916, "learning_rate": 3.8489469862018884e-05, "loss": 0.024320678337171556, "step": 5000}
06/26/2023 17:52:19 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:52:19 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:52:19 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:52:19 - INFO - __main__ -     Batch size = 48
06/26/2023 17:52:28 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:52:28 - INFO - __main__ -     acc = 0.7395424836601308
06/26/2023 17:52:28 - INFO - __main__ -     auc = 0.8010429749241745
06/26/2023 17:52:28 - INFO - __main__ -     f1 = 0.7371655038695779
06/26/2023 17:52:28 - INFO - __main__ -     mcc = 0.48799272609079725
06/26/2023 17:52:28 - INFO - __main__ -     precision = 0.7485330546369834
06/26/2023 17:52:28 - INFO - __main__ -     recall = 0.7395424836601308
06/26/2023 17:52:28 - INFO - __main__ -   {"eval_acc": 0.7395424836601308, "eval_f1": 0.7371655038695779, "eval_mcc": 0.48799272609079725, "eval_auc": 0.8010429749241745, "eval_precision": 0.7485330546369834, "eval_recall": 0.7395424836601308, "learning_rate": 3.7037037037037037e-05, "loss": 0.019755850728106452, "step": 5100}
06/26/2023 17:53:11 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:53:11 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:53:11 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:53:11 - INFO - __main__ -     Batch size = 48
06/26/2023 17:53:20 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:53:20 - INFO - __main__ -     acc = 0.7382352941176471
06/26/2023 17:53:20 - INFO - __main__ -     auc = 0.793755820410953
06/26/2023 17:53:20 - INFO - __main__ -     f1 = 0.737471984576455
06/26/2023 17:53:20 - INFO - __main__ -     mcc = 0.4792657030503987
06/26/2023 17:53:20 - INFO - __main__ -     precision = 0.7410386074102888
06/26/2023 17:53:20 - INFO - __main__ -     recall = 0.7382352941176471
06/26/2023 17:53:20 - INFO - __main__ -   {"eval_acc": 0.7382352941176471, "eval_f1": 0.737471984576455, "eval_mcc": 0.4792657030503987, "eval_auc": 0.793755820410953, "eval_precision": 0.7410386074102888, "eval_recall": 0.7382352941176471, "learning_rate": 3.5584604212055195e-05, "loss": 0.017098073406959884, "step": 5200}
06/26/2023 17:54:03 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:54:03 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:54:03 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:54:03 - INFO - __main__ -     Batch size = 48
06/26/2023 17:54:13 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:54:13 - INFO - __main__ -     acc = 0.734967320261438
06/26/2023 17:54:13 - INFO - __main__ -     auc = 0.7964028792344824
06/26/2023 17:54:13 - INFO - __main__ -     f1 = 0.7346666964610573
06/26/2023 17:54:13 - INFO - __main__ -     mcc = 0.4710031498056593
06/26/2023 17:54:13 - INFO - __main__ -     precision = 0.7360370443004758
06/26/2023 17:54:13 - INFO - __main__ -     recall = 0.734967320261438
06/26/2023 17:54:13 - INFO - __main__ -   {"eval_acc": 0.734967320261438, "eval_f1": 0.7346666964610573, "eval_mcc": 0.4710031498056593, "eval_auc": 0.7964028792344824, "eval_precision": 0.7360370443004758, "eval_recall": 0.734967320261438, "learning_rate": 3.413217138707335e-05, "loss": 0.015172435299828067, "step": 5300}
06/26/2023 17:54:56 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:54:57 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:54:57 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:54:57 - INFO - __main__ -     Batch size = 48
06/26/2023 17:55:06 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:55:06 - INFO - __main__ -     acc = 0.734313725490196
06/26/2023 17:55:06 - INFO - __main__ -     auc = 0.7966521423384167
06/26/2023 17:55:06 - INFO - __main__ -     f1 = 0.7328435317986729
06/26/2023 17:55:06 - INFO - __main__ -     mcc = 0.47387202079955104
06/26/2023 17:55:06 - INFO - __main__ -     precision = 0.7395876421951706
06/26/2023 17:55:06 - INFO - __main__ -     recall = 0.7343137254901961
06/26/2023 17:55:06 - INFO - __main__ -   {"eval_acc": 0.734313725490196, "eval_f1": 0.7328435317986729, "eval_mcc": 0.47387202079955104, "eval_auc": 0.7966521423384167, "eval_precision": 0.7395876421951706, "eval_recall": 0.7343137254901961, "learning_rate": 3.2679738562091506e-05, "loss": 0.015729240881701117, "step": 5400}
06/26/2023 17:55:49 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:55:50 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:55:50 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:55:50 - INFO - __main__ -     Batch size = 48
06/26/2023 17:55:59 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:55:59 - INFO - __main__ -     acc = 0.7316993464052287
06/26/2023 17:55:59 - INFO - __main__ -     auc = 0.7984461104703319
06/26/2023 17:55:59 - INFO - __main__ -     f1 = 0.729578363513477
06/26/2023 17:55:59 - INFO - __main__ -     mcc = 0.47084342883878877
06/26/2023 17:55:59 - INFO - __main__ -     precision = 0.7392038841716653
06/26/2023 17:55:59 - INFO - __main__ -     recall = 0.7316993464052288
06/26/2023 17:55:59 - INFO - __main__ -   {"eval_acc": 0.7316993464052287, "eval_f1": 0.729578363513477, "eval_mcc": 0.47084342883878877, "eval_auc": 0.7984461104703319, "eval_precision": 0.7392038841716653, "eval_recall": 0.7316993464052288, "learning_rate": 3.122730573710966e-05, "loss": 0.016031138604303122, "step": 5500}
06/26/2023 17:56:42 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:56:42 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:56:42 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:56:42 - INFO - __main__ -     Batch size = 48
06/26/2023 17:56:51 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:56:51 - INFO - __main__ -     acc = 0.723202614379085
06/26/2023 17:56:51 - INFO - __main__ -     auc = 0.79519244734931
06/26/2023 17:56:51 - INFO - __main__ -     f1 = 0.7232025848180811
06/26/2023 17:56:51 - INFO - __main__ -     mcc = 0.4464053241072604
06/26/2023 17:56:51 - INFO - __main__ -     precision = 0.7232027097281857
06/26/2023 17:56:51 - INFO - __main__ -     recall = 0.723202614379085
06/26/2023 17:56:51 - INFO - __main__ -   {"eval_acc": 0.723202614379085, "eval_f1": 0.7232025848180811, "eval_mcc": 0.4464053241072604, "eval_auc": 0.79519244734931, "eval_precision": 0.7232027097281857, "eval_recall": 0.723202614379085, "learning_rate": 2.9774872912127817e-05, "loss": 0.015315991100651445, "step": 5600}
06/26/2023 17:57:34 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:57:35 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:57:35 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:57:35 - INFO - __main__ -     Batch size = 48
06/26/2023 17:57:44 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:57:44 - INFO - __main__ -     acc = 0.7375816993464053
06/26/2023 17:57:44 - INFO - __main__ -     auc = 0.8009109744115511
06/26/2023 17:57:44 - INFO - __main__ -     f1 = 0.737069941013603
06/26/2023 17:57:44 - INFO - __main__ -     mcc = 0.47702395424988564
06/26/2023 17:57:44 - INFO - __main__ -     precision = 0.7394458975104137
06/26/2023 17:57:44 - INFO - __main__ -     recall = 0.7375816993464053
06/26/2023 17:57:44 - INFO - __main__ -   {"eval_acc": 0.7375816993464053, "eval_f1": 0.737069941013603, "eval_mcc": 0.47702395424988564, "eval_auc": 0.8009109744115511, "eval_precision": 0.7394458975104137, "eval_recall": 0.7375816993464053, "learning_rate": 2.832244008714597e-05, "loss": 0.016756192475295393, "step": 5700}
06/26/2023 17:58:26 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:58:26 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:58:26 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:58:26 - INFO - __main__ -     Batch size = 48
06/26/2023 17:58:36 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:58:36 - INFO - __main__ -     acc = 0.7284313725490196
06/26/2023 17:58:36 - INFO - __main__ -     auc = 0.7987004998077663
06/26/2023 17:58:36 - INFO - __main__ -     f1 = 0.7274989098820466
06/26/2023 17:58:36 - INFO - __main__ -     mcc = 0.4600218602690684
06/26/2023 17:58:36 - INFO - __main__ -     precision = 0.7316014100471272
06/26/2023 17:58:36 - INFO - __main__ -     recall = 0.7284313725490196
06/26/2023 17:58:36 - INFO - __main__ -   {"eval_acc": 0.7284313725490196, "eval_f1": 0.7274989098820466, "eval_mcc": 0.4600218602690684, "eval_auc": 0.7987004998077663, "eval_precision": 0.7316014100471272, "eval_recall": 0.7284313725490196, "learning_rate": 2.6870007262164125e-05, "loss": 0.0064230507849060816, "step": 5800}
06/26/2023 17:59:18 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 17:59:19 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 17:59:19 - INFO - __main__ -     Num examples = 3060
06/26/2023 17:59:19 - INFO - __main__ -     Batch size = 48
06/26/2023 17:59:28 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 17:59:28 - INFO - __main__ -     acc = 0.7339869281045751
06/26/2023 17:59:28 - INFO - __main__ -     auc = 0.7962392669486096
06/26/2023 17:59:28 - INFO - __main__ -     f1 = 0.7318050731828329
06/26/2023 17:59:28 - INFO - __main__ -     mcc = 0.4757791225867277
06/26/2023 17:59:28 - INFO - __main__ -     precision = 0.7418572859209334
06/26/2023 17:59:28 - INFO - __main__ -     recall = 0.7339869281045752
06/26/2023 17:59:28 - INFO - __main__ -   {"eval_acc": 0.7339869281045751, "eval_f1": 0.7318050731828329, "eval_mcc": 0.4757791225867277, "eval_auc": 0.7962392669486096, "eval_precision": 0.7418572859209334, "eval_recall": 0.7339869281045752, "learning_rate": 2.5417574437182277e-05, "loss": 0.017238159331682254, "step": 5900}
06/26/2023 18:00:10 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:00:11 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:00:11 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:00:11 - INFO - __main__ -     Batch size = 48
06/26/2023 18:00:20 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:00:20 - INFO - __main__ -     acc = 0.7297385620915032
06/26/2023 18:00:20 - INFO - __main__ -     auc = 0.79718954248366
06/26/2023 18:00:20 - INFO - __main__ -     f1 = 0.7268809863030375
06/26/2023 18:00:20 - INFO - __main__ -     mcc = 0.4694046292677843
06/26/2023 18:00:20 - INFO - __main__ -     precision = 0.7397733144711094
06/26/2023 18:00:20 - INFO - __main__ -     recall = 0.7297385620915033
06/26/2023 18:00:20 - INFO - __main__ -   {"eval_acc": 0.7297385620915032, "eval_f1": 0.7268809863030375, "eval_mcc": 0.4694046292677843, "eval_auc": 0.79718954248366, "eval_precision": 0.7397733144711094, "eval_recall": 0.7297385620915033, "learning_rate": 2.3965141612200436e-05, "loss": 0.006265197907923721, "step": 6000}
06/26/2023 18:01:04 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:01:04 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:01:04 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:01:04 - INFO - __main__ -     Batch size = 48
06/26/2023 18:01:13 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:01:13 - INFO - __main__ -     acc = 0.7375816993464053
06/26/2023 18:01:13 - INFO - __main__ -     auc = 0.8020842411038489
06/26/2023 18:01:13 - INFO - __main__ -     f1 = 0.7368890788697788
06/26/2023 18:01:13 - INFO - __main__ -     mcc = 0.47768499661623015
06/26/2023 18:01:13 - INFO - __main__ -     precision = 0.7401099880798756
06/26/2023 18:01:13 - INFO - __main__ -     recall = 0.7375816993464053
06/26/2023 18:01:13 - INFO - __main__ -   {"eval_acc": 0.7375816993464053, "eval_f1": 0.7368890788697788, "eval_mcc": 0.47768499661623015, "eval_auc": 0.8020842411038489, "eval_precision": 0.7401099880798756, "eval_recall": 0.7375816993464053, "learning_rate": 2.251270878721859e-05, "loss": 0.019637210586297443, "step": 6100}
06/26/2023 18:01:56 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:01:56 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:01:56 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:01:56 - INFO - __main__ -     Batch size = 48
06/26/2023 18:02:05 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:02:05 - INFO - __main__ -     acc = 0.734313725490196
06/26/2023 18:02:05 - INFO - __main__ -     auc = 0.802908923918151
06/26/2023 18:02:05 - INFO - __main__ -     f1 = 0.7339761812774743
06/26/2023 18:02:05 - INFO - __main__ -     mcc = 0.46982123259114683
06/26/2023 18:02:05 - INFO - __main__ -     precision = 0.735509027620642
06/26/2023 18:02:05 - INFO - __main__ -     recall = 0.7343137254901961
06/26/2023 18:02:05 - INFO - __main__ -   {"eval_acc": 0.734313725490196, "eval_f1": 0.7339761812774743, "eval_mcc": 0.46982123259114683, "eval_auc": 0.802908923918151, "eval_precision": 0.735509027620642, "eval_recall": 0.7343137254901961, "learning_rate": 2.1060275962236747e-05, "loss": 0.006610519611822383, "step": 6200}
06/26/2023 18:02:48 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:02:49 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:02:49 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:02:49 - INFO - __main__ -     Batch size = 48
06/26/2023 18:02:58 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:02:58 - INFO - __main__ -     acc = 0.734313725490196
06/26/2023 18:02:58 - INFO - __main__ -     auc = 0.8019671921056004
06/26/2023 18:02:58 - INFO - __main__ -     f1 = 0.7316477133295399
06/26/2023 18:02:58 - INFO - __main__ -     mcc = 0.478225882234737
06/26/2023 18:02:58 - INFO - __main__ -     precision = 0.744010454317967
06/26/2023 18:02:58 - INFO - __main__ -     recall = 0.7343137254901961
06/26/2023 18:02:58 - INFO - __main__ -   {"eval_acc": 0.734313725490196, "eval_f1": 0.7316477133295399, "eval_mcc": 0.478225882234737, "eval_auc": 0.8019671921056004, "eval_precision": 0.744010454317967, "eval_recall": 0.7343137254901961, "learning_rate": 1.9607843137254903e-05, "loss": 0.005203836613873136, "step": 6300}
06/26/2023 18:03:42 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:03:43 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:03:43 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:03:43 - INFO - __main__ -     Batch size = 48
06/26/2023 18:03:52 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:03:52 - INFO - __main__ -     acc = 0.7339869281045751
06/26/2023 18:03:52 - INFO - __main__ -     auc = 0.7991906958861977
06/26/2023 18:03:52 - INFO - __main__ -     f1 = 0.7338913249623193
06/26/2023 18:03:52 - INFO - __main__ -     mcc = 0.468310470932919
06/26/2023 18:03:52 - INFO - __main__ -     precision = 0.7343236638922352
06/26/2023 18:03:52 - INFO - __main__ -     recall = 0.7339869281045752
06/26/2023 18:03:52 - INFO - __main__ -   {"eval_acc": 0.7339869281045751, "eval_f1": 0.7338913249623193, "eval_mcc": 0.468310470932919, "eval_auc": 0.7991906958861977, "eval_precision": 0.7343236638922352, "eval_recall": 0.7339869281045752, "learning_rate": 1.8155410312273058e-05, "loss": 0.011655543380838936, "step": 6400}
06/26/2023 18:04:36 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:04:36 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:04:36 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:04:36 - INFO - __main__ -     Batch size = 48
06/26/2023 18:04:45 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:04:45 - INFO - __main__ -     acc = 0.7375816993464053
06/26/2023 18:04:45 - INFO - __main__ -     auc = 0.7968949976504763
06/26/2023 18:04:45 - INFO - __main__ -     f1 = 0.735285419949097
06/26/2023 18:04:45 - INFO - __main__ -     mcc = 0.483627981893969
06/26/2023 18:04:45 - INFO - __main__ -     precision = 0.7461216767898038
06/26/2023 18:04:45 - INFO - __main__ -     recall = 0.7375816993464053
06/26/2023 18:04:45 - INFO - __main__ -   {"eval_acc": 0.7375816993464053, "eval_f1": 0.735285419949097, "eval_mcc": 0.483627981893969, "eval_auc": 0.7968949976504763, "eval_precision": 0.7461216767898038, "eval_recall": 0.7375816993464053, "learning_rate": 1.6702977487291213e-05, "loss": 0.005011349290180078, "step": 6500}
06/26/2023 18:05:29 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:05:30 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:05:30 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:05:30 - INFO - __main__ -     Batch size = 48
06/26/2023 18:05:39 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:05:39 - INFO - __main__ -     acc = 0.7323529411764705
06/26/2023 18:05:39 - INFO - __main__ -     auc = 0.8005841770259303
06/26/2023 18:05:39 - INFO - __main__ -     f1 = 0.7319197973657938
06/26/2023 18:05:39 - INFO - __main__ -     mcc = 0.46621487421588353
06/26/2023 18:05:39 - INFO - __main__ -     precision = 0.733864383036851
06/26/2023 18:05:39 - INFO - __main__ -     recall = 0.7323529411764707
06/26/2023 18:05:39 - INFO - __main__ -   {"eval_acc": 0.7323529411764705, "eval_f1": 0.7319197973657938, "eval_mcc": 0.46621487421588353, "eval_auc": 0.8005841770259303, "eval_precision": 0.733864383036851, "eval_recall": 0.7323529411764707, "learning_rate": 1.5250544662309369e-05, "loss": 0.006382550224352599, "step": 6600}
06/26/2023 18:06:22 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:06:23 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:06:23 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:06:23 - INFO - __main__ -     Batch size = 48
06/26/2023 18:06:32 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:06:32 - INFO - __main__ -     acc = 0.7375816993464053
06/26/2023 18:06:32 - INFO - __main__ -     auc = 0.8006852065444914
06/26/2023 18:06:32 - INFO - __main__ -     f1 = 0.7373177434585204
06/26/2023 18:06:32 - INFO - __main__ -     mcc = 0.47612122157901954
06/26/2023 18:06:32 - INFO - __main__ -     precision = 0.7385404876107178
06/26/2023 18:06:32 - INFO - __main__ -     recall = 0.7375816993464053
06/26/2023 18:06:32 - INFO - __main__ -   {"eval_acc": 0.7375816993464053, "eval_f1": 0.7373177434585204, "eval_mcc": 0.47612122157901954, "eval_auc": 0.8006852065444914, "eval_precision": 0.7385404876107178, "eval_recall": 0.7375816993464053, "learning_rate": 1.3798111837327524e-05, "loss": 0.003567590036400361, "step": 6700}
06/26/2023 18:07:15 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:07:15 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:07:15 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:07:15 - INFO - __main__ -     Batch size = 48
06/26/2023 18:07:24 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:07:24 - INFO - __main__ -     acc = 0.734313725490196
06/26/2023 18:07:24 - INFO - __main__ -     auc = 0.8002763894228715
06/26/2023 18:07:24 - INFO - __main__ -     f1 = 0.7342215051550951
06/26/2023 18:07:24 - INFO - __main__ -     mcc = 0.468953000413736
06/26/2023 18:07:24 - INFO - __main__ -     precision = 0.7346393880010318
06/26/2023 18:07:24 - INFO - __main__ -     recall = 0.7343137254901961
06/26/2023 18:07:24 - INFO - __main__ -   {"eval_acc": 0.734313725490196, "eval_f1": 0.7342215051550951, "eval_mcc": 0.468953000413736, "eval_auc": 0.8002763894228715, "eval_precision": 0.7346393880010318, "eval_recall": 0.7343137254901961, "learning_rate": 1.2345679012345678e-05, "loss": 0.001712714131008397, "step": 6800}
06/26/2023 18:08:08 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:08:08 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:08:08 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:08:08 - INFO - __main__ -     Batch size = 48
06/26/2023 18:08:17 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:08:17 - INFO - __main__ -     acc = 0.7336601307189542
06/26/2023 18:08:17 - INFO - __main__ -     auc = 0.8011508394207356
06/26/2023 18:08:17 - INFO - __main__ -     f1 = 0.7328257891088182
06/26/2023 18:08:17 - INFO - __main__ -     mcc = 0.47026662373548606
06/26/2023 18:08:17 - INFO - __main__ -     precision = 0.7366157811338091
06/26/2023 18:08:17 - INFO - __main__ -     recall = 0.7336601307189543
06/26/2023 18:08:17 - INFO - __main__ -   {"eval_acc": 0.7336601307189542, "eval_f1": 0.7328257891088182, "eval_mcc": 0.47026662373548606, "eval_auc": 0.8011508394207356, "eval_precision": 0.7366157811338091, "eval_recall": 0.7336601307189543, "learning_rate": 1.0893246187363835e-05, "loss": 0.006216056876055518, "step": 6900}
06/26/2023 18:09:01 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:09:02 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:09:02 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:09:02 - INFO - __main__ -     Batch size = 48
06/26/2023 18:09:11 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:09:11 - INFO - __main__ -     acc = 0.7297385620915032
06/26/2023 18:09:11 - INFO - __main__ -     auc = 0.8016959289162289
06/26/2023 18:09:11 - INFO - __main__ -     f1 = 0.7291635161545419
06/26/2023 18:09:11 - INFO - __main__ -     mcc = 0.4614407846615773
06/26/2023 18:09:11 - INFO - __main__ -     precision = 0.7317064186032083
06/26/2023 18:09:11 - INFO - __main__ -     recall = 0.7297385620915033
06/26/2023 18:09:11 - INFO - __main__ -   {"eval_acc": 0.7297385620915032, "eval_f1": 0.7291635161545419, "eval_mcc": 0.4614407846615773, "eval_auc": 0.8016959289162289, "eval_precision": 0.7317064186032083, "eval_recall": 0.7297385620915033, "learning_rate": 9.440813362381991e-06, "loss": 0.003184486966965778, "step": 7000}
06/26/2023 18:09:55 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:09:55 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:09:55 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:09:55 - INFO - __main__ -     Batch size = 48
06/26/2023 18:10:04 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:10:04 - INFO - __main__ -     acc = 0.7352941176470589
06/26/2023 18:10:04 - INFO - __main__ -     auc = 0.8018341236276646
06/26/2023 18:10:04 - INFO - __main__ -     f1 = 0.7339931168331079
06/26/2023 18:10:04 - INFO - __main__ -     mcc = 0.4752600523313097
06/26/2023 18:10:04 - INFO - __main__ -     precision = 0.7399891246758317
06/26/2023 18:10:04 - INFO - __main__ -     recall = 0.7352941176470589
06/26/2023 18:10:04 - INFO - __main__ -   {"eval_acc": 0.7352941176470589, "eval_f1": 0.7339931168331079, "eval_mcc": 0.4752600523313097, "eval_auc": 0.8018341236276646, "eval_precision": 0.7399891246758317, "eval_recall": 0.7352941176470589, "learning_rate": 7.988380537400146e-06, "loss": 0.0018900964492422644, "step": 7100}
06/26/2023 18:10:47 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:10:47 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:10:47 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:10:47 - INFO - __main__ -     Batch size = 48
06/26/2023 18:10:57 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:10:57 - INFO - __main__ -     acc = 0.734640522875817
06/26/2023 18:10:57 - INFO - __main__ -     auc = 0.8012290144816095
06/26/2023 18:10:57 - INFO - __main__ -     f1 = 0.7338382513998365
06/26/2023 18:10:57 - INFO - __main__ -     mcc = 0.4721359251968074
06/26/2023 18:10:57 - INFO - __main__ -     precision = 0.7375040861754953
06/26/2023 18:10:57 - INFO - __main__ -     recall = 0.734640522875817
06/26/2023 18:10:57 - INFO - __main__ -   {"eval_acc": 0.734640522875817, "eval_f1": 0.7338382513998365, "eval_mcc": 0.4721359251968074, "eval_auc": 0.8012290144816095, "eval_precision": 0.7375040861754953, "eval_recall": 0.734640522875817, "learning_rate": 6.535947712418301e-06, "loss": 0.00028966045487322845, "step": 7200}
06/26/2023 18:11:40 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:11:41 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:11:41 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:11:41 - INFO - __main__ -     Batch size = 48
06/26/2023 18:11:50 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:11:50 - INFO - __main__ -     acc = 0.7339869281045751
06/26/2023 18:11:50 - INFO - __main__ -     auc = 0.8016683754111666
06/26/2023 18:11:50 - INFO - __main__ -     f1 = 0.7331240188383046
06/26/2023 18:11:50 - INFO - __main__ -     mcc = 0.47102979827788555
06/26/2023 18:11:50 - INFO - __main__ -     precision = 0.7370528480618223
06/26/2023 18:11:50 - INFO - __main__ -     recall = 0.7339869281045752
06/26/2023 18:11:50 - INFO - __main__ -   {"eval_acc": 0.7339869281045751, "eval_f1": 0.7331240188383046, "eval_mcc": 0.47102979827788555, "eval_auc": 0.8016683754111666, "eval_precision": 0.7370528480618223, "eval_recall": 0.7339869281045752, "learning_rate": 5.083514887436457e-06, "loss": 0.0034698787383604214, "step": 7300}
06/26/2023 18:12:34 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:12:34 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:12:34 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:12:34 - INFO - __main__ -     Batch size = 48
06/26/2023 18:12:43 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:12:43 - INFO - __main__ -     acc = 0.7339869281045751
06/26/2023 18:12:43 - INFO - __main__ -     auc = 0.8015015592293564
06/26/2023 18:12:43 - INFO - __main__ -     f1 = 0.7336427311126557
06/26/2023 18:12:43 - INFO - __main__ -     mcc = 0.4691880324825032
06/26/2023 18:12:43 - INFO - __main__ -     precision = 0.7352026794915836
06/26/2023 18:12:43 - INFO - __main__ -     recall = 0.7339869281045752
06/26/2023 18:12:43 - INFO - __main__ -   {"eval_acc": 0.7339869281045751, "eval_f1": 0.7336427311126557, "eval_mcc": 0.4691880324825032, "eval_auc": 0.8015015592293564, "eval_precision": 0.7352026794915836, "eval_recall": 0.7339869281045752, "learning_rate": 3.6310820624546117e-06, "loss": 0.0020591386243904706, "step": 7400}
06/26/2023 18:13:26 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:13:27 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:13:27 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:13:27 - INFO - __main__ -     Batch size = 48
06/26/2023 18:13:36 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:13:36 - INFO - __main__ -     acc = 0.7310457516339869
06/26/2023 18:13:36 - INFO - __main__ -     auc = 0.8013373061642958
06/26/2023 18:13:36 - INFO - __main__ -     f1 = 0.730638383757571
06/26/2023 18:13:36 - INFO - __main__ -     mcc = 0.4634955609272233
06/26/2023 18:13:36 - INFO - __main__ -     precision = 0.7324519423966332
06/26/2023 18:13:36 - INFO - __main__ -     recall = 0.731045751633987
06/26/2023 18:13:36 - INFO - __main__ -   {"eval_acc": 0.7310457516339869, "eval_f1": 0.730638383757571, "eval_mcc": 0.4634955609272233, "eval_auc": 0.8013373061642958, "eval_precision": 0.7324519423966332, "eval_recall": 0.731045751633987, "learning_rate": 2.178649237472767e-06, "loss": 0.00042410706910231963, "step": 7500}
06/26/2023 18:14:18 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:14:19 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:14:19 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:14:19 - INFO - __main__ -     Batch size = 48
06/26/2023 18:14:28 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:14:28 - INFO - __main__ -     acc = 0.7323529411764705
06/26/2023 18:14:28 - INFO - __main__ -     auc = 0.801528044769106
06/26/2023 18:14:28 - INFO - __main__ -     f1 = 0.7317995320987312
06/26/2023 18:14:28 - INFO - __main__ -     mcc = 0.46663559892769285
06/26/2023 18:14:28 - INFO - __main__ -     precision = 0.7342866643779945
06/26/2023 18:14:28 - INFO - __main__ -     recall = 0.7323529411764707
06/26/2023 18:14:28 - INFO - __main__ -   {"eval_acc": 0.7323529411764705, "eval_f1": 0.7317995320987312, "eval_mcc": 0.46663559892769285, "eval_auc": 0.801528044769106, "eval_precision": 0.7342866643779945, "eval_recall": 0.7323529411764707, "learning_rate": 7.262164124909224e-07, "loss": 0.0017551774015191768, "step": 7600}
06/26/2023 18:14:50 - INFO - __main__ -    global_step = 7650, average loss = 0.1327932832406738
06/26/2023 18:14:50 - INFO - __main__ -   Saving model checkpoint to /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold1
06/26/2023 18:14:50 - INFO - transformers.configuration_utils -   Configuration saved in /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold1/config.json
06/26/2023 18:14:50 - INFO - transformers.modeling_utils -   Model weights saved in /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold1/pytorch_model.bin
06/26/2023 18:14:50 - INFO - transformers.configuration_utils -   loading configuration file /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold1/config.json
06/26/2023 18:14:50 - INFO - transformers.configuration_utils -   Model config BertConfig {
  "architectures": [
    "BertForSequenceClassification"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "do_sample": false,
  "eos_token_ids": 0,
  "filter_num": 128,
  "filter_size": [
    2,
    3,
    4,
    5,
    6
  ],
  "finetuning_task": "dnaprom",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "num_return_sequences": 1,
  "num_rnn_layer": 2,
  "output_attentions": false,
  "output_hidden_states": true,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "rnn": "lstm",
  "rnn_dropout": 0.0,
  "rnn_hidden": 768,
  "split": 0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 4101
}

06/26/2023 18:14:50 - INFO - transformers.modeling_utils -   loading weights file /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold1/pytorch_model.bin
06/26/2023 18:14:52 - INFO - transformers.tokenization_utils -   Model name '/data3/linming/DNABERT/examples/output/fold5_100_15296/_fold1' not found in model shortcut name list (dna3, dna4, dna5, dna6). Assuming '/data3/linming/DNABERT/examples/output/fold5_100_15296/_fold1' is a path, a model identifier, or url to a directory containing tokenizer files.
06/26/2023 18:14:52 - INFO - transformers.tokenization_utils -   Didn't find file /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold1/added_tokens.json. We won't load it.
06/26/2023 18:14:52 - INFO - transformers.tokenization_utils -   loading file /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold1/vocab.txt
06/26/2023 18:14:52 - INFO - transformers.tokenization_utils -   loading file None
06/26/2023 18:14:52 - INFO - transformers.tokenization_utils -   loading file /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold1/special_tokens_map.json
06/26/2023 18:14:52 - INFO - transformers.tokenization_utils -   loading file /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold1/tokenizer_config.json
06/26/2023 18:14:52 - INFO - transformers.tokenization_utils -   Model name '/data3/linming/DNABERT/examples/output/fold5_100_15296/_fold1' not found in model shortcut name list (dna3, dna4, dna5, dna6). Assuming '/data3/linming/DNABERT/examples/output/fold5_100_15296/_fold1' is a path, a model identifier, or url to a directory containing tokenizer files.
06/26/2023 18:14:52 - INFO - transformers.tokenization_utils -   Didn't find file /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold1/added_tokens.json. We won't load it.
06/26/2023 18:14:52 - INFO - transformers.tokenization_utils -   loading file /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold1/vocab.txt
06/26/2023 18:14:52 - INFO - transformers.tokenization_utils -   loading file None
06/26/2023 18:14:52 - INFO - transformers.tokenization_utils -   loading file /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold1/special_tokens_map.json
06/26/2023 18:14:52 - INFO - transformers.tokenization_utils -   loading file /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold1/tokenizer_config.json
06/26/2023 18:14:52 - INFO - __main__ -   Evaluate the following checkpoints: ['/data3/linming/DNABERT/examples/output/fold5_100_15296/_fold1']
06/26/2023 18:14:52 - INFO - transformers.configuration_utils -   loading configuration file /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold1/config.json
06/26/2023 18:14:52 - INFO - transformers.configuration_utils -   Model config BertConfig {
  "architectures": [
    "BertForSequenceClassification"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "do_sample": false,
  "eos_token_ids": 0,
  "filter_num": 128,
  "filter_size": [
    2,
    3,
    4,
    5,
    6
  ],
  "finetuning_task": "dnaprom",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "num_return_sequences": 1,
  "num_rnn_layer": 2,
  "output_attentions": false,
  "output_hidden_states": true,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "rnn": "lstm",
  "rnn_dropout": 0.0,
  "rnn_hidden": 768,
  "split": 0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 4101
}

06/26/2023 18:14:52 - INFO - transformers.modeling_utils -   loading weights file /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold1/pytorch_model.bin
06/26/2023 18:14:54 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/1/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:14:55 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:14:55 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:14:55 - INFO - __main__ -     Batch size = 48
06/26/2023 18:15:04 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:15:04 - INFO - __main__ -     acc = 0.7333333333333333
06/26/2023 18:15:04 - INFO - __main__ -     auc = 0.8015291127344184
06/26/2023 18:15:04 - INFO - __main__ -     f1 = 0.732820980555219
06/26/2023 18:15:04 - INFO - __main__ -     mcc = 0.4684668254206766
06/26/2023 18:15:04 - INFO - __main__ -     precision = 0.7351369641282786
06/26/2023 18:15:04 - INFO - __main__ -     recall = 0.7333333333333334
06/26/2023 18:15:04 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
06/26/2023 18:15:04 - INFO - transformers.configuration_utils -   loading configuration file /data3/linming/DNABERT/examples/embeding_model/6-new-12w-0/config.json
06/26/2023 18:15:04 - INFO - transformers.configuration_utils -   Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "do_sample": false,
  "eos_token_ids": 0,
  "finetuning_task": "dnaprom",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "num_return_sequences": 1,
  "num_rnn_layer": 1,
  "output_attentions": false,
  "output_hidden_states": true,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "rnn": "lstm",
  "rnn_dropout": 0.0,
  "rnn_hidden": 768,
  "split": 10,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 4101
}

06/26/2023 18:15:05 - INFO - transformers.tokenization_utils -   loading file https://raw.githubusercontent.com/jerryji1993/DNABERT/master/src/transformers/dnabert-config/bert-config-6/vocab.txt from cache at /data3/linming/.cache/torch/transformers/ea1474aad40c1c8ed4e1cb7c11345ddda6df27a857fb29e1d4c901d9b900d32d.26f8bd5a32e49c2a8271a46950754a4a767726709b7741c68723bc1db840a87e
06/26/2023 18:15:05 - INFO - transformers.modeling_utils -   loading weights file /data3/linming/DNABERT/examples/embeding_model/6-new-12w-0/pytorch_model.bin
06/26/2023 18:15:07 - INFO - transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
06/26/2023 18:15:07 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']
06/26/2023 18:15:07 - INFO - __main__ -   finish loading model
06/26/2023 18:15:07 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, attention_probs_dropout_prob=0.1, beta1=0.9, beta2=0.999, cache_dir='', config_name='', data_dir='/data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/', device=device(type='cuda'), do_ensemble_pred=False, do_eval=True, do_lower_case=False, do_predict=False, do_train=True, do_visualize=False, early_stop=15, eval_all_checkpoints=False, eval_batch_size=48, evaluate_during_training=True, filter_num=128, filter_size=[2, 3, 4, 5, 6], fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, hidden_dropout_prob=0.1, learning_rate=0.0001, local_rank=-1, logging_steps=100, max_grad_norm=1.0, max_seq_length=300, max_steps=-1, model_name='mutant_Bert_fold5_100_15296_fold2', model_name_or_path='/data3/linming/DNABERT/examples/embeding_model/6-new-12w-0/', model_num=5, model_type='dna', n_gpu=1, n_process=8, no_cuda=False, num_rnn_layer=2, num_train_epochs=30.0, output_dir='/data3/linming/DNABERT/examples/output/fold5_100_15296/_fold2', output_mode='classification', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=48, per_gpu_pred_batch_size=8, per_gpu_train_batch_size=48, predict_dir=None, predict_scan_size=1, result_dir=None, rnn='lstm', rnn_dropout=0.0, rnn_hidden=768, save_steps=4000, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, task_name='dnaprom', tokenizer_name='dna6', train_batch_size=48, visualize_data_dir=None, visualize_models=None, visualize_train=False, warmup_percent=0.1, warmup_steps=0, weight_decay=0.01)
06/26/2023 18:15:07 - INFO - __main__ -   Creating features from dataset file at /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/
06/26/2023 18:15:07 - INFO - transformers.data.processors.glue -   LOOKING AT /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/train.tsv
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   Writing example 0/1529
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   guid: train-1
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   input_ids: 2 3716 2564 2050 4091 4064 3956 3524 1796 3076 4099 4095 4079 4015 3757 2728 2708 2628 2307 1022 4075 3997 3688 2452 1603 2302 1004 4003 3710 2537 1942 3660 2338 1147 479 1901 3495 1679 2605 2216 660 2627 2303 1007 4015 3760 2740 2755 2816 3060 4036 3841 3064 4052 3906 3323 990 3947 3487 1647 2478 1708 2721 2679 2512 1844 3267 767 3055 4015 3759 2733 2728 2707 2622 2283 925 3688 2451 1599 2286 939 3744 2674 2491 1758 2923 3487 1647 2477 1704 2707 2624 2291 958 3819 2976 3699 2495 1776 2996 3777 2808 3028 3908 3332 1027 4093 4072 3987 3647 2286 940 3747 2688 2548 1987 3839 3055 4014 3756 2724 2692 2563 2045 4071 3982 3628 2211 639 2543 1965 3752 2708 2627 2301 1000 3985 3637 2248 786 3129 216 849 3383 1232 817 3255 720 2868 3268 771 3070 4074 3996 3684 2435 1535 2032 4019 3776 2803 3005 3816 2962 3644 2275 893 3559 1936 3636 2243 768 3060 4035 3839 3053 4006 3724 2593 2168 468 1857 3317 968 3859 3134 236 929 3701 2504 1810 3132 228 898 3577 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   Writing example 0/1529
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   guid: train-2
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   input_ids: 2 3602 2107 221 872 3474 1594 2267 864 3442 1465 1750 2889 3349 1094 265 1046 74 283 1118 363 1438 1641 2455 1616 2354 1210 729 2904 3412 1345 1272 978 3900 3298 892 3555 1917 3558 1929 3606 2122 282 1114 345 1366 1356 1315 1149 486 1930 3610 2140 356 1411 1534 2025 3991 3661 2342 1164 548 2178 508 2019 3966 3564 1955 3711 2541 1959 3726 2604 2210 634 2522 1884 3427 1406 1514 1945 3671 2382 1322 1179 605 2406 1419 1567 2160 433 1720 2769 2871 3278 812 3236 643 2558 2028 4001 3703 2512 1841 3254 716 2851 3199 496 1972 3780 2820 3076 4098 4092 4067 3966 3561 1942 3660 2339 1152 498 1980 3812 2947 3581 2023 3982 3627 2206 620 2468 1666 2556 2020 3970 3580 2017 3960 3538 1852 3298 892 3553 1911 3535 1838 3242 668 2658 2428 1507 1919 3567 1967 3757 2726 2700 2594 2172 483 1919 3567 1965 3751 2702 2604 2212 643 2557 2024 3988 3649 2294 972 3873 3190 458 1818 3163 350 1388 1442 1659 2526 1900 3492 1667 2559 2030 4010 3739 2653 2407 1422 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   guid: train-1530
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   input_ids: 2 2623 2285 936 3732 2625 2293 968 3860 3138 252 996 3970 3578 2009 3928 3409 1333 1224 787 3134 236 932 3716 2564 2050 4092 4066 3963 3549 1896 3474 1593 2261 839 3341 1061 134 524 2083 127 493 1959 3727 2605 2214 650 2586 2138 348 1378 1401 1495 1871 3374 1194 668 2657 2422 1484 1827 3199 493 1958 3722 2587 2141 359 1422 1579 2206 619 2462 1644 2468 1667 2557 2024 3988 3650 2297 984 3921 3381 1224 788 3137 245 966 3852 3106 124 484 1922 3580 2017 3957 3525 1800 3089 56 212 835 3326 1003 3998 3690 2459 1630 2412 1442 1660 2532 1923 3581 2022 3977 3608 2132 322 1273 981 3909 3333 1029 7 15 45 168 660 2627 2303 1005 4007 3725 2600 2195 573 2277 901 3589 2056 19 63 237 935 3726 2604 2209 629 2501 1799 3085 39 141 552 2196 578 2297 981 3912 3345 1080 209 824 3281 822 3276 801 3191 461 1830 3210 539 2141 360 1428 1603 2302 1004 4001 3701 2503 1805 3112 147 576 2289 951 3791 2861 3240 659 2623 2286 940 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   guid: train-3
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   input_ids: 2 1813 3144 273 1077 200 788 3137 246 972 3873 3192 468 1857 3320 977 3893 3270 780 3105 120 467 1854 3308 932 3713 2550 1995 3869 3176 404 1601 2293 965 3845 3080 17 56 209 824 3282 828 3300 897 3576 2002 3897 3286 844 3363 1149 488 1938 3644 2275 894 3563 1952 3697 2486 1740 2849 3192 466 1850 3289 856 3409 1333 1224 785 3126 202 794 3162 345 1367 1358 1324 1185 631 2509 1829 3206 522 2074 92 356 1409 1528 2003 3902 3305 920 3665 2358 1228 801 3189 456 1812 3137 248 979 3901 3304 916 3651 2304 1012 4036 3842 3066 4059 3933 3431 1424 1588 2243 766 3049 3989 3653 2312 1043 61 229 902 3595 2080 114 442 1755 2909 3432 1425 1592 2257 824 3281 823 3277 808 3217 568 2258 828 3300 897 3574 1996 3873 3189 456 1809 3128 212 835 3327 1006 4010 3740 2657 2421 1478 1802 3098 91 351 1391 1455 1710 2729 2711 2640 2353 1208 724 2882 3321 982 3916 3362 1146 476 1892 3459 1533 2024 3987 3647 2287 943 3758 2731 2719 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   guid: train-1531
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   input_ids: 2 111 429 1704 2708 2625 2294 972 3876 3204 516 2051 4094 4076 4001 3704 2516 1857 3317 967 3855 3117 167 653 2599 2189 549 2182 524 2083 126 492 1954 3705 2519 1869 3368 1172 579 2302 1004 4003 3710 2540 1956 3716 2563 2045 4072 3985 3639 2255 814 3241 663 2640 2355 1214 748 2977 3704 2515 1853 3304 916 3649 2295 974 3884 3236 644 2564 2050 4091 4061 3943 3469 1574 2185 535 2128 307 1214 748 2979 3711 2542 1963 3743 2669 2471 1679 2608 2227 704 2802 3001 3800 2897 3381 1223 782 3115 158 619 2462 1642 2459 1631 2416 1457 1717 2759 2829 3110 140 548 2179 511 2029 4006 3724 2595 2174 492 1954 3708 2531 1917 3558 1932 3617 2166 460 1825 3192 466 1851 3294 876 3491 1662 2540 1956 3714 2556 2020 3972 3586 2043 4062 3946 3482 1626 2393 1368 1364 1347 1280 1012 4035 3838 3051 3999 3693 2471 1677 2600 2193 568 2258 827 3293 869 3461 1544 2068 68 260 1027 4095 4077 4006 3723 2589 2150 395 1565 2152 403 1598 2281 920 3668 2372 1281 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   guid: train-4
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   input_ids: 2 622 2475 1695 2670 2475 1695 2670 2476 1700 2689 2550 1995 3871 3182 427 1694 2667 2463 1646 2475 1696 2674 2491 1759 2927 3501 1701 2693 2567 2064 49 181 712 2833 3127 208 819 3263 752 2996 3779 2814 3049 3989 3655 2320 1075 191 752 2995 3775 2797 2982 3723 2589 2149 392 1556 2115 253 1000 3985 3640 2260 835 3325 998 3980 3620 2179 511 2029 4008 3732 2625 2295 976 3892 3267 767 3056 4018 3772 2787 2941 3560 1939 3647 2288 948 3779 2816 3059 4031 3821 2984 3729 2616 2260 833 3320 977 3893 3271 784 3123 192 756 3011 3840 3058 4028 3809 2936 3539 1854 3307 926 3691 2464 1652 2497 1784 3026 3897 3288 849 3384 1236 835 3328 1012 4035 3839 3056 4018 3769 2776 2897 3384 1235 830 3308 931 3712 2547 1984 3825 2998 3787 2846 3180 419 1662 2540 1955 3712 2547 1984 3827 3008 3827 3007 3824 2995 3773 2791 2960 3635 2240 755 3005 3816 2964 3651 2303 1007 4016 3762 2748 2785 2935 3536 1841 3253 712 2835 3136 244 963 3837 3047 3982 3628 2209 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   Writing example 0/1529
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   guid: train-1532
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   input_ids: 2 3985 3638 2252 803 3200 497 1976 3795 2877 3304 914 3642 2266 858 3420 1378 1401 1493 1861 3333 1029 6 9 24 82 316 1251 894 3564 1953 3702 2505 1813 3143 269 1061 136 532 2114 252 996 3970 3578 2010 3932 3427 1406 1515 1951 3694 2476 1698 2681 2519 1870 3372 1185 632 2516 1860 3329 1014 4041 3862 3147 288 1137 439 1742 2858 3228 611 2429 1512 1937 3637 2245 773 3079 15 45 168 657 2613 2248 786 3131 223 878 3500 1698 2684 2529 1909 3527 1807 3117 168 660 2626 2299 989 3942 3465 1557 2118 267 1054 108 417 1653 2502 1801 3093 72 273 1078 202 794 3162 346 1370 1369 1365 1349 1288 1041 53 197 773 3078 11 30 108 418 1657 2518 1867 3358 1132 417 1653 2501 1799 3086 42 155 605 2408 1427 1597 2278 906 3610 2138 345 1365 1351 1293 1061 133 519 2063 46 169 663 2637 2342 1161 533 2118 266 1050 90 345 1365 1350 1290 1051 95 366 1449 1687 2638 2346 1180 609 2421 1478 1803 3102 108 419 1662 2538 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   guid: train-5
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   input_ids: 2 3839 3056 4020 3780 2819 3070 4075 3998 3690 2460 1634 2426 1500 1889 3448 1492 1858 3322 987 3935 3439 1455 1709 2728 2708 2627 2304 1012 4033 3832 3028 3905 3317 968 3858 3129 215 846 3371 1183 622 2475 1694 2667 2463 1647 2477 1702 2700 2595 2176 500 1985 3832 3027 3901 3304 916 3649 2295 975 3888 3252 707 2815 3056 4017 3768 2771 2879 3310 940 3747 2688 2548 1987 3838 3052 4003 3710 2540 1956 3716 2564 2051 4094 4076 4003 3710 2539 1952 3700 2497 1783 3022 3884 3235 640 2548 1987 3840 3060 4035 3840 3060 4035 3840 3060 4035 3838 3052 4004 3713 2549 1992 3857 3125 197 774 3083 31 109 421 1672 2580 2116 259 1022 4076 4001 3704 2516 1860 3330 1020 4067 3966 3564 1955 3712 2548 1987 3840 3059 4031 3822 2988 3747 2687 2544 1969 3768 2771 2878 3307 927 3695 2480 1716 2756 2817 3063 4047 3888 3252 707 2815 3055 4016 3763 2752 2804 3011 3838 3051 3997 3688 2452 1601 2296 979 3904 3315 959 3823 2990 3756 2723 2685 2534 1932 3620 2179 512 2036 4036 3843 3069 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   guid: train-1533
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   input_ids: 2 3251 704 2801 2998 3788 2850 3193 471 1869 3366 1164 546 2170 475 1885 3431 1423 1581 2215 653 2597 2183 527 2093 168 660 2625 2293 968 3860 3137 246 969 3862 3148 289 1142 460 1825 3190 460 1826 3193 469 1863 3342 1068 161 631 2509 1829 3205 517 2053 5 8 17 53 197 773 3078 10 27 95 365 1445 1671 2573 2088 145 566 2252 804 3204 514 2042 4059 3935 3439 1453 1703 2701 2600 2194 571 2270 875 3487 1647 2478 1706 2713 2645 2375 1294 1067 158 618 2459 1631 2413 1448 1684 2628 2306 1018 4057 3925 3399 1294 1066 154 601 2390 1354 1305 1112 340 1348 1282 1019 4061 3943 3469 1576 2194 571 2272 884 3524 1794 3068 4068 3971 3582 2026 3993 3671 2382 1324 1186 634 2524 1889 3448 1489 1845 3270 780 3108 132 514 2044 4067 3966 3561 1944 3667 2365 1253 902 3595 2079 109 422 1675 2591 2159 429 1704 2707 2623 2285 936 3731 2621 2280 913 3640 2260 834 3322 988 3938 3449 1493 1862 3338 1050 92 356 1409 1525 1990 3849 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   guid: train-3059
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   input_ids: 2 874 3483 1629 2406 1419 1566 2153 407 1613 2343 1167 557 2216 658 2617 2264 851 3389 1254 905 3608 2129 312 1236 834 3321 984 3923 3391 1264 948 3780 2819 3071 4079 4013 3749 2695 2574 2091 159 622 2473 1687 2637 2341 1160 532 2113 245 965 3846 3083 29 102 395 1567 2157 424 1681 2613 2247 784 3124 195 767 3053 4007 3728 2609 2229 712 2833 3125 200 785 3128 211 831 3310 939 3742 2668 2468 1665 2549 1989 3845 3079 13 39 141 550 2188 548 2179 511 2032 4018 3769 2775 2893 3368 1171 573 2277 901 3589 2053 8 19 62 234 924 3683 2430 1516 1953 3704 2513 1845 3272 788 3139 254 1004 4002 3708 2531 1918 3564 1956 3715 2560 2036 4035 3838 3049 3989 3654 2316 1060 132 514 2044 4068 3969 3573 1990 3851 3102 105 405 1605 2309 1029 5 6 12 36 130 508 2017 3958 3529 1815 3151 302 1194 668 2658 2425 1495 1869 3367 1166 554 2204 610 2428 1507 1920 3570 1978 3801 2901 3400 1297 1079 207 815 3245 679 2701 2598 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   guid: train-1534
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   input_ids: 2 1646 2474 1691 2653 2408 1426 1594 2266 860 3428 1411 1533 2022 3979 3616 2163 447 1776 2993 3768 2771 2879 3310 939 3744 2676 2500 1795 3071 4079 4014 3755 2720 2674 2491 1759 2927 3502 1708 2724 2689 2551 1998 3882 3228 610 2427 1502 1898 3482 1628 2401 1400 1491 1853 3303 912 3635 2240 756 3012 3844 3075 4096 4084 4036 3843 3070 4076 4002 3707 2527 1902 3498 1692 2658 2427 1503 1903 3502 1708 2724 2690 2556 2020 3971 3584 2036 4036 3843 3070 4074 3995 3678 2412 1443 1662 2539 1952 3698 2491 1759 2927 3502 1708 2722 2684 2529 1910 3532 1827 3199 496 1971 3773 2792 2963 3645 2280 915 3647 2287 941 3750 2699 2591 2160 435 1725 2790 2956 3619 2175 494 1964 3746 2683 2527 1903 3504 1716 2754 2812 3043 3967 3566 1963 3742 2667 2463 1646 2474 1691 2654 2411 1440 1650 2491 1758 2923 3486 1643 2463 1645 2470 1674 2586 2139 350 1387 1439 1647 2478 1708 2722 2684 2530 1914 3546 1883 3422 1387 1438 1643 2462 1643 2462 1642 2459 1630 2410 1435 1630 2410 1435 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   guid: train-3060
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   input_ids: 2 81 311 1230 812 3236 644 2564 2051 4093 4069 3973 3591 2061 39 141 549 2181 517 2053 7 15 46 172 676 2690 2554 2011 3935 3437 1445 1670 2569 2071 79 302 1193 661 2632 2322 1082 218 860 3425 1397 1478 1803 3103 109 422 1676 2595 2174 490 1946 3676 2403 1406 1515 1950 3690 2459 1630 2410 1436 1633 2422 1482 1817 3158 330 1306 1114 347 1374 1386 1435 1631 2413 1445 1672 2579 2111 239 944 3762 2746 2779 2911 3438 1451 1694 2666 2458 1627 2398 1386 1435 1629 2406 1419 1566 2156 417 1653 2501 1799 3087 45 165 646 2570 2075 95 366 1450 1692 2658 2427 1501 1895 3470 1579 2205 616 2449 1591 2255 813 3237 647 2574 2091 159 623 2478 1708 2724 2691 2558 2026 3994 3675 2397 1384 1425 1591 2254 812 3233 630 2508 1827 3199 494 1963 3741 2662 2442 1562 2140 354 1402 1498 1884 3428 1409 1525 1992 3857 3125 199 783 3117 165 646 2571 2077 101 392 1553 2101 197 776 3092 65 246 971 3871 3182 428 1700 2692 2562 2044 4066 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   Writing example 0/1529
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   guid: train-3061
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   input_ids: 2 566 2249 789 3142 265 1047 79 301 1189 647 2574 2091 157 613 2437 1542 2060 35 125 488 1937 3638 2251 797 3173 391 1549 2085 134 522 2076 98 378 1498 1883 3421 1382 1419 1566 2155 414 1644 2468 1668 2561 2037 4039 3853 3110 138 539 2141 359 1421 1576 2196 580 2307 1024 4082 4026 3802 2905 3413 1349 1286 1035 30 108 419 1661 2536 1940 3650 2300 993 3959 3536 1843 3264 753 2998 3786 2844 3170 378 1499 1886 3435 1437 1637 2437 1541 2053 7 14 42 155 606 2410 1435 1629 2406 1419 1566 2155 414 1644 2468 1667 2557 2024 3988 3652 2306 1018 4058 3931 3422 1387 1438 1644 2465 1653 2502 1803 3102 107 415 1646 2474 1690 2652 2403 1407 1519 1965 3751 2702 2604 2212 643 2559 2030 4009 3735 2637 2342 1162 537 2134 329 1304 1105 309 1224 786 3132 227 894 3564 1954 3705 2518 1868 3363 1152 500 1985 3831 3023 3887 3246 684 2723 2687 2541 1958 3722 2588 2146 379 1501 1894 3467 1565 2150 396 1572 2177 503 2000 3891 3261 744 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   guid: train-4588
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   input_ids: 2 3895 3278 811 3229 615 2447 1582 2220 675 2685 2535 1933 3624 2194 571 2271 877 3496 1682 2619 2269 870 3466 1563 2143 366 1451 1693 2664 2451 1598 2283 927 3694 2474 1691 2655 2415 1454 1708 2723 2688 2545 1973 3781 2821 3078 11 29 103 397 1575 2192 563 2237 741 2951 3598 2092 164 642 2555 2013 3944 3475 1599 2288 948 3777 2805 3015 3855 3119 175 687 2734 2732 2722 2683 2528 1907 3518 1770 2969 3672 2387 1341 1253 903 3599 2093 167 655 2606 2219 672 2673 2488 1747 2878 3308 932 3713 2549 1992 3857 3126 204 803 3198 492 1956 3714 2556 2018 3963 3549 1896 3473 1589 2246 779 3104 113 439 1743 2862 3243 671 2669 2471 1678 2604 2212 644 2561 2037 4037 3847 3087 45 166 652 2596 2179 510 2028 4004 3713 2552 2002 3898 3292 865 3445 1479 1807 3118 172 673 2679 2509 1829 3205 519 2061 39 142 556 2209 631 2511 1837 3237 648 2580 2113 245 965 3846 3082 28 100 385 1525 1992 3860 3140 257 1016 4049 3893 3272 785 3128 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   guid: train-3062
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   input_ids: 2 2024 3986 3642 2268 866 3450 1499 1886 3435 1437 1639 2445 1573 2182 522 2074 91 350 1385 1429 1606 2314 1050 92 354 1402 1499 1887 3438 1450 1690 2652 2403 1406 1514 1946 3676 2403 1407 1518 1962 3739 2655 2414 1451 1694 2666 2459 1630 2411 1438 1644 2466 1658 2523 1888 3442 1466 1754 2907 3422 1386 1435 1629 2407 1422 1579 2206 619 2462 1642 2459 1629 2407 1423 1581 2214 651 2589 2150 395 1566 2154 411 1630 2411 1439 1646 2474 1691 2656 2418 1467 1760 2930 3515 1757 2918 3467 1565 2150 395 1565 2150 395 1566 2154 411 1630 2410 1435 1630 2410 1435 1630 2410 1435 1629 2406 1419 1566 2154 411 1630 2410 1435 1629 2406 1419 1566 2156 418 1658 2522 1883 3422 1386 1436 1636 2433 1526 1993 3862 3146 284 1123 382 1516 1955 3710 2540 1955 3711 2543 1966 3754 2714 2652 2401 1398 1482 1819 3166 363 1438 1642 2458 1626 2393 1366 1354 1306 1116 355 1405 1509 1927 3598 2089 150 586 2330 1115 349 1382 1418 1561 2134 330 1308 1121 376 1491 1854 3306 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   guid: train-4589
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   input_ids: 2 1188 644 2562 2042 4060 3937 3447 1486 1835 3231 621 2469 1669 2567 2062 42 155 605 2407 1422 1579 2207 621 2470 1675 2590 2155 413 1637 2440 1555 2109 230 907 3616 2161 438 1740 2850 3195 477 1893 3463 1552 2100 196 772 3076 4099 4093 4069 3975 3599 2096 180 705 2805 3016 3857 3127 207 813 3238 651 2590 2154 412 1636 2433 1528 2004 3905 3318 972 3873 3189 453 1797 3080 17 56 212 835 3326 1004 4004 3715 2559 2031 4013 3751 2703 2607 2223 686 2730 2715 2654 2411 1439 1646 2474 1692 2660 2435 1535 2032 4018 3771 2782 2923 3487 1646 2474 1692 2660 2435 1535 2032 4018 3771 2782 2922 3482 1628 2401 1400 1492 1858 3324 994 3964 3556 1923 3582 2026 3993 3671 2384 1330 1209 727 2896 3377 1208 721 2870 3276 803 3197 485 1928 3603 2109 231 910 3626 2201 600 2388 1346 1276 996 3971 3584 2036 4033 3830 3017 3864 3153 311 1229 807 3213 552 2193 567 2254 809 3222 585 2328 1105 310 1227 797 3175 398 1579 2205 613 2440 1555 2111 237 933 3720 2577 2102 204 801 3189 455 1808 3123 189 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   guid: train-3063
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   input_ids: 2 2696 2579 2111 240 948 3779 2816 3059 4029 3815 2958 3628 2211 638 2539 1949 3687 2447 1581 2216 657 2616 2259 830 3305 920 3668 2372 1284 1026 4090 4060 3937 3447 1487 1838 3244 676 2691 2557 2023 3982 3628 2211 637 2536 1939 3646 2283 928 3699 2493 1765 2952 3602 2106 219 862 3435 1439 1645 2470 1675 2590 2154 412 1636 2435 1535 2030 4011 3741 2664 2451 1599 2286 939 3743 2669 2471 1678 2602 2203 606 2409 1429 1608 2322 1081 213 838 3339 1055 109 424 1682 2618 2267 862 3433 1431 1615 2350 1196 676 2689 2552 2003 3901 3304 914 3643 2271 877 3493 1672 2580 2113 247 975 3885 3237 645 2568 2066 57 216 850 3388 1249 885 3528 1811 3133 232 916 3652 2308 1025 4087 4046 3884 3236 644 2562 2041 4056 3924 3395 1279 1007 4015 3757 2725 2694 2571 2079 109 423 1679 2605 2216 659 2623 2287 943 3758 2731 2719 2671 2478 1708 2723 2685 2534 1932 3620 2178 505 2007 3918 3371 1181 616 2449 1591 2253 807 3214 556 2211 637 2536 1940 3651 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   Writing example 0/1529
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   guid: train-4590
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   input_ids: 2 3731 2623 2286 939 3743 2671 2479 1711 2734 2731 2717 2664 2450 1594 2268 865 3448 1490 1849 3287 845 3366 1162 539 2144 372 1475 1792 3059 4031 3821 2984 3729 2613 2248 787 3133 229 903 3599 2095 173 680 2708 2627 2303 1005 4007 3727 2607 2223 687 2733 2725 2696 2579 2109 232 913 3637 2248 788 3137 248 980 3905 3320 980 3907 3327 1007 4016 3761 2744 2771 2880 3316 964 3842 3067 4062 3948 3492 1667 2559 2029 4008 3729 2616 2259 831 3311 943 3759 2734 2732 2721 2680 2513 1845 3272 788 3139 255 1007 4015 3760 2740 2755 2815 3055 4015 3757 2728 2707 2623 2287 943 3760 2740 2753 2808 3028 3905 3320 977 3896 3284 833 3318 970 3868 3172 386 1529 2008 3924 3393 1270 972 3876 3204 516 2052 4100 4099 4093 4072 3988 3649 2296 977 3896 3284 833 3320 980 3906 3324 995 3967 3565 1958 3724 2596 2179 511 2029 4007 3728 2612 2243 768 3059 4030 3819 2974 3692 2468 1667 2559 2031 4015 3759 2734 2731 2719 2670 2473 1685 2631 2319 1070 171 671 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   guid: train-6117
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   input_ids: 2 3563 1950 3692 2465 1656 2515 1854 3308 929 3703 2511 1837 3239 653 2599 2190 555 2207 623 2479 1711 2733 2726 2698 2587 2142 364 1444 1667 2559 2030 4011 3741 2664 2452 1601 2296 977 3895 3277 805 3208 529 2102 203 799 3183 430 1708 2724 2691 2558 2027 3998 3692 2467 1663 2544 1970 3772 2787 2942 3561 1941 3654 2315 1054 106 411 1629 2405 1415 1552 2098 187 735 2925 3494 1676 2594 2171 477 1894 3466 1564 2145 375 1486 1834 3227 607 2413 1447 1677 2597 2182 524 2082 123 479 1903 3502 1708 2723 2688 2548 1985 3830 3020 3874 3196 484 1922 3580 2020 3969 3573 1989 3846 3083 29 104 404 1601 2295 973 3879 3214 556 2210 635 2527 1903 3504 1716 2755 2815 3053 4006 3723 2590 2156 417 1656 2513 1847 3279 814 3244 675 2685 2533 1926 3596 2081 120 465 1847 3279 813 3239 655 2605 2213 648 2579 2110 234 924 3684 2436 1540 2049 4087 4046 3882 3226 604 2402 1402 1499 1888 3441 1462 1737 2839 3151 301 1190 650 2585 2135 333 1317 1159 526 2092 162 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   guid: train-4591
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   input_ids: 2 2563 2045 4070 3979 3614 2154 411 1630 2411 1439 1646 2475 1694 2666 2458 1628 2403 1405 1512 1937 3639 2256 819 3262 748 2979 3710 2540 1955 3710 2539 1949 3685 2440 1554 2107 223 878 3500 1700 2692 2564 2051 4094 4075 3997 3688 2452 1604 2308 1028 4100 4099 4094 4076 4004 3714 2556 2020 3972 3588 2050 4091 4063 3950 3499 1696 2676 2497 1784 3027 3902 3307 926 3691 2464 1652 2500 1795 3070 4075 3997 3688 2452 1602 2300 996 3969 3576 2004 3906 3324 996 3972 3588 2052 4099 4093 4072 3986 3644 2276 899 3581 2023 3984 3636 2244 772 3076 4099 4095 4078 4010 3738 2652 2404 1412 1540 2049 4087 4046 3883 3230 620 2465 1656 2514 1852 3300 898 3580 2020 3970 3580 2017 3958 3532 1828 3202 508 2020 3970 3580 2020 3970 3580 2019 3966 3563 1951 3694 2474 1691 2654 2410 1436 1636 2436 1540 2052 4100 4098 4092 4065 3960 3540 1857 3320 980 3907 3328 1011 4030 3820 2979 3710 2540 1955 3710 2540 1955 3712 2547 1983 3823 2991 3758 2730 2716 2660 2436 1540 2051 4094 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   guid: train-6118
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   input_ids: 2 1371 1374 1386 1434 1626 2394 1370 1371 1373 1382 1417 1560 2130 316 1250 891 3551 1901 3494 1676 2596 2180 515 2046 4073 3990 3658 2331 1119 366 1451 1693 2661 2437 1541 2054 9 23 77 293 1158 521 2070 75 286 1130 412 1634 2426 1499 1886 3434 1434 1628 2404 1411 1534 2028 4001 3702 2508 1826 3193 469 1862 3340 1057 120 466 1852 3297 885 3527 1805 3112 147 574 2284 932 3715 2559 2029 4005 3717 2568 2065 53 198 778 3100 99 381 1512 1938 3642 2265 856 3409 1333 1224 785 3125 200 787 3134 236 931 3711 2544 1970 3770 2778 2906 3418 1371 1375 1390 1452 1697 2677 2504 1810 3130 220 867 3456 1522 1977 3797 2888 3346 1081 213 837 3333 1030 10 27 93 359 1421 1573 2181 518 2057 23 78 298 1178 601 2390 1355 1310 1129 408 1619 2365 1253 903 3598 2090 153 598 2377 1304 1107 317 1256 913 3640 2258 826 3290 858 3417 1368 1364 1345 1270 970 3866 3164 353 1398 1484 1825 3192 466 1849 3285 838 3338 1052 98 379 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   guid: train-4592
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   input_ids: 2 2611 2237 743 2959 3629 2215 653 2598 2187 541 2149 391 1552 2099 192 755 3006 3819 2973 3686 2443 1566 2154 411 1630 2410 1435 1630 2410 1435 1629 2406 1419 1568 2162 443 1757 2920 3475 1597 2277 903 3599 2094 171 669 2663 2447 1581 2214 651 2592 2161 439 1742 2858 3227 606 2410 1435 1632 2419 1471 1774 2986 3739 2654 2410 1435 1629 2406 1419 1567 2159 432 1715 2750 2796 2980 3714 2555 2013 3942 3467 1566 2154 411 1630 2409 1431 1615 2350 1196 674 2683 2527 1901 3494 1675 2590 2155 415 1645 2470 1676 2596 2178 508 2017 3958 3531 1822 3180 419 1661 2535 1935 3631 2222 683 2717 2661 2440 1556 2114 252 994 3962 3547 1887 3437 1448 1684 2625 2295 973 3880 3219 573 2277 904 3604 2115 255 1006 4012 3748 2692 2561 2040 4049 3893 3271 782 3114 155 607 2416 1459 1725 2791 2959 3631 2222 683 2717 2663 2447 1584 2225 695 2767 2862 3244 675 2686 2540 1955 3710 2540 1955 3712 2547 1982 3818 2971 3680 2417 1464 1747 2879 3311 941 3749 2695 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   Writing example 0/1529
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   guid: train-6119
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   input_ids: 2 1485 1829 3205 518 2057 21 70 266 1051 93 357 1413 1541 2056 18 57 216 849 3382 1225 790 3146 282 1114 346 1369 1366 1353 1302 1100 291 1149 485 1926 3595 2078 107 414 1643 2462 1641 2455 1614 2348 1186 635 2525 1896 3473 1590 2249 789 3142 265 1046 75 287 1133 421 1671 2574 2089 150 586 2329 1111 335 1326 1194 668 2657 2421 1478 1802 3099 94 363 1437 1638 2444 1572 2177 504 2002 3900 3297 885 3527 1805 3109 134 524 2083 125 487 1933 3622 2188 547 2173 488 1938 3642 2268 865 3446 1484 1827 3197 488 1938 3642 2268 865 3446 1483 1823 3181 424 1682 2619 2269 872 3476 1601 2293 965 3847 3086 44 161 632 2513 1846 3276 801 3190 459 1822 3177 405 1605 2309 1031 14 44 162 636 2529 1909 3527 1805 3109 135 525 2088 147 575 2285 933 3717 2568 2066 58 218 858 3420 1380 1411 1533 2022 3979 3613 2149 390 1546 2073 86 329 1301 1096 276 1089 247 973 3878 3211 542 2154 412 1633 2422 1481 1814 3146 283 1118 363 1439 1645 2471 1677 2597 2183 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   guid: train-7646
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   input_ids: 2 3711 2543 1965 3751 2703 2607 2223 688 2739 2751 2799 2991 3760 2739 2749 2792 2962 3643 2269 871 3472 1586 2234 731 2910 3435 1439 1646 2475 1695 2671 2479 1712 2740 2755 2814 3052 4001 3703 2509 1830 3211 541 2151 399 1581 2214 651 2591 2158 428 1699 2686 2540 1956 3713 2551 2000 3892 3267 766 3051 3999 3696 2483 1727 2797 2984 3731 2624 2290 956 3812 2948 3587 2045 4072 3987 3647 2285 935 3725 2597 2183 526 2090 154 604 2401 1399 1485 1831 3215 557 2215 655 2605 2213 648 2579 2112 243 959 3822 2988 3748 2691 2559 2032 4017 3768 2771 2880 3315 958 3818 2971 3679 2414 1451 1693 2663 2445 1576 2195 576 2292 964 3843 3069 4072 3988 3649 2295 976 3892 3265 759 3023 3887 3247 688 2739 2751 2799 2989 3751 2704 2609 2231 720 2866 3260 739 2944 3572 1988 3842 3068 4068 3971 3584 2036 4034 3836 3044 3970 3580 2019 3965 3560 1938 3641 2263 845 3368 1171 576 2292 963 3837 3047 3984 3636 2244 771 3071 4077 4008 3731 2621 2280 915 3648 2291 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   guid: train-6120
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   input_ids: 2 2083 125 486 1930 3610 2140 355 1406 1513 1941 3653 2312 1042 58 218 858 3418 1369 1365 1349 1287 1039 47 174 684 2722 2682 2522 1881 3414 1353 1304 1108 322 1274 985 3925 3397 1288 1041 55 206 811 3229 616 2450 1595 2270 875 3486 1644 2465 1656 2513 1845 3269 773 3079 13 37 134 522 2076 100 385 1527 1998 3884 3233 630 2508 1827 3200 497 1973 3782 2828 3107 125 488 1938 3642 2266 858 3420 1380 1409 1525 1989 3845 3077 5 5 7 14 44 162 636 2532 1922 3580 2020 3969 3573 1992 3857 3126 201 790 3145 278 1097 279 1102 300 1186 636 2529 1911 3533 1829 3206 523 2079 109 423 1679 2605 2215 653 2598 2187 541 2152 403 1599 2286 940 3746 2684 2532 1923 3583 2029 4006 3722 2588 2145 373 1479 1806 3113 150 588 2340 1153 501 1992 3860 3138 249 981 3909 3333 1029 5 5 5 5 5 5 5 5 6 9 23 79 301 1191 654 2602 2202 602 2393 1365 1350 1290 1050 92 354 1401 1494 1868 3361 1141 454 1801 3094 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   guid: train-7647
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   input_ids: 2 2055 15 45 165 645 2566 2060 34 121 470 1867 3357 1128 403 1599 2286 939 3741 2661 2439 1549 2087 141 549 2184 531 2111 238 939 3743 2669 2472 1684 2627 2301 1000 3985 3637 2245 773 3077 8 17 54 204 803 3197 488 1940 3649 2293 965 3846 3083 29 104 402 1593 2264 850 3386 1242 860 3428 1410 1531 2013 3941 3461 1542 2057 23 78 298 1179 605 2406 1419 1565 2149 389 1542 2060 34 124 483 1917 3557 1925 3591 2061 40 145 565 2248 785 3126 204 802 3194 473 1878 3401 1301 1093 262 1034 25 86 329 1301 1093 262 1033 21 69 262 1036 36 131 510 2026 3993 3669 2375 1293 1064 145 566 2250 793 3159 334 1324 1186 635 2528 1907 3520 1778 3004 3809 2936 3538 1850 3290 858 3418 1370 1370 1370 1370 1370 1370 1370 1370 1370 1371 1373 1384 1425 1590 2251 797 3174 394 1562 2138 345 1365 1352 1300 1089 247 974 3882 3225 597 2375 1294 1068 162 634 2524 1891 3453 1510 1929 3605 2120 274 1082 218 860 3426 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   Writing example 0/1529
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   guid: train-6121
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   input_ids: 2 3287 846 3369 1174 587 2334 1131 413 1640 2449 1589 2245 774 3082 28 97 373 1480 1812 3137 245 965 3845 3079 15 45 166 651 2589 2152 402 1595 2271 877 3496 1684 2625 2293 968 3859 3133 229 901 3589 2053 8 19 61 229 904 3602 2106 219 861 3432 1425 1592 2260 836 3332 1025 4087 4046 3881 3222 586 2331 1119 367 1455 1709 2728 2708 2626 2299 991 3949 3496 1681 2616 2257 824 3281 824 3284 833 3317 967 3855 3118 172 675 2687 2543 1967 3757 2728 2705 2613 2248 785 3128 212 833 3320 979 3903 3311 943 3758 2732 2722 2682 2524 1891 3454 1513 1943 3661 2344 1169 568 2257 823 3279 813 3240 657 2616 2257 824 3281 824 3282 825 3287 845 3368 1169 567 2256 819 3262 748 2980 3713 2549 1992 3857 3128 211 830 3305 920 3665 2357 1224 785 3128 211 830 3308 932 3716 2561 2037 4037 3845 3080 17 53 200 785 3125 198 780 3106 122 474 1882 3419 1373 1381 1413 1541 2054 9 21 72 276 1089 248 979 3902 3306 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   guid: train-7648
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   input_ids: 2 2179 509 2024 3987 3645 2277 904 3604 2113 245 967 3854 3115 158 619 2464 1652 2500 1795 3071 4077 4008 3732 2628 2307 1023 4079 4015 3757 2728 2708 2627 2302 1004 4003 3710 2539 1949 3688 2451 1599 2286 939 3743 2670 2475 1695 2672 2483 1727 2800 2996 3780 2820 3076 4098 4090 4060 3938 3451 1503 1903 3501 1702 2700 2594 2171 479 1902 3499 1695 2669 2472 1683 2624 2292 962 3836 3044 3971 3581 2024 3987 3646 2283 925 3687 2446 1579 2205 616 2452 1602 2299 989 3942 3467 1567 2158 427 1694 2666 2459 1631 2414 1451 1695 2670 2475 1695 2670 2475 1694 2666 2459 1631 2414 1451 1695 2670 2475 1693 2663 2447 1583 2222 683 2718 2668 2467 1661 2534 1931 3615 2158 427 1693 2661 2439 1551 2095 175 685 2726 2699 2591 2157 424 1682 2617 2263 847 3374 1195 672 2673 2485 1736 2834 3131 223 878 3499 1696 2673 2488 1747 2880 3316 962 3836 3044 3972 3585 2039 4047 3887 3247 688 2740 2755 2816 3060 4036 3843 3069 4072 3986 3644 2276 900 3588 2051 4093 4072 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   guid: train-9175
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   input_ids: 2 1131 414 1643 2463 1645 2471 1678 2603 2207 622 2474 1691 2653 2408 1426 1596 2276 898 3580 2019 3966 3564 1953 3702 2507 1824 3188 451 1792 3057 4021 3782 2827 3101 104 404 1602 2300 994 3964 3556 1924 3588 2049 4085 4040 3857 3127 207 813 3237 646 2571 2078 105 407 1614 2347 1182 619 2463 1647 2480 1713 2742 2762 2843 3165 359 1424 1587 2240 755 3005 3813 2950 3596 2081 120 466 1850 3291 861 3432 1427 1599 2285 935 3728 2609 2231 717 2856 3219 575 2288 947 3773 2791 2959 3629 2215 655 2605 2216 659 2621 2279 911 3629 2215 655 2605 2214 651 2592 2164 452 1796 3074 4090 4060 3937 3448 1490 1850 3291 862 3435 1439 1645 2471 1679 2607 2224 691 2749 2791 2958 3628 2210 636 2529 1910 3532 1826 3194 476 1892 3460 1539 2045 4071 3983 3632 2227 702 2796 2979 3710 2540 1954 3707 2525 1893 3464 1556 2115 254 1003 3997 3688 2449 1590 2251 798 3180 420 1668 2561 2039 4045 3879 3213 552 2195 574 2284 932 3715 2559 2030 4012 3748 2689 2552 2003 3904 3316 962 3833 3031 3919 3376 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   guid: train-9176
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   input_ids: 2 2701 2600 2193 566 2252 804 3203 511 2031 4013 3752 2707 2622 2283 925 3686 2441 1560 2131 317 1256 915 3646 2282 924 3684 2436 1537 2039 4047 3887 3245 679 2702 2604 2210 636 2530 1915 3552 1906 3516 1763 2941 3560 1940 3651 2301 1000 3986 3642 2267 863 3437 1448 1681 2613 2248 788 3139 253 1000 3985 3640 2257 821 3271 783 3117 167 654 2602 2203 606 2411 1439 1645 2471 1680 2612 2243 767 3053 4006 3723 2591 2160 436 1731 2813 3047 3981 3621 2183 527 2095 175 687 2733 2728 2706 2617 2263 846 3369 1175 591 2350 1196 674 2681 2519 1871 3376 1204 708 2819 3071 4077 4005 3720 2577 2104 211 831 3312 948 3779 2813 3048 3987 3646 2284 931 3710 2540 1955 3709 2536 1937 3637 2247 781 3110 138 538 2138 346 1372 1380 1412 1540 2051 4095 4079 4016 3763 2751 2797 2984 3732 2625 2294 972 3874 3196 484 1923 3583 2029 4007 3726 2604 2210 635 2527 1902 3500 1699 2686 2539 1951 3694 2475 1693 2661 2439 1551 2095 175 685 2725 2696 2579 2109 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   guid: train-7649
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   input_ids: 2 2940 3555 1920 3570 1979 3805 2919 3472 1587 2238 746 2972 3681 2421 1480 1809 3127 207 813 3239 656 2610 2234 732 2916 3458 1532 2018 3964 3555 1917 3560 1939 3645 2279 912 3635 2240 756 3011 3838 3052 4001 3704 2515 1854 3307 927 3695 2480 1715 2749 2792 2964 3649 2293 968 3858 3132 228 897 3573 1992 3860 3137 248 979 3902 3308 930 3706 2524 1891 3456 1523 1981 3816 2963 3646 2284 931 3710 2539 1951 3696 2484 1731 2816 3060 4035 3837 3046 3979 3613 2152 403 1597 2279 911 3629 2215 655 2605 2215 655 2605 2216 659 2624 2290 956 3811 2943 3568 1972 3779 2815 3056 4019 3775 2797 2984 3731 2623 2286 939 3742 2667 2464 1652 2500 1794 3065 4055 3917 3366 1164 547 2174 491 1951 3696 2483 1725 2791 2957 3624 2194 571 2271 877 3496 1683 2623 2287 944 3762 2747 2783 2927 3501 1703 2702 2603 2208 627 2493 1767 2958 3627 2207 624 2483 1728 2803 3006 3820 2978 3706 2524 1891 3453 1512 1939 3647 2287 942 3756 2724 2690 2555 2016 3955 3517 1768 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   guid: train-9177
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   input_ids: 2 1828 3203 511 2029 4007 3728 2612 2243 768 3059 4032 3828 3010 3836 3044 3971 3583 2032 4018 3772 2788 2947 3584 2036 4036 3844 3075 4095 4080 4018 3772 2788 2947 3581 2023 3983 3632 2228 705 2807 3023 3887 3248 689 2743 2767 2861 3240 659 2623 2287 941 3751 2703 2605 2215 654 2603 2208 627 2494 1770 2971 3679 2413 1448 1683 2624 2292 964 3844 3075 4094 4076 4003 3709 2536 1937 3637 2248 787 3133 231 911 3632 2227 702 2796 2980 3715 2557 2021 3976 3602 2106 220 868 3460 1539 2048 4081 4023 3789 2855 3216 564 2243 767 3056 4017 3765 2760 2835 3135 237 934 3721 2584 2130 314 1243 863 3440 1460 1732 2817 3061 4037 3848 3092 68 258 1020 4067 3968 3572 1986 3836 3044 3972 3588 2049 4088 4049 3893 3272 786 3131 221 869 3463 1549 2085 136 531 2112 244 964 3841 3061 4040 3860 3140 257 1016 4051 3903 3311 943 3758 2731 2717 2661 2438 1546 2075 95 366 1450 1690 2651 2397 1383 1421 1575 2189 551 2191 559 2223 687 2734 2730 2714 2651 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   Writing example 0/1533
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   guid: train-7650
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   input_ids: 2 3572 1986 3835 3038 3948 3491 1662 2540 1956 3715 2559 2029 4008 3732 2627 2302 1004 4002 3708 2529 1912 3540 1857 3317 968 3859 3135 238 940 3748 2692 2562 2044 4068 3972 3587 2047 4078 4012 3748 2692 2564 2051 4093 4071 3983 3629 2216 660 2627 2303 1007 4013 3752 2708 2628 2307 1022 4075 4000 3700 2497 1782 3020 3875 3197 485 1925 3592 2068 67 255 1005 4008 3730 2620 2274 889 3544 1873 3383 1232 818 3259 735 2926 3499 1693 2661 2437 1544 2068 68 260 1025 4085 4040 3860 3140 258 1020 4067 3967 3565 1960 3732 2627 2304 1011 4031 3823 2992 3764 2755 2813 3045 3974 3596 2081 119 464 1842 3257 728 2899 3391 1261 935 3727 2607 2223 687 2736 2739 2750 2794 2972 3683 2429 1510 1929 3608 2132 323 1278 1004 4004 3716 2562 2041 4056 3923 3391 1261 935 3727 2606 2218 667 2656 2417 1461 1736 2833 3125 200 788 3137 247 974 3883 3232 628 2500 1795 3069 4071 3981 3622 2185 536 2129 309 1224 788 3140 258 1019 4063 3950 3499 1695 2670 2476 1700 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   guid: train-9178
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   input_ids: 2 2472 1683 2622 2282 923 3678 2410 1435 1630 2410 1435 1630 2410 1433 1622 2380 1314 1146 475 1887 3437 1447 1679 2606 2219 671 2670 2476 1699 2686 2538 1948 3684 2435 1535 2030 4012 3748 2691 2559 2031 4013 3752 2708 2625 2295 975 3887 3248 691 2749 2792 2963 3646 2283 927 3695 2479 1712 2740 2755 2815 3053 4008 3732 2626 2299 990 3948 3491 1664 2546 1978 3803 2910 3435 1438 1642 2458 1627 2398 1387 1439 1645 2472 1683 2624 2290 955 3806 2924 3491 1662 2538 1945 3670 2378 1308 1122 379 1502 1897 3480 1620 2370 1274 987 3936 3443 1471 1774 2986 3740 2660 2435 1535 2030 4012 3748 2691 2560 2033 4021 3784 2836 3137 245 968 3859 3133 232 913 3640 2260 836 3332 1025 4088 4052 3908 3329 1014 4041 3861 3143 269 1064 148 580 2305 1016 4052 3907 3326 1004 4002 3708 2532 1923 3583 2032 4020 3780 2817 3064 4049 3893 3271 784 3122 186 730 2907 3421 1384 1428 1603 2303 1007 4014 3756 2723 2687 2543 1966 3754 2714 2651 2399 1390 1451 1695 2671 2478 1707 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   guid: train-10704
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   input_ids: 2 585 2328 1106 315 1247 877 3494 1676 2593 2165 453 1798 3081 24 81 310 1228 801 3189 456 1809 3127 205 808 3218 571 2271 878 3498 1690 2649 2390 1353 1302 1100 289 1142 458 1818 3164 353 1400 1490 1849 3285 837 3335 1037 40 148 577 2295 973 3878 3210 540 2145 375 1485 1829 3207 528 2099 189 744 2961 3639 2254 810 3226 604 2401 1397 1477 1798 3083 32 114 444 1764 2946 3579 2013 3942 3465 1559 2126 300 1188 641 2549 1992 3860 3139 253 998 3980 3620 2177 501 1992 3859 3135 237 935 3726 2604 2211 639 2541 1958 3724 2593 2167 464 1841 3255 717 2855 3213 552 2194 572 2275 895 3568 1970 3769 2776 2899 3390 1259 926 3690 2457 1622 2379 1310 1129 408 1619 2365 1253 901 3590 2060 33 117 453 1798 3083 31 110 428 1698 2684 2532 1924 3588 2051 4095 4077 4007 3727 2608 2227 702 2793 2966 3660 2337 1144 467 1855 3310 940 3746 2684 2531 1918 3563 1950 3690 2458 1628 2401 1397 1480 1809 3128 209 821 3272 787 3133 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   guid: train-9179
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   input_ids: 2 31 110 426 1691 2653 2405 1415 1549 2085 136 532 2115 253 999 3981 3624 2193 565 2246 778 3098 92 353 1399 1485 1831 3213 551 2190 554 2204 611 2429 1512 1937 3637 2245 775 3085 40 146 569 2262 842 3356 1124 387 1534 2028 4001 3702 2507 1824 3188 450 1786 3034 3932 3425 1400 1489 1848 3281 822 3274 796 3172 386 1532 2020 3969 3573 1991 3854 3116 164 642 2555 2013 3943 3469 1573 2182 524 2081 118 460 1828 3204 514 2044 4065 3958 3531 1821 3173 392 1553 2101 199 782 3115 159 623 2478 1705 2710 2633 2328 1107 320 1265 950 3788 2852 3203 510 2027 3998 3692 2468 1667 2559 2029 4005 3718 2572 2082 124 484 1922 3578 2011 3935 3438 1450 1692 2658 2426 1499 1886 3435 1437 1640 2450 1596 2276 900 3586 2041 4053 3912 3346 1084 225 886 3530 1817 3160 337 1336 1234 825 3285 840 3347 1088 244 964 3844 3073 4085 4040 3857 3125 197 773 3080 18 60 227 895 3566 1964 3748 2691 2557 2023 3981 3622 2185 536 2131 317 1253 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   guid: train-10705
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   input_ids: 2 3998 3692 2467 1662 2540 1956 3715 2557 2024 3988 3649 2296 979 3902 3306 923 3679 2416 1460 1732 2820 3075 4095 4078 4012 3747 2685 2533 1925 3592 2067 63 239 943 3758 2732 2724 2692 2564 2052 4097 4087 4045 3880 3220 578 2297 984 3923 3392 1268 964 3843 3072 4084 4036 3844 3076 4099 4094 4076 4002 3708 2532 1923 3581 2021 3974 3596 2082 124 484 1922 3580 2019 3967 3566 1964 3748 2691 2558 2026 3995 3678 2411 1439 1648 2481 1720 2771 2879 3311 941 3751 2702 2602 2202 603 2398 1386 1435 1630 2410 1435 1631 2415 1453 1701 2695 2574 2090 154 601 2392 1361 1336 1236 836 3330 1018 4060 3940 3457 1526 1996 3876 3201 504 2004 3907 3327 1005 4008 3731 2623 2287 943 3757 2728 2706 2620 2274 892 3556 1921 3576 2004 3905 3320 977 3895 3280 820 3265 760 3027 3903 3311 944 3762 2748 2788 2948 3588 2051 4096 4082 4028 3810 2940 3555 1918 3563 1949 3688 2449 1589 2248 787 3134 235 927 3694 2476 1699 2685 2536 1940 3652 2307 1023 4080 4020 3780 2819 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   guid: train-10706
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   input_ids: 2 361 1430 1610 2330 1114 347 1373 1384 1426 1596 2276 900 3585 2037 4037 3846 3081 22 76 289 1144 466 1852 3297 888 3539 1853 3302 908 3618 2172 481 1912 3537 1845 3271 781 3109 136 529 2102 203 799 3183 429 1701 2694 2571 2079 110 427 1693 2664 2449 1589 2245 776 3089 56 212 833 3317 965 3846 3084 33 119 463 1837 3237 648 2577 2104 210 827 3294 874 3483 1631 2415 1453 1704 2707 2623 2285 936 3730 2618 2268 868 3457 1526 1995 3870 3180 418 1660 2529 1910 3532 1825 3190 458 1820 3170 380 1505 1912 3538 1851 3295 878 3498 1690 2649 2389 1351 1293 1062 138 538 2140 353 1398 1484 1826 3194 474 1883 3423 1390 1449 1686 2634 2329 1109 327 1293 1063 141 549 2182 522 2074 89 342 1354 1306 1114 345 1365 1352 1297 1077 197 774 3081 22 74 282 1114 346 1372 1377 1400 1491 1854 3305 920 3666 2364 1250 889 3543 1869 3367 1168 563 2237 743 2958 3628 2209 630 2505 1815 3149 296 1172 578 2300 994 3962 3547 1887 3437 1446 1676 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   guid: train-10707
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   input_ids: 2 1054 106 410 1626 2394 1369 1365 1351 1294 1065 150 585 2325 1094 265 1045 69 264 1041 56 209 821 3269 773 3078 9 22 73 277 1095 269 1062 139 541 2150 393 1559 2127 303 1197 678 2700 2595 2173 485 1928 3601 2101 200 787 3133 229 903 3597 2088 145 566 2250 794 3163 350 1386 1434 1626 2395 1373 1383 1423 1584 2226 698 2779 2911 3437 1447 1677 2597 2182 521 2070 75 287 1134 425 1685 2631 2317 1062 139 543 2159 431 1709 2727 2701 2597 2182 521 2069 72 276 1089 245 965 3847 3085 40 147 573 2277 901 3591 2061 40 147 573 2277 902 3595 2077 102 396 1569 2167 463 1840 3252 705 2806 3020 3873 3189 455 1807 3117 167 653 2600 2196 577 2293 965 3848 3090 57 213 840 3346 1083 221 869 3461 1541 2054 12 33 119 462 1836 3235 638 2538 1947 3679 2414 1451 1694 2665 2455 1615 2351 1198 684 2721 2677 2501 1800 3089 53 200 785 3125 197 773 3077 6 9 21 70 268 1058 121 470 1866 3353 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   guid: train-10708
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   input_ids: 2 3053 4005 3719 2575 2094 171 672 2674 2492 1763 2943 3568 1971 3775 2800 2996 3779 2814 3051 3999 3695 2478 1707 2719 2671 2480 1715 2750 2795 2975 3695 2478 1707 2718 2668 2467 1664 2547 1983 3823 2992 3763 2749 2792 2961 3640 2259 832 3316 963 3839 3056 4019 3776 2803 3005 3815 2958 3627 2205 615 2447 1584 2228 707 2815 3055 4014 3756 2724 2691 2560 2035 4031 3823 2992 3763 2751 2797 2984 3731 2621 2280 915 3645 2280 915 3645 2280 915 3645 2280 915 3645 2280 915 3645 2280 915 3645 2280 915 3648 2291 959 3821 2984 3731 2621 2280 915 3648 2291 960 3828 3012 3843 3071 4078 4011 3744 2676 2499 1792 3060 4036 3842 3067 4063 3949 3494 1675 2592 2163 447 1773 2984 3731 2622 2284 931 3712 2548 1986 3836 3044 3972 3588 2051 4096 4084 4035 3838 3051 3999 3694 2476 1700 2692 2563 2046 4076 4003 3712 2548 1987 3839 3054 4012 3748 2691 2559 2030 4011 3744 2676 2499 1791 3054 4011 3744 2675 2496 1780 3011 3839 3055 4014 3756 2724 2691 2558 2028 4004 3715 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:08 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 18:15:12 - INFO - __main__ -   Saving features into cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_train_6-new-12w-0_300_dnaprom
06/26/2023 18:15:16 - INFO - __main__ -   ***** Running training *****
06/26/2023 18:15:16 - INFO - __main__ -     Num examples = 12236
06/26/2023 18:15:16 - INFO - __main__ -     Num Epochs = 30
06/26/2023 18:15:16 - INFO - __main__ -     Instantaneous batch size per GPU = 48
06/26/2023 18:15:16 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 48
06/26/2023 18:15:16 - INFO - __main__ -     Gradient Accumulation steps = 1
06/26/2023 18:15:16 - INFO - __main__ -     Total optimization steps = 7650
06/26/2023 18:15:16 - INFO - __main__ -     Continuing training from checkpoint, will skip to saved global_step
06/26/2023 18:15:16 - INFO - __main__ -     Continuing training from epoch 0
06/26/2023 18:15:16 - INFO - __main__ -     Continuing training from global step 0
06/26/2023 18:15:16 - INFO - __main__ -     Will skip the first 0 steps in the first epoch
06/26/2023 18:15:59 - INFO - __main__ -   Creating features from dataset file at /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   Writing example 0/1530
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   guid: dev-1
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   input_ids: 2 1548 2084 130 508 2018 3961 3543 1871 3376 1203 703 2798 2987 3741 2662 2442 1562 2140 356 1412 1537 2039 4045 3878 3211 543 2159 430 1706 2715 2655 2413 1447 1678 2604 2212 644 2564 2050 4092 4068 3972 3587 2045 4070 3980 3617 2168 467 1856 3314 954 3803 2910 3434 1435 1630 2409 1431 1615 2349 1191 655 2605 2213 648 2579 2111 238 939 3743 2669 2470 1674 2587 2141 357 1416 1555 2111 239 943 3757 2726 2700 2596 2177 502 1995 3870 3177 408 1617 2360 1233 822 3275 797 3174 395 1565 2150 395 1567 2159 431 1709 2727 2701 2597 2184 531 2111 237 935 3725 2599 2192 561 2229 711 2829 3110 140 548 2177 503 1999 3887 3247 687 2733 2727 2703 2606 2219 671 2670 2475 1695 2669 2472 1681 2614 2252 801 3189 453 1800 3089 56 209 822 3275 797 3175 398 1579 2205 615 2445 1574 2188 548 2177 503 1999 3887 3247 687 2733 2727 2702 2602 2203 607 2413 1447 1677 2597 2184 532 2115 255 1007 4014 3755 2719 2670 2475 1695 2669 2471 1678 2601 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   guid: dev-2
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   input_ids: 2 2211 638 2539 1951 3694 2474 1689 2648 2386 1339 1247 877 3496 1681 2616 2257 823 3278 812 3235 640 2548 1985 3829 3013 3847 3087 47 173 680 2708 2628 2305 1015 4046 3884 3235 639 2542 1963 3741 2664 2451 1599 2287 943 3757 2727 2703 2608 2227 704 2803 3005 3816 2964 3652 2308 1025 4085 4040 3860 3139 256 1012 4035 3838 3050 3994 3674 2393 1367 1358 1324 1185 629 2502 1802 3099 93 360 1428 1601 2294 969 3863 3150 298 1177 599 2381 1320 1171 574 2282 923 3678 2411 1438 1644 2466 1659 2526 1899 3487 1646 2474 1692 2659 2430 1514 1948 3683 2431 1517 1960 3730 2618 2268 868 3457 1527 1999 3885 3240 659 2624 2292 964 3844 3075 4095 4077 4008 3732 2628 2308 1025 4088 4051 3903 3309 936 3732 2628 2308 1028 4099 4095 4079 4013 3752 2708 2628 2308 1027 4094 4075 3999 3693 2472 1684 2625 2296 979 3902 3307 927 3695 2477 1703 2701 2600 2195 573 2279 911 3629 2216 658 2619 2270 875 3485 1639 2447 1581 2215 656 2609 2230 715 2845 3175 399 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   guid: dev-3
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   input_ids: 2 3547 1887 3437 1445 1672 2580 2116 260 1025 4087 4045 3880 3218 569 2264 851 3391 1263 943 3758 2732 2723 2686 2539 1952 3700 2499 1791 3054 4010 3739 2656 2417 1464 1746 2874 3291 863 3437 1447 1678 2604 2211 639 2542 1961 3733 2632 2322 1084 228 899 3584 2033 4024 3794 2876 3299 893 3558 1931 3615 2157 423 1678 2603 2207 621 2472 1683 2622 2284 932 3715 2560 2035 4030 3820 2978 3708 2529 1910 3532 1828 3202 508 2020 3971 3583 2031 4015 3760 2737 2743 2766 2860 3235 637 2533 1928 3604 2113 247 973 3877 3205 518 2059 30 108 420 1667 2557 2021 3976 3604 2113 247 973 3877 3205 518 2059 30 108 417 1655 2512 1841 3256 724 2881 3317 965 3845 3079 14 44 163 640 2548 1986 3833 3030 3916 3364 1156 515 2048 4084 4036 3844 3075 4095 4077 4008 3732 2628 2306 1020 4068 3972 3588 2052 4099 4096 4084 4036 3844 3075 4096 4082 4027 3807 2926 3497 1686 2635 2333 1127 399 1582 2220 674 2683 2527 1903 3502 1708 2724 2692 2563 2046 4075 3999 3695 2479 1711 2733 2728 2708 2626 2300 994 3964 3556 1924 3585 2039 4045 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   guid: dev-4
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   input_ids: 2 13 38 138 540 2146 377 1493 1862 3338 1050 90 345 1368 1361 1334 1226 795 3167 367 1456 1713 2742 2764 2850 3196 483 1919 3565 1960 3732 2625 2294 970 3867 3166 363 1439 1646 2476 1700 2692 2562 2044 4065 3959 3534 1835 3231 623 2478 1708 2722 2681 2518 1865 3350 1099 286 1132 419 1663 2541 1957 3720 2580 2113 246 969 3862 3146 284 1122 380 1506 1913 3542 1865 3350 1098 284 1124 387 1534 2026 3996 3681 2424 1489 1848 3281 823 3280 818 3260 740 2947 3582 2028 4004 3716 2564 2049 4085 4039 3853 3112 146 569 2261 840 3347 1086 234 921 3670 2378 1307 1119 366 1450 1692 2657 2422 1484 1826 3196 481 1910 3530 1818 3164 355 1407 1518 1963 3743 2669 2470 1674 2586 2138 346 1372 1378 1403 1503 1903 3502 1706 2714 2652 2402 1404 1506 1916 3555 1918 3561 1944 3665 2358 1225 790 3148 291 1150 490 1946 3673 2391 1358 1324 1185 631 2511 1837 3237 647 2574 2091 158 617 2454 1612 2337 1144 465 1848 3281 821 3269 773 3078 10 25 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   guid: dev-5
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   input_ids: 2 255 1006 4011 3742 2666 2459 1631 2413 1445 1669 2565 2053 5 5 8 18 59 221 870 3467 1565 2152 401 1590 2250 796 3169 376 1492 1857 3317 967 3854 3116 164 641 2549 1991 3853 3109 135 525 2085 133 518 2058 28 97 373 1477 1797 3077 6 10 28 99 381 1512 1940 3651 2301 1000 3985 3637 2248 786 3129 213 837 3333 1032 20 67 254 1001 3990 3657 2325 1096 276 1089 246 972 3873 3189 453 1797 3079 13 37 134 521 2072 81 311 1230 809 3221 581 2309 1032 18 57 213 837 3336 1044 65 248 977 3893 3272 788 3137 248 979 3901 3302 905 3605 2117 261 1029 7 15 45 165 648 2577 2102 204 801 3191 463 1838 3241 663 2638 2345 1173 581 2309 1032 17 53 197 773 3077 8 17 53 197 775 3086 43 158 618 2457 1622 2377 1303 1101 296 1171 573 2280 915 3646 2284 929 3701 2501 1800 3089 53 200 785 3125 198 778 3100 99 381 1509 1928 3601 2101 197 773 3077 5 5 6 12 34 122 473 1879 3406 1323 1182 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   Writing example 0/1530
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   guid: dev-1531
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   input_ids: 2 940 3748 2689 2550 1995 3870 3178 412 1633 2422 1482 1817 3160 338 1339 1247 879 3502 1706 2716 2660 2436 1539 2047 4077 4007 3725 2600 2196 579 2304 1012 4035 3837 3047 3982 3627 2206 620 2468 1667 2558 2028 4001 3704 2514 1850 3291 861 3430 1419 1567 2157 421 1669 2565 2056 19 64 243 958 3820 2978 3705 2517 1862 3338 1051 95 367 1454 1708 2723 2686 2540 1956 3713 2552 2004 3905 3320 980 3905 3320 977 3895 3279 813 3238 651 2591 2158 428 1699 2685 2535 1934 3626 2203 608 2418 1468 1763 2941 3560 1937 3638 2251 799 3182 428 1699 2686 2538 1948 3683 2429 1511 1934 3628 2211 637 2534 1931 3613 2150 396 1570 2172 483 1917 3559 1933 3623 2191 559 2221 679 2703 2606 2219 669 2662 2443 1567 2158 428 1699 2685 2535 1935 3632 2225 696 2769 2871 3279 814 3243 669 2661 2440 1553 2103 207 815 3245 680 2705 2613 2247 781 3110 139 543 2158 428 1699 2686 2538 1948 3681 2423 1485 1829 3205 519 2061 39 143 560 2227 701 2790 2956 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   guid: dev-1532
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   input_ids: 2 3789 2856 3219 573 2280 913 3640 2257 822 3275 799 3183 431 1709 2727 2702 2604 2212 644 2561 2037 4040 3858 3132 227 893 3560 1939 3647 2288 948 3780 2820 3076 4097 4085 4040 3860 3140 259 1024 4083 4029 3815 2959 3631 2221 679 2703 2606 2220 674 2682 2524 1889 3448 1492 1858 3323 991 3949 3496 1683 2622 2283 927 3695 2478 1708 2722 2681 2520 1873 3384 1234 826 3291 863 3437 1448 1684 2627 2302 1002 3995 3678 2412 1443 1663 2541 1957 3717 2568 2066 57 215 846 3370 1179 606 2412 1444 1668 2561 2040 4050 3898 3292 865 3448 1491 1856 3315 957 3814 2955 3615 2157 423 1679 2606 2220 676 2692 2563 2048 4084 4035 3840 3059 4029 3816 2964 3650 2299 991 3951 3501 1702 2700 2595 2174 490 1946 3674 2395 1375 1391 1453 1703 2702 2603 2205 614 2444 1571 2174 490 1947 3679 2414 1452 1698 2684 2529 1912 3540 1857 3318 970 3865 3160 340 1345 1269 965 3845 3077 6 11 30 107 415 1645 2471 1678 2602 2201 597 2373 1285 1032 18 57 216 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   guid: dev-1533
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   input_ids: 2 81 309 1221 776 3090 59 223 878 3497 1685 2629 2311 1037 37 135 526 2091 157 616 2450 1593 2262 842 3355 1119 365 1445 1672 2578 2105 215 845 3365 1160 532 2115 255 1005 4008 3731 2623 2286 938 3740 2658 2426 1498 1881 3413 1350 1290 1050 92 353 1398 1484 1825 3190 457 1813 3143 272 1074 186 731 2910 3435 1438 1642 2459 1629 2408 1428 1601 2295 974 3883 3229 616 2449 1592 2259 829 3302 908 3617 2165 455 1806 3114 156 611 2430 1514 1945 3670 2377 1301 1093 262 1036 36 130 505 2008 3923 3389 1253 902 3596 2083 127 494 1964 3748 2692 2561 2037 4037 3845 3080 17 54 201 789 3142 267 1055 109 421 1669 2565 2053 5 7 13 37 135 525 2085 133 520 2066 57 213 838 3337 1045 69 262 1033 21 70 267 1053 101 392 1553 2101 197 774 3081 21 69 264 1042 58 220 867 3455 1517 1957 3718 2572 2081 117 456 1809 3128 210 826 3291 861 3431 1421 1573 2181 520 2068 66 251 989 3943 3470 1580 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   guid: dev-1534
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   input_ids: 2 1643 2463 1648 2484 1731 2813 3048 3988 3649 2293 968 3860 3138 252 994 3962 3548 1891 3454 1515 1950 3690 2459 1630 2412 1444 1666 2555 2014 3948 3492 1668 2564 2049 4087 4047 3887 3246 684 2721 2677 2504 1810 3132 227 895 3567 1968 3761 2742 2764 2852 3201 504 2004 3908 3331 1021 4070 3980 3620 2179 509 2023 3982 3628 2212 643 2558 2027 3997 3687 2447 1582 2218 668 2658 2427 1504 1905 3510 1740 2849 3189 456 1812 3137 248 980 3907 3325 997 3973 3591 2062 42 156 610 2426 1500 1889 3448 1492 1860 3330 1019 4062 3946 3484 1633 2422 1483 1822 3180 419 1662 2539 1949 3687 2448 1587 2238 747 2975 3694 2475 1696 2676 2499 1791 3055 4016 3763 2749 2791 2959 3631 2224 691 2750 2796 2980 3713 2550 1996 3876 3203 512 2036 4036 3844 3074 4091 4061 3941 3462 1546 2074 92 355 1405 1512 1940 3650 2298 988 3937 3448 1492 1860 3332 1025 4088 4050 3899 3293 872 3476 1601 2296 977 3895 3278 811 3230 620 2468 1666 2554 2012 3937 3447 1485 1832 3218 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   guid: dev-1535
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   input_ids: 2 2030 4010 3739 2654 2412 1443 1661 2536 1940 3652 2307 1021 4070 3979 3615 2158 427 1695 2669 2472 1683 2623 2287 942 3754 2715 2655 2413 1448 1683 2622 2282 924 3682 2426 1499 1886 3434 1433 1624 2387 1341 1254 907 3615 2158 426 1692 2657 2424 1492 1860 3331 1023 4077 4006 3723 2590 2155 415 1647 2479 1709 2727 2704 2611 2238 748 2979 3710 2539 1949 3688 2451 1597 2278 907 3613 2152 403 1597 2277 902 3596 2084 131 512 2036 4035 3839 3054 4012 3746 2681 2520 1876 3394 1274 988 3938 3450 1500 1892 3459 1533 2023 3981 3623 2190 553 2200 596 2369 1272 980 3908 3331 1021 4069 3973 3592 2068 65 245 968 3857 3128 209 821 3269 776 3089 53 199 782 3114 156 610 2427 1501 1894 3467 1566 2156 420 1666 2555 2014 3946 3483 1631 2413 1448 1681 2616 2257 821 3272 785 3125 198 777 3093 69 263 1039 46 172 676 2691 2558 2028 4004 3714 2554 2011 3934 3434 1434 1626 2395 1375 1389 1448 1682 2620 2273 885 3528 1809 3125 200 788 3139 253 999 3983 3629 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 18:15:59 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 18:16:03 - INFO - __main__ -   Saving features into cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:16:04 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:16:04 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:16:04 - INFO - __main__ -     Batch size = 48
06/26/2023 18:16:13 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:16:13 - INFO - __main__ -     acc = 0.6179738562091504
06/26/2023 18:16:13 - INFO - __main__ -     auc = 0.6898269896193772
06/26/2023 18:16:13 - INFO - __main__ -     f1 = 0.6151742153362942
06/26/2023 18:16:13 - INFO - __main__ -     mcc = 0.2394575848518495
06/26/2023 18:16:13 - INFO - __main__ -     precision = 0.6215098344361683
06/26/2023 18:16:13 - INFO - __main__ -     recall = 0.6179738562091504
06/26/2023 18:16:13 - INFO - __main__ -   {"eval_acc": 0.6179738562091504, "eval_f1": 0.6151742153362942, "eval_mcc": 0.2394575848518495, "eval_auc": 0.6898269896193772, "eval_precision": 0.6215098344361683, "eval_recall": 0.6179738562091504, "learning_rate": 1.3071895424836602e-05, "loss": 0.6856575065851211, "step": 100}
06/26/2023 18:16:57 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:16:58 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:16:58 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:16:58 - INFO - __main__ -     Batch size = 48
06/26/2023 18:17:07 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:17:07 - INFO - __main__ -     acc = 0.6660130718954248
06/26/2023 18:17:07 - INFO - __main__ -     auc = 0.7390903071468239
06/26/2023 18:17:07 - INFO - __main__ -     f1 = 0.6658669091866407
06/26/2023 18:17:07 - INFO - __main__ -     mcc = 0.3323170076494768
06/26/2023 18:17:07 - INFO - __main__ -     precision = 0.6663040631563452
06/26/2023 18:17:07 - INFO - __main__ -     recall = 0.6660130718954249
06/26/2023 18:17:07 - INFO - __main__ -   {"eval_acc": 0.6660130718954248, "eval_f1": 0.6658669091866407, "eval_mcc": 0.3323170076494768, "eval_auc": 0.7390903071468239, "eval_precision": 0.6663040631563452, "eval_recall": 0.6660130718954249, "learning_rate": 2.6143790849673204e-05, "loss": 0.6096767950057983, "step": 200}
06/26/2023 18:17:50 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:17:51 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:17:51 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:17:51 - INFO - __main__ -     Batch size = 48
06/26/2023 18:18:00 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:18:00 - INFO - __main__ -     acc = 0.6650326797385621
06/26/2023 18:18:00 - INFO - __main__ -     auc = 0.7584456832842069
06/26/2023 18:18:00 - INFO - __main__ -     f1 = 0.6359415579704888
06/26/2023 18:18:00 - INFO - __main__ -     mcc = 0.4001545842222906
06/26/2023 18:18:00 - INFO - __main__ -     precision = 0.7425636115340544
06/26/2023 18:18:00 - INFO - __main__ -     recall = 0.6650326797385621
06/26/2023 18:18:00 - INFO - __main__ -   {"eval_acc": 0.6650326797385621, "eval_f1": 0.6359415579704888, "eval_mcc": 0.4001545842222906, "eval_auc": 0.7584456832842069, "eval_precision": 0.7425636115340544, "eval_recall": 0.6650326797385621, "learning_rate": 3.9215686274509805e-05, "loss": 0.5916206926107407, "step": 300}
06/26/2023 18:18:43 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:18:44 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:18:44 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:18:44 - INFO - __main__ -     Batch size = 48
06/26/2023 18:18:53 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:18:53 - INFO - __main__ -     acc = 0.6745098039215687
06/26/2023 18:18:53 - INFO - __main__ -     auc = 0.7658622751933017
06/26/2023 18:18:53 - INFO - __main__ -     f1 = 0.651517459115251
06/26/2023 18:18:53 - INFO - __main__ -     mcc = 0.40680427834010646
06/26/2023 18:18:53 - INFO - __main__ -     precision = 0.7370779709175999
06/26/2023 18:18:53 - INFO - __main__ -     recall = 0.6745098039215687
06/26/2023 18:18:53 - INFO - __main__ -   {"eval_acc": 0.6745098039215687, "eval_f1": 0.651517459115251, "eval_mcc": 0.40680427834010646, "eval_auc": 0.7658622751933017, "eval_precision": 0.7370779709175999, "eval_recall": 0.6745098039215687, "learning_rate": 5.228758169934641e-05, "loss": 0.5929208296537399, "step": 400}
06/26/2023 18:19:36 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:19:36 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:19:36 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:19:36 - INFO - __main__ -     Batch size = 48
06/26/2023 18:19:45 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:19:45 - INFO - __main__ -     acc = 0.6790849673202615
06/26/2023 18:19:45 - INFO - __main__ -     auc = 0.7519075996411637
06/26/2023 18:19:45 - INFO - __main__ -     f1 = 0.6603871847393716
06/26/2023 18:19:45 - INFO - __main__ -     mcc = 0.40560601836403715
06/26/2023 18:19:45 - INFO - __main__ -     precision = 0.7296622723208808
06/26/2023 18:19:45 - INFO - __main__ -     recall = 0.6790849673202615
06/26/2023 18:19:45 - INFO - __main__ -   {"eval_acc": 0.6790849673202615, "eval_f1": 0.6603871847393716, "eval_mcc": 0.40560601836403715, "eval_auc": 0.7519075996411637, "eval_precision": 0.7296622723208808, "eval_recall": 0.6790849673202615, "learning_rate": 6.535947712418301e-05, "loss": 0.5861008176207543, "step": 500}
06/26/2023 18:20:28 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:20:29 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:20:29 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:20:29 - INFO - __main__ -     Batch size = 48
06/26/2023 18:20:38 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:20:38 - INFO - __main__ -     acc = 0.7098039215686275
06/26/2023 18:20:38 - INFO - __main__ -     auc = 0.7707394591823657
06/26/2023 18:20:38 - INFO - __main__ -     f1 = 0.7092629113768025
06/26/2023 18:20:38 - INFO - __main__ -     mcc = 0.4211782469749453
06/26/2023 18:20:38 - INFO - __main__ -     precision = 0.711377264064703
06/26/2023 18:20:38 - INFO - __main__ -     recall = 0.7098039215686274
06/26/2023 18:20:38 - INFO - __main__ -   {"eval_acc": 0.7098039215686275, "eval_f1": 0.7092629113768025, "eval_mcc": 0.4211782469749453, "eval_auc": 0.7707394591823657, "eval_precision": 0.711377264064703, "eval_recall": 0.7098039215686274, "learning_rate": 7.843137254901961e-05, "loss": 0.5442132240533829, "step": 600}
06/26/2023 18:21:21 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:21:21 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:21:21 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:21:21 - INFO - __main__ -     Batch size = 48
06/26/2023 18:21:31 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:21:31 - INFO - __main__ -     acc = 0.6875816993464052
06/26/2023 18:21:31 - INFO - __main__ -     auc = 0.7689068307061386
06/26/2023 18:21:31 - INFO - __main__ -     f1 = 0.6748286307668298
06/26/2023 18:21:31 - INFO - __main__ -     mcc = 0.4085782863705797
06/26/2023 18:21:31 - INFO - __main__ -     precision = 0.7224846782431051
06/26/2023 18:21:31 - INFO - __main__ -     recall = 0.6875816993464052
06/26/2023 18:21:31 - INFO - __main__ -   {"eval_acc": 0.6875816993464052, "eval_f1": 0.6748286307668298, "eval_mcc": 0.4085782863705797, "eval_auc": 0.7689068307061386, "eval_precision": 0.7224846782431051, "eval_recall": 0.6875816993464052, "learning_rate": 9.150326797385621e-05, "loss": 0.5614775410294532, "step": 700}
06/26/2023 18:22:13 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:22:14 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:22:14 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:22:14 - INFO - __main__ -     Batch size = 48
06/26/2023 18:22:23 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:22:23 - INFO - __main__ -     acc = 0.7124183006535948
06/26/2023 18:22:23 - INFO - __main__ -     auc = 0.7792167542398224
06/26/2023 18:22:23 - INFO - __main__ -     f1 = 0.7083820662768031
06/26/2023 18:22:23 - INFO - __main__ -     mcc = 0.43710877359413514
06/26/2023 18:22:23 - INFO - __main__ -     precision = 0.7248677248677249
06/26/2023 18:22:23 - INFO - __main__ -     recall = 0.7124183006535948
06/26/2023 18:22:23 - INFO - __main__ -   {"eval_acc": 0.7124183006535948, "eval_f1": 0.7083820662768031, "eval_mcc": 0.43710877359413514, "eval_auc": 0.7792167542398224, "eval_precision": 0.7248677248677249, "eval_recall": 0.7124183006535948, "learning_rate": 9.949164851125636e-05, "loss": 0.551625509262085, "step": 800}
06/26/2023 18:23:06 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:23:07 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:23:07 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:23:07 - INFO - __main__ -     Batch size = 48
06/26/2023 18:23:16 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:23:16 - INFO - __main__ -     acc = 0.6816993464052288
06/26/2023 18:23:16 - INFO - __main__ -     auc = 0.7734320133282071
06/26/2023 18:23:16 - INFO - __main__ -     f1 = 0.6599427418990467
06/26/2023 18:23:16 - INFO - __main__ -     mcc = 0.42128176031670755
06/26/2023 18:23:16 - INFO - __main__ -     precision = 0.7441922949735449
06/26/2023 18:23:16 - INFO - __main__ -     recall = 0.6816993464052288
06/26/2023 18:23:16 - INFO - __main__ -   {"eval_acc": 0.6816993464052288, "eval_f1": 0.6599427418990467, "eval_mcc": 0.42128176031670755, "eval_auc": 0.7734320133282071, "eval_precision": 0.7441922949735449, "eval_recall": 0.6816993464052288, "learning_rate": 9.80392156862745e-05, "loss": 0.5028676775097847, "step": 900}
06/26/2023 18:23:58 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:23:59 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:23:59 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:23:59 - INFO - __main__ -     Batch size = 48
06/26/2023 18:24:08 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:24:08 - INFO - __main__ -     acc = 0.7290849673202614
06/26/2023 18:24:08 - INFO - __main__ -     auc = 0.7932991584433338
06/26/2023 18:24:08 - INFO - __main__ -     f1 = 0.7287656073327399
06/26/2023 18:24:08 - INFO - __main__ -     mcc = 0.4592526884134828
06/26/2023 18:24:08 - INFO - __main__ -     precision = 0.7301690004828585
06/26/2023 18:24:08 - INFO - __main__ -     recall = 0.7290849673202614
06/26/2023 18:24:08 - INFO - __main__ -   {"eval_acc": 0.7290849673202614, "eval_f1": 0.7287656073327399, "eval_mcc": 0.4592526884134828, "eval_auc": 0.7932991584433338, "eval_precision": 0.7301690004828585, "eval_recall": 0.7290849673202614, "learning_rate": 9.658678286129266e-05, "loss": 0.5026007774472236, "step": 1000}
06/26/2023 18:24:51 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:24:52 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:24:52 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:24:52 - INFO - __main__ -     Batch size = 48
06/26/2023 18:25:01 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:25:01 - INFO - __main__ -     acc = 0.7209150326797386
06/26/2023 18:25:01 - INFO - __main__ -     auc = 0.7881998376692725
06/26/2023 18:25:01 - INFO - __main__ -     f1 = 0.7209131251270888
06/26/2023 18:25:01 - INFO - __main__ -     mcc = 0.4418361052808785
06/26/2023 18:25:01 - INFO - __main__ -     precision = 0.7209210726424236
06/26/2023 18:25:01 - INFO - __main__ -     recall = 0.7209150326797386
06/26/2023 18:25:01 - INFO - __main__ -   {"eval_acc": 0.7209150326797386, "eval_f1": 0.7209131251270888, "eval_mcc": 0.4418361052808785, "eval_auc": 0.7881998376692725, "eval_precision": 0.7209210726424236, "eval_recall": 0.7209150326797386, "learning_rate": 9.513435003631082e-05, "loss": 0.40216300651431086, "step": 1100}
06/26/2023 18:25:44 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:25:45 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:25:45 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:25:45 - INFO - __main__ -     Batch size = 48
06/26/2023 18:25:54 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:25:54 - INFO - __main__ -     acc = 0.7333333333333333
06/26/2023 18:25:54 - INFO - __main__ -     auc = 0.804800290486565
06/26/2023 18:25:54 - INFO - __main__ -     f1 = 0.733296419342931
06/26/2023 18:25:54 - INFO - __main__ -     mcc = 0.4667959014148286
06/26/2023 18:25:54 - INFO - __main__ -     precision = 0.7334625859760883
06/26/2023 18:25:54 - INFO - __main__ -     recall = 0.7333333333333334
06/26/2023 18:25:54 - INFO - __main__ -   {"eval_acc": 0.7333333333333333, "eval_f1": 0.733296419342931, "eval_mcc": 0.4667959014148286, "eval_auc": 0.804800290486565, "eval_precision": 0.7334625859760883, "eval_recall": 0.7333333333333334, "learning_rate": 9.368191721132898e-05, "loss": 0.38250179573893545, "step": 1200}
06/26/2023 18:26:36 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:26:37 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:26:37 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:26:37 - INFO - __main__ -     Batch size = 48
06/26/2023 18:26:46 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:26:46 - INFO - __main__ -     acc = 0.7359477124183007
06/26/2023 18:26:46 - INFO - __main__ -     auc = 0.7957488572771156
06/26/2023 18:26:46 - INFO - __main__ -     f1 = 0.7339066288296231
06/26/2023 18:26:46 - INFO - __main__ -     mcc = 0.4793057912457841
06/26/2023 18:26:46 - INFO - __main__ -     precision = 0.7434162628312141
06/26/2023 18:26:46 - INFO - __main__ -     recall = 0.7359477124183007
06/26/2023 18:26:46 - INFO - __main__ -   {"eval_acc": 0.7359477124183007, "eval_f1": 0.7339066288296231, "eval_mcc": 0.4793057912457841, "eval_auc": 0.7957488572771156, "eval_precision": 0.7434162628312141, "eval_recall": 0.7359477124183007, "learning_rate": 9.222948438634713e-05, "loss": 0.350858301743865, "step": 1300}
06/26/2023 18:27:29 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:27:30 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:27:30 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:27:30 - INFO - __main__ -     Batch size = 48
06/26/2023 18:27:39 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:27:39 - INFO - __main__ -     acc = 0.7300653594771241
06/26/2023 18:27:39 - INFO - __main__ -     auc = 0.7944935708488188
06/26/2023 18:27:39 - INFO - __main__ -     f1 = 0.728394584139265
06/26/2023 18:27:39 - INFO - __main__ -     mcc = 0.46589834832016663
06/26/2023 18:27:39 - INFO - __main__ -     precision = 0.7358691367757193
06/26/2023 18:27:39 - INFO - __main__ -     recall = 0.7300653594771243
06/26/2023 18:27:39 - INFO - __main__ -   {"eval_acc": 0.7300653594771241, "eval_f1": 0.728394584139265, "eval_mcc": 0.46589834832016663, "eval_auc": 0.7944935708488188, "eval_precision": 0.7358691367757193, "eval_recall": 0.7300653594771243, "learning_rate": 9.077705156136529e-05, "loss": 0.2872109830379486, "step": 1400}
06/26/2023 18:28:22 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:28:23 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:28:23 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:28:23 - INFO - __main__ -     Batch size = 48
06/26/2023 18:28:32 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:28:32 - INFO - __main__ -     acc = 0.7264705882352941
06/26/2023 18:28:32 - INFO - __main__ -     auc = 0.8025727284377804
06/26/2023 18:28:32 - INFO - __main__ -     f1 = 0.719540848635258
06/26/2023 18:28:32 - INFO - __main__ -     mcc = 0.4771330005096549
06/26/2023 18:28:32 - INFO - __main__ -     precision = 0.7513084612325251
06/26/2023 18:28:32 - INFO - __main__ -     recall = 0.7264705882352941
06/26/2023 18:28:32 - INFO - __main__ -   {"eval_acc": 0.7264705882352941, "eval_f1": 0.719540848635258, "eval_mcc": 0.4771330005096549, "eval_auc": 0.8025727284377804, "eval_precision": 0.7513084612325251, "eval_recall": 0.7264705882352941, "learning_rate": 8.932461873638345e-05, "loss": 0.2722908911854029, "step": 1500}
06/26/2023 18:29:15 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:29:15 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:29:15 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:29:15 - INFO - __main__ -     Batch size = 48
06/26/2023 18:29:24 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:29:24 - INFO - __main__ -     acc = 0.6973856209150326
06/26/2023 18:29:24 - INFO - __main__ -     auc = 0.7844354735358194
06/26/2023 18:29:24 - INFO - __main__ -     f1 = 0.6939545228319024
06/26/2023 18:29:24 - INFO - __main__ -     mcc = 0.4039321487471329
06/26/2023 18:29:24 - INFO - __main__ -     precision = 0.7066528200421839
06/26/2023 18:29:24 - INFO - __main__ -     recall = 0.6973856209150326
06/26/2023 18:29:24 - INFO - __main__ -   {"eval_acc": 0.6973856209150326, "eval_f1": 0.6939545228319024, "eval_mcc": 0.4039321487471329, "eval_auc": 0.7844354735358194, "eval_precision": 0.7066528200421839, "eval_recall": 0.6973856209150326, "learning_rate": 8.78721859114016e-05, "loss": 0.22238044684752822, "step": 1600}
06/26/2023 18:30:07 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:30:08 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:30:08 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:30:08 - INFO - __main__ -     Batch size = 48
06/26/2023 18:30:17 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:30:17 - INFO - __main__ -     acc = 0.7375816993464053
06/26/2023 18:30:17 - INFO - __main__ -     auc = 0.7973036011790339
06/26/2023 18:30:17 - INFO - __main__ -     f1 = 0.7373884904642241
06/26/2023 18:30:17 - INFO - __main__ -     mcc = 0.4758641213528099
06/26/2023 18:30:17 - INFO - __main__ -     precision = 0.7382829386836651
06/26/2023 18:30:17 - INFO - __main__ -     recall = 0.7375816993464053
06/26/2023 18:30:17 - INFO - __main__ -   {"eval_acc": 0.7375816993464053, "eval_f1": 0.7373884904642241, "eval_mcc": 0.4758641213528099, "eval_auc": 0.7973036011790339, "eval_precision": 0.7382829386836651, "eval_recall": 0.7375816993464053, "learning_rate": 8.641975308641975e-05, "loss": 0.20837558912113308, "step": 1700}
06/26/2023 18:31:00 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:31:00 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:31:00 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:31:00 - INFO - __main__ -     Batch size = 48
06/26/2023 18:31:09 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:31:09 - INFO - __main__ -     acc = 0.7186274509803922
06/26/2023 18:31:09 - INFO - __main__ -     auc = 0.7929759921397753
06/26/2023 18:31:09 - INFO - __main__ -     f1 = 0.7099592800733705
06/26/2023 18:31:09 - INFO - __main__ -     mcc = 0.4659946232359771
06/26/2023 18:31:09 - INFO - __main__ -     precision = 0.7483116689041895
06/26/2023 18:31:09 - INFO - __main__ -     recall = 0.7186274509803922
06/26/2023 18:31:09 - INFO - __main__ -   {"eval_acc": 0.7186274509803922, "eval_f1": 0.7099592800733705, "eval_mcc": 0.4659946232359771, "eval_auc": 0.7929759921397753, "eval_precision": 0.7483116689041895, "eval_recall": 0.7186274509803922, "learning_rate": 8.496732026143791e-05, "loss": 0.18674682155251504, "step": 1800}
06/26/2023 18:31:52 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:31:53 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:31:53 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:31:53 - INFO - __main__ -     Batch size = 48
06/26/2023 18:32:02 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:32:02 - INFO - __main__ -     acc = 0.7290849673202614
06/26/2023 18:32:02 - INFO - __main__ -     auc = 0.79461083344013
06/26/2023 18:32:02 - INFO - __main__ -     f1 = 0.7288657979008406
06/26/2023 18:32:02 - INFO - __main__ -     mcc = 0.4589124526225757
06/26/2023 18:32:02 - INFO - __main__ -     precision = 0.7298280869709441
06/26/2023 18:32:02 - INFO - __main__ -     recall = 0.7290849673202614
06/26/2023 18:32:02 - INFO - __main__ -   {"eval_acc": 0.7290849673202614, "eval_f1": 0.7288657979008406, "eval_mcc": 0.4589124526225757, "eval_auc": 0.79461083344013, "eval_precision": 0.7298280869709441, "eval_recall": 0.7290849673202614, "learning_rate": 8.351488743645607e-05, "loss": 0.14400647396221758, "step": 1900}
06/26/2023 18:32:45 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:32:45 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:32:45 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:32:45 - INFO - __main__ -     Batch size = 48
06/26/2023 18:32:54 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:32:54 - INFO - __main__ -     acc = 0.7287581699346405
06/26/2023 18:32:54 - INFO - __main__ -     auc = 0.7896306975949422
06/26/2023 18:32:54 - INFO - __main__ -     f1 = 0.7273998856277337
06/26/2023 18:32:54 - INFO - __main__ -     mcc = 0.4621449776550079
06/26/2023 18:32:54 - INFO - __main__ -     precision = 0.7334102214062672
06/26/2023 18:32:54 - INFO - __main__ -     recall = 0.7287581699346406
06/26/2023 18:32:54 - INFO - __main__ -   {"eval_acc": 0.7287581699346405, "eval_f1": 0.7273998856277337, "eval_mcc": 0.4621449776550079, "eval_auc": 0.7896306975949422, "eval_precision": 0.7334102214062672, "eval_recall": 0.7287581699346406, "learning_rate": 8.206245461147423e-05, "loss": 0.15965495210140943, "step": 2000}
06/26/2023 18:33:39 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:33:39 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:33:39 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:33:39 - INFO - __main__ -     Batch size = 48
06/26/2023 18:33:48 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:33:48 - INFO - __main__ -     acc = 0.7303921568627451
06/26/2023 18:33:48 - INFO - __main__ -     auc = 0.7878345935324023
06/26/2023 18:33:48 - INFO - __main__ -     f1 = 0.7284467444212184
06/26/2023 18:33:48 - INFO - __main__ -     mcc = 0.46753181713015646
06/26/2023 18:33:48 - INFO - __main__ -     precision = 0.7371890638612836
06/26/2023 18:33:48 - INFO - __main__ -     recall = 0.7303921568627452
06/26/2023 18:33:48 - INFO - __main__ -   {"eval_acc": 0.7303921568627451, "eval_f1": 0.7284467444212184, "eval_mcc": 0.46753181713015646, "eval_auc": 0.7878345935324023, "eval_precision": 0.7371890638612836, "eval_recall": 0.7303921568627452, "learning_rate": 8.061002178649237e-05, "loss": 0.12385381233878434, "step": 2100}
06/26/2023 18:34:32 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:34:33 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:34:33 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:34:33 - INFO - __main__ -     Batch size = 48
06/26/2023 18:34:42 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:34:42 - INFO - __main__ -     acc = 0.7274509803921568
06/26/2023 18:34:42 - INFO - __main__ -     auc = 0.7972254261181597
06/26/2023 18:34:42 - INFO - __main__ -     f1 = 0.723711424137023
06/26/2023 18:34:42 - INFO - __main__ -     mcc = 0.46773982298004674
06/26/2023 18:34:42 - INFO - __main__ -     precision = 0.7404699922860276
06/26/2023 18:34:42 - INFO - __main__ -     recall = 0.7274509803921569
06/26/2023 18:34:42 - INFO - __main__ -   {"eval_acc": 0.7274509803921568, "eval_f1": 0.723711424137023, "eval_mcc": 0.46773982298004674, "eval_auc": 0.7972254261181597, "eval_precision": 0.7404699922860276, "eval_recall": 0.7274509803921569, "learning_rate": 7.915758896151053e-05, "loss": 0.12516169420443476, "step": 2200}
06/26/2023 18:35:25 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:35:26 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:35:26 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:35:26 - INFO - __main__ -     Batch size = 48
06/26/2023 18:35:35 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:35:35 - INFO - __main__ -     acc = 0.7333333333333333
06/26/2023 18:35:35 - INFO - __main__ -     auc = 0.7983608868383955
06/26/2023 18:35:35 - INFO - __main__ -     f1 = 0.732865914300044
06/26/2023 18:35:35 - INFO - __main__ -     mcc = 0.4683083936443417
06/26/2023 18:35:35 - INFO - __main__ -     precision = 0.7349779480975824
06/26/2023 18:35:35 - INFO - __main__ -     recall = 0.7333333333333334
06/26/2023 18:35:35 - INFO - __main__ -   {"eval_acc": 0.7333333333333333, "eval_f1": 0.732865914300044, "eval_mcc": 0.4683083936443417, "eval_auc": 0.7983608868383955, "eval_precision": 0.7349779480975824, "eval_recall": 0.7333333333333334, "learning_rate": 7.770515613652869e-05, "loss": 0.12451079961843789, "step": 2300}
06/26/2023 18:36:19 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:36:19 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:36:19 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:36:19 - INFO - __main__ -     Batch size = 48
06/26/2023 18:36:28 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:36:28 - INFO - __main__ -     acc = 0.734967320261438
06/26/2023 18:36:28 - INFO - __main__ -     auc = 0.7885403050108932
06/26/2023 18:36:28 - INFO - __main__ -     f1 = 0.7340160261758943
06/26/2023 18:36:28 - INFO - __main__ -     mcc = 0.4733325937073839
06/26/2023 18:36:28 - INFO - __main__ -     precision = 0.7383775582243475
06/26/2023 18:36:28 - INFO - __main__ -     recall = 0.734967320261438
06/26/2023 18:36:28 - INFO - __main__ -   {"eval_acc": 0.734967320261438, "eval_f1": 0.7340160261758943, "eval_mcc": 0.4733325937073839, "eval_auc": 0.7885403050108932, "eval_precision": 0.7383775582243475, "eval_recall": 0.734967320261438, "learning_rate": 7.625272331154685e-05, "loss": 0.10067809408763423, "step": 2400}
06/26/2023 18:37:12 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:37:13 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:37:13 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:37:13 - INFO - __main__ -     Batch size = 48
06/26/2023 18:37:22 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:37:22 - INFO - __main__ -     acc = 0.7330065359477124
06/26/2023 18:37:22 - INFO - __main__ -     auc = 0.7815271903968559
06/26/2023 18:37:22 - INFO - __main__ -     f1 = 0.7330042262956906
06/26/2023 18:37:22 - INFO - __main__ -     mcc = 0.4660211346145599
06/26/2023 18:37:22 - INFO - __main__ -     precision = 0.733014598736596
06/26/2023 18:37:22 - INFO - __main__ -     recall = 0.7330065359477125
06/26/2023 18:37:22 - INFO - __main__ -   {"eval_acc": 0.7330065359477124, "eval_f1": 0.7330042262956906, "eval_mcc": 0.4660211346145599, "eval_auc": 0.7815271903968559, "eval_precision": 0.733014598736596, "eval_recall": 0.7330065359477125, "learning_rate": 7.4800290486565e-05, "loss": 0.106157112903893, "step": 2500}
06/26/2023 18:38:05 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:38:05 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:38:05 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:38:05 - INFO - __main__ -     Batch size = 48
06/26/2023 18:38:14 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:38:14 - INFO - __main__ -     acc = 0.7300653594771241
06/26/2023 18:38:14 - INFO - __main__ -     auc = 0.7813791704045453
06/26/2023 18:38:14 - INFO - __main__ -     f1 = 0.7288123518293761
06/26/2023 18:38:14 - INFO - __main__ -     mcc = 0.46444259774228136
06/26/2023 18:38:14 - INFO - __main__ -     precision = 0.7343974415442656
06/26/2023 18:38:14 - INFO - __main__ -     recall = 0.7300653594771243
06/26/2023 18:38:14 - INFO - __main__ -   {"eval_acc": 0.7300653594771241, "eval_f1": 0.7288123518293761, "eval_mcc": 0.46444259774228136, "eval_auc": 0.7813791704045453, "eval_precision": 0.7343974415442656, "eval_recall": 0.7300653594771243, "learning_rate": 7.334785766158315e-05, "loss": 0.11096280304715038, "step": 2600}
06/26/2023 18:38:57 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:38:58 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:38:58 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:38:58 - INFO - __main__ -     Batch size = 48
06/26/2023 18:39:07 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:39:07 - INFO - __main__ -     acc = 0.7421568627450981
06/26/2023 18:39:07 - INFO - __main__ -     auc = 0.8016109188773549
06/26/2023 18:39:07 - INFO - __main__ -     f1 = 0.7410170845655369
06/26/2023 18:39:07 - INFO - __main__ -     mcc = 0.4886337553301824
06/26/2023 18:39:07 - INFO - __main__ -     precision = 0.7464961597014556
06/26/2023 18:39:07 - INFO - __main__ -     recall = 0.7421568627450981
06/26/2023 18:39:07 - INFO - __main__ -   {"eval_acc": 0.7421568627450981, "eval_f1": 0.7410170845655369, "eval_mcc": 0.4886337553301824, "eval_auc": 0.8016109188773549, "eval_precision": 0.7464961597014556, "eval_recall": 0.7421568627450981, "learning_rate": 7.189542483660131e-05, "loss": 0.10155869703739881, "step": 2700}
06/26/2023 18:39:50 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:39:51 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:39:51 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:39:51 - INFO - __main__ -     Batch size = 48
06/26/2023 18:40:00 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:40:00 - INFO - __main__ -     acc = 0.7238562091503268
06/26/2023 18:40:00 - INFO - __main__ -     auc = 0.7757932846341151
06/26/2023 18:40:00 - INFO - __main__ -     f1 = 0.7234923693325801
06/26/2023 18:40:00 - INFO - __main__ -     mcc = 0.4488953257774052
06/26/2023 18:40:00 - INFO - __main__ -     precision = 0.7250406793155826
06/26/2023 18:40:00 - INFO - __main__ -     recall = 0.7238562091503268
06/26/2023 18:40:00 - INFO - __main__ -   {"eval_acc": 0.7238562091503268, "eval_f1": 0.7234923693325801, "eval_mcc": 0.4488953257774052, "eval_auc": 0.7757932846341151, "eval_precision": 0.7250406793155826, "eval_recall": 0.7238562091503268, "learning_rate": 7.044299201161947e-05, "loss": 0.09318015199620276, "step": 2800}
06/26/2023 18:40:42 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:40:43 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:40:43 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:40:43 - INFO - __main__ -     Batch size = 48
06/26/2023 18:40:52 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:40:52 - INFO - __main__ -     acc = 0.7248366013071895
06/26/2023 18:40:52 - INFO - __main__ -     auc = 0.7661700627963604
06/26/2023 18:40:52 - INFO - __main__ -     f1 = 0.7248196736438997
06/26/2023 18:40:52 - INFO - __main__ -     mcc = 0.4497285359420909
06/26/2023 18:40:52 - INFO - __main__ -     precision = 0.7248919380393484
06/26/2023 18:40:52 - INFO - __main__ -     recall = 0.7248366013071895
06/26/2023 18:40:52 - INFO - __main__ -   {"eval_acc": 0.7248366013071895, "eval_f1": 0.7248196736438997, "eval_mcc": 0.4497285359420909, "eval_auc": 0.7661700627963604, "eval_precision": 0.7248919380393484, "eval_recall": 0.7248366013071895, "learning_rate": 6.899055918663763e-05, "loss": 0.07787913544103503, "step": 2900}
06/26/2023 18:41:35 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:41:35 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:41:35 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:41:35 - INFO - __main__ -     Batch size = 48
06/26/2023 18:41:44 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:41:44 - INFO - __main__ -     acc = 0.7163398692810458
06/26/2023 18:41:44 - INFO - __main__ -     auc = 0.7905912255969926
06/26/2023 18:41:44 - INFO - __main__ -     f1 = 0.7072917855941643
06/26/2023 18:41:44 - INFO - __main__ -     mcc = 0.46219674872204797
06/26/2023 18:41:44 - INFO - __main__ -     precision = 0.7468636909590067
06/26/2023 18:41:44 - INFO - __main__ -     recall = 0.7163398692810458
06/26/2023 18:41:44 - INFO - __main__ -   {"eval_acc": 0.7163398692810458, "eval_f1": 0.7072917855941643, "eval_mcc": 0.46219674872204797, "eval_auc": 0.7905912255969926, "eval_precision": 0.7468636909590067, "eval_recall": 0.7163398692810458, "learning_rate": 6.753812636165577e-05, "loss": 0.08555791038204916, "step": 3000}
06/26/2023 18:42:28 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:42:28 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:42:28 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:42:28 - INFO - __main__ -     Batch size = 48
06/26/2023 18:42:37 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:42:37 - INFO - __main__ -     acc = 0.7356209150326798
06/26/2023 18:42:37 - INFO - __main__ -     auc = 0.8018849587765389
06/26/2023 18:42:37 - INFO - __main__ -     f1 = 0.7328615168062517
06/26/2023 18:42:37 - INFO - __main__ -     mcc = 0.4812896447497871
06/26/2023 18:42:37 - INFO - __main__ -     precision = 0.7457758494309055
06/26/2023 18:42:37 - INFO - __main__ -     recall = 0.7356209150326798
06/26/2023 18:42:37 - INFO - __main__ -   {"eval_acc": 0.7356209150326798, "eval_f1": 0.7328615168062517, "eval_mcc": 0.4812896447497871, "eval_auc": 0.8018849587765389, "eval_precision": 0.7457758494309055, "eval_recall": 0.7356209150326798, "learning_rate": 6.608569353667393e-05, "loss": 0.07529008256038651, "step": 3100}
06/26/2023 18:43:20 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:43:21 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:43:21 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:43:21 - INFO - __main__ -     Batch size = 48
06/26/2023 18:43:30 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:43:30 - INFO - __main__ -     acc = 0.734967320261438
06/26/2023 18:43:30 - INFO - __main__ -     auc = 0.8026130975265924
06/26/2023 18:43:30 - INFO - __main__ -     f1 = 0.7317910394045594
06/26/2023 18:43:30 - INFO - __main__ -     mcc = 0.481476824703733
06/26/2023 18:43:30 - INFO - __main__ -     precision = 0.7466512497023556
06/26/2023 18:43:30 - INFO - __main__ -     recall = 0.734967320261438
06/26/2023 18:43:30 - INFO - __main__ -   {"eval_acc": 0.734967320261438, "eval_f1": 0.7317910394045594, "eval_mcc": 0.481476824703733, "eval_auc": 0.8026130975265924, "eval_precision": 0.7466512497023556, "eval_recall": 0.734967320261438, "learning_rate": 6.463326071169209e-05, "loss": 0.07881640002131463, "step": 3200}
06/26/2023 18:44:12 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:44:13 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:44:13 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:44:13 - INFO - __main__ -     Batch size = 48
06/26/2023 18:44:22 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:44:22 - INFO - __main__ -     acc = 0.7428104575163399
06/26/2023 18:44:22 - INFO - __main__ -     auc = 0.8014315007048572
06/26/2023 18:44:22 - INFO - __main__ -     f1 = 0.7424837080754886
06/26/2023 18:44:22 - INFO - __main__ -     mcc = 0.48685798579528883
06/26/2023 18:44:22 - INFO - __main__ -     precision = 0.7440491039360349
06/26/2023 18:44:22 - INFO - __main__ -     recall = 0.7428104575163399
06/26/2023 18:44:22 - INFO - __main__ -   {"eval_acc": 0.7428104575163399, "eval_f1": 0.7424837080754886, "eval_mcc": 0.48685798579528883, "eval_auc": 0.8014315007048572, "eval_precision": 0.7440491039360349, "eval_recall": 0.7428104575163399, "learning_rate": 6.318082788671025e-05, "loss": 0.07759250030154362, "step": 3300}
06/26/2023 18:45:05 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:45:06 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:45:06 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:45:06 - INFO - __main__ -     Batch size = 48
06/26/2023 18:45:15 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:45:15 - INFO - __main__ -     acc = 0.7330065359477124
06/26/2023 18:45:15 - INFO - __main__ -     auc = 0.7946665812294416
06/26/2023 18:45:15 - INFO - __main__ -     f1 = 0.7296492096790432
06/26/2023 18:45:15 - INFO - __main__ -     mcc = 0.47803721634070295
06/26/2023 18:45:15 - INFO - __main__ -     precision = 0.7451858048501789
06/26/2023 18:45:15 - INFO - __main__ -     recall = 0.7330065359477125
06/26/2023 18:45:15 - INFO - __main__ -   {"eval_acc": 0.7330065359477124, "eval_f1": 0.7296492096790432, "eval_mcc": 0.47803721634070295, "eval_auc": 0.7946665812294416, "eval_precision": 0.7451858048501789, "eval_recall": 0.7330065359477125, "learning_rate": 6.17283950617284e-05, "loss": 0.06348137158085593, "step": 3400}
06/26/2023 18:45:57 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:45:58 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:45:58 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:45:58 - INFO - __main__ -     Batch size = 48
06/26/2023 18:46:07 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:46:07 - INFO - __main__ -     acc = 0.7395424836601308
06/26/2023 18:46:07 - INFO - __main__ -     auc = 0.7917653466615405
06/26/2023 18:46:07 - INFO - __main__ -     f1 = 0.7395391178855637
06/26/2023 18:46:07 - INFO - __main__ -     mcc = 0.47909734963655987
06/26/2023 18:46:07 - INFO - __main__ -     precision = 0.7395548661364444
06/26/2023 18:46:07 - INFO - __main__ -     recall = 0.7395424836601308
06/26/2023 18:46:07 - INFO - __main__ -   {"eval_acc": 0.7395424836601308, "eval_f1": 0.7395391178855637, "eval_mcc": 0.47909734963655987, "eval_auc": 0.7917653466615405, "eval_precision": 0.7395548661364444, "eval_recall": 0.7395424836601308, "learning_rate": 6.0275962236746555e-05, "loss": 0.0635373159556184, "step": 3500}
06/26/2023 18:46:50 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:46:51 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:46:51 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:46:51 - INFO - __main__ -     Batch size = 48
06/26/2023 18:47:00 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:47:00 - INFO - __main__ -     acc = 0.7281045751633987
06/26/2023 18:47:00 - INFO - __main__ -     auc = 0.781114955786236
06/26/2023 18:47:00 - INFO - __main__ -     f1 = 0.7269614031836485
06/26/2023 18:47:00 - INFO - __main__ -     mcc = 0.4600779729411419
06/26/2023 18:47:00 - INFO - __main__ -     precision = 0.7319898023023023
06/26/2023 18:47:00 - INFO - __main__ -     recall = 0.7281045751633987
06/26/2023 18:47:00 - INFO - __main__ -   {"eval_acc": 0.7281045751633987, "eval_f1": 0.7269614031836485, "eval_mcc": 0.4600779729411419, "eval_auc": 0.781114955786236, "eval_precision": 0.7319898023023023, "eval_recall": 0.7281045751633987, "learning_rate": 5.882352941176471e-05, "loss": 0.05499861257208977, "step": 3600}
06/26/2023 18:47:43 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:47:44 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:47:44 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:47:44 - INFO - __main__ -     Batch size = 48
06/26/2023 18:47:53 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:47:53 - INFO - __main__ -     acc = 0.7405228758169935
06/26/2023 18:47:53 - INFO - __main__ -     auc = 0.7850762527233115
06/26/2023 18:47:53 - INFO - __main__ -     f1 = 0.7403177613485127
06/26/2023 18:47:53 - INFO - __main__ -     mcc = 0.48180748157536313
06/26/2023 18:47:53 - INFO - __main__ -     precision = 0.7412852088532953
06/26/2023 18:47:53 - INFO - __main__ -     recall = 0.7405228758169935
06/26/2023 18:47:53 - INFO - __main__ -   {"eval_acc": 0.7405228758169935, "eval_f1": 0.7403177613485127, "eval_mcc": 0.48180748157536313, "eval_auc": 0.7850762527233115, "eval_precision": 0.7412852088532953, "eval_recall": 0.7405228758169935, "learning_rate": 5.7371096586782866e-05, "loss": 0.05577956289518624, "step": 3700}
06/26/2023 18:48:36 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:48:37 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:48:37 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:48:37 - INFO - __main__ -     Batch size = 48
06/26/2023 18:48:46 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:48:46 - INFO - __main__ -     acc = 0.7372549019607844
06/26/2023 18:48:46 - INFO - __main__ -     auc = 0.8031248665043359
06/26/2023 18:48:46 - INFO - __main__ -     f1 = 0.7335672514619883
06/26/2023 18:48:46 - INFO - __main__ -     mcc = 0.488216876352834
06/26/2023 18:48:46 - INFO - __main__ -     precision = 0.7511599511599512
06/26/2023 18:48:46 - INFO - __main__ -     recall = 0.7372549019607844
06/26/2023 18:48:46 - INFO - __main__ -   {"eval_acc": 0.7372549019607844, "eval_f1": 0.7335672514619883, "eval_mcc": 0.488216876352834, "eval_auc": 0.8031248665043359, "eval_precision": 0.7511599511599512, "eval_recall": 0.7372549019607844, "learning_rate": 5.591866376180102e-05, "loss": 0.058680728155886756, "step": 3800}
06/26/2023 18:49:29 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:49:29 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:49:29 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:49:29 - INFO - __main__ -     Batch size = 48
06/26/2023 18:49:38 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:49:38 - INFO - __main__ -     acc = 0.7388888888888889
06/26/2023 18:49:38 - INFO - __main__ -     auc = 0.7944724251356315
06/26/2023 18:49:38 - INFO - __main__ -     f1 = 0.7374947537924887
06/26/2023 18:49:38 - INFO - __main__ -     mcc = 0.4829349374271193
06/26/2023 18:49:38 - INFO - __main__ -     precision = 0.7440738818708861
06/26/2023 18:49:38 - INFO - __main__ -     recall = 0.7388888888888889
06/26/2023 18:49:38 - INFO - __main__ -   {"eval_acc": 0.7388888888888889, "eval_f1": 0.7374947537924887, "eval_mcc": 0.4829349374271193, "eval_auc": 0.7944724251356315, "eval_precision": 0.7440738818708861, "eval_recall": 0.7388888888888889, "learning_rate": 5.446623093681917e-05, "loss": 0.049953596325358375, "step": 3900}
06/26/2023 18:50:21 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:50:21 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:50:21 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:50:21 - INFO - __main__ -     Batch size = 48
06/26/2023 18:50:31 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:50:31 - INFO - __main__ -     acc = 0.746078431372549
06/26/2023 18:50:31 - INFO - __main__ -     auc = 0.803197488145585
06/26/2023 18:50:31 - INFO - __main__ -     f1 = 0.7455381524208936
06/26/2023 18:50:31 - INFO - __main__ -     mcc = 0.4942601861311062
06/26/2023 18:50:31 - INFO - __main__ -     precision = 0.7481862492293256
06/26/2023 18:50:31 - INFO - __main__ -     recall = 0.746078431372549
06/26/2023 18:50:31 - INFO - __main__ -   {"eval_acc": 0.746078431372549, "eval_f1": 0.7455381524208936, "eval_mcc": 0.4942601861311062, "eval_auc": 0.803197488145585, "eval_precision": 0.7481862492293256, "eval_recall": 0.746078431372549, "learning_rate": 5.301379811183733e-05, "loss": 0.04551006464636884, "step": 4000}
06/26/2023 18:50:31 - INFO - transformers.configuration_utils -   Configuration saved in /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold2/checkpoint-4000/config.json
06/26/2023 18:50:31 - INFO - transformers.modeling_utils -   Model weights saved in /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold2/checkpoint-4000/pytorch_model.bin
06/26/2023 18:50:31 - INFO - __main__ -   Saving model checkpoint to /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold2/checkpoint-4000
06/26/2023 18:50:32 - INFO - __main__ -   Saving optimizer and scheduler states to /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold2/checkpoint-4000
06/26/2023 18:51:15 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:51:15 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:51:15 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:51:15 - INFO - __main__ -     Batch size = 48
06/26/2023 18:51:24 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:51:24 - INFO - __main__ -     acc = 0.7359477124183007
06/26/2023 18:51:24 - INFO - __main__ -     auc = 0.7907826049809903
06/26/2023 18:51:24 - INFO - __main__ -     f1 = 0.7340865797439122
06/26/2023 18:51:24 - INFO - __main__ -     mcc = 0.47864304895077575
06/26/2023 18:51:24 - INFO - __main__ -     precision = 0.74274357860984
06/26/2023 18:51:24 - INFO - __main__ -     recall = 0.7359477124183007
06/26/2023 18:51:24 - INFO - __main__ -   {"eval_acc": 0.7359477124183007, "eval_f1": 0.7340865797439122, "eval_mcc": 0.47864304895077575, "eval_auc": 0.7907826049809903, "eval_precision": 0.74274357860984, "eval_recall": 0.7359477124183007, "learning_rate": 5.156136528685549e-05, "loss": 0.04927860568684991, "step": 4100}
06/26/2023 18:52:07 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:52:07 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:52:07 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:52:07 - INFO - __main__ -     Batch size = 48
06/26/2023 18:52:16 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:52:16 - INFO - __main__ -     acc = 0.7421568627450981
06/26/2023 18:52:16 - INFO - __main__ -     auc = 0.78859562561408
06/26/2023 18:52:16 - INFO - __main__ -     f1 = 0.7418171353886458
06/26/2023 18:52:16 - INFO - __main__ -     mcc = 0.4855933378117624
06/26/2023 18:52:16 - INFO - __main__ -     precision = 0.7434381655078054
06/26/2023 18:52:16 - INFO - __main__ -     recall = 0.7421568627450981
06/26/2023 18:52:16 - INFO - __main__ -   {"eval_acc": 0.7421568627450981, "eval_f1": 0.7418171353886458, "eval_mcc": 0.4855933378117624, "eval_auc": 0.78859562561408, "eval_precision": 0.7434381655078054, "eval_recall": 0.7421568627450981, "learning_rate": 5.0108932461873634e-05, "loss": 0.03324341566389194, "step": 4200}
06/26/2023 18:52:59 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:53:00 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:53:00 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:53:00 - INFO - __main__ -     Batch size = 48
06/26/2023 18:53:09 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:53:09 - INFO - __main__ -     acc = 0.7388888888888889
06/26/2023 18:53:09 - INFO - __main__ -     auc = 0.8008293818616772
06/26/2023 18:53:09 - INFO - __main__ -     f1 = 0.7374694982000918
06/26/2023 18:53:09 - INFO - __main__ -     mcc = 0.4830293949466538
06/26/2023 18:53:09 - INFO - __main__ -     precision = 0.7441693683072994
06/26/2023 18:53:09 - INFO - __main__ -     recall = 0.7388888888888889
06/26/2023 18:53:09 - INFO - __main__ -   {"eval_acc": 0.7388888888888889, "eval_f1": 0.7374694982000918, "eval_mcc": 0.4830293949466538, "eval_auc": 0.8008293818616772, "eval_precision": 0.7441693683072994, "eval_recall": 0.7388888888888889, "learning_rate": 4.865649963689179e-05, "loss": 0.04726349440577906, "step": 4300}
06/26/2023 18:53:51 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:53:52 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:53:52 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:53:52 - INFO - __main__ -     Batch size = 48
06/26/2023 18:54:01 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:54:01 - INFO - __main__ -     acc = 0.738562091503268
06/26/2023 18:54:01 - INFO - __main__ -     auc = 0.7932534495279594
06/26/2023 18:54:01 - INFO - __main__ -     f1 = 0.7375502546234254
06/26/2023 18:54:01 - INFO - __main__ -     mcc = 0.48084625447671964
06/26/2023 18:54:01 - INFO - __main__ -     precision = 0.742298681013537
06/26/2023 18:54:01 - INFO - __main__ -     recall = 0.738562091503268
06/26/2023 18:54:01 - INFO - __main__ -   {"eval_acc": 0.738562091503268, "eval_f1": 0.7375502546234254, "eval_mcc": 0.48084625447671964, "eval_auc": 0.7932534495279594, "eval_precision": 0.742298681013537, "eval_recall": 0.738562091503268, "learning_rate": 4.720406681190995e-05, "loss": 0.035971046071499584, "step": 4400}
06/26/2023 18:54:43 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:54:44 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:54:44 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:54:44 - INFO - __main__ -     Batch size = 48
06/26/2023 18:54:53 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:54:53 - INFO - __main__ -     acc = 0.7437908496732026
06/26/2023 18:54:53 - INFO - __main__ -     auc = 0.8107629544192405
06/26/2023 18:54:53 - INFO - __main__ -     f1 = 0.7424105248510107
06/26/2023 18:54:53 - INFO - __main__ -     mcc = 0.49289276629719625
06/26/2023 18:54:53 - INFO - __main__ -     precision = 0.7491308424760033
06/26/2023 18:54:53 - INFO - __main__ -     recall = 0.7437908496732026
06/26/2023 18:54:53 - INFO - __main__ -   {"eval_acc": 0.7437908496732026, "eval_f1": 0.7424105248510107, "eval_mcc": 0.49289276629719625, "eval_auc": 0.8107629544192405, "eval_precision": 0.7491308424760033, "eval_recall": 0.7437908496732026, "learning_rate": 4.5751633986928104e-05, "loss": 0.02945260488515487, "step": 4500}
06/26/2023 18:55:35 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:55:36 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:55:36 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:55:36 - INFO - __main__ -     Batch size = 48
06/26/2023 18:55:45 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:55:45 - INFO - __main__ -     acc = 0.7444444444444445
06/26/2023 18:55:45 - INFO - __main__ -     auc = 0.8065756760220428
06/26/2023 18:55:45 - INFO - __main__ -     f1 = 0.7430428098762483
06/26/2023 18:55:45 - INFO - __main__ -     mcc = 0.49431130887447233
06/26/2023 18:55:45 - INFO - __main__ -     precision = 0.749896935310312
06/26/2023 18:55:45 - INFO - __main__ -     recall = 0.7444444444444445
06/26/2023 18:55:45 - INFO - __main__ -   {"eval_acc": 0.7444444444444445, "eval_f1": 0.7430428098762483, "eval_mcc": 0.49431130887447233, "eval_auc": 0.8065756760220428, "eval_precision": 0.749896935310312, "eval_recall": 0.7444444444444445, "learning_rate": 4.429920116194626e-05, "loss": 0.0406821352528641, "step": 4600}
06/26/2023 18:56:27 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:56:28 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:56:28 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:56:28 - INFO - __main__ -     Batch size = 48
06/26/2023 18:56:37 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:56:37 - INFO - __main__ -     acc = 0.7454248366013072
06/26/2023 18:56:37 - INFO - __main__ -     auc = 0.8084093724635824
06/26/2023 18:56:37 - INFO - __main__ -     f1 = 0.7441141718780644
06/26/2023 18:56:37 - INFO - __main__ -     mcc = 0.49595661411420183
06/26/2023 18:56:37 - INFO - __main__ -     precision = 0.750558344552559
06/26/2023 18:56:37 - INFO - __main__ -     recall = 0.7454248366013072
06/26/2023 18:56:37 - INFO - __main__ -   {"eval_acc": 0.7454248366013072, "eval_f1": 0.7441141718780644, "eval_mcc": 0.49595661411420183, "eval_auc": 0.8084093724635824, "eval_precision": 0.750558344552559, "eval_recall": 0.7454248366013072, "learning_rate": 4.2846768336964415e-05, "loss": 0.03059234900138108, "step": 4700}
06/26/2023 18:57:20 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:57:20 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:57:20 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:57:20 - INFO - __main__ -     Batch size = 48
06/26/2023 18:57:29 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:57:29 - INFO - __main__ -     acc = 0.7434640522875817
06/26/2023 18:57:29 - INFO - __main__ -     auc = 0.7990567730360119
06/26/2023 18:57:29 - INFO - __main__ -     f1 = 0.7423074963190234
06/26/2023 18:57:29 - INFO - __main__ -     mcc = 0.49135863660984297
06/26/2023 18:57:29 - INFO - __main__ -     precision = 0.747914740905878
06/26/2023 18:57:29 - INFO - __main__ -     recall = 0.7434640522875817
06/26/2023 18:57:29 - INFO - __main__ -   {"eval_acc": 0.7434640522875817, "eval_f1": 0.7423074963190234, "eval_mcc": 0.49135863660984297, "eval_auc": 0.7990567730360119, "eval_precision": 0.747914740905878, "eval_recall": 0.7434640522875817, "learning_rate": 4.1394335511982573e-05, "loss": 0.022404116365360095, "step": 4800}
06/26/2023 18:58:11 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:58:12 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:58:12 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:58:12 - INFO - __main__ -     Batch size = 48
06/26/2023 18:58:21 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:58:21 - INFO - __main__ -     acc = 0.7486928104575163
06/26/2023 18:58:21 - INFO - __main__ -     auc = 0.7983766927250204
06/26/2023 18:58:21 - INFO - __main__ -     f1 = 0.7470979523891051
06/26/2023 18:58:21 - INFO - __main__ -     mcc = 0.5037801083989171
06/26/2023 18:58:21 - INFO - __main__ -     precision = 0.7551284023365241
06/26/2023 18:58:21 - INFO - __main__ -     recall = 0.7486928104575163
06/26/2023 18:58:21 - INFO - __main__ -   {"eval_acc": 0.7486928104575163, "eval_f1": 0.7470979523891051, "eval_mcc": 0.5037801083989171, "eval_auc": 0.7983766927250204, "eval_precision": 0.7551284023365241, "eval_recall": 0.7486928104575163, "learning_rate": 3.9941902687000726e-05, "loss": 0.022081609022425255, "step": 4900}
06/26/2023 18:59:05 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:59:05 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:59:05 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:59:05 - INFO - __main__ -     Batch size = 48
06/26/2023 18:59:14 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 18:59:14 - INFO - __main__ -     acc = 0.75
06/26/2023 18:59:14 - INFO - __main__ -     auc = 0.8000147379213125
06/26/2023 18:59:14 - INFO - __main__ -     f1 = 0.7494058438141866
06/26/2023 18:59:14 - INFO - __main__ -     mcc = 0.5023879889709987
06/26/2023 18:59:14 - INFO - __main__ -     precision = 0.7523936914623244
06/26/2023 18:59:14 - INFO - __main__ -     recall = 0.75
06/26/2023 18:59:14 - INFO - __main__ -   {"eval_acc": 0.75, "eval_f1": 0.7494058438141866, "eval_mcc": 0.5023879889709987, "eval_auc": 0.8000147379213125, "eval_precision": 0.7523936914623244, "eval_recall": 0.75, "learning_rate": 3.8489469862018884e-05, "loss": 0.03170557040983112, "step": 5000}
06/26/2023 18:59:58 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 18:59:59 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 18:59:59 - INFO - __main__ -     Num examples = 3060
06/26/2023 18:59:59 - INFO - __main__ -     Batch size = 48
06/26/2023 19:00:08 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:00:08 - INFO - __main__ -     acc = 0.7441176470588236
06/26/2023 19:00:08 - INFO - __main__ -     auc = 0.8010933828869239
06/26/2023 19:00:08 - INFO - __main__ -     f1 = 0.7437430153078464
06/26/2023 19:00:08 - INFO - __main__ -     mcc = 0.4896691248867147
06/26/2023 19:00:08 - INFO - __main__ -     precision = 0.7455535832376179
06/26/2023 19:00:08 - INFO - __main__ -     recall = 0.7441176470588236
06/26/2023 19:00:08 - INFO - __main__ -   {"eval_acc": 0.7441176470588236, "eval_f1": 0.7437430153078464, "eval_mcc": 0.4896691248867147, "eval_auc": 0.8010933828869239, "eval_precision": 0.7455535832376179, "eval_recall": 0.7441176470588236, "learning_rate": 3.7037037037037037e-05, "loss": 0.028560911920212675, "step": 5100}
06/26/2023 19:00:52 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:00:52 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:00:52 - INFO - __main__ -     Num examples = 3060
06/26/2023 19:00:52 - INFO - __main__ -     Batch size = 48
06/26/2023 19:01:01 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:01:01 - INFO - __main__ -     acc = 0.7486928104575163
06/26/2023 19:01:01 - INFO - __main__ -     auc = 0.8055350506215558
06/26/2023 19:01:01 - INFO - __main__ -     f1 = 0.7484400307840624
06/26/2023 19:01:01 - INFO - __main__ -     mcc = 0.49838823881930383
06/26/2023 19:01:01 - INFO - __main__ -     precision = 0.7496964388882479
06/26/2023 19:01:01 - INFO - __main__ -     recall = 0.7486928104575163
06/26/2023 19:01:01 - INFO - __main__ -   {"eval_acc": 0.7486928104575163, "eval_f1": 0.7484400307840624, "eval_mcc": 0.49838823881930383, "eval_auc": 0.8055350506215558, "eval_precision": 0.7496964388882479, "eval_recall": 0.7486928104575163, "learning_rate": 3.5584604212055195e-05, "loss": 0.016957016777887475, "step": 5200}
06/26/2023 19:01:45 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:01:46 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:01:46 - INFO - __main__ -     Num examples = 3060
06/26/2023 19:01:46 - INFO - __main__ -     Batch size = 48
06/26/2023 19:01:55 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:01:55 - INFO - __main__ -     acc = 0.7392156862745098
06/26/2023 19:01:55 - INFO - __main__ -     auc = 0.8042902302533214
06/26/2023 19:01:55 - INFO - __main__ -     f1 = 0.7379097695553392
06/26/2023 19:01:55 - INFO - __main__ -     mcc = 0.4832716052049511
06/26/2023 19:01:55 - INFO - __main__ -     precision = 0.744080402956268
06/26/2023 19:01:55 - INFO - __main__ -     recall = 0.7392156862745098
06/26/2023 19:01:55 - INFO - __main__ -   {"eval_acc": 0.7392156862745098, "eval_f1": 0.7379097695553392, "eval_mcc": 0.4832716052049511, "eval_auc": 0.8042902302533214, "eval_precision": 0.744080402956268, "eval_recall": 0.7392156862745098, "learning_rate": 3.413217138707335e-05, "loss": 0.023042828161051146, "step": 5300}
06/26/2023 19:02:39 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:02:39 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:02:39 - INFO - __main__ -     Num examples = 3060
06/26/2023 19:02:39 - INFO - __main__ -     Batch size = 48
06/26/2023 19:02:48 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:02:48 - INFO - __main__ -     acc = 0.7428104575163399
06/26/2023 19:02:48 - INFO - __main__ -     auc = 0.8109175957964886
06/26/2023 19:02:48 - INFO - __main__ -     f1 = 0.7415582421169855
06/26/2023 19:02:48 - INFO - __main__ -     mcc = 0.49039635410839066
06/26/2023 19:02:48 - INFO - __main__ -     precision = 0.747609376654029
06/26/2023 19:02:48 - INFO - __main__ -     recall = 0.7428104575163399
06/26/2023 19:02:48 - INFO - __main__ -   {"eval_acc": 0.7428104575163399, "eval_f1": 0.7415582421169855, "eval_mcc": 0.49039635410839066, "eval_auc": 0.8109175957964886, "eval_precision": 0.747609376654029, "eval_recall": 0.7428104575163399, "learning_rate": 3.2679738562091506e-05, "loss": 0.013525377164551173, "step": 5400}
06/26/2023 19:03:32 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:03:33 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:03:33 - INFO - __main__ -     Num examples = 3060
06/26/2023 19:03:33 - INFO - __main__ -     Batch size = 48
06/26/2023 19:03:42 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:03:42 - INFO - __main__ -     acc = 0.7382352941176471
06/26/2023 19:03:42 - INFO - __main__ -     auc = 0.8113041992396086
06/26/2023 19:03:42 - INFO - __main__ -     f1 = 0.7351361929639588
06/26/2023 19:03:42 - INFO - __main__ -     mcc = 0.4880280116636668
06/26/2023 19:03:42 - INFO - __main__ -     precision = 0.7499328878310288
06/26/2023 19:03:42 - INFO - __main__ -     recall = 0.7382352941176471
06/26/2023 19:03:42 - INFO - __main__ -   {"eval_acc": 0.7382352941176471, "eval_f1": 0.7351361929639588, "eval_mcc": 0.4880280116636668, "eval_auc": 0.8113041992396086, "eval_precision": 0.7499328878310288, "eval_recall": 0.7382352941176471, "learning_rate": 3.122730573710966e-05, "loss": 0.01470014947153686, "step": 5500}
06/26/2023 19:04:25 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:04:25 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:04:25 - INFO - __main__ -     Num examples = 3060
06/26/2023 19:04:25 - INFO - __main__ -     Batch size = 48
06/26/2023 19:04:34 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:04:34 - INFO - __main__ -     acc = 0.7421568627450981
06/26/2023 19:04:34 - INFO - __main__ -     auc = 0.8109421589986757
06/26/2023 19:04:34 - INFO - __main__ -     f1 = 0.7405475180911456
06/26/2023 19:04:34 - INFO - __main__ -     mcc = 0.4904361434662295
06/26/2023 19:04:34 - INFO - __main__ -     precision = 0.7483179787797456
06/26/2023 19:04:34 - INFO - __main__ -     recall = 0.7421568627450981
06/26/2023 19:04:34 - INFO - __main__ -   {"eval_acc": 0.7421568627450981, "eval_f1": 0.7405475180911456, "eval_mcc": 0.4904361434662295, "eval_auc": 0.8109421589986757, "eval_precision": 0.7483179787797456, "eval_recall": 0.7421568627450981, "learning_rate": 2.9774872912127817e-05, "loss": 0.019619408373073383, "step": 5600}
06/26/2023 19:05:18 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:05:18 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:05:18 - INFO - __main__ -     Num examples = 3060
06/26/2023 19:05:18 - INFO - __main__ -     Batch size = 48
06/26/2023 19:05:27 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:05:27 - INFO - __main__ -     acc = 0.7480392156862745
06/26/2023 19:05:27 - INFO - __main__ -     auc = 0.8097201930881286
06/26/2023 19:05:27 - INFO - __main__ -     f1 = 0.7476575867279309
06/26/2023 19:05:27 - INFO - __main__ -     mcc = 0.4975857577705269
06/26/2023 19:05:27 - INFO - __main__ -     precision = 0.7495488320778566
06/26/2023 19:05:27 - INFO - __main__ -     recall = 0.7480392156862745
06/26/2023 19:05:27 - INFO - __main__ -   {"eval_acc": 0.7480392156862745, "eval_f1": 0.7476575867279309, "eval_mcc": 0.4975857577705269, "eval_auc": 0.8097201930881286, "eval_precision": 0.7495488320778566, "eval_recall": 0.7480392156862745, "learning_rate": 2.832244008714597e-05, "loss": 0.00918896328046685, "step": 5700}
06/26/2023 19:06:11 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:06:11 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:06:11 - INFO - __main__ -     Num examples = 3060
06/26/2023 19:06:11 - INFO - __main__ -     Batch size = 48
06/26/2023 19:06:21 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:06:21 - INFO - __main__ -     acc = 0.7486928104575163
06/26/2023 19:06:21 - INFO - __main__ -     auc = 0.8150993207740613
06/26/2023 19:06:21 - INFO - __main__ -     f1 = 0.7465247792564688
06/26/2023 19:06:21 - INFO - __main__ -     mcc = 0.5061188679653527
06/26/2023 19:06:21 - INFO - __main__ -     precision = 0.7575027280033582
06/26/2023 19:06:21 - INFO - __main__ -     recall = 0.7486928104575163
06/26/2023 19:06:21 - INFO - __main__ -   {"eval_acc": 0.7486928104575163, "eval_f1": 0.7465247792564688, "eval_mcc": 0.5061188679653527, "eval_auc": 0.8150993207740613, "eval_precision": 0.7575027280033582, "eval_recall": 0.7486928104575163, "learning_rate": 2.6870007262164125e-05, "loss": 0.01231138612703944, "step": 5800}
06/26/2023 19:07:04 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:07:05 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:07:05 - INFO - __main__ -     Num examples = 3060
06/26/2023 19:07:05 - INFO - __main__ -     Batch size = 48
06/26/2023 19:07:14 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:07:14 - INFO - __main__ -     acc = 0.7441176470588236
06/26/2023 19:07:14 - INFO - __main__ -     auc = 0.8123584945960954
06/26/2023 19:07:14 - INFO - __main__ -     f1 = 0.7416842050108723
06/26/2023 19:07:14 - INFO - __main__ -     mcc = 0.4977024628642266
06/26/2023 19:07:14 - INFO - __main__ -     precision = 0.7536766027830715
06/26/2023 19:07:14 - INFO - __main__ -     recall = 0.7441176470588236
06/26/2023 19:07:14 - INFO - __main__ -   {"eval_acc": 0.7441176470588236, "eval_f1": 0.7416842050108723, "eval_mcc": 0.4977024628642266, "eval_auc": 0.8123584945960954, "eval_precision": 0.7536766027830715, "eval_recall": 0.7441176470588236, "learning_rate": 2.5417574437182277e-05, "loss": 0.012393266109647812, "step": 5900}
06/26/2023 19:07:57 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:07:58 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:07:58 - INFO - __main__ -     Num examples = 3060
06/26/2023 19:07:58 - INFO - __main__ -     Batch size = 48
06/26/2023 19:08:07 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:08:07 - INFO - __main__ -     acc = 0.7477124183006536
06/26/2023 19:08:07 - INFO - __main__ -     auc = 0.8130157204493998
06/26/2023 19:08:07 - INFO - __main__ -     f1 = 0.7468750482179503
06/26/2023 19:08:07 - INFO - __main__ -     mcc = 0.4987355891553804
06/26/2023 19:08:07 - INFO - __main__ -     precision = 0.7510342331609179
06/26/2023 19:08:07 - INFO - __main__ -     recall = 0.7477124183006536
06/26/2023 19:08:07 - INFO - __main__ -   {"eval_acc": 0.7477124183006536, "eval_f1": 0.7468750482179503, "eval_mcc": 0.4987355891553804, "eval_auc": 0.8130157204493998, "eval_precision": 0.7510342331609179, "eval_recall": 0.7477124183006536, "learning_rate": 2.3965141612200436e-05, "loss": 0.010998602750551072, "step": 6000}
06/26/2023 19:08:49 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:08:50 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:08:50 - INFO - __main__ -     Num examples = 3060
06/26/2023 19:08:50 - INFO - __main__ -     Batch size = 48
06/26/2023 19:08:59 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:08:59 - INFO - __main__ -     acc = 0.7467320261437909
06/26/2023 19:08:59 - INFO - __main__ -     auc = 0.811435345379982
06/26/2023 19:08:59 - INFO - __main__ -     f1 = 0.746554438856138
06/26/2023 19:08:59 - INFO - __main__ -     mcc = 0.494157042013885
06/26/2023 19:08:59 - INFO - __main__ -     precision = 0.7474255024655801
06/26/2023 19:08:59 - INFO - __main__ -     recall = 0.7467320261437909
06/26/2023 19:08:59 - INFO - __main__ -   {"eval_acc": 0.7467320261437909, "eval_f1": 0.746554438856138, "eval_mcc": 0.494157042013885, "eval_auc": 0.811435345379982, "eval_precision": 0.7474255024655801, "eval_recall": 0.7467320261437909, "learning_rate": 2.251270878721859e-05, "loss": 0.01481345193398738, "step": 6100}
06/26/2023 19:09:41 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:09:42 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:09:42 - INFO - __main__ -     Num examples = 3060
06/26/2023 19:09:42 - INFO - __main__ -     Batch size = 48
06/26/2023 19:09:51 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:09:51 - INFO - __main__ -     acc = 0.7447712418300654
06/26/2023 19:09:51 - INFO - __main__ -     auc = 0.813313896364646
06/26/2023 19:09:51 - INFO - __main__ -     f1 = 0.7440627376460468
06/26/2023 19:09:51 - INFO - __main__ -     mcc = 0.4922755769341383
06/26/2023 19:09:51 - INFO - __main__ -     precision = 0.7475119644713839
06/26/2023 19:09:51 - INFO - __main__ -     recall = 0.7447712418300654
06/26/2023 19:09:51 - INFO - __main__ -   {"eval_acc": 0.7447712418300654, "eval_f1": 0.7440627376460468, "eval_mcc": 0.4922755769341383, "eval_auc": 0.813313896364646, "eval_precision": 0.7475119644713839, "eval_recall": 0.7447712418300654, "learning_rate": 2.1060275962236747e-05, "loss": 0.008296213261310185, "step": 6200}
06/26/2023 19:10:33 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:10:34 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:10:34 - INFO - __main__ -     Num examples = 3060
06/26/2023 19:10:34 - INFO - __main__ -     Batch size = 48
06/26/2023 19:10:43 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:10:43 - INFO - __main__ -     acc = 0.7434640522875817
06/26/2023 19:10:43 - INFO - __main__ -     auc = 0.8131964201802726
06/26/2023 19:10:43 - INFO - __main__ -     f1 = 0.7412192461519815
06/26/2023 19:10:43 - INFO - __main__ -     mcc = 0.4956022648019352
06/26/2023 19:10:43 - INFO - __main__ -     precision = 0.7522154734641043
06/26/2023 19:10:43 - INFO - __main__ -     recall = 0.7434640522875817
06/26/2023 19:10:43 - INFO - __main__ -   {"eval_acc": 0.7434640522875817, "eval_f1": 0.7412192461519815, "eval_mcc": 0.4956022648019352, "eval_auc": 0.8131964201802726, "eval_precision": 0.7522154734641043, "eval_recall": 0.7434640522875817, "learning_rate": 1.9607843137254903e-05, "loss": 0.007587263603163592, "step": 6300}
06/26/2023 19:11:26 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:11:26 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:11:26 - INFO - __main__ -     Num examples = 3060
06/26/2023 19:11:26 - INFO - __main__ -     Batch size = 48
06/26/2023 19:11:35 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:11:35 - INFO - __main__ -     acc = 0.746078431372549
06/26/2023 19:11:35 - INFO - __main__ -     auc = 0.813760946644453
06/26/2023 19:11:35 - INFO - __main__ -     f1 = 0.7455226828721915
06/26/2023 19:11:35 - INFO - __main__ -     mcc = 0.4943206749343504
06/26/2023 19:11:35 - INFO - __main__ -     precision = 0.7482470002598632
06/26/2023 19:11:35 - INFO - __main__ -     recall = 0.746078431372549
06/26/2023 19:11:35 - INFO - __main__ -   {"eval_acc": 0.746078431372549, "eval_f1": 0.7455226828721915, "eval_mcc": 0.4943206749343504, "eval_auc": 0.813760946644453, "eval_precision": 0.7482470002598632, "eval_recall": 0.746078431372549, "learning_rate": 1.8155410312273058e-05, "loss": 0.008911794923697015, "step": 6400}
06/26/2023 19:12:18 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:12:18 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:12:18 - INFO - __main__ -     Num examples = 3060
06/26/2023 19:12:18 - INFO - __main__ -     Batch size = 48
06/26/2023 19:12:27 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:12:27 - INFO - __main__ -     acc = 0.7421568627450981
06/26/2023 19:12:27 - INFO - __main__ -     auc = 0.8107336921696784
06/26/2023 19:12:27 - INFO - __main__ -     f1 = 0.7392878766821743
06/26/2023 19:12:27 - INFO - __main__ -     mcc = 0.49533823025976675
06/26/2023 19:12:27 - INFO - __main__ -     precision = 0.7533068437287604
06/26/2023 19:12:27 - INFO - __main__ -     recall = 0.7421568627450981
06/26/2023 19:12:27 - INFO - __main__ -   {"eval_acc": 0.7421568627450981, "eval_f1": 0.7392878766821743, "eval_mcc": 0.49533823025976675, "eval_auc": 0.8107336921696784, "eval_precision": 0.7533068437287604, "eval_recall": 0.7421568627450981, "learning_rate": 1.6702977487291213e-05, "loss": 0.010752753121960269, "step": 6500}
06/26/2023 19:13:11 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:13:12 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:13:12 - INFO - __main__ -     Num examples = 3060
06/26/2023 19:13:12 - INFO - __main__ -     Batch size = 48
06/26/2023 19:13:21 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:13:21 - INFO - __main__ -     acc = 0.74640522875817
06/26/2023 19:13:21 - INFO - __main__ -     auc = 0.8105203127002436
06/26/2023 19:13:21 - INFO - __main__ -     f1 = 0.7459324540860348
06/26/2023 19:13:21 - INFO - __main__ -     mcc = 0.49465482588646226
06/26/2023 19:13:21 - INFO - __main__ -     precision = 0.7482530484498227
06/26/2023 19:13:21 - INFO - __main__ -     recall = 0.74640522875817
06/26/2023 19:13:21 - INFO - __main__ -   {"eval_acc": 0.74640522875817, "eval_f1": 0.7459324540860348, "eval_mcc": 0.49465482588646226, "eval_auc": 0.8105203127002436, "eval_precision": 0.7482530484498227, "eval_recall": 0.74640522875817, "learning_rate": 1.5250544662309369e-05, "loss": 0.003181099825305864, "step": 6600}
06/26/2023 19:14:04 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:14:05 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:14:05 - INFO - __main__ -     Num examples = 3060
06/26/2023 19:14:05 - INFO - __main__ -     Batch size = 48
06/26/2023 19:14:14 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:14:14 - INFO - __main__ -     acc = 0.7496732026143791
06/26/2023 19:14:14 - INFO - __main__ -     auc = 0.8101764278696229
06/26/2023 19:14:14 - INFO - __main__ -     f1 = 0.7493947523392004
06/26/2023 19:14:14 - INFO - __main__ -     mcc = 0.5004597765222849
06/26/2023 19:14:14 - INFO - __main__ -     precision = 0.7507878151260504
06/26/2023 19:14:14 - INFO - __main__ -     recall = 0.7496732026143791
06/26/2023 19:14:14 - INFO - __main__ -   {"eval_acc": 0.7496732026143791, "eval_f1": 0.7493947523392004, "eval_mcc": 0.5004597765222849, "eval_auc": 0.8101764278696229, "eval_precision": 0.7507878151260504, "eval_recall": 0.7496732026143791, "learning_rate": 1.3798111837327524e-05, "loss": 0.004943603028077632, "step": 6700}
06/26/2023 19:14:57 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:14:57 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:14:57 - INFO - __main__ -     Num examples = 3060
06/26/2023 19:14:57 - INFO - __main__ -     Batch size = 48
06/26/2023 19:15:06 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:15:06 - INFO - __main__ -     acc = 0.7490196078431373
06/26/2023 19:15:06 - INFO - __main__ -     auc = 0.81199709513435
06/26/2023 19:15:06 - INFO - __main__ -     f1 = 0.7482425787652522
06/26/2023 19:15:06 - INFO - __main__ -     mcc = 0.5011422937808353
06/26/2023 19:15:06 - INFO - __main__ -     precision = 0.7521323529411765
06/26/2023 19:15:06 - INFO - __main__ -     recall = 0.7490196078431373
06/26/2023 19:15:06 - INFO - __main__ -   {"eval_acc": 0.7490196078431373, "eval_f1": 0.7482425787652522, "eval_mcc": 0.5011422937808353, "eval_auc": 0.81199709513435, "eval_precision": 0.7521323529411765, "eval_recall": 0.7490196078431373, "learning_rate": 1.2345679012345678e-05, "loss": 0.005064377882081317, "step": 6800}
06/26/2023 19:15:50 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:15:51 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:15:51 - INFO - __main__ -     Num examples = 3060
06/26/2023 19:15:51 - INFO - __main__ -     Batch size = 48
06/26/2023 19:16:00 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:16:00 - INFO - __main__ -     acc = 0.7470588235294118
06/26/2023 19:16:00 - INFO - __main__ -     auc = 0.8103859626639327
06/26/2023 19:16:00 - INFO - __main__ -     f1 = 0.7461409444889378
06/26/2023 19:16:00 - INFO - __main__ -     mcc = 0.49773004437616397
06/26/2023 19:16:00 - INFO - __main__ -     precision = 0.7506844256113017
06/26/2023 19:16:00 - INFO - __main__ -     recall = 0.7470588235294118
06/26/2023 19:16:00 - INFO - __main__ -   {"eval_acc": 0.7470588235294118, "eval_f1": 0.7461409444889378, "eval_mcc": 0.49773004437616397, "eval_auc": 0.8103859626639327, "eval_precision": 0.7506844256113017, "eval_recall": 0.7470588235294118, "learning_rate": 1.0893246187363835e-05, "loss": 0.006690812095985166, "step": 6900}
06/26/2023 19:16:43 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:16:44 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:16:44 - INFO - __main__ -     Num examples = 3060
06/26/2023 19:16:44 - INFO - __main__ -     Batch size = 48
06/26/2023 19:16:53 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:16:53 - INFO - __main__ -     acc = 0.7457516339869281
06/26/2023 19:16:53 - INFO - __main__ -     auc = 0.8091983852364476
06/26/2023 19:16:53 - INFO - __main__ -     f1 = 0.7455506528074847
06/26/2023 19:16:53 - INFO - __main__ -     mcc = 0.4922815572617841
06/26/2023 19:16:53 - INFO - __main__ -     precision = 0.7465305394805408
06/26/2023 19:16:53 - INFO - __main__ -     recall = 0.7457516339869281
06/26/2023 19:16:53 - INFO - __main__ -   {"eval_acc": 0.7457516339869281, "eval_f1": 0.7455506528074847, "eval_mcc": 0.4922815572617841, "eval_auc": 0.8091983852364476, "eval_precision": 0.7465305394805408, "eval_recall": 0.7457516339869281, "learning_rate": 9.440813362381991e-06, "loss": 0.0076457621480949456, "step": 7000}
06/26/2023 19:17:35 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:17:36 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:17:36 - INFO - __main__ -     Num examples = 3060
06/26/2023 19:17:36 - INFO - __main__ -     Batch size = 48
06/26/2023 19:17:45 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:17:45 - INFO - __main__ -     acc = 0.7513071895424837
06/26/2023 19:17:45 - INFO - __main__ -     auc = 0.8118031526336025
06/26/2023 19:17:45 - INFO - __main__ -     f1 = 0.7498818236567288
06/26/2023 19:17:45 - INFO - __main__ -     mcc = 0.5084427819258391
06/26/2023 19:17:45 - INFO - __main__ -     precision = 0.7571693859645672
06/26/2023 19:17:45 - INFO - __main__ -     recall = 0.7513071895424837
06/26/2023 19:17:45 - INFO - __main__ -   {"eval_acc": 0.7513071895424837, "eval_f1": 0.7498818236567288, "eval_mcc": 0.5084427819258391, "eval_auc": 0.8118031526336025, "eval_precision": 0.7571693859645672, "eval_recall": 0.7513071895424837, "learning_rate": 7.988380537400146e-06, "loss": 0.005768364756022493, "step": 7100}
06/26/2023 19:18:27 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:18:28 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:18:28 - INFO - __main__ -     Num examples = 3060
06/26/2023 19:18:28 - INFO - __main__ -     Batch size = 48
06/26/2023 19:18:37 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:18:37 - INFO - __main__ -     acc = 0.7516339869281046
06/26/2023 19:18:37 - INFO - __main__ -     auc = 0.8119539493357257
06/26/2023 19:18:37 - INFO - __main__ -     f1 = 0.750147831348497
06/26/2023 19:18:37 - INFO - __main__ -     mcc = 0.5093639883088564
06/26/2023 19:18:37 - INFO - __main__ -     precision = 0.7577669214652171
06/26/2023 19:18:37 - INFO - __main__ -     recall = 0.7516339869281046
06/26/2023 19:18:37 - INFO - __main__ -   {"eval_acc": 0.7516339869281046, "eval_f1": 0.750147831348497, "eval_mcc": 0.5093639883088564, "eval_auc": 0.8119539493357257, "eval_precision": 0.7577669214652171, "eval_recall": 0.7516339869281046, "learning_rate": 6.535947712418301e-06, "loss": 0.00401652117683625, "step": 7200}
06/26/2023 19:19:19 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:19:20 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:19:20 - INFO - __main__ -     Num examples = 3060
06/26/2023 19:19:20 - INFO - __main__ -     Batch size = 48
06/26/2023 19:19:29 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:19:29 - INFO - __main__ -     acc = 0.7496732026143791
06/26/2023 19:19:29 - INFO - __main__ -     auc = 0.8123473877568457
06/26/2023 19:19:29 - INFO - __main__ -     f1 = 0.7478528399311531
06/26/2023 19:19:29 - INFO - __main__ -     mcc = 0.5067164257184729
06/26/2023 19:19:29 - INFO - __main__ -     precision = 0.7570976114019268
06/26/2023 19:19:29 - INFO - __main__ -     recall = 0.7496732026143791
06/26/2023 19:19:29 - INFO - __main__ -   {"eval_acc": 0.7496732026143791, "eval_f1": 0.7478528399311531, "eval_mcc": 0.5067164257184729, "eval_auc": 0.8123473877568457, "eval_precision": 0.7570976114019268, "eval_recall": 0.7496732026143791, "learning_rate": 5.083514887436457e-06, "loss": 0.0041233030962757765, "step": 7300}
06/26/2023 19:20:12 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:20:13 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:20:13 - INFO - __main__ -     Num examples = 3060
06/26/2023 19:20:13 - INFO - __main__ -     Batch size = 48
06/26/2023 19:20:22 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:20:22 - INFO - __main__ -     acc = 0.7509803921568627
06/26/2023 19:20:22 - INFO - __main__ -     auc = 0.8120035029262249
06/26/2023 19:20:22 - INFO - __main__ -     f1 = 0.7494131135011193
06/26/2023 19:20:22 - INFO - __main__ -     mcc = 0.5083600687309258
06/26/2023 19:20:22 - INFO - __main__ -     precision = 0.7574204674508924
06/26/2023 19:20:22 - INFO - __main__ -     recall = 0.7509803921568627
06/26/2023 19:20:22 - INFO - __main__ -   {"eval_acc": 0.7509803921568627, "eval_f1": 0.7494131135011193, "eval_mcc": 0.5083600687309258, "eval_auc": 0.8120035029262249, "eval_precision": 0.7574204674508924, "eval_recall": 0.7509803921568627, "learning_rate": 3.6310820624546117e-06, "loss": 0.0005531980929481506, "step": 7400}
06/26/2023 19:21:05 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:21:05 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:21:05 - INFO - __main__ -     Num examples = 3060
06/26/2023 19:21:05 - INFO - __main__ -     Batch size = 48
06/26/2023 19:21:14 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:21:14 - INFO - __main__ -     acc = 0.7506535947712418
06/26/2023 19:21:14 - INFO - __main__ -     auc = 0.8122961254218464
06/26/2023 19:21:14 - INFO - __main__ -     f1 = 0.7493933082889077
06/26/2023 19:21:14 - INFO - __main__ -     mcc = 0.5064266461022434
06/26/2023 19:21:14 - INFO - __main__ -     precision = 0.7557991918253073
06/26/2023 19:21:14 - INFO - __main__ -     recall = 0.7506535947712418
06/26/2023 19:21:14 - INFO - __main__ -   {"eval_acc": 0.7506535947712418, "eval_f1": 0.7493933082889077, "eval_mcc": 0.5064266461022434, "eval_auc": 0.8122961254218464, "eval_precision": 0.7557991918253073, "eval_recall": 0.7506535947712418, "learning_rate": 2.178649237472767e-06, "loss": 0.0029249699160391173, "step": 7500}
06/26/2023 19:21:57 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:21:57 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:21:57 - INFO - __main__ -     Num examples = 3060
06/26/2023 19:21:57 - INFO - __main__ -     Batch size = 48
06/26/2023 19:22:06 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:22:06 - INFO - __main__ -     acc = 0.7513071895424837
06/26/2023 19:22:06 - INFO - __main__ -     auc = 0.8124477764962195
06/26/2023 19:22:06 - INFO - __main__ -     f1 = 0.7499310303798156
06/26/2023 19:22:06 - INFO - __main__ -     mcc = 0.5082393082215547
06/26/2023 19:22:06 - INFO - __main__ -     precision = 0.7569635939303851
06/26/2023 19:22:06 - INFO - __main__ -     recall = 0.7513071895424837
06/26/2023 19:22:06 - INFO - __main__ -   {"eval_acc": 0.7513071895424837, "eval_f1": 0.7499310303798156, "eval_mcc": 0.5082393082215547, "eval_auc": 0.8124477764962195, "eval_precision": 0.7569635939303851, "eval_recall": 0.7513071895424837, "learning_rate": 7.262164124909224e-07, "loss": 0.00167173452944553, "step": 7600}
06/26/2023 19:22:28 - INFO - __main__ -    global_step = 7650, average loss = 0.13881584615550582
06/26/2023 19:22:28 - INFO - __main__ -   Saving model checkpoint to /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold2
06/26/2023 19:22:28 - INFO - transformers.configuration_utils -   Configuration saved in /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold2/config.json
06/26/2023 19:22:28 - INFO - transformers.modeling_utils -   Model weights saved in /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold2/pytorch_model.bin
06/26/2023 19:22:28 - INFO - transformers.configuration_utils -   loading configuration file /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold2/config.json
06/26/2023 19:22:28 - INFO - transformers.configuration_utils -   Model config BertConfig {
  "architectures": [
    "BertForSequenceClassification"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "do_sample": false,
  "eos_token_ids": 0,
  "filter_num": 128,
  "filter_size": [
    2,
    3,
    4,
    5,
    6
  ],
  "finetuning_task": "dnaprom",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "num_return_sequences": 1,
  "num_rnn_layer": 2,
  "output_attentions": false,
  "output_hidden_states": true,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "rnn": "lstm",
  "rnn_dropout": 0.0,
  "rnn_hidden": 768,
  "split": 0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 4101
}

06/26/2023 19:22:28 - INFO - transformers.modeling_utils -   loading weights file /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold2/pytorch_model.bin
06/26/2023 19:22:30 - INFO - transformers.tokenization_utils -   Model name '/data3/linming/DNABERT/examples/output/fold5_100_15296/_fold2' not found in model shortcut name list (dna3, dna4, dna5, dna6). Assuming '/data3/linming/DNABERT/examples/output/fold5_100_15296/_fold2' is a path, a model identifier, or url to a directory containing tokenizer files.
06/26/2023 19:22:30 - INFO - transformers.tokenization_utils -   Didn't find file /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold2/added_tokens.json. We won't load it.
06/26/2023 19:22:30 - INFO - transformers.tokenization_utils -   loading file /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold2/vocab.txt
06/26/2023 19:22:30 - INFO - transformers.tokenization_utils -   loading file None
06/26/2023 19:22:30 - INFO - transformers.tokenization_utils -   loading file /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold2/special_tokens_map.json
06/26/2023 19:22:30 - INFO - transformers.tokenization_utils -   loading file /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold2/tokenizer_config.json
06/26/2023 19:22:30 - INFO - transformers.tokenization_utils -   Model name '/data3/linming/DNABERT/examples/output/fold5_100_15296/_fold2' not found in model shortcut name list (dna3, dna4, dna5, dna6). Assuming '/data3/linming/DNABERT/examples/output/fold5_100_15296/_fold2' is a path, a model identifier, or url to a directory containing tokenizer files.
06/26/2023 19:22:30 - INFO - transformers.tokenization_utils -   Didn't find file /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold2/added_tokens.json. We won't load it.
06/26/2023 19:22:30 - INFO - transformers.tokenization_utils -   loading file /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold2/vocab.txt
06/26/2023 19:22:30 - INFO - transformers.tokenization_utils -   loading file None
06/26/2023 19:22:30 - INFO - transformers.tokenization_utils -   loading file /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold2/special_tokens_map.json
06/26/2023 19:22:30 - INFO - transformers.tokenization_utils -   loading file /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold2/tokenizer_config.json
06/26/2023 19:22:30 - INFO - __main__ -   Evaluate the following checkpoints: ['/data3/linming/DNABERT/examples/output/fold5_100_15296/_fold2']
06/26/2023 19:22:30 - INFO - transformers.configuration_utils -   loading configuration file /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold2/config.json
06/26/2023 19:22:30 - INFO - transformers.configuration_utils -   Model config BertConfig {
  "architectures": [
    "BertForSequenceClassification"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "do_sample": false,
  "eos_token_ids": 0,
  "filter_num": 128,
  "filter_size": [
    2,
    3,
    4,
    5,
    6
  ],
  "finetuning_task": "dnaprom",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "num_return_sequences": 1,
  "num_rnn_layer": 2,
  "output_attentions": false,
  "output_hidden_states": true,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "rnn": "lstm",
  "rnn_dropout": 0.0,
  "rnn_hidden": 768,
  "split": 0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 4101
}

06/26/2023 19:22:30 - INFO - transformers.modeling_utils -   loading weights file /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold2/pytorch_model.bin
06/26/2023 19:22:32 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/2/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:22:33 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:22:33 - INFO - __main__ -     Num examples = 3060
06/26/2023 19:22:33 - INFO - __main__ -     Batch size = 48
06/26/2023 19:22:42 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:22:42 - INFO - __main__ -     acc = 0.7516339869281046
06/26/2023 19:22:42 - INFO - __main__ -     auc = 0.8123480285360332
06/26/2023 19:22:42 - INFO - __main__ -     f1 = 0.7501980713606857
06/26/2023 19:22:42 - INFO - __main__ -     mcc = 0.5091554852715922
06/26/2023 19:22:42 - INFO - __main__ -     precision = 0.7575559360510975
06/26/2023 19:22:42 - INFO - __main__ -     recall = 0.7516339869281046
06/26/2023 19:22:42 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
06/26/2023 19:22:42 - INFO - transformers.configuration_utils -   loading configuration file /data3/linming/DNABERT/examples/embeding_model/6-new-12w-0/config.json
06/26/2023 19:22:42 - INFO - transformers.configuration_utils -   Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "do_sample": false,
  "eos_token_ids": 0,
  "finetuning_task": "dnaprom",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "num_return_sequences": 1,
  "num_rnn_layer": 1,
  "output_attentions": false,
  "output_hidden_states": true,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "rnn": "lstm",
  "rnn_dropout": 0.0,
  "rnn_hidden": 768,
  "split": 10,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 4101
}

06/26/2023 19:22:43 - INFO - transformers.tokenization_utils -   loading file https://raw.githubusercontent.com/jerryji1993/DNABERT/master/src/transformers/dnabert-config/bert-config-6/vocab.txt from cache at /data3/linming/.cache/torch/transformers/ea1474aad40c1c8ed4e1cb7c11345ddda6df27a857fb29e1d4c901d9b900d32d.26f8bd5a32e49c2a8271a46950754a4a767726709b7741c68723bc1db840a87e
06/26/2023 19:22:43 - INFO - transformers.modeling_utils -   loading weights file /data3/linming/DNABERT/examples/embeding_model/6-new-12w-0/pytorch_model.bin
06/26/2023 19:22:45 - INFO - transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
06/26/2023 19:22:45 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']
06/26/2023 19:22:45 - INFO - __main__ -   finish loading model
06/26/2023 19:22:45 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, attention_probs_dropout_prob=0.1, beta1=0.9, beta2=0.999, cache_dir='', config_name='', data_dir='/data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/', device=device(type='cuda'), do_ensemble_pred=False, do_eval=True, do_lower_case=False, do_predict=False, do_train=True, do_visualize=False, early_stop=15, eval_all_checkpoints=False, eval_batch_size=48, evaluate_during_training=True, filter_num=128, filter_size=[2, 3, 4, 5, 6], fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, hidden_dropout_prob=0.1, learning_rate=0.0001, local_rank=-1, logging_steps=100, max_grad_norm=1.0, max_seq_length=300, max_steps=-1, model_name='mutant_Bert_fold5_100_15296_fold3', model_name_or_path='/data3/linming/DNABERT/examples/embeding_model/6-new-12w-0/', model_num=5, model_type='dna', n_gpu=1, n_process=8, no_cuda=False, num_rnn_layer=2, num_train_epochs=30.0, output_dir='/data3/linming/DNABERT/examples/output/fold5_100_15296/_fold3', output_mode='classification', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=48, per_gpu_pred_batch_size=8, per_gpu_train_batch_size=48, predict_dir=None, predict_scan_size=1, result_dir=None, rnn='lstm', rnn_dropout=0.0, rnn_hidden=768, save_steps=4000, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, task_name='dnaprom', tokenizer_name='dna6', train_batch_size=48, visualize_data_dir=None, visualize_models=None, visualize_train=False, warmup_percent=0.1, warmup_steps=0, weight_decay=0.01)
06/26/2023 19:22:45 - INFO - __main__ -   Creating features from dataset file at /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/
06/26/2023 19:22:45 - INFO - transformers.data.processors.glue -   LOOKING AT /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/train.tsv
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   Writing example 0/1529
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   guid: train-1
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   input_ids: 2 261 1029 7 16 49 182 716 2851 3198 491 1951 3694 2475 1693 2664 2452 1602 2298 986 3930 3418 1370 1369 1365 1351 1294 1066 154 603 2398 1386 1434 1625 2389 1349 1287 1037 40 146 570 2265 856 3412 1347 1280 1009 4022 3786 2841 3160 337 1336 1233 821 3269 773 3077 6 12 34 122 473 1877 3397 1288 1041 56 212 834 3321 982 3914 3356 1124 385 1525 1992 3857 3126 202 794 3162 348 1379 1406 1516 1953 3701 2504 1809 3126 204 804 3202 508 2017 3960 3537 1845 3272 785 3126 202 793 3157 325 1286 1034 28 99 382 1514 1945 3671 2382 1324 1188 642 2553 2005 3909 3335 1040 51 192 754 3002 3803 2909 3429 1415 1550 2092 164 643 2560 2036 4033 3829 3016 3857 3127 207 814 3243 669 2664 2450 1596 2273 888 3538 1849 3288 850 3386 1243 862 3434 1433 1623 2382 1324 1187 639 2543 1966 3755 2718 2665 2455 1615 2350 1194 665 2647 2382 1321 1175 591 2350 1194 666 2651 2399 1389 1447 1679 2606 2218 666 2651 2399 1391 1453 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   guid: train-2
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   input_ids: 2 1681 2616 2259 829 3301 904 3601 2101 197 773 3080 20 67 254 1001 3991 3664 2354 1211 735 2927 3503 1710 2732 2722 2683 2528 1905 3509 1736 2836 3137 248 977 3896 3282 828 3300 897 3575 2000 3892 3266 764 3041 3957 3528 1812 3138 252 995 3967 3566 1964 3748 2689 2549 1989 3847 3088 52 195 767 3053 4008 3729 2616 2257 821 3269 773 3080 17 55 207 814 3241 664 2644 2371 1280 1012 4034 3835 3040 3953 3510 1740 2850 3194 476 1891 3456 1524 1986 3836 3044 3969 3575 1997 3879 3214 556 2210 636 2531 1917 3560 1939 3645 2279 909 3624 2195 575 2285 936 3729 2614 2252 804 3204 516 2050 4091 4063 3949 3495 1679 2607 2222 683 2717 2663 2447 1582 2219 671 2669 2471 1679 2607 2222 683 2719 2671 2478 1708 2724 2689 2552 2001 3893 3272 786 3131 223 879 3504 1713 2741 2758 2828 3105 117 456 1811 3136 241 951 3791 2863 3247 688 2739 2750 2795 2974 3692 2465 1654 2506 1820 3172 385 1525 1992 3857 3126 204 801 3189 455 1806 3114 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   guid: train-3
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   input_ids: 2 129 504 2003 3901 3301 902 3593 2069 69 261 1031 15 47 173 680 2706 2620 2276 898 3578 2009 3926 3404 1315 1150 490 1945 3671 2383 1325 1190 650 2586 2138 347 1373 1382 1419 1567 2157 424 1681 2616 2257 821 3269 773 3077 6 11 29 102 395 1567 2158 428 1697 2680 2515 1853 3302 905 3608 2131 320 1265 949 3781 2822 3082 26 90 346 1371 1373 1384 1428 1601 2295 975 3885 3239 653 2600 2196 579 2301 997 3974 3593 2069 69 263 1037 39 141 550 2187 541 2150 395 1565 2151 399 1581 2213 645 2568 2065 53 197 774 3083 29 102 396 1572 2177 504 2001 3895 3277 805 3208 530 2106 217 855 3407 1326 1193 662 2636 2340 1153 504 2001 3893 3269 776 3091 61 232 913 3637 2245 775 3085 39 142 556 2209 630 2506 1820 3170 377 1494 1865 3350 1100 289 1142 460 1828 3202 507 2015 3950 3500 1698 2684 2529 1911 3533 1829 3206 524 2081 117 455 1807 3118 171 669 2663 2445 1575 2190 553 2199 589 2343 1166 556 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   Writing example 0/1529
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   guid: train-4
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   input_ids: 2 2091 159 621 2471 1679 2606 2217 663 2638 2347 1182 617 2453 1606 2313 1046 75 285 1127 397 1574 2187 543 2159 430 1708 2721 2680 2513 1845 3271 783 3119 175 686 2732 2722 2682 2524 1890 3450 1499 1887 3438 1452 1698 2681 2518 1865 3350 1099 286 1129 406 1609 2326 1098 283 1118 361 1432 1619 2367 1261 934 3723 2589 2149 389 1542 2059 29 101 390 1547 2079 110 425 1686 2633 2327 1102 299 1181 615 2446 1580 2209 632 2513 1848 3284 835 3326 1003 3997 3685 2440 1553 2104 210 828 3297 888 3537 1846 3276 804 3203 509 2022 3979 3615 2157 422 1674 2588 2145 376 1489 1845 3270 780 3105 117 456 1809 3127 207 813 3239 655 2606 2218 668 2660 2434 1529 2005 3909 3333 1029 5 8 17 53 199 781 3112 145 568 2257 823 3278 810 3226 601 2391 1357 1318 1163 542 2154 410 1628 2402 1401 1495 1871 3376 1201 696 2769 2870 3276 803 3198 492 1955 3710 2540 1953 3703 2509 1829 3205 520 2067 62 234 924 3682 2428 1508 1921 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   guid: train-1530
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   input_ids: 2 4015 3758 2731 2719 2669 2472 1684 2627 2301 999 3981 3624 2194 570 2267 862 3434 1435 1631 2415 1454 1708 2722 2683 2527 1901 3493 1671 2575 2094 171 670 2668 2466 1660 2531 1919 3567 1965 3752 2705 2613 2248 788 3139 255 1006 4012 3748 2690 2555 2013 3941 3461 1544 2068 65 248 980 3907 3327 1005 4007 3727 2605 2215 655 2605 2215 655 2605 2215 655 2608 2227 703 2797 2983 3727 2608 2227 703 2797 2983 3727 2605 2215 654 2601 2199 591 2349 1191 655 2606 2219 671 2672 2483 1727 2800 2995 3775 2797 2983 3727 2605 2215 654 2604 2211 639 2542 1963 3743 2669 2471 1678 2601 2199 591 2352 1203 702 2796 2979 3711 2541 1959 3727 2607 2223 686 2732 2721 2677 2504 1809 3125 200 785 3128 209 824 3284 836 3329 1013 4039 3855 3117 167 653 2600 2195 573 2279 909 3624 2196 579 2303 1006 4012 3746 2684 2530 1915 3550 1899 3487 1646 2474 1692 2658 2428 1505 1910 3532 1826 3194 474 1882 3418 1371 1373 1382 1420 1572 2178 506 2011 3934 3436 1444 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   guid: train-5
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   input_ids: 2 1052 97 376 1489 1845 3269 776 3090 60 227 895 3566 1962 3739 2654 2412 1441 1653 2503 1805 3111 142 555 2205 613 2437 1541 2054 9 21 70 267 1055 111 430 1706 2715 2654 2411 1438 1642 2460 1636 2433 1525 1991 3853 3112 148 580 2305 1016 4052 3907 3326 1004 4003 3710 2539 1949 3688 2452 1601 2293 968 3858 3129 216 849 3382 1225 792 3155 317 1253 901 3591 2062 44 163 637 2533 1927 3598 2090 154 602 2395 1373 1381 1416 1556 2113 248 977 3893 3271 783 3120 178 697 2776 2900 3393 1272 980 3905 3317 968 3857 3125 200 788 3137 248 977 3896 3284 833 3317 968 3860 3137 248 977 3893 3272 785 3128 209 823 3280 820 3267 765 3048 3985 3640 2260 833 3317 968 3860 3140 260 1028 4097 4085 4040 3857 3128 210 828 3299 893 3560 1939 3647 2286 940 3747 2687 2542 1964 3748 2691 2559 2030 4011 3741 2663 2446 1578 2204 611 2430 1514 1947 3677 2407 1424 1587 2237 742 2956 3617 2167 461 1829 3207 525 2085 135 527 2093 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   guid: train-1531
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   input_ids: 2 3093 69 262 1034 27 94 364 1443 1662 2540 1956 3716 2563 2047 4077 4005 3717 2566 2058 27 94 361 1430 1609 2328 1105 312 1235 829 3301 903 3599 2093 165 645 2566 2060 34 121 469 1862 3338 1049 85 326 1292 1058 122 473 1880 3411 1341 1253 902 3594 2075 93 359 1423 1582 2218 668 2660 2435 1533 2024 3988 3650 2299 989 3941 3462 1545 2069 69 261 1031 15 45 168 657 2616 2257 824 3283 831 3309 935 3728 2610 2234 730 2906 3417 1365 1349 1287 1037 37 136 531 2111 237 936 3729 2613 2245 773 3077 8 17 55 206 809 3222 587 2333 1126 396 1571 2176 498 1979 3807 2925 3496 1683 2622 2284 929 3702 2505 1814 3147 285 1127 399 1582 2217 663 2639 2351 1197 680 2706 2617 2264 852 3393 1271 975 3886 3241 662 2633 2325 1094 265 1045 69 262 1033 21 72 273 1080 209 823 3277 805 3207 525 2086 140 546 2170 474 1881 3416 1361 1333 1224 785 3128 209 822 3273 791 3150 298 1178 601 2391 1357 1317 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   guid: train-1532
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   input_ids: 2 2280 916 3649 2293 968 3860 3140 259 1023 4077 4008 3732 2625 2296 978 3898 3292 865 3446 1484 1825 3192 468 1858 3321 984 3921 3382 1227 799 3184 436 1730 2811 3039 3949 3494 1675 2589 2150 396 1569 2166 460 1828 3202 508 2017 3958 3532 1825 3190 460 1827 3198 492 1954 3705 2519 1871 3373 1192 659 2624 2291 958 3820 2980 3713 2549 1992 3859 3135 239 943 3758 2732 2724 2691 2559 2029 4008 3732 2627 2302 1004 4002 3707 2527 1902 3498 1692 2657 2422 1484 1825 3189 456 1812 3138 252 994 3964 3556 1923 3582 2028 4001 3701 2503 1805 3111 141 549 2181 520 2067 63 240 946 3772 2787 2942 3564 1955 3710 2539 1949 3686 2443 1566 2155 415 1648 2481 1717 2760 2833 3125 200 785 3126 204 804 3204 516 2051 4095 4078 4010 3739 2653 2407 1424 1588 2243 767 3053 4008 3732 2628 2307 1021 4072 3985 3639 2255 814 3244 676 2689 2552 2004 3908 3329 1015 4045 3879 3215 560 2228 707 2816 3057 4023 3790 2859 3229 616 2449 1591 2253 808 3219 575 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   Writing example 0/1529
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   guid: train-1533
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   input_ids: 2 1589 2245 776 3089 56 209 823 3278 811 3229 616 2449 1589 2248 787 3136 244 963 3840 3057 4021 3784 2835 3133 229 901 3589 2055 15 45 167 656 2610 2235 733 2919 3470 1580 2211 639 2544 1969 3767 2768 2865 3255 718 2858 3226 604 2402 1404 1507 1917 3560 1937 3639 2254 810 3227 606 2412 1442 1659 2525 1894 3467 1568 2164 451 1789 3048 3987 3645 2277 903 3600 2100 193 758 3017 3863 3149 294 1163 542 2154 409 1621 2373 1286 1033 21 72 275 1085 232 916 3651 2301 999 3981 3624 2195 575 2287 942 3754 2716 2657 2424 1492 1857 3319 974 3881 3223 591 2349 1192 659 2621 2279 910 3627 2206 620 2468 1667 2559 2030 4011 3742 2666 2459 1632 2419 1470 1772 2979 3711 2542 1964 3748 2691 2559 2029 4006 3724 2595 2174 492 1955 3709 2533 1925 3589 2053 7 15 47 174 682 2715 2655 2414 1452 1700 2689 2552 2004 3908 3332 1027 4094 4076 4004 3715 2557 2021 3973 3592 2068 67 253 1000 3988 3649 2295 974 3883 3231 621 2469 1672 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   guid: train-3059
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   input_ids: 2 3812 2948 3585 2040 4050 3898 3292 865 3447 1485 1829 3206 523 2077 103 398 1580 2212 643 2560 2033 4022 3787 2846 3178 412 1635 2429 1512 1937 3639 2253 807 3213 549 2182 523 2078 106 410 1628 2402 1401 1496 1875 3390 1258 922 3674 2393 1367 1359 1325 1189 645 2568 2065 56 211 830 3308 931 3709 2534 1932 3619 2175 496 1969 3767 2767 2861 3239 656 2612 2243 765 3045 3973 3589 2053 6 12 33 117 456 1809 3127 208 817 3254 716 2849 3190 460 1825 3192 468 1860 3330 1018 4057 3925 3397 1286 1034 26 91 351 1391 1453 1704 2705 2616 2259 831 3311 943 3759 2733 2727 2704 2612 2241 757 3014 3850 3100 99 383 1520 1969 3766 2764 2849 3190 459 1822 3178 410 1625 2390 1354 1305 1112 339 1341 1254 905 3606 2122 282 1113 341 1351 1296 1074 186 732 2916 3459 1535 2029 4005 3720 2577 2102 202 794 3162 348 1379 1407 1517 1957 3719 2574 2090 156 609 2421 1477 1797 3079 14 43 160 627 2493 1768 2963 3646 2284 932 3713 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   guid: train-1534
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   input_ids: 2 1406 1516 1953 3704 2515 1855 3312 947 3774 2796 2977 3703 2511 1837 3238 652 2595 2175 494 1964 3748 2690 2554 2009 3926 3404 1316 1153 504 2004 3908 3332 1027 4093 4072 3987 3646 2282 923 3678 2412 1443 1662 2540 1956 3713 2552 2003 3903 3310 939 3742 2668 2466 1658 2522 1882 3418 1372 1380 1410 1532 2019 3966 3562 1947 3678 2412 1444 1665 2551 1998 3884 3236 641 2550 1993 3861 3143 271 1069 165 647 2575 2094 171 671 2669 2472 1681 2616 2260 833 3317 965 3846 3081 24 83 318 1257 918 3659 2333 1126 395 1565 2151 399 1582 2219 671 2669 2470 1676 2596 2180 513 2038 4042 3866 3163 349 1384 1427 1600 2289 949 3781 2822 3083 29 104 404 1603 2302 1001 3990 3658 2331 1117 360 1428 1603 2301 999 3982 3625 2199 592 2353 1208 723 2877 3301 903 3600 2100 194 764 3041 3960 3539 1853 3302 908 3617 2168 465 1848 3281 823 3278 812 3234 636 2530 1916 3554 1916 3554 1916 3554 1916 3554 1916 3554 1916 3554 1916 3554 1916 3554 1916 3554 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   guid: train-3060
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   input_ids: 2 1035 31 109 422 1673 2582 2122 281 1109 326 1292 1059 127 494 1962 3737 2646 2377 1302 1097 279 1103 302 1195 670 2665 2453 1605 2310 1036 34 122 474 1882 3420 1380 1412 1538 2042 4059 3934 3436 1443 1663 2543 1966 3753 2710 2633 2325 1093 262 1035 31 111 431 1710 2731 2717 2664 2451 1598 2283 925 3687 2447 1582 2219 671 2670 2474 1692 2657 2424 1490 1850 3290 857 3414 1355 1309 1128 402 1593 2261 840 3345 1077 198 779 3102 106 412 1633 2422 1482 1818 3163 351 1390 1451 1693 2662 2441 1558 2122 282 1113 342 1355 1310 1130 411 1630 2410 1434 1626 2394 1372 1377 1400 1489 1848 3282 825 3287 846 3372 1186 633 2517 1864 3345 1078 201 789 3144 274 1081 216 849 3382 1226 793 3157 325 1285 1029 6 10 26 91 349 1384 1425 1592 2258 825 3288 849 3381 1221 774 3082 25 88 338 1339 1245 871 3469 1575 2189 552 2196 579 2301 997 3974 3593 2071 79 303 1199 687 2735 2734 2731 2719 2671 2478 1705 2711 2637 2342 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   Writing example 0/1529
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   guid: train-3061
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   input_ids: 2 2065 56 209 822 3276 801 3190 460 1826 3195 477 1896 3475 1597 2277 901 3591 2063 46 169 661 2632 2321 1077 198 780 3106 124 484 1924 3585 2038 4041 3863 3149 294 1161 535 2126 297 1175 590 2348 1185 629 2502 1804 3107 125 485 1925 3592 2068 65 247 973 3879 3215 557 2215 653 2599 2189 551 2189 551 2192 563 2237 742 2956 3618 2172 483 1917 3559 1933 3623 2189 551 2189 551 2189 551 2189 551 2192 563 2238 746 2970 3674 2394 1369 1367 1357 1320 1170 572 2276 898 3578 2009 3925 3397 1285 1030 12 34 123 477 1895 3470 1579 2206 620 2465 1656 2513 1848 3284 833 3318 969 3864 3155 319 1263 942 3756 2721 2680 2515 1853 3304 914 3643 2270 874 3483 1629 2408 1425 1592 2257 823 3280 819 3262 746 2972 3682 2426 1498 1883 3421 1383 1422 1579 2206 619 2461 1639 2445 1575 2191 559 2221 680 2705 2614 2252 803 3198 492 1955 3710 2538 1947 3677 2407 1423 1582 2218 665 2645 2373 1286 1033 21 71 269 1061 133 517 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   guid: train-4588
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   input_ids: 2 4011 3743 2670 2474 1692 2658 2425 1495 1870 3370 1178 603 2400 1395 1469 1768 2964 3651 2302 1003 3998 3691 2464 1650 2491 1760 2930 3515 1759 2926 3498 1692 2658 2427 1503 1901 3496 1683 2622 2283 927 3694 2476 1700 2689 2550 1995 3870 3179 415 1646 2476 1700 2689 2550 1996 3875 3198 491 1950 3690 2459 1630 2412 1444 1668 2563 2047 4080 4020 3780 2820 3076 4099 4094 4074 3996 3682 2425 1496 1874 3386 1244 865 3447 1487 1840 3249 696 2770 2876 3299 894 3563 1949 3686 2443 1567 2158 427 1696 2674 2490 1755 2910 3435 1439 1648 2483 1726 2796 2979 3709 2533 1926 3595 2078 108 420 1668 2563 2047 4077 4008 3731 2622 2284 931 3710 2539 1952 3700 2499 1790 3052 4002 3708 2532 1924 3587 2046 4075 3999 3694 2476 1699 2686 2539 1949 3688 2451 1599 2285 934 3724 2595 2174 491 1949 3685 2440 1555 2110 234 921 3672 2387 1343 1262 940 3748 2692 2562 2043 4064 3956 3524 1793 3063 4045 3879 3215 558 2220 674 2684 2532 1924 3587 2048 4084 4036 3841 3063 4048 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   guid: train-3062
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   input_ids: 2 1802 3098 90 347 1374 1385 1430 1610 2330 1115 350 1386 1435 1631 2414 1451 1695 2671 2477 1703 2702 2604 2212 644 2562 2042 4058 3930 3419 1373 1382 1419 1566 2155 414 1641 2456 1619 2367 1261 936 3730 2619 2269 871 3470 1577 2198 585 2326 1098 282 1116 353 1399 1486 1834 3228 611 2430 1516 1953 3702 2506 1818 3164 354 1401 1494 1866 3354 1114 347 1374 1386 1434 1626 2394 1369 1368 1364 1345 1270 970 3866 3162 345 1367 1357 1320 1170 570 2266 858 3418 1369 1365 1351 1296 1076 193 760 3028 3907 3325 1000 3986 3643 2270 876 3490 1659 2525 1896 3476 1601 2296 979 3901 3303 909 3622 2188 547 2175 495 1965 3749 2693 2565 2056 17 54 203 798 3180 419 1661 2533 1925 3592 2066 57 213 840 3346 1084 226 890 3546 1881 3413 1350 1289 1047 78 299 1181 613 2437 1542 2058 27 93 357 1414 1547 2079 109 422 1674 2588 2147 382 1514 1946 3675 2399 1390 1451 1693 2664 2450 1594 2265 855 3405 1318 1161 536 2130 316 1251 894 3562 1945 3670 2378 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   guid: train-4589
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   input_ids: 2 1548 2083 126 491 1950 3691 2461 1637 2438 1546 2076 100 385 1526 1996 3873 3192 466 1850 3290 858 3418 1369 1365 1349 1285 1029 6 9 22 76 290 1145 471 1869 3366 1162 540 2145 376 1490 1850 3289 855 3405 1317 1157 520 2065 53 200 788 3137 245 968 3859 3133 230 905 3605 2120 274 1082 218 860 3425 1400 1489 1845 3269 773 3077 6 11 30 108 419 1661 2534 1930 3609 2133 326 1290 1050 91 349 1383 1422 1578 2201 599 2382 1324 1185 629 2501 1799 3085 37 135 525 2085 135 525 2088 148 577 2294 969 3862 3145 277 1093 261 1030 12 35 125 485 1925 3592 2065 55 206 809 3223 590 2347 1182 619 2462 1642 2459 1629 2405 1416 1555 2109 230 908 3619 2174 491 1949 3688 2450 1593 2261 839 3342 1066 155 606 2412 1444 1668 2562 2042 4058 3931 3422 1386 1436 1633 2421 1477 1797 3078 11 29 104 401 1592 2260 834 3322 988 3938 3449 1493 1863 3343 1070 169 661 2629 2309 1032 17 55 207 813 3240 657 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   Writing example 0/1529
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   guid: train-3063
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   input_ids: 2 3303 911 3630 2219 671 2670 2475 1693 2662 2441 1560 2130 315 1247 879 3503 1711 2734 2731 2718 2668 2468 1666 2554 2011 3933 3430 1419 1567 2158 427 1695 2670 2476 1699 2686 2539 1949 3686 2444 1571 2175 494 1964 3746 2683 2527 1901 3494 1675 2590 2155 415 1646 2475 1693 2661 2439 1552 2098 187 735 2926 3499 1693 2662 2441 1560 2130 315 1245 870 3466 1563 2142 363 1437 1640 2452 1603 2302 1003 4000 3700 2500 1795 3070 4075 3997 3688 2452 1603 2302 1003 4000 3700 2500 1795 3070 4075 3997 3688 2452 1603 2302 1003 3997 3688 2452 1603 2302 1003 3997 3688 2452 1603 2302 1003 3997 3688 2452 1603 2302 1003 3998 3692 2467 1662 2538 1947 3680 2418 1465 1751 2893 3367 1166 556 2212 643 2558 2027 3998 3690 2459 1631 2414 1451 1695 2669 2471 1679 2606 2220 676 2689 2552 2004 3907 3327 1006 4010 3739 2655 2413 1448 1681 2616 2258 827 3295 878 3497 1688 2644 2372 1284 1028 4099 4093 4072 3985 3640 2259 830 3308 932 3716 2564 2052 4099 4094 4075 3999 3694 2475 1693 2662 2442 1564 2146 379 1503 1902 3500 1697 2680 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   guid: train-4590
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   input_ids: 2 3880 3218 569 2264 851 3391 1263 943 3758 2732 2723 2686 2539 1952 3700 2499 1791 3054 4010 3739 2656 2417 1464 1746 2874 3291 863 3437 1447 1678 2604 2211 639 2542 1961 3733 2632 2322 1084 228 899 3584 2033 4024 3794 2876 3299 893 3558 1931 3615 2157 423 1678 2603 2207 621 2472 1683 2622 2284 932 3715 2560 2035 4030 3820 2978 3708 2529 1910 3532 1828 3202 508 2020 3971 3583 2031 4015 3760 2737 2743 2766 2860 3235 637 2533 1928 3604 2113 247 973 3877 3205 518 2059 30 108 417 1655 2512 1841 3256 722 2875 3294 876 3489 1655 2512 1841 3256 724 2881 3317 965 3845 3079 14 44 163 640 2548 1986 3833 3030 3916 3364 1156 515 2048 4084 4036 3844 3075 4095 4077 4008 3732 2628 2306 1020 4068 3972 3588 2052 4099 4096 4084 4036 3844 3075 4096 4082 4027 3807 2926 3497 1686 2635 2333 1127 399 1582 2220 674 2683 2527 1903 3502 1708 2724 2692 2563 2046 4075 3999 3695 2479 1711 2733 2728 2708 2626 2300 994 3964 3556 1924 3585 2039 4045 3878 3212 547 2173 488 1938 3644 2273 886 3530 1818 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   guid: train-6117
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   input_ids: 2 34 124 481 1910 3530 1819 3168 369 1461 1734 2826 3097 86 330 1307 1119 366 1451 1693 2663 2447 1581 2215 653 2597 2183 526 2089 151 589 2341 1158 524 2083 125 488 1939 3646 2281 918 3658 2329 1109 326 1289 1045 72 274 1081 215 845 3365 1159 527 2093 166 652 2593 2167 461 1830 3210 540 2147 383 1519 1966 3754 2715 2654 2412 1444 1665 2549 1991 3854 3116 164 641 2551 2000 3889 3253 711 2831 3119 174 682 2713 2648 2386 1340 1251 894 3561 1941 3653 2311 1037 37 135 525 2088 147 574 2281 919 3664 2354 1210 729 2903 3405 1319 1167 558 2217 662 2634 2330 1116 355 1405 1510 1930 3612 2147 382 1516 1953 3703 2509 1829 3208 532 2113 245 966 3849 3095 77 295 1168 561 2229 711 2829 3110 139 542 2154 411 1631 2414 1451 1693 2661 2437 1542 2058 26 92 356 1409 1526 1995 3870 3180 420 1667 2558 2025 3990 3660 2338 1145 469 1864 3346 1084 228 899 3582 2028 4004 3716 2564 2049 4085 4040 3857 3128 210 827 3294 874 3483 1631 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   guid: train-6118
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   input_ids: 2 3563 1950 3692 2465 1656 2515 1854 3308 929 3703 2511 1837 3239 653 2599 2190 555 2207 623 2479 1711 2733 2726 2698 2587 2142 364 1444 1667 2559 2030 4011 3741 2664 2452 1601 2296 977 3895 3277 805 3208 529 2102 203 799 3183 430 1708 2724 2691 2558 2027 3998 3692 2467 1663 2544 1970 3772 2787 2942 3561 1941 3654 2315 1054 106 411 1629 2405 1415 1552 2098 187 735 2925 3494 1676 2594 2171 477 1894 3466 1564 2145 375 1486 1834 3227 607 2413 1447 1677 2597 2182 524 2082 123 479 1903 3502 1708 2723 2688 2548 1985 3830 3020 3874 3196 484 1922 3580 2020 3969 3573 1989 3846 3083 29 104 404 1601 2295 973 3879 3214 556 2210 635 2527 1903 3504 1716 2755 2815 3053 4006 3723 2590 2156 417 1656 2513 1847 3279 814 3244 675 2685 2533 1926 3596 2081 120 465 1847 3279 813 3239 655 2605 2213 648 2579 2110 234 924 3684 2436 1540 2049 4087 4046 3882 3226 604 2402 1402 1499 1888 3441 1462 1737 2839 3151 301 1190 650 2585 2135 333 1317 1159 526 2092 162 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   guid: train-4591
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   input_ids: 2 363 1439 1645 2472 1681 2613 2248 787 3135 240 948 3777 2806 3020 3873 3189 456 1811 3133 231 909 3624 2196 578 2300 996 3972 3586 2043 4062 3946 3484 1634 2427 1503 1901 3494 1673 2582 2122 282 1114 347 1373 1382 1419 1565 2150 395 1567 2159 430 1708 2722 2682 2524 1892 3460 1538 2044 4067 3967 3565 1960 3731 2621 2278 908 3619 2175 493 1957 3717 2566 2058 26 91 351 1391 1454 1706 2715 2654 2409 1430 1610 2331 1119 366 1450 1690 2650 2393 1366 1355 1311 1134 428 1699 2687 2542 1963 3742 2667 2463 1647 2479 1711 2734 2732 2723 2687 2543 1967 3758 2730 2714 2651 2397 1382 1419 1567 2158 426 1690 2650 2395 1373 1384 1425 1591 2254 811 3230 617 2456 1617 2360 1235 830 3306 922 3676 2401 1400 1490 1850 3291 863 3439 1454 1708 2722 2682 2524 1890 3449 1496 1874 3386 1244 866 3451 1503 1902 3499 1695 2670 2475 1695 2670 2476 1700 2690 2556 2020 3969 3576 2003 3901 3304 915 3646 2282 922 3674 2395 1373 1381 1413 1543 2062 43 159 622 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   Writing example 0/1529
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   guid: train-6119
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   input_ids: 2 1377 1400 1489 1846 3274 793 3160 338 1338 1242 858 3418 1369 1366 1355 1309 1126 393 1560 2131 317 1253 903 3600 2098 188 738 2940 3556 1921 3573 1989 3846 3082 27 94 364 1441 1653 2504 1811 3134 236 929 3703 2509 1830 3212 545 2165 456 1810 3130 220 868 3458 1530 2010 3932 3425 1398 1483 1823 3184 434 1724 2786 2940 3554 1916 3553 1909 3527 1805 3110 138 540 2146 380 1507 1919 3566 1962 3738 2651 2399 1389 1448 1682 2620 2274 890 3545 1877 3400 1298 1083 222 874 3484 1633 2424 1490 1851 3293 872 3473 1591 2253 808 3217 568 2259 829 3302 907 3616 2163 446 1772 2979 3711 2543 1968 3762 2748 2785 2934 3529 1816 3155 319 1261 935 3726 2604 2210 634 2522 1882 3418 1372 1377 1398 1481 1813 3141 263 1038 43 157 613 2439 1551 2093 166 652 2593 2168 466 1849 3286 841 3349 1093 261 1029 8 18 57 215 847 3374 1196 676 2689 2550 1996 3875 3199 496 1969 3768 2771 2877 3304 913 3640 2258 826 3289 854 3404 1315 1152 497 1974 3788 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   guid: train-4592
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   input_ids: 2 2536 1937 3640 2260 835 3326 1004 4003 3712 2546 1977 3798 2890 3356 1121 373 1480 1812 3139 254 1004 4003 3710 2539 1950 3691 2462 1644 2465 1653 2504 1811 3134 235 927 3695 2478 1708 2723 2687 2543 1967 3757 2728 2708 2626 2299 989 3943 3472 1587 2239 752 2995 3775 2800 2996 3778 2810 3035 3935 3437 1448 1681 2614 2252 801 3189 454 1803 3103 109 424 1681 2616 2258 828 3300 900 3588 2052 4099 4093 4072 3988 3651 2303 1006 4010 3739 2656 2418 1468 1763 2941 3559 1936 3634 2236 740 2947 3583 2032 4018 3772 2788 2947 3583 2032 4018 3772 2788 2947 3583 2032 4020 3778 2812 3044 3971 3583 2030 4011 3742 2668 2466 1660 2531 1919 3568 1970 3772 2788 2947 3582 2028 4002 3708 2530 1914 3547 1885 3431 1424 1588 2244 771 3069 4070 3978 3610 2138 347 1376 1393 1463 1741 2856 3218 572 2274 890 3546 1883 3423 1392 1458 1724 2787 2941 3557 1928 3602 2108 228 900 3587 2046 4073 3990 3660 2337 1144 467 1853 3303 910 3625 2199 592 2355 1215 752 2993 3768 2772 2883 3328 1011 4031 3823 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   guid: train-6120
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   input_ids: 2 2662 2444 1572 2179 511 2030 4011 3743 2671 2480 1714 2747 2782 2922 3483 1631 2415 1453 1704 2708 2628 2307 1023 4080 4018 3771 2783 2927 3502 1707 2719 2669 2469 1672 2579 2109 231 910 3628 2212 643 2559 2030 4011 3741 2663 2447 1582 2219 670 2668 2465 1656 2515 1853 3304 915 3646 2283 925 3686 2441 1560 2132 323 1277 999 3984 3636 2243 767 3055 4013 3751 2704 2610 2234 732 2913 3445 1479 1806 3114 155 607 2416 1458 1724 2787 2944 3571 1984 3828 3009 3830 3020 3873 3189 456 1811 3135 240 947 3774 2796 2978 3707 2527 1902 3498 1691 2654 2411 1438 1642 2460 1635 2429 1511 1935 3631 2222 683 2718 2667 2463 1648 2483 1727 2797 2983 3728 2612 2243 767 3053 4007 3727 2608 2227 703 2797 2984 3731 2622 2283 927 3694 2475 1695 2671 2479 1711 2736 2737 2744 2772 2883 3327 1008 4019 3775 2798 2988 3747 2688 2547 1983 3822 2988 3747 2685 2535 1935 3629 2214 651 2590 2155 415 1646 2476 1699 2685 2536 1939 3646 2283 926 3691 2464 1651 2493 1767 2958 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   guid: train-7646
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   input_ids: 2 1025 4088 4052 3908 3330 1019 4061 3942 3467 1565 2150 395 1565 2151 398 1580 2211 639 2543 1967 3760 2738 2748 2786 2940 3553 1911 3536 1843 3264 755 3006 3820 2977 3703 2512 1841 3254 715 2846 3180 418 1659 2527 1903 3503 1709 2727 2703 2608 2227 703 2797 2983 3725 2600 2195 574 2283 925 3685 2439 1552 2100 196 770 3067 4064 3956 3523 1791 3053 4007 3727 2605 2214 651 2589 2149 391 1552 2099 191 749 2981 3719 2576 2098 188 739 2941 3560 1940 3650 2300 996 3972 3585 2039 4047 3885 3240 659 2622 2284 931 3711 2544 1972 3779 2816 3059 4031 3823 2989 3752 2707 2622 2284 931 3711 2544 1972 3779 2814 3051 3997 3688 2452 1604 2305 1015 4048 3891 3263 752 2995 3775 2798 2988 3748 2692 2563 2045 4069 3975 3600 2100 196 772 3074 4092 4067 3965 3560 1938 3644 2275 895 3566 1964 3748 2691 2559 2029 4006 3724 2596 2180 515 2046 4076 4004 3716 2564 2051 4095 4078 4010 3739 2654 2412 1444 1668 2563 2045 4072 3988 3649 2293 967 3855 3120 178 700 2788 2948 3585 2038 4043 3872 3187 447 1773 2984 3731 2624 2290 955 3807 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   guid: train-6121
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   input_ids: 2 2472 1684 2628 2307 1023 4078 4011 3742 2666 2457 1623 2383 1326 1196 675 2685 2533 1925 3592 2067 63 238 939 3743 2669 2472 1684 2625 2293 966 3851 3102 108 417 1653 2504 1812 3137 247 975 3887 3245 677 2696 2579 2111 238 940 3747 2688 2545 1975 3791 2861 3239 656 2609 2232 724 2881 3317 967 3855 3117 168 657 2615 2253 808 3217 565 2245 776 3090 60 228 899 3581 2022 3978 3612 2146 380 1507 1917 3560 1939 3645 2278 906 3610 2139 351 1391 1456 1713 2742 2761 2839 3151 302 1193 664 2641 2357 1221 776 3089 56 209 821 3272 785 3128 212 833 3320 978 3897 3285 837 3335 1037 40 147 573 2277 901 3590 2060 33 117 456 1809 3127 206 811 3229 614 2442 1564 2147 384 1521 1973 3782 2828 3106 124 484 1924 3588 2049 4086 4041 3862 3146 284 1121 375 1487 1837 3238 649 2584 2132 322 1276 996 3972 3587 2048 4083 4031 3823 2989 3750 2700 2594 2172 483 1917 3558 1932 3617 2165 454 1802 3098 89 343 1360 1331 1213 741 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   guid: train-7647
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   input_ids: 2 3768 2772 2881 3319 976 3889 3256 723 2878 3308 931 3712 2547 1984 3827 3007 3824 2995 3774 2794 2972 3683 2432 1523 1982 3819 2975 3695 2480 1716 2755 2815 3055 4016 3763 2750 2795 2974 3692 2467 1662 2540 1956 3716 2564 2052 4100 4099 4096 4083 4030 3820 2980 3715 2560 2036 4035 3840 3059 4029 3816 2963 3646 2282 924 3683 2432 1523 1982 3820 2979 3710 2540 1956 3716 2563 2047 4078 4010 3740 2660 2436 1539 2046 4076 4003 3710 2540 1955 3709 2535 1936 3635 2240 754 3002 3804 2915 3454 1516 1955 3710 2540 1956 3714 2556 2019 3966 3564 1955 3710 2540 1955 3710 2540 1956 3714 2556 2019 3966 3564 1955 3710 2540 1955 3710 2540 1954 3708 2531 1919 3568 1971 3775 2798 2988 3747 2688 2548 1985 3832 3028 3907 3326 1004 4003 3712 2548 1988 3843 3071 4079 4016 3764 2756 2819 3071 4079 4016 3763 2752 2803 3006 3819 2976 3699 2496 1779 3007 3824 2995 3773 2792 2963 3647 2287 944 3764 2755 2814 3052 4002 3707 2528 1907 3518 1772 2977 3703 2511 1840 3249 695 2767 2863 3248 691 2750 2796 2980 3714 2556 2020 3971 3583 2032 4017 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   Writing example 0/1529
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   guid: train-7648
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   input_ids: 2 4001 3703 2510 1834 3227 606 2411 1437 1640 2449 1590 2250 793 3160 340 1348 1284 1025 4088 4052 3908 3329 1013 4040 3860 3140 259 1022 4075 3997 3688 2451 1597 2280 915 3648 2290 955 3808 2932 3524 1796 3073 4088 4049 3896 3282 826 3292 868 3460 1540 2050 4089 4055 3918 3370 1180 612 2435 1535 2030 4010 3739 2653 2405 1415 1550 2091 159 622 2476 1698 2682 2522 1884 3425 1397 1479 1806 3116 164 643 2560 2033 4022 3785 2838 3145 280 1108 321 1270 971 3870 3178 412 1634 2428 1507 1918 3564 1953 3702 2506 1818 3162 347 1373 1384 1427 1599 2286 939 3743 2670 2474 1690 2650 2396 1380 1412 1540 2049 4086 4044 3876 3201 501 1991 3854 3114 155 605 2405 1415 1552 2099 190 746 2971 3678 2410 1434 1628 2401 1397 1480 1811 3135 239 942 3754 2713 2646 2380 1313 1141 455 1807 3117 165 648 2577 2101 197 775 3087 46 170 667 2656 2418 1466 1755 2909 3432 1428 1601 2295 975 3886 3243 669 2661 2437 1541 2054 11 29 101 389 1543 2063 47 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   guid: train-9175
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   input_ids: 2 605 2408 1427 1597 2279 909 3623 2189 551 2191 557 2216 657 2613 2246 779 3101 103 399 1582 2220 674 2684 2531 1919 3567 1967 3757 2728 2705 2613 2245 776 3091 61 231 912 3636 2243 766 3050 3996 3683 2430 1514 1948 3682 2427 1503 1903 3501 1703 2703 2607 2223 685 2728 2708 2628 2306 1018 4058 3931 3422 1385 1429 1606 2314 1051 93 360 1428 1601 2296 978 3898 3291 862 3436 1444 1668 2563 2048 4084 4036 3844 3075 4094 4076 4004 3713 2552 2001 3893 3270 780 3106 122 475 1887 3439 1455 1712 2740 2753 2808 3025 3894 3274 795 3166 364 1441 1654 2508 1827 3198 490 1946 3675 2398 1387 1438 1644 2467 1661 2536 1940 3649 2296 979 3903 3309 935 3725 2600 2194 570 2267 861 3429 1416 1555 2109 232 913 3640 2257 824 3284 833 3319 974 3884 3235 640 2548 1985 3832 3028 3907 3326 1002 3996 3681 2424 1489 1847 3277 808 3220 577 2293 965 3848 3089 56 210 826 3290 860 3425 1398 1481 1816 3156 322 1274 987 3935 3437 1448 1684 2625 2295 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   guid: train-7649
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   input_ids: 2 3756 2724 2691 2559 2032 4020 3780 2819 3070 4073 3991 3661 2342 1161 535 2127 301 1191 653 2598 2188 548 2178 507 2015 3952 3506 1724 2786 2940 3554 1913 3543 1869 3367 1165 551 2192 563 2240 754 3004 3810 2940 3556 1924 3588 2052 4100 4099 4095 4079 4016 3761 2744 2769 2872 3281 823 3279 813 3238 652 2596 2179 510 2027 3997 3688 2452 1601 2295 973 3880 3220 580 2305 1013 4038 3851 3102 108 420 1665 2552 2001 3896 3281 822 3276 803 3198 492 1953 3701 2503 1806 3114 156 612 2436 1539 2046 4074 3996 3684 2436 1539 2046 4074 3996 3684 2435 1535 2030 4010 3740 2660 2435 1535 2029 4006 3724 2596 2180 515 2045 4071 3984 3635 2238 748 2979 3712 2547 1982 3818 2972 3683 2432 1523 1981 3816 2964 3652 2308 1027 4095 4079 4016 3763 2752 2804 3012 3843 3070 4076 4001 3704 2516 1859 3328 1009 4024 3796 2884 3330 1019 4061 3944 3473 1592 2259 830 3306 923 3679 2413 1448 1682 2617 2264 852 3395 1278 1004 4002 3708 2532 1922 3579 2015 3950 3499 1693 2662 2443 1565 2149 392 1555 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   guid: train-9176
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   input_ids: 2 3295 880 3508 1731 2815 3053 4008 3731 2622 2283 928 3700 2500 1794 3067 4063 3951 3504 1715 2752 2804 3009 3829 3016 3858 3132 228 899 3581 2024 3988 3652 2308 1025 4088 4051 3904 3316 962 3836 3042 3964 3555 1920 3571 1983 3823 2992 3764 2756 2820 3076 4099 4095 4079 4013 3752 2707 2624 2291 960 3828 3012 3843 3071 4078 4010 3740 2660 2435 1536 2036 4033 3829 3016 3857 3128 212 833 3320 980 3905 3320 980 3905 3320 980 3905 3320 980 3905 3320 980 3907 3325 1000 3985 3640 2257 821 3272 785 3128 211 829 3303 912 3636 2241 760 3028 3906 3324 996 3972 3587 2048 4082 4028 3812 2947 3584 2034 4026 3803 2910 3435 1439 1646 2476 1700 2691 2559 2031 4016 3763 2751 2799 2989 3751 2701 2600 2195 576 2292 964 3844 3076 4100 4099 4094 4073 3992 3666 2363 1246 875 3488 1652 2499 1791 3053 4007 3728 2611 2239 752 2994 3769 2776 2898 3385 1239 845 3367 1165 550 2187 543 2158 428 1699 2686 2538 1948 3683 2431 1519 1965 3751 2704 2611 2239 749 2982 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   guid: train-9177
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   input_ids: 2 1501 1894 3468 1570 2172 481 1911 3535 1837 3239 654 2604 2209 631 2511 1840 3250 698 2780 2915 3455 1519 1967 3759 2733 2727 2703 2606 2219 669 2663 2446 1580 2211 639 2543 1966 3754 2716 2657 2424 1490 1851 3295 879 3501 1703 2702 2604 2209 631 2511 1838 3243 671 2671 2480 1713 2744 2772 2883 3325 1000 3987 3645 2278 905 3605 2120 275 1085 232 916 3649 2296 977 3896 3281 821 3272 785 3125 200 788 3139 254 1001 3992 3666 2363 1247 878 3498 1692 2660 2435 1533 2023 3981 3621 2184 532 2115 255 1007 4015 3760 2737 2744 2772 2884 3331 1021 4072 3987 3647 2285 935 3725 2600 2195 575 2286 939 3744 2676 2499 1791 3054 4012 3748 2691 2559 2030 4011 3743 2670 2476 1699 2685 2534 1931 3615 2157 424 1681 2616 2258 827 3293 871 3471 1581 2215 655 2605 2215 655 2606 2220 675 2685 2536 1939 3646 2282 922 3676 2404 1411 1535 2029 4008 3729 2616 2259 831 3312 945 3765 2760 2836 3140 259 1023 4077 4008 3730 2619 2271 879 3503 1712 2738 2748 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   Writing example 0/1535
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   guid: train-7650
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   input_ids: 2 2084 131 512 2033 4023 3791 2862 3243 671 2670 2475 1695 2669 2470 1675 2590 2156 419 1661 2536 1939 3645 2280 916 3649 2294 972 3876 3203 511 2030 4011 3744 2673 2486 1740 2851 3200 500 1986 3835 3039 3950 3498 1692 2658 2425 1495 1869 3366 1163 542 2154 412 1636 2433 1528 2002 3899 3295 878 3498 1689 2647 2384 1330 1209 728 2898 3388 1251 895 3565 1960 3732 2627 2301 999 3982 3628 2211 637 2536 1939 3646 2283 928 3697 2485 1735 2829 3110 139 542 2155 415 1646 2475 1695 2670 2475 1695 2669 2470 1676 2595 2173 487 1934 3628 2211 637 2536 1940 3652 2308 1028 4099 4096 4084 4035 3837 3048 3987 3646 2283 925 3688 2451 1599 2287 943 3759 2733 2727 2701 2600 2196 579 2303 1006 4012 3745 2680 2516 1859 3327 1007 4015 3759 2735 2733 2726 2698 2587 2142 364 1444 1667 2559 2031 4014 3754 2716 2660 2436 1540 2050 4089 4054 3913 3351 1102 299 1183 624 2484 1732 2819 3069 4072 3988 3652 2308 1027 4094 4075 3997 3688 2449 1589 2248 787 3133 230 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   guid: train-9178
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   input_ids: 2 2720 2676 2499 1792 3059 4032 3825 2999 3789 2856 3219 575 2287 943 3759 2735 2734 2731 2719 2671 2480 1715 2752 2801 3000 3795 2879 3311 941 3751 2701 2600 2193 567 2256 819 3264 755 3008 3827 3005 3815 2957 3624 2195 575 2288 947 3773 2792 2964 3650 2300 996 3969 3576 2003 3904 3316 961 3831 3022 3883 3229 616 2451 1599 2286 938 3738 2649 2390 1354 1307 1119 368 1459 1728 2803 3007 3822 2987 3744 2676 2499 1789 3048 3988 3651 2304 1012 4036 3844 3076 4098 4092 4068 3972 3588 2052 4099 4096 4084 4036 3844 3075 4096 4084 4035 3838 3051 3997 3688 2451 1597 2280 916 3652 2307 1024 4083 4031 3823 2989 3752 2707 2621 2278 907 3614 2155 415 1646 2475 1696 2675 2493 1767 2957 3622 2188 548 2179 510 2025 3992 3668 2371 1277 999 3983 3632 2227 704 2804 3011 3837 3047 3984 3634 2236 740 2945 3573 1992 3859 3133 232 915 3647 2286 940 3747 2688 2548 1988 3842 3065 4056 3921 3384 1236 835 3328 1012 4036 3843 3069 4072 3988 3650 2297 984 3922 3388 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   guid: train-9179
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   guid: train-10704
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   input_ids: 2 2705 2616 2257 824 3281 821 3269 776 3089 53 197 776 3090 60 225 887 3535 1838 3243 670 2667 2462 1644 2465 1656 2516 1860 3330 1019 4062 3948 3490 1660 2530 1915 3550 1899 3487 1646 2473 1687 2639 2350 1196 676 2691 2558 2026 3995 3680 2417 1463 1742 2859 3231 624 2484 1732 2820 3075 4095 4078 4011 3744 2676 2498 1786 3035 3934 3434 1433 1622 2380 1313 1144 468 1860 3332 1027 4094 4076 4003 3711 2544 1972 3780 2819 3070 4076 4003 3712 2547 1982 3819 2974 3691 2462 1642 2459 1630 2410 1435 1630 2410 1435 1631 2415 1455 1710 2731 2719 2669 2472 1684 2628 2306 1019 4063 3950 3500 1700 2692 2563 2047 4078 4011 3741 2664 2452 1601 2296 977 3894 3276 802 3196 481 1912 3539 1853 3301 903 3597 2085 136 529 2101 197 774 3081 24 83 318 1257 920 3668 2369 1272 978 3897 3288 852 3393 1270 972 3873 3189 456 1812 3139 253 1000 3988 3652 2306 1019 4061 3944 3473 1589 2245 773 3079 15 47 174 681 2711 2638 2348 1188 643 2558 2028 4004 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   input_ids: 2 1484 1828 3202 508 2017 3959 3535 1838 3243 671 2670 2476 1697 2677 2502 1802 3099 95 367 1455 1711 2733 2728 2707 2624 2292 964 3844 3075 4093 4072 3985 3639 2256 820 3268 772 3073 4085 4040 3859 3135 237 936 3732 2628 2307 1023 4077 4007 3727 2607 2222 682 2713 2647 2383 1325 1191 654 2604 2209 629 2504 1812 3137 248 979 3903 3311 943 3759 2733 2725 2693 2566 2059 31 109 423 1679 2605 2215 655 2605 2213 645 2568 2067 63 237 935 3727 2605 2216 658 2620 2275 895 3568 1969 3765 2757 2823 3087 45 168 659 2622 2283 927 3696 2481 1717 2760 2835 3135 240 947 3775 2800 2996 3779 2813 3047 3983 3629 2213 645 2568 2067 63 237 935 3727 2605 2213 646 2572 2083 127 493 1957 3717 2568 2067 63 238 939 3743 2669 2472 1683 2621 2279 911 3631 2223 687 2733 2725 2693 2568 2067 61 232 916 3651 2301 999 3983 3630 2218 668 2658 2427 1504 1906 3516 1761 2935 3535 1839 3245 680 2707 2623 2285 935 3725 2599 2190 555 2205 614 2444 1572 2177 504 2001 3894 3276 803 3198 490 1946 3674 2396 1378 1402 1499 1887 3439 1455 1711 2734 2732 2721 2680 2516 1858 3322 988 3938 3449 1496 1873 3384 1236 835 3326 1002 3995 3678 2412 1443 1662 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   guid: train-10705
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   input_ids: 2 532 2116 259 1021 4071 3982 3627 2206 619 2462 1643 2463 1646 2475 1693 2664 2452 1604 2306 1020 4065 3959 3535 1839 3247 685 2727 2703 2606 2219 671 2669 2469 1671 2575 2095 175 688 2739 2751 2797 2984 3731 2623 2287 942 3756 2721 2679 2511 1838 3241 663 2639 2349 1191 654 2603 2205 615 2447 1582 2219 671 2669 2472 1684 2626 2300 995 3966 3563 1949 3688 2452 1602 2300 996 3972 3588 2050 4091 4061 3944 3474 1593 2264 852 3393 1270 972 3875 3200 500 1988 3843 3071 4077 4007 3728 2610 2234 731 2911 3439 1455 1710 2732 2723 2687 2543 1967 3757 2728 2705 2613 2246 779 3101 103 400 1588 2243 766 3052 4002 3708 2530 1915 3549 1895 3469 1576 2195 574 2283 925 3688 2452 1602 2299 990 3948 3492 1667 2558 2027 3999 3693 2472 1683 2622 2284 932 3713 2552 2004 3908 3332 1025 4085 4037 3848 3092 66 251 990 3946 3484 1633 2422 1481 1816 3156 324 1282 1019 4063 3951 3503 1711 2733 2728 2707 2623 2286 939 3744 2675 2494 1771 2975 3693 2471 1678 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   guid: train-10706
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   input_ids: 2 2515 1855 3312 948 3779 2815 3055 4015 3759 2733 2728 2708 2628 2307 1023 4077 4008 3731 2621 2279 912 3636 2243 767 3056 4018 3771 2781 2919 3472 1586 2236 737 2934 3529 1816 3155 320 1267 959 3823 2989 3752 2708 2627 2301 1000 3987 3645 2279 909 3622 2185 536 2131 320 1265 950 3788 2851 3200 497 1976 3796 2883 3325 1000 3987 3647 2288 948 3779 2815 3055 4013 3752 2707 2624 2292 963 3837 3046 3979 3615 2157 423 1679 2606 2219 672 2676 2499 1792 3060 4033 3832 3027 3903 3312 947 3775 2800 2994 3771 2782 2923 3487 1648 2481 1717 2760 2834 3131 223 879 3501 1704 2707 2624 2290 956 3810 2940 3556 1923 3581 2024 3986 3644 2273 887 3533 1832 3220 580 2305 1016 4051 3904 3316 964 3844 3075 4093 4072 3987 3648 2289 950 3788 2850 3196 484 1921 3573 1992 3860 3139 254 1004 4003 3710 2537 1944 3667 2366 1260 932 3715 2559 2029 4008 3729 2616 2260 835 3327 1005 4008 3729 2616 2260 834 3323 991 3952 3506 1724 2788 2948 3588 2051 4095 4079 4015 3757 2727 2703 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   guid: train-10707
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   input_ids: 2 2039 4048 3889 3253 712 2835 3134 236 929 3702 2505 1814 3147 288 1140 449 1783 3023 3887 3246 684 2724 2692 2563 2047 4077 4005 3717 2568 2067 63 239 944 3764 2753 2806 3019 3871 3181 424 1684 2627 2304 1012 4036 3841 3064 4051 3901 3304 913 3637 2248 787 3134 233 917 3653 2312 1043 63 237 933 3717 2568 2067 63 239 941 3749 2696 2577 2104 209 824 3282 828 3300 899 3581 2024 3986 3644 2275 895 3565 1960 3731 2621 2279 910 3628 2212 642 2556 2019 3967 3565 1960 3730 2617 2263 847 3373 1189 646 2569 2069 71 269 1064 146 572 2275 895 3565 1960 3730 2620 2275 895 3565 1960 3730 2620 2275 895 3565 1960 3731 2621 2279 911 3629 2216 658 2620 2276 898 3580 2020 3971 3582 2026 3995 3677 2408 1426 1596 2275 894 3564 1956 3714 2556 2019 3967 3565 1960 3731 2623 2286 940 3745 2679 2511 1840 3251 703 2797 2983 3726 2603 2206 619 2461 1639 2445 1574 2186 538 2140 356 1412 1539 2046 4075 3998 3690 2459 1632 2419 1470 1772 2980 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   guid: train-10708
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   input_ids: 2 1505 1912 3540 1860 3330 1020 4065 3958 3531 1823 3181 421 1672 2577 2101 197 776 3089 53 199 784 3121 184 721 2869 3269 776 3092 68 259 1022 4074 3994 3676 2401 1400 1489 1845 3271 782 3113 150 585 2325 1093 261 1030 12 35 126 489 1944 3665 2360 1233 822 3274 794 3164 356 1411 1534 2028 4002 3708 2529 1910 3530 1817 3160 339 1343 1263 942 3756 2724 2692 2564 2049 4087 4045 3877 3207 526 2091 159 621 2469 1672 2577 2103 207 815 3245 679 2703 2607 2222 684 2722 2681 2517 1862 3340 1059 127 495 1968 3763 2749 2792 2964 3649 2295 974 3883 3232 628 2498 1786 3036 3937 3446 1484 1828 3201 504 2004 3905 3320 977 3895 3279 814 3244 676 2692 2561 2040 4050 3900 3298 891 3549 1896 3476 1604 2306 1020 4066 3962 3548 1889 3448 1490 1852 3300 897 3576 2001 3896 3281 822 3276 804 3202 508 2019 3966 3563 1949 3688 2449 1591 2254 811 3229 616 2452 1604 2307 1022 4073 3990 3657 2327 1103 303 1198 684 2721 2680 2516 1857 3318 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:22:46 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 19:22:51 - INFO - __main__ -   Saving features into cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_train_6-new-12w-0_300_dnaprom
06/26/2023 19:22:55 - INFO - __main__ -   ***** Running training *****
06/26/2023 19:22:55 - INFO - __main__ -     Num examples = 12238
06/26/2023 19:22:55 - INFO - __main__ -     Num Epochs = 30
06/26/2023 19:22:55 - INFO - __main__ -     Instantaneous batch size per GPU = 48
06/26/2023 19:22:55 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 48
06/26/2023 19:22:55 - INFO - __main__ -     Gradient Accumulation steps = 1
06/26/2023 19:22:55 - INFO - __main__ -     Total optimization steps = 7650
06/26/2023 19:22:55 - INFO - __main__ -     Continuing training from checkpoint, will skip to saved global_step
06/26/2023 19:22:55 - INFO - __main__ -     Continuing training from epoch 0
06/26/2023 19:22:55 - INFO - __main__ -     Continuing training from global step 0
06/26/2023 19:22:55 - INFO - __main__ -     Will skip the first 0 steps in the first epoch
06/26/2023 19:23:37 - INFO - __main__ -   Creating features from dataset file at /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   Writing example 0/1529
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   guid: dev-1
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   input_ids: 2 2564 2050 4091 4061 3944 3476 1604 2308 1027 4095 4077 4006 3724 2593 2167 462 1834 3227 607 2413 1446 1674 2586 2139 351 1392 1457 1719 2766 2860 3235 637 2536 1938 3642 2267 862 3434 1434 1627 2397 1384 1426 1594 2267 862 3434 1435 1629 2408 1427 1597 2280 913 3639 2253 805 3208 530 2106 220 868 3459 1535 2029 4005 3720 2577 2102 202 794 3163 349 1382 1419 1566 2154 411 1629 2406 1418 1561 2133 326 1291 1054 107 415 1646 2475 1693 2662 2443 1568 2161 440 1746 2874 3291 862 3434 1435 1630 2410 1436 1633 2422 1483 1822 3180 417 1653 2502 1802 3098 91 350 1388 1443 1662 2540 1954 3708 2531 1918 3563 1950 3692 2465 1655 2509 1830 3210 537 2134 330 1306 1114 346 1370 1371 1374 1385 1429 1605 2310 1033 22 74 281 1110 330 1306 1114 345 1367 1358 1321 1176 593 2357 1221 773 3080 17 53 200 785 3125 198 777 3093 70 267 1053 101 389 1544 2065 54 204 801 3190 458 1818 3162 346 1369 1365 1349 1285 1029 8 17 53 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   guid: dev-2
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   input_ids: 2 2946 3577 2007 3918 3371 1184 628 2499 1791 3053 4008 3730 2619 2270 876 3492 1667 2560 2035 4031 3824 2995 3775 2800 2994 3770 2779 2910 3435 1439 1646 2474 1692 2657 2424 1489 1848 3283 831 3310 939 3741 2661 2440 1556 2115 256 1011 4032 3827 3008 3828 3011 3839 3053 4005 3720 2579 2112 243 958 3820 2980 3715 2560 2035 4029 3816 2963 3646 2283 928 3698 2491 1760 2931 3518 1772 2978 3705 2520 1876 3396 1284 1028 4099 4095 4077 4008 3729 2614 2252 803 3200 498 1980 3811 2943 3567 1965 3752 2706 2620 2276 900 3587 2046 4075 3997 3688 2451 1598 2282 923 3678 2411 1438 1642 2460 1635 2429 1512 1939 3646 2283 928 3698 2492 1763 2941 3560 1939 3646 2282 923 3678 2412 1444 1667 2560 2035 4032 3827 3008 3827 3007 3823 2990 3755 2718 2666 2460 1636 2433 1528 2003 3902 3307 926 3692 2467 1664 2547 1984 3827 3005 3816 2963 3648 2292 963 3838 3051 3999 3693 2471 1679 2606 2218 667 2654 2412 1444 1667 2560 2036 4034 3833 3032 3921 3384 1235 830 3307 927 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   guid: dev-3
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   input_ids: 2 1406 1516 1954 3706 2522 1883 3421 1384 1427 1598 2282 922 3673 2389 1349 1286 1034 27 93 357 1413 1541 2054 10 25 86 329 1302 1098 282 1115 350 1385 1429 1605 2309 1032 18 60 227 894 3564 1956 3713 2550 1994 3866 3162 346 1370 1370 1370 1370 1370 1370 1369 1368 1364 1347 1280 1010 4026 3802 2907 3421 1382 1419 1565 2149 389 1543 2064 52 196 770 3065 4054 3913 3350 1100 290 1148 482 1915 3550 1898 3482 1625 2391 1359 1325 1189 645 2566 2060 33 120 468 1858 3321 982 3916 3362 1145 470 1867 3358 1132 418 1660 2530 1914 3546 1884 3425 1397 1478 1802 3098 90 346 1370 1370 1370 1372 1378 1402 1498 1882 3417 1368 1361 1336 1235 829 3304 913 3637 2245 775 3085 37 136 529 2101 199 782 3113 151 591 2349 1190 651 2590 2154 412 1633 2423 1485 1829 3206 521 2070 74 281 1109 328 1298 1083 222 874 3483 1631 2413 1445 1670 2571 2079 109 422 1676 2596 2178 505 2007 3917 3368 1171 574 2281 919 3662 2346 1178 604 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   Writing example 0/1529
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   guid: dev-4
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   input_ids: 2 666 2649 2389 1349 1288 1043 61 232 915 3645 2278 907 3613 2150 393 1557 2117 263 1037 38 139 541 2150 394 1562 2140 354 1404 1505 1912 3537 1847 3277 806 3210 539 2143 365 1446 1675 2589 2150 396 1570 2169 469 1864 3345 1077 199 783 3118 171 671 2671 2479 1709 2725 2696 2580 2113 246 971 3869 3176 403 1599 2285 935 3726 2602 2202 604 2404 1412 1537 2037 4038 3851 3103 111 429 1704 2705 2614 2250 795 3166 362 1435 1630 2410 1436 1633 2421 1478 1802 3098 92 354 1404 1506 1916 3554 1914 3547 1887 3438 1452 1700 2691 2557 2021 3974 3594 2075 96 369 1464 1747 2877 3303 910 3626 2202 602 2395 1373 1383 1421 1576 2194 570 2268 868 3459 1533 2021 3973 3591 2063 47 173 677 2693 2568 2067 62 234 923 3677 2406 1419 1565 2149 389 1541 2056 17 53 198 778 3098 92 354 1404 1506 1916 3555 1917 3557 1925 3592 2065 55 206 812 3233 632 2514 1851 3295 879 3502 1707 2719 2669 2469 1669 2566 2057 23 78 300 1187 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   guid: dev-1530
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   input_ids: 2 4049 3893 3271 782 3113 150 587 2334 1130 410 1626 2396 1378 1404 1505 1911 3533 1830 3210 540 2148 385 1526 1996 3873 3192 465 1846 3274 796 3172 388 1540 2049 4085 4040 3857 3128 212 833 3317 968 3857 3126 204 803 3197 488 1939 3646 2284 931 3709 2535 1933 3622 2187 542 2153 408 1619 2365 1255 909 3621 2184 531 2110 235 926 3689 2456 1618 2363 1245 871 3470 1580 2210 636 2532 1921 3574 1996 3873 3189 456 1810 3129 213 838 3338 1052 97 374 1484 1825 3189 456 1809 3125 199 782 3113 149 581 2310 1033 22 76 292 1153 501 1992 3857 3125 197 774 3084 36 130 505 2005 3909 3333 1029 5 6 10 27 93 357 1413 1542 2058 27 93 359 1422 1578 2202 602 2394 1369 1367 1357 1318 1162 537 2136 337 1334 1228 801 3189 454 1802 3097 85 326 1290 1052 97 375 1487 1837 3237 648 2577 2102 204 801 3190 458 1820 3171 381 1510 1930 3610 2139 351 1391 1453 1703 2701 2600 2194 572 2273 885 3527 1807 3118 169 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   guid: dev-5
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   input_ids: 2 1545 2070 75 286 1129 406 1609 2328 1105 312 1234 827 3294 874 3482 1626 2395 1375 1389 1445 1671 2574 2089 150 586 2329 1109 327 1295 1070 171 669 2661 2440 1555 2112 243 958 3818 2969 3672 2387 1342 1260 932 3713 2552 2004 3905 3317 968 3857 3128 212 833 3317 966 3849 3093 69 261 1030 11 32 114 443 1758 2922 3483 1629 2405 1413 1544 2066 59 221 870 3467 1565 2150 395 1565 2150 393 1560 2130 315 1245 870 3467 1567 2158 427 1695 2670 2475 1693 2662 2443 1568 2163 447 1775 2990 3755 2717 2664 2449 1589 2248 785 3128 212 833 3320 980 3905 3317 966 3851 3101 102 395 1566 2156 418 1657 2519 1870 3370 1178 603 2398 1386 1435 1631 2414 1451 1693 2662 2441 1559 2126 300 1185 631 2510 1833 3222 585 2328 1106 315 1245 870 3467 1567 2157 423 1679 2606 2219 671 2669 2470 1674 2587 2144 369 1464 1745 2871 3278 811 3231 621 2469 1672 2577 2104 209 824 3281 821 3269 776 3089 56 212 833 3318 971 3869 3175 398 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   guid: dev-1531
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   input_ids: 2 2189 549 2183 525 2085 134 524 2081 120 467 1854 3308 932 3713 2552 2003 3903 3311 941 3751 2703 2607 2223 685 2728 2708 2628 2305 1013 4039 3853 3111 142 555 2206 620 2467 1664 2548 1987 3837 3048 3985 3639 2256 818 3258 730 2908 3425 1400 1489 1845 3270 779 3101 104 404 1602 2300 993 3957 3527 1807 3120 179 701 2790 2954 3611 2142 362 1433 1621 2375 1296 1073 182 716 2851 3199 495 1968 3761 2744 2769 2871 3277 805 3208 529 2103 206 812 3236 643 2558 2027 3998 3692 2467 1662 2539 1949 3688 2449 1589 2245 774 3083 31 111 430 1708 2722 2683 2526 1900 3489 1653 2502 1801 3095 77 293 1158 521 2069 71 270 1066 155 605 2405 1416 1554 2107 222 873 3478 1612 2340 1154 507 2016 3954 3516 1762 2939 3551 1904 3508 1729 2808 3027 3902 3305 917 3653 2312 1044 66 250 987 3935 3437 1445 1672 2577 2102 202 793 3157 327 1293 1062 139 542 2155 415 1647 2477 1704 2708 2626 2300 993 3960 3537 1845 3272 787 3135 238 938 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   guid: dev-1532
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   input_ids: 2 1286 1036 35 125 485 1926 3594 2074 92 356 1409 1525 1989 3846 3083 30 105 406 1612 2339 1150 492 1955 3710 2540 1954 3708 2530 1913 3541 1862 3339 1053 102 395 1565 2149 391 1549 2087 142 556 2210 634 2522 1882 3418 1370 1369 1365 1350 1289 1046 74 283 1117 359 1422 1580 2210 633 2518 1865 3350 1098 282 1114 347 1375 1391 1455 1710 2730 2714 2650 2393 1366 1353 1302 1099 286 1132 419 1661 2536 1940 3651 2301 997 3976 3601 2104 210 826 3290 859 3421 1382 1417 1557 2119 271 1072 178 699 2782 2922 3483 1629 2407 1421 1573 2181 518 2059 31 110 427 1695 2671 2479 1709 2725 2696 2578 2105 216 851 3390 1257 919 3663 2350 1193 662 2635 2333 1127 397 1576 2193 568 2259 829 3301 902 3594 2073 85 325 1288 1042 58 217 855 3405 1320 1170 569 2264 849 3382 1228 804 3201 503 1999 3886 3243 672 2676 2500 1793 3061 4039 3855 3119 173 680 2705 2613 2248 786 3129 213 840 3346 1081 215 846 3371 1183 623 2479 1710 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   guid: dev-1533
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   input_ids: 2 1455 1711 2733 2728 2708 2627 2301 999 3982 3627 2205 615 2447 1584 2225 693 2757 2822 3084 36 131 509 2022 3979 3614 2155 414 1644 2467 1663 2543 1967 3759 2734 2730 2715 2656 2420 1476 1795 3070 4076 4004 3714 2553 2008 3923 3392 1267 959 3821 2984 3732 2626 2300 993 3957 3528 1812 3137 248 977 3894 3276 802 3195 477 1894 3467 1566 2156 417 1656 2513 1847 3279 815 3245 679 2702 2603 2205 615 2446 1580 2212 641 2551 1999 3885 3240 657 2613 2248 788 3137 248 979 3901 3304 915 3645 2280 914 3644 2275 893 3560 1940 3652 2306 1019 4061 3943 3471 1583 2224 692 2756 2817 3064 4051 3903 3311 941 3751 2701 2600 2195 573 2279 911 3629 2214 652 2596 2177 503 1999 3886 3243 671 2671 2478 1708 2722 2683 2528 1908 3522 1788 3042 3961 3541 1861 3335 1039 45 167 656 2609 2230 716 2852 3203 511 2030 4012 3748 2692 2563 2047 4080 4020 3780 2820 3073 4087 4045 3880 3219 573 2279 910 3628 2211 637 2533 1928 3603 2109 231 909 3621 2181 520 2066 60 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   guid: dev-1534
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   input_ids: 2 3725 2600 2194 572 2276 900 3585 2037 4040 3857 3126 203 797 3173 389 1544 2068 68 259 1022 4075 3997 3686 2441 1559 2127 301 1192 659 2621 2280 916 3650 2300 993 3957 3525 1798 3083 29 101 391 1551 2094 171 669 2662 2443 1566 2155 415 1646 2475 1695 2669 2469 1672 2577 2102 204 801 3189 456 1809 3126 201 789 3141 261 1029 6 11 30 108 420 1668 2561 2037 4040 3857 3127 205 808 3217 568 2259 830 3308 929 3703 2510 1834 3227 606 2409 1429 1608 2321 1077 198 780 3106 124 483 1918 3563 1949 3686 2444 1569 2165 455 1806 3115 157 614 2441 1560 2132 322 1273 982 3914 3353 1110 330 1308 1121 376 1489 1847 3278 812 3236 644 2561 2038 4042 3867 3165 359 1422 1580 2212 642 2555 2015 3949 3493 1669 2568 2068 66 252 995 3967 3565 1960 3729 2616 2260 836 3331 1022 4075 3997 3688 2449 1591 2255 815 3245 680 2705 2616 2258 825 3288 851 3389 1253 904 3604 2113 248 978 3899 3293 872 3474 1593 2261 838 3339 1055 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 19:23:37 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 19:23:42 - INFO - __main__ -   Saving features into cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:23:43 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:23:43 - INFO - __main__ -     Num examples = 3058
06/26/2023 19:23:43 - INFO - __main__ -     Batch size = 48
06/26/2023 19:23:52 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:23:52 - INFO - __main__ -     acc = 0.6438848920863309
06/26/2023 19:23:52 - INFO - __main__ -     auc = 0.6957451340788361
06/26/2023 19:23:52 - INFO - __main__ -     f1 = 0.6163674343821506
06/26/2023 19:23:52 - INFO - __main__ -     mcc = 0.3407802803310856
06/26/2023 19:23:52 - INFO - __main__ -     precision = 0.7017779590661516
06/26/2023 19:23:52 - INFO - __main__ -     recall = 0.6438848920863309
06/26/2023 19:23:52 - INFO - __main__ -   {"eval_acc": 0.6438848920863309, "eval_f1": 0.6163674343821506, "eval_mcc": 0.3407802803310856, "eval_auc": 0.6957451340788361, "eval_precision": 0.7017779590661516, "eval_recall": 0.6438848920863309, "learning_rate": 1.3071895424836602e-05, "loss": 0.6802548456192017, "step": 100}
06/26/2023 19:24:36 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:24:37 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:24:37 - INFO - __main__ -     Num examples = 3058
06/26/2023 19:24:37 - INFO - __main__ -     Batch size = 48
06/26/2023 19:24:46 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:24:46 - INFO - __main__ -     acc = 0.6782210595160235
06/26/2023 19:24:46 - INFO - __main__ -     auc = 0.7374889909108447
06/26/2023 19:24:46 - INFO - __main__ -     f1 = 0.6717303422562942
06/26/2023 19:24:46 - INFO - __main__ -     mcc = 0.37143295896081435
06/26/2023 19:24:46 - INFO - __main__ -     precision = 0.6935271333492186
06/26/2023 19:24:46 - INFO - __main__ -     recall = 0.6782210595160236
06/26/2023 19:24:46 - INFO - __main__ -   {"eval_acc": 0.6782210595160235, "eval_f1": 0.6717303422562942, "eval_mcc": 0.37143295896081435, "eval_auc": 0.7374889909108447, "eval_precision": 0.6935271333492186, "eval_recall": 0.6782210595160236, "learning_rate": 2.6143790849673204e-05, "loss": 0.6115321245789528, "step": 200}
06/26/2023 19:25:29 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:25:30 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:25:30 - INFO - __main__ -     Num examples = 3058
06/26/2023 19:25:30 - INFO - __main__ -     Batch size = 48
06/26/2023 19:25:39 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:25:39 - INFO - __main__ -     acc = 0.6756049705689994
06/26/2023 19:25:39 - INFO - __main__ -     auc = 0.744480484344316
06/26/2023 19:25:39 - INFO - __main__ -     f1 = 0.6748638377851861
06/26/2023 19:25:39 - INFO - __main__ -     mcc = 0.3528221076332913
06/26/2023 19:25:39 - INFO - __main__ -     precision = 0.6772208372454431
06/26/2023 19:25:39 - INFO - __main__ -     recall = 0.6756049705689993
06/26/2023 19:25:39 - INFO - __main__ -   {"eval_acc": 0.6756049705689994, "eval_f1": 0.6748638377851861, "eval_mcc": 0.3528221076332913, "eval_auc": 0.744480484344316, "eval_precision": 0.6772208372454431, "eval_recall": 0.6756049705689993, "learning_rate": 3.9215686274509805e-05, "loss": 0.5903451055288315, "step": 300}
06/26/2023 19:26:23 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:26:24 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:26:24 - INFO - __main__ -     Num examples = 3058
06/26/2023 19:26:24 - INFO - __main__ -     Batch size = 48
06/26/2023 19:26:33 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:26:33 - INFO - __main__ -     acc = 0.7037279267495095
06/26/2023 19:26:33 - INFO - __main__ -     auc = 0.7601179892045695
06/26/2023 19:26:33 - INFO - __main__ -     f1 = 0.7014347693958968
06/26/2023 19:26:33 - INFO - __main__ -     mcc = 0.41386286972001834
06/26/2023 19:26:33 - INFO - __main__ -     precision = 0.7101853163502304
06/26/2023 19:26:33 - INFO - __main__ -     recall = 0.7037279267495095
06/26/2023 19:26:33 - INFO - __main__ -   {"eval_acc": 0.7037279267495095, "eval_f1": 0.7014347693958968, "eval_mcc": 0.41386286972001834, "eval_auc": 0.7601179892045695, "eval_precision": 0.7101853163502304, "eval_recall": 0.7037279267495095, "learning_rate": 5.228758169934641e-05, "loss": 0.575568108856678, "step": 400}
06/26/2023 19:27:17 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:27:17 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:27:17 - INFO - __main__ -     Num examples = 3058
06/26/2023 19:27:17 - INFO - __main__ -     Batch size = 48
06/26/2023 19:27:26 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:27:26 - INFO - __main__ -     acc = 0.6572923479398299
06/26/2023 19:27:26 - INFO - __main__ -     auc = 0.7577942640239435
06/26/2023 19:27:26 - INFO - __main__ -     f1 = 0.6238348658742996
06/26/2023 19:27:26 - INFO - __main__ -     mcc = 0.39193911229132394
06/26/2023 19:27:26 - INFO - __main__ -     precision = 0.7441572488358983
06/26/2023 19:27:26 - INFO - __main__ -     recall = 0.6572923479398299
06/26/2023 19:27:26 - INFO - __main__ -   {"eval_acc": 0.6572923479398299, "eval_f1": 0.6238348658742996, "eval_mcc": 0.39193911229132394, "eval_auc": 0.7577942640239435, "eval_precision": 0.7441572488358983, "eval_recall": 0.6572923479398299, "learning_rate": 6.535947712418301e-05, "loss": 0.5808018162846565, "step": 500}
06/26/2023 19:28:11 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:28:11 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:28:11 - INFO - __main__ -     Num examples = 3058
06/26/2023 19:28:11 - INFO - __main__ -     Batch size = 48
06/26/2023 19:28:20 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:28:20 - INFO - __main__ -     acc = 0.6981687377370831
06/26/2023 19:28:20 - INFO - __main__ -     auc = 0.7681912499609683
06/26/2023 19:28:20 - INFO - __main__ -     f1 = 0.6842066634108737
06/26/2023 19:28:20 - INFO - __main__ -     mcc = 0.436843474592205
06/26/2023 19:28:20 - INFO - __main__ -     precision = 0.7407446092064403
06/26/2023 19:28:20 - INFO - __main__ -     recall = 0.6981687377370831
06/26/2023 19:28:20 - INFO - __main__ -   {"eval_acc": 0.6981687377370831, "eval_f1": 0.6842066634108737, "eval_mcc": 0.436843474592205, "eval_auc": 0.7681912499609683, "eval_precision": 0.7407446092064403, "eval_recall": 0.6981687377370831, "learning_rate": 7.843137254901961e-05, "loss": 0.554637199640274, "step": 600}
06/26/2023 19:29:04 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:29:05 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:29:05 - INFO - __main__ -     Num examples = 3058
06/26/2023 19:29:05 - INFO - __main__ -     Batch size = 48
06/26/2023 19:29:14 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:29:14 - INFO - __main__ -     acc = 0.7040549378678875
06/26/2023 19:29:14 - INFO - __main__ -     auc = 0.7694098957114704
06/26/2023 19:29:14 - INFO - __main__ -     f1 = 0.7027189578121498
06/26/2023 19:29:14 - INFO - __main__ -     mcc = 0.41182817048806614
06/26/2023 19:29:14 - INFO - __main__ -     precision = 0.7077901713377728
06/26/2023 19:29:14 - INFO - __main__ -     recall = 0.7040549378678875
06/26/2023 19:29:14 - INFO - __main__ -   {"eval_acc": 0.7040549378678875, "eval_f1": 0.7027189578121498, "eval_mcc": 0.41182817048806614, "eval_auc": 0.7694098957114704, "eval_precision": 0.7077901713377728, "eval_recall": 0.7040549378678875, "learning_rate": 9.150326797385621e-05, "loss": 0.5512067154049873, "step": 700}
06/26/2023 19:29:57 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:29:57 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:29:57 - INFO - __main__ -     Num examples = 3058
06/26/2023 19:29:57 - INFO - __main__ -     Batch size = 48
06/26/2023 19:30:07 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:30:07 - INFO - __main__ -     acc = 0.7024198822759974
06/26/2023 19:30:07 - INFO - __main__ -     auc = 0.7619923681721726
06/26/2023 19:30:07 - INFO - __main__ -     f1 = 0.6941784916741397
06/26/2023 19:30:07 - INFO - __main__ -     mcc = 0.42859832112256385
06/26/2023 19:30:07 - INFO - __main__ -     precision = 0.7268755899909725
06/26/2023 19:30:07 - INFO - __main__ -     recall = 0.7024198822759974
06/26/2023 19:30:07 - INFO - __main__ -   {"eval_acc": 0.7024198822759974, "eval_f1": 0.6941784916741397, "eval_mcc": 0.42859832112256385, "eval_auc": 0.7619923681721726, "eval_precision": 0.7268755899909725, "eval_recall": 0.7024198822759974, "learning_rate": 9.949164851125636e-05, "loss": 0.5216655018925667, "step": 800}
06/26/2023 19:30:49 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:30:50 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:30:50 - INFO - __main__ -     Num examples = 3058
06/26/2023 19:30:50 - INFO - __main__ -     Batch size = 48
06/26/2023 19:30:59 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:30:59 - INFO - __main__ -     acc = 0.6742969260954872
06/26/2023 19:30:59 - INFO - __main__ -     auc = 0.7767692499190493
06/26/2023 19:30:59 - INFO - __main__ -     f1 = 0.6668233132055658
06/26/2023 19:30:59 - INFO - __main__ -     mcc = 0.3653705509349219
06/26/2023 19:30:59 - INFO - __main__ -     precision = 0.6914773290628111
06/26/2023 19:30:59 - INFO - __main__ -     recall = 0.6742969260954872
06/26/2023 19:30:59 - INFO - __main__ -   {"eval_acc": 0.6742969260954872, "eval_f1": 0.6668233132055658, "eval_mcc": 0.3653705509349219, "eval_auc": 0.7767692499190493, "eval_precision": 0.6914773290628111, "eval_recall": 0.6742969260954872, "learning_rate": 9.80392156862745e-05, "loss": 0.48513779550790787, "step": 900}
06/26/2023 19:31:43 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:31:43 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:31:43 - INFO - __main__ -     Num examples = 3058
06/26/2023 19:31:43 - INFO - __main__ -     Batch size = 48
06/26/2023 19:31:52 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:31:52 - INFO - __main__ -     acc = 0.7168083714846305
06/26/2023 19:31:52 - INFO - __main__ -     auc = 0.7928674362371094
06/26/2023 19:31:52 - INFO - __main__ -     f1 = 0.7085749927810292
06/26/2023 19:31:52 - INFO - __main__ -     mcc = 0.4604116709074106
06/26/2023 19:31:52 - INFO - __main__ -     precision = 0.7444311827723646
06/26/2023 19:31:52 - INFO - __main__ -     recall = 0.7168083714846305
06/26/2023 19:31:52 - INFO - __main__ -   {"eval_acc": 0.7168083714846305, "eval_f1": 0.7085749927810292, "eval_mcc": 0.4604116709074106, "eval_auc": 0.7928674362371094, "eval_precision": 0.7444311827723646, "eval_recall": 0.7168083714846305, "learning_rate": 9.658678286129266e-05, "loss": 0.48610818684101104, "step": 1000}
06/26/2023 19:32:35 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:32:36 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:32:36 - INFO - __main__ -     Num examples = 3058
06/26/2023 19:32:36 - INFO - __main__ -     Batch size = 48
06/26/2023 19:32:45 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:32:45 - INFO - __main__ -     acc = 0.7220405493786789
06/26/2023 19:32:45 - INFO - __main__ -     auc = 0.7844938984302183
06/26/2023 19:32:45 - INFO - __main__ -     f1 = 0.7207485953094617
06/26/2023 19:32:45 - INFO - __main__ -     mcc = 0.4482480988295966
06/26/2023 19:32:45 - INFO - __main__ -     precision = 0.7262270998096817
06/26/2023 19:32:45 - INFO - __main__ -     recall = 0.7220405493786789
06/26/2023 19:32:45 - INFO - __main__ -   {"eval_acc": 0.7220405493786789, "eval_f1": 0.7207485953094617, "eval_mcc": 0.4482480988295966, "eval_auc": 0.7844938984302183, "eval_precision": 0.7262270998096817, "eval_recall": 0.7220405493786789, "learning_rate": 9.513435003631082e-05, "loss": 0.39294077903032304, "step": 1100}
06/26/2023 19:33:28 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:33:29 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:33:29 - INFO - __main__ -     Num examples = 3058
06/26/2023 19:33:29 - INFO - __main__ -     Batch size = 48
06/26/2023 19:33:38 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:33:38 - INFO - __main__ -     acc = 0.7128842380640942
06/26/2023 19:33:38 - INFO - __main__ -     auc = 0.7854306601689337
06/26/2023 19:33:38 - INFO - __main__ -     f1 = 0.7120150507232541
06/26/2023 19:33:38 - INFO - __main__ -     mcc = 0.4283620662916206
06/26/2023 19:33:38 - INFO - __main__ -     precision = 0.7154857277202238
06/26/2023 19:33:38 - INFO - __main__ -     recall = 0.7128842380640942
06/26/2023 19:33:38 - INFO - __main__ -   {"eval_acc": 0.7128842380640942, "eval_f1": 0.7120150507232541, "eval_mcc": 0.4283620662916206, "eval_auc": 0.7854306601689337, "eval_precision": 0.7154857277202238, "eval_recall": 0.7128842380640942, "learning_rate": 9.368191721132898e-05, "loss": 0.36236073687672615, "step": 1200}
06/26/2023 19:34:21 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:34:22 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:34:22 - INFO - __main__ -     Num examples = 3058
06/26/2023 19:34:22 - INFO - __main__ -     Batch size = 48
06/26/2023 19:34:31 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:34:31 - INFO - __main__ -     acc = 0.7037279267495095
06/26/2023 19:34:31 - INFO - __main__ -     auc = 0.7809996488212843
06/26/2023 19:34:31 - INFO - __main__ -     f1 = 0.7024294994071247
06/26/2023 19:34:31 - INFO - __main__ -     mcc = 0.4110588958008148
06/26/2023 19:34:31 - INFO - __main__ -     precision = 0.7073468995057546
06/26/2023 19:34:31 - INFO - __main__ -     recall = 0.7037279267495095
06/26/2023 19:34:31 - INFO - __main__ -   {"eval_acc": 0.7037279267495095, "eval_f1": 0.7024294994071247, "eval_mcc": 0.4110588958008148, "eval_auc": 0.7809996488212843, "eval_precision": 0.7073468995057546, "eval_recall": 0.7037279267495095, "learning_rate": 9.222948438634713e-05, "loss": 0.34236292123794554, "step": 1300}
06/26/2023 19:35:15 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:35:16 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:35:16 - INFO - __main__ -     Num examples = 3058
06/26/2023 19:35:16 - INFO - __main__ -     Batch size = 48
06/26/2023 19:35:25 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:35:25 - INFO - __main__ -     acc = 0.7289077828646174
06/26/2023 19:35:25 - INFO - __main__ -     auc = 0.7944826016824926
06/26/2023 19:35:25 - INFO - __main__ -     f1 = 0.7266322626255416
06/26/2023 19:35:25 - INFO - __main__ -     mcc = 0.46563307366641754
06/26/2023 19:35:25 - INFO - __main__ -     precision = 0.7367920353982301
06/26/2023 19:35:25 - INFO - __main__ -     recall = 0.7289077828646173
06/26/2023 19:35:25 - INFO - __main__ -   {"eval_acc": 0.7289077828646174, "eval_f1": 0.7266322626255416, "eval_mcc": 0.46563307366641754, "eval_auc": 0.7944826016824926, "eval_precision": 0.7367920353982301, "eval_recall": 0.7289077828646173, "learning_rate": 9.077705156136529e-05, "loss": 0.249433086887002, "step": 1400}
06/26/2023 19:36:08 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:36:08 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:36:08 - INFO - __main__ -     Num examples = 3058
06/26/2023 19:36:08 - INFO - __main__ -     Batch size = 48
06/26/2023 19:36:17 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:36:17 - INFO - __main__ -     acc = 0.7197514715500327
06/26/2023 19:36:17 - INFO - __main__ -     auc = 0.79200039694744
06/26/2023 19:36:17 - INFO - __main__ -     f1 = 0.7191543937871396
06/26/2023 19:36:17 - INFO - __main__ -     mcc = 0.44138371371919033
06/26/2023 19:36:17 - INFO - __main__ -     precision = 0.7216362663721548
06/26/2023 19:36:17 - INFO - __main__ -     recall = 0.7197514715500326
06/26/2023 19:36:17 - INFO - __main__ -   {"eval_acc": 0.7197514715500327, "eval_f1": 0.7191543937871396, "eval_mcc": 0.44138371371919033, "eval_auc": 0.79200039694744, "eval_precision": 0.7216362663721548, "eval_recall": 0.7197514715500326, "learning_rate": 8.932461873638345e-05, "loss": 0.2741373585164547, "step": 1500}
06/26/2023 19:37:00 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:37:00 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:37:00 - INFO - __main__ -     Num examples = 3058
06/26/2023 19:37:00 - INFO - __main__ -     Batch size = 48
06/26/2023 19:37:09 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:37:09 - INFO - __main__ -     acc = 0.723348593852191
06/26/2023 19:37:09 - INFO - __main__ -     auc = 0.7870111782623369
06/26/2023 19:37:09 - INFO - __main__ -     f1 = 0.7203242294253986
06/26/2023 19:37:09 - INFO - __main__ -     mcc = 0.4566833565503431
06/26/2023 19:37:09 - INFO - __main__ -     precision = 0.7334463859308085
06/26/2023 19:37:09 - INFO - __main__ -     recall = 0.723348593852191
06/26/2023 19:37:09 - INFO - __main__ -   {"eval_acc": 0.723348593852191, "eval_f1": 0.7203242294253986, "eval_mcc": 0.4566833565503431, "eval_auc": 0.7870111782623369, "eval_precision": 0.7334463859308085, "eval_recall": 0.723348593852191, "learning_rate": 8.78721859114016e-05, "loss": 0.20986116725951434, "step": 1600}
06/26/2023 19:37:52 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:37:53 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:37:53 - INFO - __main__ -     Num examples = 3058
06/26/2023 19:37:53 - INFO - __main__ -     Batch size = 48
06/26/2023 19:38:02 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:38:02 - INFO - __main__ -     acc = 0.7197514715500327
06/26/2023 19:38:02 - INFO - __main__ -     auc = 0.7929987539785639
06/26/2023 19:38:02 - INFO - __main__ -     f1 = 0.7155189810073235
06/26/2023 19:38:02 - INFO - __main__ -     mcc = 0.45319498953125453
06/26/2023 19:38:02 - INFO - __main__ -     precision = 0.7336567954329626
06/26/2023 19:38:02 - INFO - __main__ -     recall = 0.7197514715500327
06/26/2023 19:38:02 - INFO - __main__ -   {"eval_acc": 0.7197514715500327, "eval_f1": 0.7155189810073235, "eval_mcc": 0.45319498953125453, "eval_auc": 0.7929987539785639, "eval_precision": 0.7336567954329626, "eval_recall": 0.7197514715500327, "learning_rate": 8.641975308641975e-05, "loss": 0.17537431607022883, "step": 1700}
06/26/2023 19:38:46 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:38:47 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:38:47 - INFO - __main__ -     Num examples = 3058
06/26/2023 19:38:47 - INFO - __main__ -     Batch size = 48
06/26/2023 19:38:56 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:38:56 - INFO - __main__ -     acc = 0.7200784826684107
06/26/2023 19:38:56 - INFO - __main__ -     auc = 0.7845642624968935
06/26/2023 19:38:56 - INFO - __main__ -     f1 = 0.7199975183609202
06/26/2023 19:38:56 - INFO - __main__ -     mcc = 0.44041173413336626
06/26/2023 19:38:56 - INFO - __main__ -     precision = 0.7203333251967659
06/26/2023 19:38:56 - INFO - __main__ -     recall = 0.7200784826684108
06/26/2023 19:38:56 - INFO - __main__ -   {"eval_acc": 0.7200784826684107, "eval_f1": 0.7199975183609202, "eval_mcc": 0.44041173413336626, "eval_auc": 0.7845642624968935, "eval_precision": 0.7203333251967659, "eval_recall": 0.7200784826684108, "learning_rate": 8.496732026143791e-05, "loss": 0.17663691226392986, "step": 1800}
06/26/2023 19:39:40 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:39:40 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:39:40 - INFO - __main__ -     Num examples = 3058
06/26/2023 19:39:40 - INFO - __main__ -     Batch size = 48
06/26/2023 19:39:49 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:39:49 - INFO - __main__ -     acc = 0.7243296272073251
06/26/2023 19:39:49 - INFO - __main__ -     auc = 0.7891933198194403
06/26/2023 19:39:49 - INFO - __main__ -     f1 = 0.7201208285241825
06/26/2023 19:39:49 - INFO - __main__ -     mcc = 0.46279402074538484
06/26/2023 19:39:49 - INFO - __main__ -     precision = 0.7386870476093383
06/26/2023 19:39:49 - INFO - __main__ -     recall = 0.724329627207325
06/26/2023 19:39:49 - INFO - __main__ -   {"eval_acc": 0.7243296272073251, "eval_f1": 0.7201208285241825, "eval_mcc": 0.46279402074538484, "eval_auc": 0.7891933198194403, "eval_precision": 0.7386870476093383, "eval_recall": 0.724329627207325, "learning_rate": 8.351488743645607e-05, "loss": 0.13368618870154023, "step": 1900}
06/26/2023 19:40:32 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:40:33 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:40:33 - INFO - __main__ -     Num examples = 3058
06/26/2023 19:40:33 - INFO - __main__ -     Batch size = 48
06/26/2023 19:40:42 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:40:42 - INFO - __main__ -     acc = 0.7279267495094833
06/26/2023 19:40:42 - INFO - __main__ -     auc = 0.78218664143541
06/26/2023 19:40:42 - INFO - __main__ -     f1 = 0.7271984903070852
06/26/2023 19:40:42 - INFO - __main__ -     mcc = 0.45830701991435063
06/26/2023 19:40:42 - INFO - __main__ -     precision = 0.7303868731454375
06/26/2023 19:40:42 - INFO - __main__ -     recall = 0.7279267495094833
06/26/2023 19:40:42 - INFO - __main__ -   {"eval_acc": 0.7279267495094833, "eval_f1": 0.7271984903070852, "eval_mcc": 0.45830701991435063, "eval_auc": 0.78218664143541, "eval_precision": 0.7303868731454375, "eval_recall": 0.7279267495094833, "learning_rate": 8.206245461147423e-05, "loss": 0.14830900949425996, "step": 2000}
06/26/2023 19:41:26 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:41:27 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:41:27 - INFO - __main__ -     Num examples = 3058
06/26/2023 19:41:27 - INFO - __main__ -     Batch size = 48
06/26/2023 19:41:36 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:41:36 - INFO - __main__ -     acc = 0.7174623937213865
06/26/2023 19:41:36 - INFO - __main__ -     auc = 0.7821389478583018
06/26/2023 19:41:36 - INFO - __main__ -     f1 = 0.7173535831670547
06/26/2023 19:41:36 - INFO - __main__ -     mcc = 0.4352600411741936
06/26/2023 19:41:36 - INFO - __main__ -     precision = 0.7177977766648773
06/26/2023 19:41:36 - INFO - __main__ -     recall = 0.7174623937213865
06/26/2023 19:41:36 - INFO - __main__ -   {"eval_acc": 0.7174623937213865, "eval_f1": 0.7173535831670547, "eval_mcc": 0.4352600411741936, "eval_auc": 0.7821389478583018, "eval_precision": 0.7177977766648773, "eval_recall": 0.7174623937213865, "learning_rate": 8.061002178649237e-05, "loss": 0.1289228495582938, "step": 2100}
06/26/2023 19:42:20 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:42:20 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:42:20 - INFO - __main__ -     Num examples = 3058
06/26/2023 19:42:20 - INFO - __main__ -     Batch size = 48
06/26/2023 19:42:29 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:42:29 - INFO - __main__ -     acc = 0.7210595160235448
06/26/2023 19:42:29 - INFO - __main__ -     auc = 0.7852073772339523
06/26/2023 19:42:29 - INFO - __main__ -     f1 = 0.7207302647152315
06/26/2023 19:42:29 - INFO - __main__ -     mcc = 0.4431652260734185
06/26/2023 19:42:29 - INFO - __main__ -     precision = 0.7221069478635183
06/26/2023 19:42:29 - INFO - __main__ -     recall = 0.7210595160235448
06/26/2023 19:42:29 - INFO - __main__ -   {"eval_acc": 0.7210595160235448, "eval_f1": 0.7207302647152315, "eval_mcc": 0.4431652260734185, "eval_auc": 0.7852073772339523, "eval_precision": 0.7221069478635183, "eval_recall": 0.7210595160235448, "learning_rate": 7.915758896151053e-05, "loss": 0.1248120612418279, "step": 2200}
06/26/2023 19:43:13 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:43:14 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:43:14 - INFO - __main__ -     Num examples = 3058
06/26/2023 19:43:14 - INFO - __main__ -     Batch size = 48
06/26/2023 19:43:23 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:43:23 - INFO - __main__ -     acc = 0.7266187050359713
06/26/2023 19:43:23 - INFO - __main__ -     auc = 0.7968304944604873
06/26/2023 19:43:23 - INFO - __main__ -     f1 = 0.7238900142867202
06/26/2023 19:43:23 - INFO - __main__ -     mcc = 0.46247041750838125
06/26/2023 19:43:23 - INFO - __main__ -     precision = 0.7359457563712883
06/26/2023 19:43:23 - INFO - __main__ -     recall = 0.7266187050359711
06/26/2023 19:43:23 - INFO - __main__ -   {"eval_acc": 0.7266187050359713, "eval_f1": 0.7238900142867202, "eval_mcc": 0.46247041750838125, "eval_auc": 0.7968304944604873, "eval_precision": 0.7359457563712883, "eval_recall": 0.7266187050359711, "learning_rate": 7.770515613652869e-05, "loss": 0.12038617979735136, "step": 2300}
06/26/2023 19:44:06 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:44:07 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:44:07 - INFO - __main__ -     Num examples = 3058
06/26/2023 19:44:07 - INFO - __main__ -     Batch size = 48
06/26/2023 19:44:16 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:44:16 - INFO - __main__ -     acc = 0.7243296272073251
06/26/2023 19:44:16 - INFO - __main__ -     auc = 0.7974092335620772
06/26/2023 19:44:16 - INFO - __main__ -     f1 = 0.7205206249190284
06/26/2023 19:44:16 - INFO - __main__ -     mcc = 0.4614126168339897
06/26/2023 19:44:16 - INFO - __main__ -     precision = 0.7372642499610929
06/26/2023 19:44:16 - INFO - __main__ -     recall = 0.724329627207325
06/26/2023 19:44:16 - INFO - __main__ -   {"eval_acc": 0.7243296272073251, "eval_f1": 0.7205206249190284, "eval_mcc": 0.4614126168339897, "eval_auc": 0.7974092335620772, "eval_precision": 0.7372642499610929, "eval_recall": 0.724329627207325, "learning_rate": 7.625272331154685e-05, "loss": 0.10379462104756385, "step": 2400}
06/26/2023 19:44:59 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:44:59 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:44:59 - INFO - __main__ -     Num examples = 3058
06/26/2023 19:44:59 - INFO - __main__ -     Batch size = 48
06/26/2023 19:45:08 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:45:08 - INFO - __main__ -     acc = 0.7220405493786789
06/26/2023 19:45:08 - INFO - __main__ -     auc = 0.7824646757414212
06/26/2023 19:45:08 - INFO - __main__ -     f1 = 0.7220400737947086
06/26/2023 19:45:08 - INFO - __main__ -     mcc = 0.44408261839322083
06/26/2023 19:45:08 - INFO - __main__ -     precision = 0.722042069017142
06/26/2023 19:45:08 - INFO - __main__ -     recall = 0.7220405493786789
06/26/2023 19:45:08 - INFO - __main__ -   {"eval_acc": 0.7220405493786789, "eval_f1": 0.7220400737947086, "eval_mcc": 0.44408261839322083, "eval_auc": 0.7824646757414212, "eval_precision": 0.722042069017142, "eval_recall": 0.7220405493786789, "learning_rate": 7.4800290486565e-05, "loss": 0.09918592193163932, "step": 2500}
06/26/2023 19:45:52 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:45:52 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:45:52 - INFO - __main__ -     Num examples = 3058
06/26/2023 19:45:52 - INFO - __main__ -     Batch size = 48
06/26/2023 19:46:02 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:46:02 - INFO - __main__ -     acc = 0.7253106605624591
06/26/2023 19:46:02 - INFO - __main__ -     auc = 0.7827360799985971
06/26/2023 19:46:02 - INFO - __main__ -     f1 = 0.7231845544067917
06/26/2023 19:46:02 - INFO - __main__ -     mcc = 0.4577070902682065
06/26/2023 19:46:02 - INFO - __main__ -     precision = 0.7324521395911858
06/26/2023 19:46:02 - INFO - __main__ -     recall = 0.7253106605624591
06/26/2023 19:46:02 - INFO - __main__ -   {"eval_acc": 0.7253106605624591, "eval_f1": 0.7231845544067917, "eval_mcc": 0.4577070902682065, "eval_auc": 0.7827360799985971, "eval_precision": 0.7324521395911858, "eval_recall": 0.7253106605624591, "learning_rate": 7.334785766158315e-05, "loss": 0.07839677620911971, "step": 2600}
06/26/2023 19:46:45 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:46:45 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:46:45 - INFO - __main__ -     Num examples = 3058
06/26/2023 19:46:45 - INFO - __main__ -     Batch size = 48
06/26/2023 19:46:54 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:46:54 - INFO - __main__ -     acc = 0.7305428384565075
06/26/2023 19:46:54 - INFO - __main__ -     auc = 0.7922305238038001
06/26/2023 19:46:54 - INFO - __main__ -     f1 = 0.7300244455187217
06/26/2023 19:46:54 - INFO - __main__ -     mcc = 0.4628666478831422
06/26/2023 19:46:54 - INFO - __main__ -     precision = 0.7323272489800141
06/26/2023 19:46:54 - INFO - __main__ -     recall = 0.7305428384565076
06/26/2023 19:46:54 - INFO - __main__ -   {"eval_acc": 0.7305428384565075, "eval_f1": 0.7300244455187217, "eval_mcc": 0.4628666478831422, "eval_auc": 0.7922305238038001, "eval_precision": 0.7323272489800141, "eval_recall": 0.7305428384565076, "learning_rate": 7.189542483660131e-05, "loss": 0.08892917282297276, "step": 2700}
06/26/2023 19:47:37 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:47:37 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:47:37 - INFO - __main__ -     Num examples = 3058
06/26/2023 19:47:37 - INFO - __main__ -     Batch size = 48
06/26/2023 19:47:46 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:47:46 - INFO - __main__ -     acc = 0.7253106605624591
06/26/2023 19:47:46 - INFO - __main__ -     auc = 0.776895862464556
06/26/2023 19:47:46 - INFO - __main__ -     f1 = 0.7252249785204988
06/26/2023 19:47:46 - INFO - __main__ -     mcc = 0.4509026153363829
06/26/2023 19:47:46 - INFO - __main__ -     precision = 0.7255920425709605
06/26/2023 19:47:46 - INFO - __main__ -     recall = 0.7253106605624591
06/26/2023 19:47:46 - INFO - __main__ -   {"eval_acc": 0.7253106605624591, "eval_f1": 0.7252249785204988, "eval_mcc": 0.4509026153363829, "eval_auc": 0.776895862464556, "eval_precision": 0.7255920425709605, "eval_recall": 0.7253106605624591, "learning_rate": 7.044299201161947e-05, "loss": 0.09164653619285673, "step": 2800}
06/26/2023 19:48:29 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:48:29 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:48:29 - INFO - __main__ -     Num examples = 3058
06/26/2023 19:48:29 - INFO - __main__ -     Batch size = 48
06/26/2023 19:48:39 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:48:39 - INFO - __main__ -     acc = 0.7279267495094833
06/26/2023 19:48:39 - INFO - __main__ -     auc = 0.7797493499344053
06/26/2023 19:48:39 - INFO - __main__ -     f1 = 0.7263517016329051
06/26/2023 19:48:39 - INFO - __main__ -     mcc = 0.46119343022578196
06/26/2023 19:48:39 - INFO - __main__ -     precision = 0.7332979570642425
06/26/2023 19:48:39 - INFO - __main__ -     recall = 0.7279267495094833
06/26/2023 19:48:39 - INFO - __main__ -   {"eval_acc": 0.7279267495094833, "eval_f1": 0.7263517016329051, "eval_mcc": 0.46119343022578196, "eval_auc": 0.7797493499344053, "eval_precision": 0.7332979570642425, "eval_recall": 0.7279267495094833, "learning_rate": 6.899055918663763e-05, "loss": 0.07727551318123005, "step": 2900}
06/26/2023 19:49:22 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:49:22 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:49:22 - INFO - __main__ -     Num examples = 3058
06/26/2023 19:49:22 - INFO - __main__ -     Batch size = 48
06/26/2023 19:49:32 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:49:32 - INFO - __main__ -     acc = 0.7282537606278614
06/26/2023 19:49:32 - INFO - __main__ -     auc = 0.7782526698778915
06/26/2023 19:49:32 - INFO - __main__ -     f1 = 0.7255233363133495
06/26/2023 19:49:32 - INFO - __main__ -     mcc = 0.46587032543405005
06/26/2023 19:49:32 - INFO - __main__ -     precision = 0.7377125786701448
06/26/2023 19:49:32 - INFO - __main__ -     recall = 0.7282537606278614
06/26/2023 19:49:32 - INFO - __main__ -   {"eval_acc": 0.7282537606278614, "eval_f1": 0.7255233363133495, "eval_mcc": 0.46587032543405005, "eval_auc": 0.7782526698778915, "eval_precision": 0.7377125786701448, "eval_recall": 0.7282537606278614, "learning_rate": 6.753812636165577e-05, "loss": 0.07266115829377667, "step": 3000}
06/26/2023 19:50:14 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:50:15 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:50:15 - INFO - __main__ -     Num examples = 3058
06/26/2023 19:50:15 - INFO - __main__ -     Batch size = 48
06/26/2023 19:50:24 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:50:24 - INFO - __main__ -     acc = 0.7269457161543492
06/26/2023 19:50:24 - INFO - __main__ -     auc = 0.7812507351868667
06/26/2023 19:50:24 - INFO - __main__ -     f1 = 0.7267633609530875
06/26/2023 19:50:24 - INFO - __main__ -     mcc = 0.4544984925599147
06/26/2023 19:50:24 - INFO - __main__ -     precision = 0.7275531823640418
06/26/2023 19:50:24 - INFO - __main__ -     recall = 0.7269457161543493
06/26/2023 19:50:24 - INFO - __main__ -   {"eval_acc": 0.7269457161543492, "eval_f1": 0.7267633609530875, "eval_mcc": 0.4544984925599147, "eval_auc": 0.7812507351868667, "eval_precision": 0.7275531823640418, "eval_recall": 0.7269457161543493, "learning_rate": 6.608569353667393e-05, "loss": 0.06848339970572852, "step": 3100}
06/26/2023 19:51:06 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:51:07 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:51:07 - INFO - __main__ -     Num examples = 3058
06/26/2023 19:51:07 - INFO - __main__ -     Batch size = 48
06/26/2023 19:51:16 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:51:16 - INFO - __main__ -     acc = 0.7266187050359713
06/26/2023 19:51:16 - INFO - __main__ -     auc = 0.7825219935829683
06/26/2023 19:51:16 - INFO - __main__ -     f1 = 0.7264497429161226
06/26/2023 19:51:16 - INFO - __main__ -     mcc = 0.45379834647339184
06/26/2023 19:51:16 - INFO - __main__ -     precision = 0.7271799885509195
06/26/2023 19:51:16 - INFO - __main__ -     recall = 0.7266187050359713
06/26/2023 19:51:16 - INFO - __main__ -   {"eval_acc": 0.7266187050359713, "eval_f1": 0.7264497429161226, "eval_mcc": 0.45379834647339184, "eval_auc": 0.7825219935829683, "eval_precision": 0.7271799885509195, "eval_recall": 0.7266187050359713, "learning_rate": 6.463326071169209e-05, "loss": 0.07440405541099608, "step": 3200}
06/26/2023 19:51:59 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:52:00 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:52:00 - INFO - __main__ -     Num examples = 3058
06/26/2023 19:52:00 - INFO - __main__ -     Batch size = 48
06/26/2023 19:52:09 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:52:09 - INFO - __main__ -     acc = 0.7308698495748855
06/26/2023 19:52:09 - INFO - __main__ -     auc = 0.7921084025816982
06/26/2023 19:52:09 - INFO - __main__ -     f1 = 0.7284104787009548
06/26/2023 19:52:09 - INFO - __main__ -     mcc = 0.4703365018070524
06/26/2023 19:52:09 - INFO - __main__ -     precision = 0.7395466811056471
06/26/2023 19:52:09 - INFO - __main__ -     recall = 0.7308698495748855
06/26/2023 19:52:09 - INFO - __main__ -   {"eval_acc": 0.7308698495748855, "eval_f1": 0.7284104787009548, "eval_mcc": 0.4703365018070524, "eval_auc": 0.7921084025816982, "eval_precision": 0.7395466811056471, "eval_recall": 0.7308698495748855, "learning_rate": 6.318082788671025e-05, "loss": 0.07047411912935786, "step": 3300}
06/26/2023 19:52:53 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:52:53 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:52:53 - INFO - __main__ -     Num examples = 3058
06/26/2023 19:52:53 - INFO - __main__ -     Batch size = 48
06/26/2023 19:53:02 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:53:02 - INFO - __main__ -     acc = 0.7295618051013735
06/26/2023 19:53:02 - INFO - __main__ -     auc = 0.7914744843639924
06/26/2023 19:53:02 - INFO - __main__ -     f1 = 0.7263557771140545
06/26/2023 19:53:02 - INFO - __main__ -     mcc = 0.47027536697338124
06/26/2023 19:53:02 - INFO - __main__ -     precision = 0.7408489956378912
06/26/2023 19:53:02 - INFO - __main__ -     recall = 0.7295618051013735
06/26/2023 19:53:02 - INFO - __main__ -   {"eval_acc": 0.7295618051013735, "eval_f1": 0.7263557771140545, "eval_mcc": 0.47027536697338124, "eval_auc": 0.7914744843639924, "eval_precision": 0.7408489956378912, "eval_recall": 0.7295618051013735, "learning_rate": 6.17283950617284e-05, "loss": 0.06247045469004661, "step": 3400}
06/26/2023 19:53:46 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:53:47 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:53:47 - INFO - __main__ -     Num examples = 3058
06/26/2023 19:53:47 - INFO - __main__ -     Batch size = 48
06/26/2023 19:53:56 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:53:56 - INFO - __main__ -     acc = 0.7285807717462394
06/26/2023 19:53:56 - INFO - __main__ -     auc = 0.7845533549971961
06/26/2023 19:53:56 - INFO - __main__ -     f1 = 0.7271943627577431
06/26/2023 19:53:56 - INFO - __main__ -     mcc = 0.4618802342579347
06/26/2023 19:53:56 - INFO - __main__ -     precision = 0.7333238150002817
06/26/2023 19:53:56 - INFO - __main__ -     recall = 0.7285807717462394
06/26/2023 19:53:56 - INFO - __main__ -   {"eval_acc": 0.7285807717462394, "eval_f1": 0.7271943627577431, "eval_mcc": 0.4618802342579347, "eval_auc": 0.7845533549971961, "eval_precision": 0.7333238150002817, "eval_recall": 0.7285807717462394, "learning_rate": 6.0275962236746555e-05, "loss": 0.06178046066663228, "step": 3500}
06/26/2023 19:54:40 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:54:40 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:54:40 - INFO - __main__ -     Num examples = 3058
06/26/2023 19:54:40 - INFO - __main__ -     Batch size = 48
06/26/2023 19:54:49 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:54:49 - INFO - __main__ -     acc = 0.7253106605624591
06/26/2023 19:54:49 - INFO - __main__ -     auc = 0.7863567282804947
06/26/2023 19:54:49 - INFO - __main__ -     f1 = 0.7239588169147763
06/26/2023 19:54:49 - INFO - __main__ -     mcc = 0.45510085554659657
06/26/2023 19:54:49 - INFO - __main__ -     precision = 0.7298124600520497
06/26/2023 19:54:49 - INFO - __main__ -     recall = 0.7253106605624591
06/26/2023 19:54:49 - INFO - __main__ -   {"eval_acc": 0.7253106605624591, "eval_f1": 0.7239588169147763, "eval_mcc": 0.45510085554659657, "eval_auc": 0.7863567282804947, "eval_precision": 0.7298124600520497, "eval_recall": 0.7253106605624591, "learning_rate": 5.882352941176471e-05, "loss": 0.05867122024181299, "step": 3600}
06/26/2023 19:55:33 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:55:33 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:55:33 - INFO - __main__ -     Num examples = 3058
06/26/2023 19:55:33 - INFO - __main__ -     Batch size = 48
06/26/2023 19:55:42 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:55:42 - INFO - __main__ -     acc = 0.7292347939829954
06/26/2023 19:55:42 - INFO - __main__ -     auc = 0.7927194364372941
06/26/2023 19:55:42 - INFO - __main__ -     f1 = 0.7262747777354965
06/26/2023 19:55:42 - INFO - __main__ -     mcc = 0.4687189354931047
06/26/2023 19:55:42 - INFO - __main__ -     precision = 0.7395987064970669
06/26/2023 19:55:42 - INFO - __main__ -     recall = 0.7292347939829954
06/26/2023 19:55:42 - INFO - __main__ -   {"eval_acc": 0.7292347939829954, "eval_f1": 0.7262747777354965, "eval_mcc": 0.4687189354931047, "eval_auc": 0.7927194364372941, "eval_precision": 0.7395987064970669, "eval_recall": 0.7292347939829954, "learning_rate": 5.7371096586782866e-05, "loss": 0.04686427316279151, "step": 3700}
06/26/2023 19:56:26 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:56:27 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:56:27 - INFO - __main__ -     Num examples = 3058
06/26/2023 19:56:27 - INFO - __main__ -     Batch size = 48
06/26/2023 19:56:36 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:56:36 - INFO - __main__ -     acc = 0.7226945716154349
06/26/2023 19:56:36 - INFO - __main__ -     auc = 0.7819965087446067
06/26/2023 19:56:36 - INFO - __main__ -     f1 = 0.7221121322828137
06/26/2023 19:56:36 - INFO - __main__ -     mcc = 0.44726799302133163
06/26/2023 19:56:36 - INFO - __main__ -     precision = 0.7245773843185415
06/26/2023 19:56:36 - INFO - __main__ -     recall = 0.7226945716154349
06/26/2023 19:56:36 - INFO - __main__ -   {"eval_acc": 0.7226945716154349, "eval_f1": 0.7221121322828137, "eval_mcc": 0.44726799302133163, "eval_auc": 0.7819965087446067, "eval_precision": 0.7245773843185415, "eval_recall": 0.7226945716154349, "learning_rate": 5.591866376180102e-05, "loss": 0.053245758991106416, "step": 3800}
06/26/2023 19:57:20 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:57:21 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:57:21 - INFO - __main__ -     Num examples = 3058
06/26/2023 19:57:21 - INFO - __main__ -     Batch size = 48
06/26/2023 19:57:30 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:57:30 - INFO - __main__ -     acc = 0.7298888162197514
06/26/2023 19:57:30 - INFO - __main__ -     auc = 0.7907246472279339
06/26/2023 19:57:30 - INFO - __main__ -     f1 = 0.7270474885509217
06/26/2023 19:57:30 - INFO - __main__ -     mcc = 0.46965953269643695
06/26/2023 19:57:30 - INFO - __main__ -     precision = 0.7398769112388903
06/26/2023 19:57:30 - INFO - __main__ -     recall = 0.7298888162197514
06/26/2023 19:57:30 - INFO - __main__ -   {"eval_acc": 0.7298888162197514, "eval_f1": 0.7270474885509217, "eval_mcc": 0.46965953269643695, "eval_auc": 0.7907246472279339, "eval_precision": 0.7398769112388903, "eval_recall": 0.7298888162197514, "learning_rate": 5.446623093681917e-05, "loss": 0.04164647274010349, "step": 3900}
06/26/2023 19:58:14 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:58:15 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:58:15 - INFO - __main__ -     Num examples = 3058
06/26/2023 19:58:15 - INFO - __main__ -     Batch size = 48
06/26/2023 19:58:24 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:58:24 - INFO - __main__ -     acc = 0.73675604970569
06/26/2023 19:58:24 - INFO - __main__ -     auc = 0.7949268149544816
06/26/2023 19:58:24 - INFO - __main__ -     f1 = 0.7354483366664377
06/26/2023 19:58:24 - INFO - __main__ -     mcc = 0.47826394659065086
06/26/2023 19:58:24 - INFO - __main__ -     precision = 0.7415317400471981
06/26/2023 19:58:24 - INFO - __main__ -     recall = 0.73675604970569
06/26/2023 19:58:24 - INFO - __main__ -   {"eval_acc": 0.73675604970569, "eval_f1": 0.7354483366664377, "eval_mcc": 0.47826394659065086, "eval_auc": 0.7949268149544816, "eval_precision": 0.7415317400471981, "eval_recall": 0.73675604970569, "learning_rate": 5.301379811183733e-05, "loss": 0.04091997047158657, "step": 4000}
06/26/2023 19:58:24 - INFO - transformers.configuration_utils -   Configuration saved in /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold3/checkpoint-4000/config.json
06/26/2023 19:58:24 - INFO - transformers.modeling_utils -   Model weights saved in /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold3/checkpoint-4000/pytorch_model.bin
06/26/2023 19:58:24 - INFO - __main__ -   Saving model checkpoint to /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold3/checkpoint-4000
06/26/2023 19:58:25 - INFO - __main__ -   Saving optimizer and scheduler states to /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold3/checkpoint-4000
06/26/2023 19:59:09 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 19:59:09 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 19:59:09 - INFO - __main__ -     Num examples = 3058
06/26/2023 19:59:09 - INFO - __main__ -     Batch size = 48
06/26/2023 19:59:18 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 19:59:18 - INFO - __main__ -     acc = 0.7259646827992152
06/26/2023 19:59:18 - INFO - __main__ -     auc = 0.7928543900119812
06/26/2023 19:59:18 - INFO - __main__ -     f1 = 0.7236478002071398
06/26/2023 19:59:18 - INFO - __main__ -     mcc = 0.4597032189121231
06/26/2023 19:59:18 - INFO - __main__ -     precision = 0.7338053969986381
06/26/2023 19:59:18 - INFO - __main__ -     recall = 0.7259646827992152
06/26/2023 19:59:18 - INFO - __main__ -   {"eval_acc": 0.7259646827992152, "eval_f1": 0.7236478002071398, "eval_mcc": 0.4597032189121231, "eval_auc": 0.7928543900119812, "eval_precision": 0.7338053969986381, "eval_recall": 0.7259646827992152, "learning_rate": 5.156136528685549e-05, "loss": 0.043086426922818645, "step": 4100}
06/26/2023 20:00:02 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:00:02 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:00:02 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:00:02 - INFO - __main__ -     Batch size = 48
06/26/2023 20:00:11 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:00:11 - INFO - __main__ -     acc = 0.724002616088947
06/26/2023 20:00:11 - INFO - __main__ -     auc = 0.7826195194626152
06/26/2023 20:00:11 - INFO - __main__ -     f1 = 0.7202537858029787
06/26/2023 20:00:11 - INFO - __main__ -     mcc = 0.46051786034670633
06/26/2023 20:00:11 - INFO - __main__ -     precision = 0.7366899809041706
06/26/2023 20:00:11 - INFO - __main__ -     recall = 0.724002616088947
06/26/2023 20:00:11 - INFO - __main__ -   {"eval_acc": 0.724002616088947, "eval_f1": 0.7202537858029787, "eval_mcc": 0.46051786034670633, "eval_auc": 0.7826195194626152, "eval_precision": 0.7366899809041706, "eval_recall": 0.724002616088947, "learning_rate": 5.0108932461873634e-05, "loss": 0.02827557918652019, "step": 4200}
06/26/2023 20:00:55 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:00:55 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:00:55 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:00:55 - INFO - __main__ -     Batch size = 48
06/26/2023 20:01:04 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:01:04 - INFO - __main__ -     acc = 0.710595160235448
06/26/2023 20:01:04 - INFO - __main__ -     auc = 0.7806510365760545
06/26/2023 20:01:04 - INFO - __main__ -     f1 = 0.7082701158315309
06/26/2023 20:01:04 - INFO - __main__ -     mcc = 0.4280688779776404
06/26/2023 20:01:04 - INFO - __main__ -     precision = 0.7175298854068728
06/26/2023 20:01:04 - INFO - __main__ -     recall = 0.710595160235448
06/26/2023 20:01:04 - INFO - __main__ -   {"eval_acc": 0.710595160235448, "eval_f1": 0.7082701158315309, "eval_mcc": 0.4280688779776404, "eval_auc": 0.7806510365760545, "eval_precision": 0.7175298854068728, "eval_recall": 0.710595160235448, "learning_rate": 4.865649963689179e-05, "loss": 0.046314694417378635, "step": 4300}
06/26/2023 20:01:47 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:01:48 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:01:48 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:01:48 - INFO - __main__ -     Batch size = 48
06/26/2023 20:01:57 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:01:57 - INFO - __main__ -     acc = 0.723675604970569
06/26/2023 20:01:57 - INFO - __main__ -     auc = 0.7891580308498312
06/26/2023 20:01:57 - INFO - __main__ -     f1 = 0.7191306605849559
06/26/2023 20:01:57 - INFO - __main__ -     mcc = 0.46257203593110036
06/26/2023 20:01:57 - INFO - __main__ -     precision = 0.739155370177268
06/26/2023 20:01:57 - INFO - __main__ -     recall = 0.723675604970569
06/26/2023 20:01:57 - INFO - __main__ -   {"eval_acc": 0.723675604970569, "eval_f1": 0.7191306605849559, "eval_mcc": 0.46257203593110036, "eval_auc": 0.7891580308498312, "eval_precision": 0.739155370177268, "eval_recall": 0.723675604970569, "learning_rate": 4.720406681190995e-05, "loss": 0.03505433581332909, "step": 4400}
06/26/2023 20:02:41 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:02:41 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:02:41 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:02:41 - INFO - __main__ -     Batch size = 48
06/26/2023 20:02:50 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:02:50 - INFO - __main__ -     acc = 0.7266187050359713
06/26/2023 20:02:50 - INFO - __main__ -     auc = 0.7917345533763844
06/26/2023 20:02:50 - INFO - __main__ -     f1 = 0.7233975701717636
06/26/2023 20:02:50 - INFO - __main__ -     mcc = 0.4641773536071734
06/26/2023 20:02:50 - INFO - __main__ -     precision = 0.7376906791162261
06/26/2023 20:02:50 - INFO - __main__ -     recall = 0.7266187050359713
06/26/2023 20:02:50 - INFO - __main__ -   {"eval_acc": 0.7266187050359713, "eval_f1": 0.7233975701717636, "eval_mcc": 0.4641773536071734, "eval_auc": 0.7917345533763844, "eval_precision": 0.7376906791162261, "eval_recall": 0.7266187050359713, "learning_rate": 4.5751633986928104e-05, "loss": 0.03245831938365882, "step": 4500}
06/26/2023 20:03:33 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:03:34 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:03:34 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:03:34 - INFO - __main__ -     Batch size = 48
06/26/2023 20:03:43 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:03:43 - INFO - __main__ -     acc = 0.7334859385219098
06/26/2023 20:03:43 - INFO - __main__ -     auc = 0.7913927850525336
06/26/2023 20:03:43 - INFO - __main__ -     f1 = 0.7323295130697007
06/26/2023 20:03:43 - INFO - __main__ -     mcc = 0.4710598860597385
06/26/2023 20:03:43 - INFO - __main__ -     precision = 0.7375918413538547
06/26/2023 20:03:43 - INFO - __main__ -     recall = 0.7334859385219097
06/26/2023 20:03:43 - INFO - __main__ -   {"eval_acc": 0.7334859385219098, "eval_f1": 0.7323295130697007, "eval_mcc": 0.4710598860597385, "eval_auc": 0.7913927850525336, "eval_precision": 0.7375918413538547, "eval_recall": 0.7334859385219097, "learning_rate": 4.429920116194626e-05, "loss": 0.03670356761256698, "step": 4600}
06/26/2023 20:04:25 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:04:26 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:04:26 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:04:26 - INFO - __main__ -     Batch size = 48
06/26/2023 20:04:35 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:04:35 - INFO - __main__ -     acc = 0.7289077828646174
06/26/2023 20:04:35 - INFO - __main__ -     auc = 0.7940323999792971
06/26/2023 20:04:35 - INFO - __main__ -     f1 = 0.7260745768367294
06/26/2023 20:04:35 - INFO - __main__ -     mcc = 0.4675902903826916
06/26/2023 20:04:35 - INFO - __main__ -     precision = 0.7387868565717142
06/26/2023 20:04:35 - INFO - __main__ -     recall = 0.7289077828646173
06/26/2023 20:04:35 - INFO - __main__ -   {"eval_acc": 0.7289077828646174, "eval_f1": 0.7260745768367294, "eval_mcc": 0.4675902903826916, "eval_auc": 0.7940323999792971, "eval_precision": 0.7387868565717142, "eval_recall": 0.7289077828646173, "learning_rate": 4.2846768336964415e-05, "loss": 0.021877092876966344, "step": 4700}
06/26/2023 20:05:18 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:05:19 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:05:19 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:05:19 - INFO - __main__ -     Batch size = 48
06/26/2023 20:05:28 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:05:28 - INFO - __main__ -     acc = 0.7256376716808371
06/26/2023 20:05:28 - INFO - __main__ -     auc = 0.7927033959965626
06/26/2023 20:05:28 - INFO - __main__ -     f1 = 0.7229534974601983
06/26/2023 20:05:28 - INFO - __main__ -     mcc = 0.4602823931616158
06/26/2023 20:05:28 - INFO - __main__ -     precision = 0.7347346077855503
06/26/2023 20:05:28 - INFO - __main__ -     recall = 0.7256376716808371
06/26/2023 20:05:28 - INFO - __main__ -   {"eval_acc": 0.7256376716808371, "eval_f1": 0.7229534974601983, "eval_mcc": 0.4602823931616158, "eval_auc": 0.7927033959965626, "eval_precision": 0.7347346077855503, "eval_recall": 0.7256376716808371, "learning_rate": 4.1394335511982573e-05, "loss": 0.02525149758810585, "step": 4800}
06/26/2023 20:06:11 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:06:12 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:06:12 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:06:12 - INFO - __main__ -     Batch size = 48
06/26/2023 20:06:21 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:06:21 - INFO - __main__ -     acc = 0.7197514715500327
06/26/2023 20:06:21 - INFO - __main__ -     auc = 0.7800310200736491
06/26/2023 20:06:21 - INFO - __main__ -     f1 = 0.7153325860835353
06/26/2023 20:06:21 - INFO - __main__ -     mcc = 0.4538179246369043
06/26/2023 20:06:21 - INFO - __main__ -     precision = 0.7342995785978803
06/26/2023 20:06:21 - INFO - __main__ -     recall = 0.7197514715500327
06/26/2023 20:06:21 - INFO - __main__ -   {"eval_acc": 0.7197514715500327, "eval_f1": 0.7153325860835353, "eval_mcc": 0.4538179246369043, "eval_auc": 0.7800310200736491, "eval_precision": 0.7342995785978803, "eval_recall": 0.7197514715500327, "learning_rate": 3.9941902687000726e-05, "loss": 0.01719398596076644, "step": 4900}
06/26/2023 20:07:05 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:07:05 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:07:05 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:07:05 - INFO - __main__ -     Batch size = 48
06/26/2023 20:07:14 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:07:14 - INFO - __main__ -     acc = 0.7213865271419229
06/26/2023 20:07:14 - INFO - __main__ -     auc = 0.7813681512130208
06/26/2023 20:07:14 - INFO - __main__ -     f1 = 0.7213864079663279
06/26/2023 20:07:14 - INFO - __main__ -     mcc = 0.44277343307232825
06/26/2023 20:07:14 - INFO - __main__ -     precision = 0.7213869059305674
06/26/2023 20:07:14 - INFO - __main__ -     recall = 0.7213865271419229
06/26/2023 20:07:14 - INFO - __main__ -   {"eval_acc": 0.7213865271419229, "eval_f1": 0.7213864079663279, "eval_mcc": 0.44277343307232825, "eval_auc": 0.7813681512130208, "eval_precision": 0.7213869059305674, "eval_recall": 0.7213865271419229, "learning_rate": 3.8489469862018884e-05, "loss": 0.018698005248515982, "step": 5000}
06/26/2023 20:07:59 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:07:59 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:07:59 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:07:59 - INFO - __main__ -     Batch size = 48
06/26/2023 20:08:08 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:08:08 - INFO - __main__ -     acc = 0.7243296272073251
06/26/2023 20:08:08 - INFO - __main__ -     auc = 0.7906983409051342
06/26/2023 20:08:08 - INFO - __main__ -     f1 = 0.7201662788671804
06/26/2023 20:08:08 - INFO - __main__ -     mcc = 0.46263655181315566
06/26/2023 20:08:08 - INFO - __main__ -     precision = 0.738524645337816
06/26/2023 20:08:08 - INFO - __main__ -     recall = 0.724329627207325
06/26/2023 20:08:08 - INFO - __main__ -   {"eval_acc": 0.7243296272073251, "eval_f1": 0.7201662788671804, "eval_mcc": 0.46263655181315566, "eval_auc": 0.7906983409051342, "eval_precision": 0.738524645337816, "eval_recall": 0.724329627207325, "learning_rate": 3.7037037037037037e-05, "loss": 0.022871449973245035, "step": 5100}
06/26/2023 20:08:52 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:08:53 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:08:53 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:08:53 - INFO - __main__ -     Batch size = 48
06/26/2023 20:09:02 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:09:02 - INFO - __main__ -     acc = 0.7302158273381295
06/26/2023 20:09:02 - INFO - __main__ -     auc = 0.7916008830369559
06/26/2023 20:09:02 - INFO - __main__ -     f1 = 0.7273225142856155
06/26/2023 20:09:02 - INFO - __main__ -     mcc = 0.47052516689315815
06/26/2023 20:09:02 - INFO - __main__ -     precision = 0.7404199737695076
06/26/2023 20:09:02 - INFO - __main__ -     recall = 0.7302158273381294
06/26/2023 20:09:02 - INFO - __main__ -   {"eval_acc": 0.7302158273381295, "eval_f1": 0.7273225142856155, "eval_mcc": 0.47052516689315815, "eval_auc": 0.7916008830369559, "eval_precision": 0.7404199737695076, "eval_recall": 0.7302158273381294, "learning_rate": 3.5584604212055195e-05, "loss": 0.021143415405167617, "step": 5200}
06/26/2023 20:09:46 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:09:47 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:09:47 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:09:47 - INFO - __main__ -     Batch size = 48
06/26/2023 20:09:56 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:09:56 - INFO - __main__ -     acc = 0.723348593852191
06/26/2023 20:09:56 - INFO - __main__ -     auc = 0.7963103564357028
06/26/2023 20:09:56 - INFO - __main__ -     f1 = 0.7214871484823117
06/26/2023 20:09:56 - INFO - __main__ -     mcc = 0.45279065749282543
06/26/2023 20:09:56 - INFO - __main__ -     precision = 0.7294836246523049
06/26/2023 20:09:56 - INFO - __main__ -     recall = 0.723348593852191
06/26/2023 20:09:56 - INFO - __main__ -   {"eval_acc": 0.723348593852191, "eval_f1": 0.7214871484823117, "eval_mcc": 0.45279065749282543, "eval_auc": 0.7963103564357028, "eval_precision": 0.7294836246523049, "eval_recall": 0.723348593852191, "learning_rate": 3.413217138707335e-05, "loss": 0.02038759137642046, "step": 5300}
06/26/2023 20:10:39 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:10:40 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:10:40 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:10:40 - INFO - __main__ -     Batch size = 48
06/26/2023 20:10:49 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:10:49 - INFO - __main__ -     acc = 0.7279267495094833
06/26/2023 20:10:49 - INFO - __main__ -     auc = 0.7977184932593789
06/26/2023 20:10:49 - INFO - __main__ -     f1 = 0.7263517016329051
06/26/2023 20:10:49 - INFO - __main__ -     mcc = 0.46119343022578196
06/26/2023 20:10:49 - INFO - __main__ -     precision = 0.7332979570642425
06/26/2023 20:10:49 - INFO - __main__ -     recall = 0.7279267495094833
06/26/2023 20:10:49 - INFO - __main__ -   {"eval_acc": 0.7279267495094833, "eval_f1": 0.7263517016329051, "eval_mcc": 0.46119343022578196, "eval_auc": 0.7977184932593789, "eval_precision": 0.7332979570642425, "eval_recall": 0.7279267495094833, "learning_rate": 3.2679738562091506e-05, "loss": 0.019258612315243225, "step": 5400}
06/26/2023 20:11:33 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:11:34 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:11:34 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:11:34 - INFO - __main__ -     Batch size = 48
06/26/2023 20:11:43 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:11:43 - INFO - __main__ -     acc = 0.7315238718116416
06/26/2023 20:11:43 - INFO - __main__ -     auc = 0.7940910010561026
06/26/2023 20:11:43 - INFO - __main__ -     f1 = 0.7307399643012615
06/26/2023 20:11:43 - INFO - __main__ -     mcc = 0.46576770181088045
06/26/2023 20:11:43 - INFO - __main__ -     precision = 0.734251818562669
06/26/2023 20:11:43 - INFO - __main__ -     recall = 0.7315238718116416
06/26/2023 20:11:43 - INFO - __main__ -   {"eval_acc": 0.7315238718116416, "eval_f1": 0.7307399643012615, "eval_mcc": 0.46576770181088045, "eval_auc": 0.7940910010561026, "eval_precision": 0.734251818562669, "eval_recall": 0.7315238718116416, "learning_rate": 3.122730573710966e-05, "loss": 0.011430488181867987, "step": 5500}
06/26/2023 20:12:26 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:12:26 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:12:26 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:12:26 - INFO - __main__ -     Batch size = 48
06/26/2023 20:12:35 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:12:35 - INFO - __main__ -     acc = 0.7266187050359713
06/26/2023 20:12:35 - INFO - __main__ -     auc = 0.7911887506464298
06/26/2023 20:12:35 - INFO - __main__ -     f1 = 0.7250085192362634
06/26/2023 20:12:35 - INFO - __main__ -     mcc = 0.4586402803695424
06/26/2023 20:12:35 - INFO - __main__ -     precision = 0.7320537781116341
06/26/2023 20:12:35 - INFO - __main__ -     recall = 0.7266187050359713
06/26/2023 20:12:35 - INFO - __main__ -   {"eval_acc": 0.7266187050359713, "eval_f1": 0.7250085192362634, "eval_mcc": 0.4586402803695424, "eval_auc": 0.7911887506464298, "eval_precision": 0.7320537781116341, "eval_recall": 0.7266187050359713, "learning_rate": 2.9774872912127817e-05, "loss": 0.0162529163454019, "step": 5600}
06/26/2023 20:13:18 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:13:18 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:13:18 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:13:18 - INFO - __main__ -     Batch size = 48
06/26/2023 20:13:27 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:13:27 - INFO - __main__ -     acc = 0.7295618051013735
06/26/2023 20:13:27 - INFO - __main__ -     auc = 0.7887118927249543
06/26/2023 20:13:27 - INFO - __main__ -     f1 = 0.7291653436214047
06/26/2023 20:13:27 - INFO - __main__ -     mcc = 0.4604737189408448
06/26/2023 20:13:27 - INFO - __main__ -     precision = 0.7309138989188315
06/26/2023 20:13:27 - INFO - __main__ -     recall = 0.7295618051013735
06/26/2023 20:13:27 - INFO - __main__ -   {"eval_acc": 0.7295618051013735, "eval_f1": 0.7291653436214047, "eval_mcc": 0.4604737189408448, "eval_auc": 0.7887118927249543, "eval_precision": 0.7309138989188315, "eval_recall": 0.7295618051013735, "learning_rate": 2.832244008714597e-05, "loss": 0.010277028279961086, "step": 5700}
06/26/2023 20:14:10 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:14:11 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:14:11 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:14:11 - INFO - __main__ -     Batch size = 48
06/26/2023 20:14:20 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:14:20 - INFO - __main__ -     acc = 0.7292347939829954
06/26/2023 20:14:20 - INFO - __main__ -     auc = 0.7823906758415137
06/26/2023 20:14:20 - INFO - __main__ -     f1 = 0.7290204760975209
06/26/2023 20:14:20 - INFO - __main__ -     mcc = 0.45919652102032793
06/26/2023 20:14:20 - INFO - __main__ -     precision = 0.7299623033369164
06/26/2023 20:14:20 - INFO - __main__ -     recall = 0.7292347939829955
06/26/2023 20:14:20 - INFO - __main__ -   {"eval_acc": 0.7292347939829954, "eval_f1": 0.7290204760975209, "eval_mcc": 0.45919652102032793, "eval_auc": 0.7823906758415137, "eval_precision": 0.7299623033369164, "eval_recall": 0.7292347939829955, "learning_rate": 2.6870007262164125e-05, "loss": 0.007596426171185158, "step": 5800}
06/26/2023 20:15:03 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:15:04 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:15:04 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:15:04 - INFO - __main__ -     Batch size = 48
06/26/2023 20:15:13 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:15:13 - INFO - __main__ -     acc = 0.7318508829300197
06/26/2023 20:15:13 - INFO - __main__ -     auc = 0.7924118877203369
06/26/2023 20:15:13 - INFO - __main__ -     f1 = 0.7306989609685541
06/26/2023 20:15:13 - INFO - __main__ -     mcc = 0.46772033069867996
06/26/2023 20:15:13 - INFO - __main__ -     precision = 0.7358868607532028
06/26/2023 20:15:13 - INFO - __main__ -     recall = 0.7318508829300197
06/26/2023 20:15:13 - INFO - __main__ -   {"eval_acc": 0.7318508829300197, "eval_f1": 0.7306989609685541, "eval_mcc": 0.46772033069867996, "eval_auc": 0.7924118877203369, "eval_precision": 0.7358868607532028, "eval_recall": 0.7318508829300197, "learning_rate": 2.5417574437182277e-05, "loss": 0.017829183271314834, "step": 5900}
06/26/2023 20:15:57 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:15:57 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:15:57 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:15:57 - INFO - __main__ -     Batch size = 48
06/26/2023 20:16:06 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:16:06 - INFO - __main__ -     acc = 0.7266187050359713
06/26/2023 20:16:06 - INFO - __main__ -     auc = 0.791291623339654
06/26/2023 20:16:06 - INFO - __main__ -     f1 = 0.7225123684193387
06/26/2023 20:16:06 - INFO - __main__ -     mcc = 0.46727817462047494
06/26/2023 20:16:06 - INFO - __main__ -     precision = 0.7408769528115349
06/26/2023 20:16:06 - INFO - __main__ -     recall = 0.7266187050359711
06/26/2023 20:16:06 - INFO - __main__ -   {"eval_acc": 0.7266187050359713, "eval_f1": 0.7225123684193387, "eval_mcc": 0.46727817462047494, "eval_auc": 0.791291623339654, "eval_precision": 0.7408769528115349, "eval_recall": 0.7266187050359711, "learning_rate": 2.3965141612200436e-05, "loss": 0.00980466503640855, "step": 6000}
06/26/2023 20:16:50 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:16:50 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:16:50 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:16:50 - INFO - __main__ -     Batch size = 48
06/26/2023 20:16:59 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:16:59 - INFO - __main__ -     acc = 0.7315238718116416
06/26/2023 20:16:59 - INFO - __main__ -     auc = 0.7939911225784817
06/26/2023 20:16:59 - INFO - __main__ -     f1 = 0.7298738584734658
06/26/2023 20:16:59 - INFO - __main__ -     mcc = 0.4688104375433357
06/26/2023 20:16:59 - INFO - __main__ -     precision = 0.737322424497527
06/26/2023 20:16:59 - INFO - __main__ -     recall = 0.7315238718116416
06/26/2023 20:16:59 - INFO - __main__ -   {"eval_acc": 0.7315238718116416, "eval_f1": 0.7298738584734658, "eval_mcc": 0.4688104375433357, "eval_auc": 0.7939911225784817, "eval_precision": 0.737322424497527, "eval_recall": 0.7315238718116416, "learning_rate": 2.251270878721859e-05, "loss": 0.012002980551678775, "step": 6100}
06/26/2023 20:17:42 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:17:43 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:17:43 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:17:43 - INFO - __main__ -     Batch size = 48
06/26/2023 20:17:52 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:17:52 - INFO - __main__ -     acc = 0.7266187050359713
06/26/2023 20:17:52 - INFO - __main__ -     auc = 0.7889721756098896
06/26/2023 20:17:52 - INFO - __main__ -     f1 = 0.7233579406869716
06/26/2023 20:17:52 - INFO - __main__ -     mcc = 0.46431527667129757
06/26/2023 20:17:52 - INFO - __main__ -     precision = 0.7378319522610934
06/26/2023 20:17:52 - INFO - __main__ -     recall = 0.7266187050359713
06/26/2023 20:17:52 - INFO - __main__ -   {"eval_acc": 0.7266187050359713, "eval_f1": 0.7233579406869716, "eval_mcc": 0.46431527667129757, "eval_auc": 0.7889721756098896, "eval_precision": 0.7378319522610934, "eval_recall": 0.7266187050359713, "learning_rate": 2.1060275962236747e-05, "loss": 0.005873800147819566, "step": 6200}
06/26/2023 20:18:34 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:18:35 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:18:35 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:18:35 - INFO - __main__ -     Batch size = 48
06/26/2023 20:18:44 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:18:44 - INFO - __main__ -     acc = 0.7272727272727273
06/26/2023 20:18:44 - INFO - __main__ -     auc = 0.7945527518766247
06/26/2023 20:18:44 - INFO - __main__ -     f1 = 0.7263663272387373
06/26/2023 20:18:44 - INFO - __main__ -     mcc = 0.45758703890935337
06/26/2023 20:18:44 - INFO - __main__ -     precision = 0.7303244879956131
06/26/2023 20:18:44 - INFO - __main__ -     recall = 0.7272727272727273
06/26/2023 20:18:44 - INFO - __main__ -   {"eval_acc": 0.7272727272727273, "eval_f1": 0.7263663272387373, "eval_mcc": 0.45758703890935337, "eval_auc": 0.7945527518766247, "eval_precision": 0.7303244879956131, "eval_recall": 0.7272727272727273, "learning_rate": 1.9607843137254903e-05, "loss": 0.010794382262829458, "step": 6300}
06/26/2023 20:19:28 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:19:28 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:19:28 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:19:28 - INFO - __main__ -     Batch size = 48
06/26/2023 20:19:37 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:19:37 - INFO - __main__ -     acc = 0.7275997383911053
06/26/2023 20:19:37 - INFO - __main__ -     auc = 0.796440604814442
06/26/2023 20:19:37 - INFO - __main__ -     f1 = 0.7248627426582672
06/26/2023 20:19:37 - INFO - __main__ -     mcc = 0.46453545344140235
06/26/2023 20:19:37 - INFO - __main__ -     precision = 0.7370314538028953
06/26/2023 20:19:37 - INFO - __main__ -     recall = 0.7275997383911053
06/26/2023 20:19:37 - INFO - __main__ -   {"eval_acc": 0.7275997383911053, "eval_f1": 0.7248627426582672, "eval_mcc": 0.46453545344140235, "eval_auc": 0.796440604814442, "eval_precision": 0.7370314538028953, "eval_recall": 0.7275997383911053, "learning_rate": 1.8155410312273058e-05, "loss": 0.009360653114999878, "step": 6400}
06/26/2023 20:20:21 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:20:21 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:20:21 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:20:21 - INFO - __main__ -     Batch size = 48
06/26/2023 20:20:30 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:20:30 - INFO - __main__ -     acc = 0.7253106605624591
06/26/2023 20:20:30 - INFO - __main__ -     auc = 0.7962171080069176
06/26/2023 20:20:30 - INFO - __main__ -     f1 = 0.7227126644636706
06/26/2023 20:20:30 - INFO - __main__ -     mcc = 0.4593103683890231
06/26/2023 20:20:30 - INFO - __main__ -     precision = 0.7340834805408347
06/26/2023 20:20:30 - INFO - __main__ -     recall = 0.7253106605624591
06/26/2023 20:20:30 - INFO - __main__ -   {"eval_acc": 0.7253106605624591, "eval_f1": 0.7227126644636706, "eval_mcc": 0.4593103683890231, "eval_auc": 0.7962171080069176, "eval_precision": 0.7340834805408347, "eval_recall": 0.7253106605624591, "learning_rate": 1.6702977487291213e-05, "loss": 0.009495442798997828, "step": 6500}
06/26/2023 20:21:13 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:21:14 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:21:14 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:21:14 - INFO - __main__ -     Batch size = 48
06/26/2023 20:21:23 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:21:23 - INFO - __main__ -     acc = 0.7292347939829954
06/26/2023 20:21:23 - INFO - __main__ -     auc = 0.7959253858581485
06/26/2023 20:21:23 - INFO - __main__ -     f1 = 0.7287293468781673
06/26/2023 20:21:23 - INFO - __main__ -     mcc = 0.4601876916463499
06/26/2023 20:21:23 - INFO - __main__ -     precision = 0.7309561169393259
06/26/2023 20:21:23 - INFO - __main__ -     recall = 0.7292347939829955
06/26/2023 20:21:23 - INFO - __main__ -   {"eval_acc": 0.7292347939829954, "eval_f1": 0.7287293468781673, "eval_mcc": 0.4601876916463499, "eval_auc": 0.7959253858581485, "eval_precision": 0.7309561169393259, "eval_recall": 0.7292347939829955, "learning_rate": 1.5250544662309369e-05, "loss": 0.004548760453162686, "step": 6600}
06/26/2023 20:22:05 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:22:06 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:22:06 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:22:06 - INFO - __main__ -     Batch size = 48
06/26/2023 20:22:15 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:22:15 - INFO - __main__ -     acc = 0.7295618051013735
06/26/2023 20:22:15 - INFO - __main__ -     auc = 0.7963505644738029
06/26/2023 20:22:15 - INFO - __main__ -     f1 = 0.729123570689898
06/26/2023 20:22:15 - INFO - __main__ -     mcc = 0.46061643560464094
06/26/2023 20:22:15 - INFO - __main__ -     precision = 0.7310570574397515
06/26/2023 20:22:15 - INFO - __main__ -     recall = 0.7295618051013735
06/26/2023 20:22:15 - INFO - __main__ -   {"eval_acc": 0.7295618051013735, "eval_f1": 0.729123570689898, "eval_mcc": 0.46061643560464094, "eval_auc": 0.7963505644738029, "eval_precision": 0.7310570574397515, "eval_recall": 0.7295618051013735, "learning_rate": 1.3798111837327524e-05, "loss": 0.005465120440167084, "step": 6700}
06/26/2023 20:22:58 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:22:58 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:22:58 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:22:58 - INFO - __main__ -     Batch size = 48
06/26/2023 20:23:07 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:23:07 - INFO - __main__ -     acc = 0.7321778940483976
06/26/2023 20:23:07 - INFO - __main__ -     auc = 0.7959097731625033
06/26/2023 20:23:07 - INFO - __main__ -     f1 = 0.7307717486965633
06/26/2023 20:23:07 - INFO - __main__ -     mcc = 0.4692836811973996
06/26/2023 20:23:07 - INFO - __main__ -     precision = 0.7371319353429445
06/26/2023 20:23:07 - INFO - __main__ -     recall = 0.7321778940483976
06/26/2023 20:23:07 - INFO - __main__ -   {"eval_acc": 0.7321778940483976, "eval_f1": 0.7307717486965633, "eval_mcc": 0.4692836811973996, "eval_auc": 0.7959097731625033, "eval_precision": 0.7371319353429445, "eval_recall": 0.7321778940483976, "learning_rate": 1.2345679012345678e-05, "loss": 0.005491709248908592, "step": 6800}
06/26/2023 20:23:50 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:23:50 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:23:50 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:23:50 - INFO - __main__ -     Batch size = 48
06/26/2023 20:23:59 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:23:59 - INFO - __main__ -     acc = 0.7253106605624591
06/26/2023 20:23:59 - INFO - __main__ -     auc = 0.793854671895993
06/26/2023 20:23:59 - INFO - __main__ -     f1 = 0.7241542241542241
06/26/2023 20:23:59 - INFO - __main__ -     mcc = 0.454447820990241
06/26/2023 20:23:59 - INFO - __main__ -     precision = 0.7291534069972772
06/26/2023 20:23:59 - INFO - __main__ -     recall = 0.7253106605624591
06/26/2023 20:23:59 - INFO - __main__ -   {"eval_acc": 0.7253106605624591, "eval_f1": 0.7241542241542241, "eval_mcc": 0.454447820990241, "eval_auc": 0.793854671895993, "eval_precision": 0.7291534069972772, "eval_recall": 0.7253106605624591, "learning_rate": 1.0893246187363835e-05, "loss": 0.005909208349385154, "step": 6900}
06/26/2023 20:24:42 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:24:42 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:24:42 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:24:42 - INFO - __main__ -     Batch size = 48
06/26/2023 20:24:51 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:24:51 - INFO - __main__ -     acc = 0.7266187050359713
06/26/2023 20:24:51 - INFO - __main__ -     auc = 0.790835005460166
06/26/2023 20:24:51 - INFO - __main__ -     f1 = 0.7238169934640523
06/26/2023 20:24:51 - INFO - __main__ -     mcc = 0.4627227203290574
06/26/2023 20:24:51 - INFO - __main__ -     precision = 0.7362032691374009
06/26/2023 20:24:51 - INFO - __main__ -     recall = 0.7266187050359711
06/26/2023 20:24:51 - INFO - __main__ -   {"eval_acc": 0.7266187050359713, "eval_f1": 0.7238169934640523, "eval_mcc": 0.4627227203290574, "eval_auc": 0.790835005460166, "eval_precision": 0.7362032691374009, "eval_recall": 0.7266187050359711, "learning_rate": 9.440813362381991e-06, "loss": 0.0006786718150215165, "step": 7000}
06/26/2023 20:25:34 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:25:35 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:25:35 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:25:35 - INFO - __main__ -     Batch size = 48
06/26/2023 20:25:44 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:25:44 - INFO - __main__ -     acc = 0.7259646827992152
06/26/2023 20:25:44 - INFO - __main__ -     auc = 0.7907954390396952
06/26/2023 20:25:44 - INFO - __main__ -     f1 = 0.7240000861623298
06/26/2023 20:25:44 - INFO - __main__ -     mcc = 0.45850385961369594
06/26/2023 20:25:44 - INFO - __main__ -     precision = 0.7325869984154288
06/26/2023 20:25:44 - INFO - __main__ -     recall = 0.7259646827992152
06/26/2023 20:25:44 - INFO - __main__ -   {"eval_acc": 0.7259646827992152, "eval_f1": 0.7240000861623298, "eval_mcc": 0.45850385961369594, "eval_auc": 0.7907954390396952, "eval_precision": 0.7325869984154288, "eval_recall": 0.7259646827992152, "learning_rate": 7.988380537400146e-06, "loss": 0.003768585033030831, "step": 7100}
06/26/2023 20:26:27 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:26:28 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:26:28 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:26:28 - INFO - __main__ -     Batch size = 48
06/26/2023 20:26:37 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:26:37 - INFO - __main__ -     acc = 0.7249836494440811
06/26/2023 20:26:37 - INFO - __main__ -     auc = 0.7892521347687889
06/26/2023 20:26:37 - INFO - __main__ -     f1 = 0.7230273824851391
06/26/2023 20:26:37 - INFO - __main__ -     mcc = 0.4564615023362582
06/26/2023 20:26:37 - INFO - __main__ -     precision = 0.7315247170515611
06/26/2023 20:26:37 - INFO - __main__ -     recall = 0.7249836494440811
06/26/2023 20:26:37 - INFO - __main__ -   {"eval_acc": 0.7249836494440811, "eval_f1": 0.7230273824851391, "eval_mcc": 0.4564615023362582, "eval_auc": 0.7892521347687889, "eval_precision": 0.7315247170515611, "eval_recall": 0.7249836494440811, "learning_rate": 6.535947712418301e-06, "loss": 0.00258659255981911, "step": 7200}
06/26/2023 20:27:19 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:27:20 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:27:20 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:27:20 - INFO - __main__ -     Batch size = 48
06/26/2023 20:27:29 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:27:29 - INFO - __main__ -     acc = 0.7243296272073251
06/26/2023 20:27:29 - INFO - __main__ -     auc = 0.7896606313260826
06/26/2023 20:27:29 - INFO - __main__ -     f1 = 0.7232499860706785
06/26/2023 20:27:29 - INFO - __main__ -     mcc = 0.45220133020085485
06/26/2023 20:27:29 - INFO - __main__ -     precision = 0.7278856849862689
06/26/2023 20:27:29 - INFO - __main__ -     recall = 0.724329627207325
06/26/2023 20:27:29 - INFO - __main__ -   {"eval_acc": 0.7243296272073251, "eval_f1": 0.7232499860706785, "eval_mcc": 0.45220133020085485, "eval_auc": 0.7896606313260826, "eval_precision": 0.7278856849862689, "eval_recall": 0.724329627207325, "learning_rate": 5.083514887436457e-06, "loss": 0.0031612516481891364, "step": 7300}
06/26/2023 20:28:12 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:28:12 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:28:12 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:28:12 - INFO - __main__ -     Batch size = 48
06/26/2023 20:28:21 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:28:21 - INFO - __main__ -     acc = 0.7266187050359713
06/26/2023 20:28:21 - INFO - __main__ -     auc = 0.7893109497181373
06/26/2023 20:28:21 - INFO - __main__ -     f1 = 0.7253233603344656
06/26/2023 20:28:21 - INFO - __main__ -     mcc = 0.4575736908478662
06/26/2023 20:28:21 - INFO - __main__ -     precision = 0.7309757291690736
06/26/2023 20:28:21 - INFO - __main__ -     recall = 0.7266187050359711
06/26/2023 20:28:21 - INFO - __main__ -   {"eval_acc": 0.7266187050359713, "eval_f1": 0.7253233603344656, "eval_mcc": 0.4575736908478662, "eval_auc": 0.7893109497181373, "eval_precision": 0.7309757291690736, "eval_recall": 0.7266187050359711, "learning_rate": 3.6310820624546117e-06, "loss": 0.003764066583398744, "step": 7400}
06/26/2023 20:29:04 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:29:05 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:29:05 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:29:05 - INFO - __main__ -     Batch size = 48
06/26/2023 20:29:14 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:29:14 - INFO - __main__ -     acc = 0.7256376716808371
06/26/2023 20:29:14 - INFO - __main__ -     auc = 0.7892254007009032
06/26/2023 20:29:14 - INFO - __main__ -     f1 = 0.7243252088812501
06/26/2023 20:29:14 - INFO - __main__ -     mcc = 0.4556346685448208
06/26/2023 20:29:14 - INFO - __main__ -     precision = 0.7300180524305374
06/26/2023 20:29:14 - INFO - __main__ -     recall = 0.7256376716808371
06/26/2023 20:29:14 - INFO - __main__ -   {"eval_acc": 0.7256376716808371, "eval_f1": 0.7243252088812501, "eval_mcc": 0.4556346685448208, "eval_auc": 0.7892254007009032, "eval_precision": 0.7300180524305374, "eval_recall": 0.7256376716808371, "learning_rate": 2.178649237472767e-06, "loss": 0.003957972646512644, "step": 7500}
06/26/2023 20:29:56 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:29:57 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:29:57 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:29:57 - INFO - __main__ -     Batch size = 48
06/26/2023 20:30:06 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:30:06 - INFO - __main__ -     acc = 0.7256376716808371
06/26/2023 20:30:06 - INFO - __main__ -     auc = 0.7888876959553707
06/26/2023 20:30:06 - INFO - __main__ -     f1 = 0.7242232761495981
06/26/2023 20:30:06 - INFO - __main__ -     mcc = 0.45597678146043413
06/26/2023 20:30:06 - INFO - __main__ -     precision = 0.7303635998392929
06/26/2023 20:30:06 - INFO - __main__ -     recall = 0.7256376716808371
06/26/2023 20:30:06 - INFO - __main__ -   {"eval_acc": 0.7256376716808371, "eval_f1": 0.7242232761495981, "eval_mcc": 0.45597678146043413, "eval_auc": 0.7888876959553707, "eval_precision": 0.7303635998392929, "eval_recall": 0.7256376716808371, "learning_rate": 7.262164124909224e-07, "loss": 0.0005065091132382804, "step": 7600}
06/26/2023 20:30:28 - INFO - __main__ -    global_step = 7650, average loss = 0.13358170937972436
06/26/2023 20:30:28 - INFO - __main__ -   Saving model checkpoint to /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold3
06/26/2023 20:30:28 - INFO - transformers.configuration_utils -   Configuration saved in /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold3/config.json
06/26/2023 20:30:28 - INFO - transformers.modeling_utils -   Model weights saved in /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold3/pytorch_model.bin
06/26/2023 20:30:28 - INFO - transformers.configuration_utils -   loading configuration file /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold3/config.json
06/26/2023 20:30:28 - INFO - transformers.configuration_utils -   Model config BertConfig {
  "architectures": [
    "BertForSequenceClassification"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "do_sample": false,
  "eos_token_ids": 0,
  "filter_num": 128,
  "filter_size": [
    2,
    3,
    4,
    5,
    6
  ],
  "finetuning_task": "dnaprom",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "num_return_sequences": 1,
  "num_rnn_layer": 2,
  "output_attentions": false,
  "output_hidden_states": true,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "rnn": "lstm",
  "rnn_dropout": 0.0,
  "rnn_hidden": 768,
  "split": 0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 4101
}

06/26/2023 20:30:28 - INFO - transformers.modeling_utils -   loading weights file /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold3/pytorch_model.bin
06/26/2023 20:30:30 - INFO - transformers.tokenization_utils -   Model name '/data3/linming/DNABERT/examples/output/fold5_100_15296/_fold3' not found in model shortcut name list (dna3, dna4, dna5, dna6). Assuming '/data3/linming/DNABERT/examples/output/fold5_100_15296/_fold3' is a path, a model identifier, or url to a directory containing tokenizer files.
06/26/2023 20:30:30 - INFO - transformers.tokenization_utils -   Didn't find file /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold3/added_tokens.json. We won't load it.
06/26/2023 20:30:30 - INFO - transformers.tokenization_utils -   loading file /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold3/vocab.txt
06/26/2023 20:30:30 - INFO - transformers.tokenization_utils -   loading file None
06/26/2023 20:30:30 - INFO - transformers.tokenization_utils -   loading file /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold3/special_tokens_map.json
06/26/2023 20:30:30 - INFO - transformers.tokenization_utils -   loading file /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold3/tokenizer_config.json
06/26/2023 20:30:30 - INFO - transformers.tokenization_utils -   Model name '/data3/linming/DNABERT/examples/output/fold5_100_15296/_fold3' not found in model shortcut name list (dna3, dna4, dna5, dna6). Assuming '/data3/linming/DNABERT/examples/output/fold5_100_15296/_fold3' is a path, a model identifier, or url to a directory containing tokenizer files.
06/26/2023 20:30:30 - INFO - transformers.tokenization_utils -   Didn't find file /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold3/added_tokens.json. We won't load it.
06/26/2023 20:30:30 - INFO - transformers.tokenization_utils -   loading file /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold3/vocab.txt
06/26/2023 20:30:30 - INFO - transformers.tokenization_utils -   loading file None
06/26/2023 20:30:30 - INFO - transformers.tokenization_utils -   loading file /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold3/special_tokens_map.json
06/26/2023 20:30:30 - INFO - transformers.tokenization_utils -   loading file /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold3/tokenizer_config.json
06/26/2023 20:30:30 - INFO - __main__ -   Evaluate the following checkpoints: ['/data3/linming/DNABERT/examples/output/fold5_100_15296/_fold3']
06/26/2023 20:30:30 - INFO - transformers.configuration_utils -   loading configuration file /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold3/config.json
06/26/2023 20:30:30 - INFO - transformers.configuration_utils -   Model config BertConfig {
  "architectures": [
    "BertForSequenceClassification"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "do_sample": false,
  "eos_token_ids": 0,
  "filter_num": 128,
  "filter_size": [
    2,
    3,
    4,
    5,
    6
  ],
  "finetuning_task": "dnaprom",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "num_return_sequences": 1,
  "num_rnn_layer": 2,
  "output_attentions": false,
  "output_hidden_states": true,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "rnn": "lstm",
  "rnn_dropout": 0.0,
  "rnn_hidden": 768,
  "split": 0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 4101
}

06/26/2023 20:30:30 - INFO - transformers.modeling_utils -   loading weights file /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold3/pytorch_model.bin
06/26/2023 20:30:32 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/3/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:30:33 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:30:33 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:30:33 - INFO - __main__ -     Batch size = 48
06/26/2023 20:30:42 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:30:42 - INFO - __main__ -     acc = 0.7266187050359713
06/26/2023 20:30:42 - INFO - __main__ -     auc = 0.7890818922244927
06/26/2023 20:30:42 - INFO - __main__ -     f1 = 0.7252732987389915
06/26/2023 20:30:42 - INFO - __main__ -     mcc = 0.45774295049897157
06/26/2023 20:30:42 - INFO - __main__ -     precision = 0.7311466397911036
06/26/2023 20:30:42 - INFO - __main__ -     recall = 0.7266187050359711
06/26/2023 20:30:42 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
06/26/2023 20:30:42 - INFO - transformers.configuration_utils -   loading configuration file /data3/linming/DNABERT/examples/embeding_model/6-new-12w-0/config.json
06/26/2023 20:30:42 - INFO - transformers.configuration_utils -   Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "do_sample": false,
  "eos_token_ids": 0,
  "finetuning_task": "dnaprom",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "num_return_sequences": 1,
  "num_rnn_layer": 1,
  "output_attentions": false,
  "output_hidden_states": true,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "rnn": "lstm",
  "rnn_dropout": 0.0,
  "rnn_hidden": 768,
  "split": 10,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 4101
}

06/26/2023 20:30:53 - INFO - transformers.tokenization_utils -   loading file https://raw.githubusercontent.com/jerryji1993/DNABERT/master/src/transformers/dnabert-config/bert-config-6/vocab.txt from cache at /data3/linming/.cache/torch/transformers/ea1474aad40c1c8ed4e1cb7c11345ddda6df27a857fb29e1d4c901d9b900d32d.26f8bd5a32e49c2a8271a46950754a4a767726709b7741c68723bc1db840a87e
06/26/2023 20:30:53 - INFO - transformers.modeling_utils -   loading weights file /data3/linming/DNABERT/examples/embeding_model/6-new-12w-0/pytorch_model.bin
06/26/2023 20:30:54 - INFO - transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
06/26/2023 20:30:54 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']
06/26/2023 20:30:54 - INFO - __main__ -   finish loading model
06/26/2023 20:30:55 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, attention_probs_dropout_prob=0.1, beta1=0.9, beta2=0.999, cache_dir='', config_name='', data_dir='/data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/', device=device(type='cuda'), do_ensemble_pred=False, do_eval=True, do_lower_case=False, do_predict=False, do_train=True, do_visualize=False, early_stop=15, eval_all_checkpoints=False, eval_batch_size=48, evaluate_during_training=True, filter_num=128, filter_size=[2, 3, 4, 5, 6], fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, hidden_dropout_prob=0.1, learning_rate=0.0001, local_rank=-1, logging_steps=100, max_grad_norm=1.0, max_seq_length=300, max_steps=-1, model_name='mutant_Bert_fold5_100_15296_fold4', model_name_or_path='/data3/linming/DNABERT/examples/embeding_model/6-new-12w-0/', model_num=5, model_type='dna', n_gpu=1, n_process=8, no_cuda=False, num_rnn_layer=2, num_train_epochs=30.0, output_dir='/data3/linming/DNABERT/examples/output/fold5_100_15296/_fold4', output_mode='classification', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=48, per_gpu_pred_batch_size=8, per_gpu_train_batch_size=48, predict_dir=None, predict_scan_size=1, result_dir=None, rnn='lstm', rnn_dropout=0.0, rnn_hidden=768, save_steps=4000, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, task_name='dnaprom', tokenizer_name='dna6', train_batch_size=48, visualize_data_dir=None, visualize_models=None, visualize_train=False, warmup_percent=0.1, warmup_steps=0, weight_decay=0.01)
06/26/2023 20:30:55 - INFO - __main__ -   Creating features from dataset file at /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   LOOKING AT /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/train.tsv
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   Writing example 0/1529
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   guid: train-1
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   input_ids: 2 2716 2658 2426 1498 1882 3419 1373 1384 1428 1602 2298 988 3940 3459 1533 2023 3982 3628 2209 629 2502 1802 3099 93 359 1424 1585 2231 717 2856 3218 571 2270 874 3484 1634 2425 1495 1869 3365 1158 522 2074 91 349 1382 1420 1570 2172 482 1913 3541 1863 3341 1064 147 573 2280 914 3642 2268 866 3452 1506 1914 3548 1892 3457 1528 2004 3908 3329 1014 4044 3873 3189 455 1807 3120 179 703 2800 2994 3771 2783 2925 3493 1670 2570 2074 90 345 1365 1350 1291 1056 114 442 1753 2903 3406 1323 1182 620 2468 1665 2549 1989 3847 3087 45 168 657 2616 2257 824 3282 825 3285 840 3346 1084 228 899 3584 2034 4025 3798 2892 3362 1145 469 1861 3333 1030 10 28 98 379 1501 1894 3466 1563 2142 361 1431 1613 2343 1165 549 2181 517 2053 5 6 11 29 103 400 1585 2232 723 2877 3304 913 3640 2260 836 3331 1021 4069 3973 3592 2066 60 225 885 3525 1798 3083 32 114 444 1764 2947 3582 2028 4003 3710 2538 1946 3673 2390 1355 1309 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   guid: train-2
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   input_ids: 2 2508 1825 3189 456 1809 3128 212 835 3327 1005 4005 3720 2580 2115 254 1004 4001 3701 2502 1803 3104 115 445 1768 2961 3637 2248 788 3139 254 1004 4002 3706 2524 1890 3452 1508 1921 3576 2004 3905 3318 972 3873 3192 468 1859 3326 1001 3989 3656 2324 1091 254 1004 4001 3701 2503 1807 3119 173 677 2696 2580 2113 248 979 3903 3311 944 3761 2742 2764 2852 3204 513 2037 4037 3848 3089 56 212 833 3320 980 3907 3327 1005 4005 3717 2567 2061 38 140 548 2178 508 2019 3965 3557 1925 3589 2056 17 56 212 833 3320 980 3907 3328 1012 4033 3832 3028 3905 3318 972 3875 3197 488 1937 3640 2260 833 3320 980 3907 3325 1000 3986 3644 2273 888 3538 1852 3297 888 3540 1859 3325 1000 3988 3649 2293 965 3848 3092 65 248 979 3901 3301 904 3604 2113 248 980 3907 3326 1003 3998 3692 2466 1659 2528 1906 3515 1758 2923 3487 1646 2476 1699 2686 2538 1947 3678 2412 1444 1665 2549 1992 3859 3133 229 904 3603 2111 239 943 3759 2734 2731 2718 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   Writing example 0/1529
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   guid: train-3
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   input_ids: 2 129 504 2003 3901 3301 902 3593 2069 69 261 1031 15 47 173 680 2706 2620 2276 898 3578 2009 3926 3404 1315 1150 490 1945 3671 2383 1325 1190 650 2586 2138 347 1373 1382 1419 1567 2157 424 1681 2616 2257 821 3269 773 3077 6 11 29 102 395 1567 2158 428 1697 2680 2515 1853 3302 905 3608 2131 320 1265 949 3781 2822 3082 26 90 346 1371 1373 1384 1428 1601 2295 975 3885 3239 653 2600 2196 579 2301 997 3974 3593 2069 69 263 1037 39 141 550 2187 541 2150 395 1565 2151 399 1581 2213 645 2568 2065 53 197 774 3083 29 102 396 1572 2177 504 2001 3895 3277 805 3208 530 2106 217 855 3407 1326 1193 662 2636 2340 1153 504 2001 3893 3269 776 3091 61 232 913 3637 2245 775 3085 39 142 556 2209 630 2506 1820 3170 377 1494 1865 3350 1100 289 1142 460 1828 3202 507 2015 3950 3500 1698 2684 2529 1911 3533 1829 3206 524 2081 117 455 1807 3118 171 669 2663 2445 1575 2190 553 2199 589 2343 1166 556 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   guid: train-1530
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   input_ids: 2 4099 4094 4075 4000 3699 2493 1768 2963 3647 2287 942 3756 2721 2680 2513 1848 3283 832 3313 951 3790 2859 3231 621 2470 1674 2587 2141 360 1426 1596 2276 898 3578 2011 3935 3437 1447 1677 2597 2182 524 2084 132 513 2037 4038 3851 3102 107 413 1638 2442 1563 2143 367 1453 1703 2703 2607 2221 679 2701 2599 2192 563 2237 744 2963 3647 2287 941 3752 2707 2622 2281 919 3661 2344 1172 578 2298 987 3933 3429 1416 1556 2115 255 1005 4005 3719 2573 2085 135 528 2097 183 717 2856 3219 576 2292 964 3844 3073 4088 4050 3897 3287 845 3367 1168 562 2236 739 2943 3565 1960 3729 2615 2254 812 3236 643 2559 2029 4008 3729 2615 2255 813 3240 659 2623 2286 939 3741 2664 2451 1600 2289 951 3791 2863 3246 684 2722 2684 2531 1917 3558 1931 3614 2156 417 1655 2510 1836 3234 636 2531 1918 3562 1946 3675 2399 1392 1460 1730 2811 3037 3944 3474 1596 2276 897 3576 2004 3905 3317 968 3860 3139 255 1007 4015 3757 2728 2708 2628 2306 1020 4068 3969 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   guid: train-4
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   input_ids: 2 1617 2358 1226 794 3162 347 1374 1386 1434 1627 2399 1391 1453 1701 2693 2566 2060 36 129 504 2001 3896 3283 831 3311 941 3749 2693 2565 2053 8 17 53 200 786 3129 213 839 3341 1061 133 517 2056 17 55 206 811 3229 614 2442 1563 2141 358 1419 1565 2149 392 1554 2108 225 885 3528 1809 3125 200 785 3125 197 773 3078 11 31 110 426 1690 2649 2390 1354 1306 1114 346 1370 1372 1377 1398 1484 1825 3192 467 1853 3301 901 3589 2053 6 9 21 70 265 1045 69 262 1034 28 99 382 1516 1954 3706 2523 1885 3431 1421 1575 2190 556 2212 641 2550 1993 3861 3144 273 1079 207 813 3238 649 2582 2123 285 1125 389 1541 2056 18 60 225 887 3533 1832 3218 569 2261 837 3335 1037 38 140 546 2169 471 1869 3367 1166 556 2210 634 2524 1892 3458 1532 2018 3962 3545 1878 3401 1302 1100 292 1156 516 2049 4086 4044 3876 3204 516 2050 4090 4059 3934 3435 1440 1652 2498 1785 3029 3910 3338 1050 90 348 1378 1402 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   guid: train-1531
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   Writing example 0/1529
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   input_ids: 2 1125 392 1553 2101 200 786 3131 221 870 3466 1562 2139 349 1381 1413 1541 2056 19 61 230 908 3618 2170 474 1883 3421 1384 1425 1591 2253 807 3216 561 2231 717 2855 3215 560 2227 701 2791 2960 3636 2244 770 3066 4059 3934 3435 1437 1639 2447 1582 2218 668 2658 2427 1504 1905 3509 1733 2824 3091 61 232 916 3649 2294 969 3863 3149 295 1165 552 2195 573 2279 912 3636 2241 758 3018 3866 3163 351 1392 1458 1723 2781 2917 3463 1551 2093 168 659 2623 2285 936 3732 2628 2306 1017 4054 3916 3362 1148 484 1923 3582 2028 4002 3707 2525 1893 3461 1541 2054 11 32 115 447 1773 2983 3726 2604 2211 639 2542 1964 3747 2685 2533 1927 3597 2088 148 577 2293 968 3857 3128 212 834 3324 996 3971 3581 2024 3985 3640 2258 826 3289 856 3411 1341 1256 916 3652 2306 1017 4055 3919 3373 1192 659 2621 2280 916 3649 2293 968 3858 3131 223 878 3499 1695 2669 2472 1684 2625 2296 979 3902 3305 919 3661 2344 1170 569 2264 852 3394 1276 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   guid: train-3059
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   input_ids: 2 2049 4087 4047 3885 3240 660 2628 2308 1025 4088 4049 3894 3273 792 3153 309 1221 773 3077 6 9 23 79 303 1200 692 2756 2820 3074 4091 4062 3947 3486 1642 2459 1629 2406 1418 1561 2134 330 1308 1123 382 1516 1955 3710 2538 1947 3679 2414 1451 1694 2666 2459 1630 2409 1430 1610 2329 1109 327 1295 1070 172 673 2679 2511 1839 3246 683 2719 2671 2479 1710 2731 2718 2668 2466 1658 2523 1886 3434 1435 1631 2415 1455 1709 2728 2705 2613 2245 773 3080 17 54 202 796 3169 376 1491 1855 3310 939 3741 2662 2444 1571 2174 491 1950 3692 2466 1658 2523 1886 3434 1436 1636 2436 1537 2037 4038 3851 3103 109 422 1676 2596 2177 504 2004 3908 3329 1013 4040 3857 3126 204 802 3196 483 1919 3566 1964 3746 2683 2527 1902 3500 1698 2684 2530 1915 3549 1893 3464 1554 2107 222 876 3492 1666 2556 2017 3958 3532 1825 3192 465 1847 3279 813 3240 657 2615 2254 811 3231 621 2472 1683 2622 2284 932 3713 2552 2004 3906 3321 981 3909 3333 1029 7 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   guid: train-5
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   input_ids: 2 1720 2772 2881 3320 979 3901 3304 916 3651 2304 1012 4036 3844 3076 4099 4096 4083 4031 3824 2996 3780 2820 3075 4094 4074 3994 3674 2396 1379 1406 1516 1953 3704 2514 1850 3292 868 3459 1536 2036 4036 3844 3074 4090 4060 3940 3459 1535 2029 4006 3724 2596 2179 511 2032 4019 3774 2796 2979 3711 2543 1968 3763 2751 2799 2989 3752 2707 2624 2291 960 3828 3012 3844 3076 4099 4095 4080 4020 3777 2808 3027 3902 3307 927 3695 2480 1715 2750 2795 2975 3694 2476 1700 2692 2564 2051 4094 4076 4003 3710 2540 1955 3710 2540 1955 3710 2540 1955 3710 2540 1955 3710 2540 1955 3710 2540 1955 3710 2540 1956 3716 2564 2052 4097 4087 4047 3887 3248 692 2756 2819 3071 4080 4020 3780 2820 3076 4100 4099 4096 4084 4035 3839 3054 4011 3744 2673 2488 1747 2880 3316 964 3841 3061 4039 3856 3123 192 753 2999 3791 2864 3252 708 2819 3071 4078 4012 3748 2692 2563 2047 4078 4011 3744 2676 2497 1784 3027 3904 3315 960 3828 3012 3843 3072 4084 4036 3841 3064 4051 3904 3315 960 3825 3000 3796 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   guid: train-1532
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   input_ids: 2 2612 2243 767 3055 4013 3752 2707 2622 2283 927 3694 2475 1694 2666 2458 1626 2396 1380 1409 1525 1989 3847 3085 40 147 574 2283 927 3693 2472 1684 2626 2298 986 3930 3419 1374 1387 1439 1645 2472 1684 2628 2306 1019 4064 3955 3517 1765 2952 3603 2109 229 901 3592 2068 68 260 1027 4095 4078 4011 3741 2663 2447 1583 2221 679 2701 2599 2190 556 2210 634 2524 1891 3454 1514 1945 3671 2382 1322 1179 605 2406 1419 1567 2157 423 1678 2603 2207 622 2475 1695 2669 2472 1684 2627 2301 1000 3985 3639 2256 817 3256 724 2883 3325 999 3982 3628 2212 642 2555 2015 3949 3495 1679 2605 2215 653 2598 2187 543 2157 423 1677 2600 2193 567 2253 808 3220 578 2298 987 3934 3436 1444 1666 2554 2012 3940 3458 1531 2013 3944 3473 1592 2259 831 3312 947 3774 2794 2971 3677 2405 1414 1547 2078 106 409 1622 2378 1307 1117 360 1428 1601 2294 972 3876 3202 508 2020 3972 3588 2051 4095 4079 4013 3751 2702 2604 2212 644 2564 2049 4088 4049 3893 3272 788 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   guid: train-3060
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   input_ids: 2 2437 1542 2057 21 70 267 1054 105 407 1613 2343 1165 550 2185 533 2120 273 1080 210 826 3290 858 3419 1374 1387 1437 1640 2450 1594 2267 862 3433 1429 1606 2315 1054 108 417 1656 2513 1845 3272 787 3134 236 929 3703 2511 1838 3244 673 2680 2513 1846 3274 796 3170 378 1500 1892 3457 1525 1989 3845 3080 20 65 246 972 3875 3198 490 1946 3674 2394 1370 1371 1375 1392 1460 1732 2818 3066 4058 3929 3414 1356 1315 1151 493 1959 3725 2600 2196 579 2301 997 3976 3601 2101 199 781 3112 147 573 2280 914 3643 2269 870 3468 1570 2171 479 1901 3496 1684 2625 2294 972 3875 3198 491 1950 3692 2467 1663 2544 1969 3765 2760 2836 3137 247 973 3880 3219 574 2284 932 3716 2562 2043 4062 3946 3484 1636 2436 1540 2052 4097 4087 4045 3880 3218 569 2261 838 3340 1060 129 504 2002 3900 3300 897 3576 2004 3906 3323 989 3941 3463 1549 2085 134 524 2083 126 492 1954 3705 2518 1865 3349 1094 265 1047 77 296 1169 568 2258 827 3293 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   guid: train-1533
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   input_ids: 2 3691 2464 1652 2498 1786 3035 3935 3438 1451 1694 2667 2461 1640 2450 1595 2272 884 3521 1783 3022 3882 3227 607 2414 1452 1697 2679 2512 1843 3263 752 2995 3775 2797 2984 3730 2620 2276 900 3587 2048 4084 4036 3844 3075 4095 4079 4015 3758 2730 2716 2660 2436 1539 2047 4080 4018 3771 2784 2931 3519 1773 2983 3727 2605 2215 654 2604 2210 633 2520 1874 3387 1245 870 3468 1570 2169 471 1871 3375 1197 679 2703 2608 2227 703 2800 2995 3775 2800 2995 3775 2800 2995 3773 2790 2955 3616 2164 452 1793 3063 4046 3882 3227 605 2406 1419 1566 2155 416 1652 2498 1788 3041 3959 3536 1843 3262 748 2977 3704 2515 1854 3306 922 3676 2404 1411 1536 2033 4024 3793 2869 3271 782 3113 150 588 2337 1143 461 1829 3207 525 2088 147 573 2277 904 3601 2104 210 826 3292 868 3459 1536 2036 4035 3840 3060 4035 3840 3059 4030 3819 2976 3698 2492 1763 2942 3564 1956 3713 2552 2004 3908 3330 1020 4065 3960 3540 1860 3330 1019 4064 3955 3520 1779 3007 3824 2996 3780 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   guid: train-3061
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   input_ids: 2 846 3372 1188 643 2558 2028 4002 3705 2520 1874 3387 1245 871 3472 1588 2244 771 3072 4084 4036 3843 3071 4079 4015 3760 2740 2756 2820 3075 4095 4078 4012 3747 2687 2542 1963 3742 2668 2468 1666 2553 2007 3919 3373 1192 658 2619 2269 871 3472 1588 2241 758 3019 3870 3178 411 1629 2407 1423 1582 2219 671 2669 2472 1683 2622 2283 925 3688 2450 1596 2274 890 3548 1892 3459 1535 2030 4011 3743 2670 2475 1695 2669 2472 1684 2628 2307 1021 4071 3984 3635 2237 743 2960 3634 2233 728 2900 3393 1272 980 3907 3327 1005 4008 3732 2627 2304 1012 4034 3835 3037 3942 3466 1564 2145 376 1492 1858 3322 987 3934 3436 1443 1661 2534 1932 3620 2178 508 2020 3971 3583 2030 4010 3739 2654 2411 1437 1639 2447 1582 2219 671 2669 2472 1683 2623 2285 936 3731 2621 2280 915 3647 2287 941 3750 2699 2589 2149 391 1549 2087 143 559 2223 687 2733 2725 2693 2568 2067 62 236 931 3710 2540 1955 3711 2541 1958 3721 2584 2131 319 1261 935 3727 2605 2215 655 2605 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   guid: train-1534
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   input_ids: 2 1687 2638 2345 1173 582 2313 1048 84 322 1273 984 3923 3391 1262 938 3738 2651 2398 1385 1429 1606 2313 1047 78 297 1173 582 2314 1049 87 333 1318 1162 540 2148 385 1528 2001 3893 3269 776 3090 57 213 840 3346 1082 218 859 3421 1383 1421 1574 2188 546 2170 475 1885 3429 1413 1541 2053 7 15 45 165 648 2578 2105 213 840 3345 1078 204 801 3190 458 1818 3161 342 1355 1310 1131 413 1639 2447 1582 2219 671 2670 2476 1699 2686 2540 1953 3702 2507 1822 3178 412 1633 2422 1482 1817 3159 333 1317 1159 527 2095 173 680 2706 2617 2261 840 3345 1079 205 806 3209 535 2125 295 1167 557 2216 657 2613 2246 777 3094 76 290 1148 484 1921 3573 1992 3857 3125 200 785 3126 201 792 3153 310 1228 804 3202 507 2013 3943 3470 1578 2202 604 2401 1397 1477 1798 3083 29 102 396 1571 2174 490 1947 3677 2406 1419 1565 2150 393 1557 2118 268 1059 126 489 1943 3661 2344 1171 573 2280 916 3650 2300 993 3957 3525 1797 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   guid: train-3062
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   input_ids: 2 3309 934 3724 2596 2178 507 2014 3948 3492 1665 2551 1999 3887 3248 692 2756 2818 3067 4063 3951 3504 1714 2748 2786 2939 3551 1902 3500 1699 2685 2536 1940 3651 2303 1008 4019 3774 2796 2979 3711 2543 1965 3752 2707 2621 2280 915 3645 2280 916 3649 2296 978 3899 3293 872 3475 1599 2285 935 3727 2605 2215 653 2599 2189 552 2193 565 2248 788 3139 253 1000 3985 3640 2257 821 3272 788 3137 248 980 3906 3323 989 3943 3471 1583 2224 691 2749 2790 2956 3620 2178 507 2013 3942 3467 1565 2150 396 1572 2178 507 2013 3942 3467 1568 2163 446 1770 2970 3675 2399 1390 1452 1697 2678 2507 1822 3180 419 1662 2540 1956 3716 2562 2044 4067 3967 3567 1966 3753 2711 2640 2355 1215 749 2984 3731 2624 2290 956 3812 2947 3581 2022 3978 3611 2142 361 1431 1613 2342 1163 542 2154 411 1629 2407 1423 1583 2221 679 2703 2605 2216 660 2628 2307 1022 4075 3999 3693 2469 1671 2574 2090 155 608 2420 1474 1787 3039 3951 3501 1702 2699 2590 2154 411 1629 2406 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   Writing example 0/1529
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   guid: train-3063
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   input_ids: 2 2139 350 1388 1444 1665 2550 1993 3863 3150 297 1173 581 2309 1030 12 36 130 508 2020 3971 3581 2021 3976 3604 2114 250 986 3929 3416 1364 1345 1270 969 3862 3148 289 1144 466 1852 3300 898 3578 2010 3930 3418 1370 1369 1366 1355 1311 1135 431 1709 2727 2702 2601 2197 581 2309 1029 7 13 40 148 578 2300 993 3957 3525 1797 3077 6 12 35 126 490 1946 3674 2396 1378 1403 1503 1903 3502 1705 2711 2637 2344 1172 578 2298 986 3929 3415 1359 1326 1193 661 2629 2311 1038 42 156 611 2430 1513 1941 3654 2316 1059 125 485 1928 3602 2106 218 857 3416 1361 1333 1224 785 3125 198 778 3098 92 353 1399 1485 1829 3205 520 2066 59 221 872 3474 1593 2261 837 3333 1029 6 12 34 122 476 1889 3446 1484 1828 3202 506 2010 3930 3418 1371 1373 1383 1423 1581 2213 645 2568 2067 63 237 936 3730 2620 2273 887 3534 1835 3230 618 2458 1626 2396 1380 1411 1535 2030 4011 3741 2662 2442 1561 2134 330 1307 1117 357 1413 1544 2066 57 215 845 3365 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   guid: train-4588
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   input_ids: 2 3816 2964 3651 2301 997 3975 3599 2095 174 684 2724 2692 2563 2047 4079 4014 3755 2719 2669 2471 1678 2604 2210 635 2527 1904 3508 1729 2808 3028 3907 3326 1003 3998 3692 2468 1668 2563 2047 4079 4014 3753 2711 2639 2350 1194 668 2660 2435 1535 2029 4008 3732 2627 2302 1004 4001 3702 2508 1825 3192 468 1860 3330 1020 4067 3967 3567 1966 3755 2719 2671 2480 1715 2750 2796 2980 3716 2562 2044 4066 3963 3551 1901 3495 1679 2606 2220 675 2685 2533 1926 3596 2083 127 495 1968 3763 2750 2795 2976 3700 2499 1791 3054 4011 3744 2675 2496 1779 3006 3819 2976 3700 2499 1791 3054 4011 3744 2675 2496 1779 3006 3819 2976 3700 2499 1791 3055 4016 3763 2750 2795 2975 3694 2474 1689 2647 2382 1323 1181 616 2451 1598 2282 922 3674 2396 1379 1406 1516 1955 3712 2547 1984 3828 3009 3832 3025 3893 3271 782 3115 159 624 2483 1727 2799 2989 3751 2702 2603 2208 628 2499 1789 3048 3987 3647 2285 936 3732 2627 2304 1011 4031 3824 2995 3775 2800 2995 3774 2795 2975 3694 2475 1695 2671 2479 1712 2739 2749 2791 2958 3626 2204 609 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   Writing example 0/1529
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   guid: train-4589
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   input_ids: 2 2783 2926 3500 1699 2688 2547 1983 3824 2995 3775 2798 2987 3743 2670 2475 1696 2676 2499 1791 3056 4019 3775 2797 2984 3731 2622 2283 927 3693 2471 1679 2606 2219 671 2671 2479 1712 2737 2744 2771 2879 3309 935 3725 2600 2196 579 2303 1007 4016 3764 2755 2814 3051 3999 3694 2476 1699 2685 2536 1940 3652 2307 1023 4077 4008 3732 2628 2307 1023 4079 4015 3760 2738 2747 2784 2931 3519 1775 2992 3763 2751 2800 2995 3776 2804 3010 3836 3043 3967 3568 1972 3779 2815 3056 4020 3779 2815 3055 4015 3757 2728 2707 2622 2283 928 3700 2500 1795 3071 4080 4019 3776 2801 2999 3791 2863 3247 685 2727 2703 2605 2215 655 2605 2216 659 2621 2280 915 3646 2283 927 3696 2484 1731 2815 3056 4020 3780 2819 3072 4083 4031 3824 2996 3779 2815 3053 4007 3728 2612 2243 768 3060 4036 3842 3068 4068 3971 3581 2023 3983 3629 2215 655 2605 2215 655 2607 2223 685 2725 2693 2568 2067 64 244 961 3829 3016 3859 3136 243 957 3814 2956 3620 2179 512 2036 4036 3843 3072 4084 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   guid: train-6117
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   input_ids: 2 139 542 2154 411 1631 2414 1451 1693 2661 2437 1542 2058 26 92 356 1409 1526 1995 3870 3180 420 1667 2558 2025 3990 3660 2338 1145 469 1864 3346 1084 228 899 3582 2028 4004 3716 2564 2049 4085 4040 3857 3128 210 827 3294 874 3483 1631 2413 1447 1677 2597 2181 520 2068 68 257 1016 4049 3894 3275 797 3176 403 1598 2282 922 3673 2392 1362 1338 1243 862 3434 1435 1629 2408 1426 1593 2263 847 3374 1194 665 2648 2385 1336 1234 826 3291 863 3437 1447 1678 2602 2204 609 2423 1487 1840 3249 696 2771 2879 3309 935 3725 2598 2188 546 2171 478 1898 3483 1632 2417 1462 1739 2846 3177 407 1613 2341 1157 520 2066 58 219 861 3431 1423 1581 2214 651 2590 2153 406 1609 2325 1095 269 1061 135 525 2086 140 546 2170 475 1886 3436 1442 1660 2531 1918 3564 1956 3715 2558 2026 3995 3679 2413 1446 1676 2593 2165 456 1812 3137 248 980 3906 3321 984 3921 3384 1233 822 3274 795 3165 358 1420 1570 2171 477 1893 3464 1556 2113 248 977 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   guid: train-4590
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   input_ids: 2 3547 1887 3437 1445 1672 2580 2116 260 1025 4087 4045 3880 3218 569 2264 851 3391 1263 943 3758 2732 2723 2686 2539 1952 3700 2499 1791 3054 4010 3739 2656 2417 1464 1746 2874 3291 863 3437 1447 1678 2604 2211 639 2542 1961 3733 2632 2322 1084 228 899 3584 2033 4024 3794 2876 3299 893 3558 1931 3615 2157 423 1678 2603 2207 621 2472 1683 2622 2284 932 3715 2560 2035 4030 3820 2978 3708 2529 1910 3532 1828 3202 508 2020 3971 3583 2031 4015 3760 2737 2743 2766 2860 3235 637 2533 1928 3604 2113 247 973 3877 3205 518 2059 30 108 420 1667 2557 2021 3976 3604 2113 247 973 3877 3205 518 2059 30 108 417 1655 2512 1841 3256 724 2881 3317 965 3845 3079 14 44 163 640 2548 1986 3833 3030 3916 3364 1156 515 2048 4084 4036 3844 3075 4095 4077 4008 3732 2628 2306 1020 4068 3972 3588 2052 4099 4096 4084 4036 3844 3075 4096 4082 4027 3807 2926 3497 1686 2635 2333 1127 399 1582 2220 674 2683 2527 1903 3502 1708 2724 2692 2563 2046 4075 3999 3695 2479 1711 2733 2728 2708 2626 2300 994 3964 3556 1924 3585 2039 4045 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   guid: train-6118
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   input_ids: 2 4097 4088 4052 3907 3328 1012 4035 3838 3050 3995 3680 2420 1476 1796 3076 4098 4090 4059 3936 3444 1475 1792 3060 4035 3840 3060 4034 3836 3044 3971 3584 2036 4035 3840 3060 4035 3840 3057 4023 3792 2868 3267 766 3050 3995 3680 2420 1476 1795 3072 4084 4035 3837 3045 3973 3590 2059 31 112 436 1731 2816 3060 4035 3840 3060 4036 3841 3064 4051 3902 3308 930 3708 2532 1921 3576 2004 3908 3332 1028 4098 4092 4068 3971 3581 2024 3986 3642 2265 855 3406 1323 1184 628 2499 1791 3054 4011 3743 2670 2475 1695 2670 2475 1695 2670 2475 1695 2670 2475 1695 2670 2475 1695 2672 2483 1728 2804 3011 3840 3060 4035 3837 3048 3987 3648 2292 963 3840 3060 4036 3844 3076 4099 4094 4076 4003 3712 2548 1986 3836 3042 3962 3545 1879 3407 1328 1204 706 2812 3041 3957 3528 1809 3125 200 787 3135 240 945 3765 2757 2821 3078 12 36 129 504 2003 3901 3303 912 3634 2235 735 2925 3496 1684 2627 2302 1004 4001 3703 2511 1837 3239 656 2609 2232 723 2878 3306 922 3674 2395 1375 1390 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   guid: train-4591
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   input_ids: 2 1556 2115 255 1006 4009 3733 2630 2316 1058 121 471 1871 3375 1197 680 2708 2628 2307 1023 4078 4010 3739 2655 2413 1448 1684 2626 2299 989 3942 3467 1567 2157 424 1681 2613 2247 782 3114 156 609 2421 1478 1804 3107 125 486 1931 3614 2156 420 1666 2555 2014 3946 3483 1630 2412 1443 1662 2537 1943 3661 2343 1166 556 2212 641 2550 1993 3864 3153 311 1230 810 3228 610 2427 1502 1899 3487 1646 2476 1698 2684 2530 1915 3549 1894 3465 1560 2131 318 1259 925 3687 2445 1574 2185 536 2129 309 1222 778 3098 89 342 1355 1311 1134 428 1699 2686 2540 1956 3713 2549 1992 3857 3128 212 834 3321 981 3912 3345 1078 204 803 3199 494 1962 3740 2660 2435 1533 2024 3985 3640 2258 825 3288 851 3389 1254 906 3610 2138 346 1370 1369 1365 1352 1297 1077 200 785 3126 203 799 3182 426 1691 2656 2417 1461 1733 2821 3077 8 17 53 197 773 3080 17 54 202 793 3159 333 1317 1160 529 2103 206 812 3234 634 2521 1877 3397 1287 1038 42 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   guid: train-6119
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   Writing example 0/1529
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   input_ids: 2 2087 141 552 2196 577 2295 976 3891 3261 743 2957 3623 2189 552 2196 579 2301 999 3984 3634 2236 739 2941 3559 1936 3633 2229 711 2829 3109 135 525 2087 144 564 2244 769 3063 4048 3891 3261 743 2960 3635 2237 744 2964 3651 2301 999 3984 3634 2236 739 2941 3559 1936 3633 2229 712 2833 3125 199 781 3111 144 564 2244 769 3063 4048 3891 3264 755 3008 3827 3005 3816 2964 3651 2301 999 3984 3634 2236 739 2941 3559 1936 3633 2229 711 2829 3109 135 525 2087 141 551 2192 564 2244 769 3063 4048 3891 3264 755 3008 3827 3005 3816 2964 3651 2301 999 3984 3634 2236 739 2941 3559 1936 3633 2229 711 2829 3109 135 525 2087 144 564 2244 769 3063 4048 3891 3264 755 3008 3827 3005 3816 2964 3651 2301 999 3984 3634 2236 739 2941 3559 1936 3633 2229 711 2829 3109 136 532 2116 257 1015 4048 3891 3264 755 3008 3827 3005 3816 2964 3651 2301 999 3984 3634 2236 739 2941 3559 1936 3633 2229 711 2829 3111 141 552 2196 577 2295 973 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   guid: train-4592
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   input_ids: 2 680 2707 2622 2282 924 3684 2435 1534 2028 4001 3703 2510 1836 3236 644 2564 2051 4094 4075 3998 3692 2467 1664 2547 1982 3817 2967 3661 2342 1163 541 2149 389 1544 2068 67 254 1004 4001 3701 2502 1802 3099 95 366 1450 1691 2655 2414 1451 1695 2670 2474 1692 2658 2427 1502 1899 3488 1649 2485 1734 2827 3102 106 411 1631 2415 1454 1708 2724 2692 2564 2052 4100 4099 4093 4072 3988 3652 2308 1025 4087 4045 3879 3215 558 2217 663 2639 2350 1194 668 2660 2434 1529 2008 3921 3381 1224 788 3140 260 1027 4094 4076 4004 3713 2552 2001 3894 3276 804 3203 512 2036 4034 3836 3044 3969 3576 2004 3907 3327 1005 4007 3725 2600 2196 580 2305 1013 4040 3859 3133 232 916 3652 2307 1022 4074 3996 3684 2436 1537 2039 4047 3885 3240 660 2627 2303 1008 4017 3768 2771 2878 3307 925 3688 2452 1603 2303 1007 4014 3756 2721 2677 2502 1804 3108 132 514 2043 4062 3948 3492 1668 2561 2040 4051 3903 3310 940 3748 2689 2549 1989 3845 3080 19 62 234 923 3677 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   guid: train-6120
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   input_ids: 2 533 2118 266 1049 85 326 1289 1046 74 282 1114 347 1373 1382 1417 1558 2124 290 1148 482 1913 3541 1862 3339 1054 105 406 1612 2339 1149 488 1938 3643 2271 878 3498 1692 2657 2422 1481 1813 3144 275 1085 229 903 3599 2094 171 670 2668 2466 1658 2521 1879 3406 1322 1178 603 2399 1390 1449 1687 2638 2347 1181 615 2447 1581 2216 658 2620 2275 893 3559 1934 3626 2201 597 2374 1292 1059 127 493 1958 3723 2590 2155 415 1645 2469 1670 2571 2079 109 421 1671 2574 2092 163 637 2536 1939 3646 2281 919 3661 2342 1162 538 2140 353 1397 1480 1811 3134 234 923 3679 2414 1452 1699 2686 2540 1954 3705 2518 1866 3356 1124 386 1529 2007 3917 3366 1161 535 2125 296 1171 573 2278 908 3618 2170 474 1884 3427 1407 1517 1959 3725 2600 2194 570 2268 866 3452 1506 1916 3555 1918 3563 1951 3693 2469 1670 2570 2074 91 349 1383 1421 1574 2186 539 2141 358 1418 1564 2145 374 1484 1826 3195 478 1900 3492 1665 2549 1989 3845 3077 6 12 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   guid: train-7646
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   input_ids: 2 570 2265 853 3398 1290 1050 92 355 1407 1517 1958 3721 2582 2121 278 1098 284 1122 378 1498 1881 3413 1352 1300 1089 248 980 3906 3321 983 3918 3371 1181 615 2447 1583 2221 679 2702 2603 2206 620 2467 1661 2533 1926 3594 2074 90 347 1373 1381 1413 1541 2053 6 10 28 98 377 1493 1861 3333 1032 18 57 214 841 3349 1096 274 1082 218 859 3422 1386 1435 1630 2412 1442 1657 2517 1861 3333 1029 6 10 28 100 388 1538 2041 4056 3922 3386 1241 854 3402 1306 1114 347 1373 1382 1419 1567 2158 427 1694 2665 2454 1610 2330 1114 348 1377 1398 1482 1817 3158 330 1305 1112 340 1348 1284 1027 4093 4072 3986 3644 2276 897 3573 1992 3858 3130 219 862 3436 1444 1665 2552 2002 3897 3286 841 3351 1103 303 1197 678 2699 2590 2156 420 1665 2552 2002 3898 3292 866 3450 1500 1891 3453 1509 1925 3592 2068 67 253 997 3974 3594 2073 86 331 1310 1132 418 1660 2529 1909 3528 1809 3128 209 824 3282 825 3285 837 3333 1030 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   guid: train-6121
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   input_ids: 2 329 1304 1105 309 1224 788 3140 260 1028 4097 4088 4052 3908 3329 1016 4050 3897 3288 849 3382 1226 793 3157 327 1293 1064 145 565 2245 776 3092 68 260 1025 4088 4052 3908 3329 1013 4040 3857 3127 206 812 3234 636 2530 1914 3546 1882 3418 1369 1365 1350 1291 1053 102 394 1562 2140 354 1403 1501 1893 3461 1542 2060 35 127 494 1963 3742 2665 2455 1615 2351 1197 680 2705 2614 2252 804 3204 514 2044 4068 3969 3576 2003 3902 3305 918 3660 2340 1155 509 2022 3977 3608 2131 319 1262 939 3743 2669 2469 1670 2572 2081 117 456 1812 3137 246 971 3870 3177 407 1615 2351 1197 680 2708 2626 2300 996 3971 3582 2028 4004 3713 2549 1992 3857 3125 197 773 3078 11 31 110 428 1697 2677 2502 1802 3098 92 355 1405 1512 1938 3642 2268 867 3454 1515 1951 3693 2472 1681 2615 2254 812 3236 641 2551 1998 3884 3233 630 2505 1814 3145 280 1106 314 1241 853 3400 1299 1085 232 914 3643 2270 876 3490 1657 2517 1864 3346 1081 215 845 3365 1157 519 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   Writing example 0/1529
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   guid: train-7647
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   input_ids: 2 3341 1062 138 539 2141 357 1416 1554 2106 219 862 3436 1442 1658 2524 1892 3460 1539 2046 4074 3994 3676 2402 1402 1500 1891 3454 1516 1954 3706 2524 1892 3458 1530 2010 3929 3416 1363 1341 1253 902 3596 2084 132 513 2038 4042 3866 3162 346 1370 1370 1370 1371 1375 1391 1455 1711 2733 2726 2699 2589 2151 397 1576 2195 574 2282 922 3676 2404 1409 1525 1989 3847 3085 38 140 545 2166 460 1825 3192 467 1853 3301 904 3604 2113 248 977 3893 3272 787 3136 244 964 3843 3070 4076 4002 3707 2525 1896 3474 1593 2261 837 3336 1041 56 212 833 3319 975 3886 3244 676 2691 2559 2029 4008 3729 2616 2259 832 3313 951 3790 2858 3226 604 2401 1398 1483 1821 3175 399 1581 2214 651 2589 2151 399 1581 2213 647 2573 2085 135 525 2086 138 540 2148 387 1534 2027 3997 3685 2438 1545 2072 83 317 1253 904 3601 2101 198 780 3106 124 482 1916 3555 1919 3567 1966 3754 2713 2645 2374 1292 1057 117 456 1810 3129 213 840 3348 1092 260 1025 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   guid: train-9175
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   input_ids: 2 1455 1710 2731 2718 2667 2462 1644 2468 1668 2562 2043 4062 3948 3490 1657 2517 1864 3348 1091 254 1002 3996 3684 2433 1526 1995 3870 3179 414 1644 2466 1658 2523 1885 3430 1418 1562 2138 346 1370 1371 1374 1385 1432 1620 2370 1275 991 3949 3494 1676 2596 2177 501 1989 3848 3089 53 197 774 3082 25 86 330 1307 1119 366 1450 1689 2648 2385 1334 1226 794 3164 353 1398 1483 1822 3177 408 1617 2358 1228 801 3189 456 1809 3125 197 774 3084 36 132 516 2051 4095 4079 4015 3759 2735 2735 2735 2734 2732 2724 2691 2557 2024 3987 3645 2280 915 3647 2287 941 3749 2695 2573 2087 143 557 2216 657 2616 2259 831 3310 939 3743 2669 2471 1677 2597 2181 517 2053 8 17 53 200 786 3132 227 893 3560 1937 3637 2248 788 3137 245 968 3860 3140 260 1027 4094 4076 4003 3712 2548 1985 3831 3023 3887 3245 677 2693 2568 2067 61 232 916 3650 2299 992 3956 3524 1796 3073 4088 4051 3903 3311 941 3752 2707 2624 2292 964 3843 3069 4072 3985 3637 2248 785 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   guid: train-7648
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   input_ids: 2 230 907 3615 2158 425 1688 2644 2369 1272 979 3903 3310 939 3741 2661 2440 1554 2107 223 878 3497 1687 2639 2350 1196 676 2692 2561 2039 4045 3879 3216 561 2232 724 2883 3328 1011 4030 3820 2980 3714 2554 2011 3934 3435 1440 1651 2494 1772 2977 3704 2515 1855 3309 936 3732 2626 2299 990 3947 3487 1647 2480 1715 2749 2790 2956 3620 2179 509 2024 3987 3647 2286 938 3740 2659 2432 1524 1986 3835 3040 3953 3509 1736 2835 3136 244 964 3843 3072 4084 4035 3839 3054 4012 3747 2686 2539 1951 3693 2472 1683 2622 2282 923 3678 2411 1439 1646 2476 1700 2691 2560 2036 4033 3830 3020 3873 3192 467 1854 3307 928 3700 2498 1788 3043 3968 3571 1981 3816 2964 3652 2307 1023 4077 4008 3731 2622 2283 925 3687 2448 1587 2238 747 2976 3698 2492 1763 2942 3563 1951 3696 2483 1727 2798 2986 3739 2654 2411 1439 1645 2472 1683 2623 2288 947 3774 2795 2975 3695 2477 1701 2696 2579 2111 238 937 3734 2636 2340 1156 516 2050 4092 4068 3972 3588 2049 4087 4045 3880 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   guid: train-9176
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   input_ids: 2 1131 414 1643 2463 1645 2471 1678 2603 2207 622 2474 1691 2653 2408 1426 1596 2276 898 3580 2019 3966 3564 1953 3702 2507 1824 3188 451 1792 3057 4021 3782 2827 3101 104 404 1602 2300 994 3964 3556 1924 3588 2049 4085 4040 3857 3127 207 813 3237 646 2571 2078 105 407 1614 2347 1182 619 2463 1647 2480 1713 2742 2762 2843 3165 359 1424 1587 2240 755 3005 3813 2950 3596 2081 120 466 1850 3291 861 3432 1427 1599 2285 935 3728 2609 2231 717 2856 3219 575 2288 947 3773 2791 2959 3629 2215 655 2605 2216 659 2621 2279 911 3629 2215 655 2605 2214 651 2592 2164 452 1796 3074 4090 4060 3937 3448 1490 1850 3291 862 3435 1439 1645 2471 1679 2607 2224 691 2749 2791 2958 3628 2210 636 2529 1910 3532 1826 3194 476 1892 3460 1539 2045 4071 3983 3632 2227 702 2796 2979 3710 2540 1954 3707 2525 1893 3464 1556 2115 254 1003 3997 3688 2449 1590 2251 798 3180 420 1668 2561 2039 4045 3879 3213 552 2195 574 2284 932 3715 2559 2030 4012 3748 2689 2552 2003 3904 3316 962 3833 3031 3919 3376 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   guid: train-7649
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   input_ids: 2 473 1879 3405 1320 1172 580 2307 1021 4069 3976 3603 2109 230 905 3605 2119 269 1061 134 521 2071 78 297 1174 586 2331 1117 360 1425 1589 2245 776 3089 56 211 831 3311 942 3754 2715 2653 2406 1418 1562 2140 355 1407 1517 1960 3732 2625 2293 968 3857 3125 198 780 3106 123 477 1896 3473 1590 2250 795 3167 365 1445 1671 2575 2094 171 669 2664 2450 1596 2273 886 3529 1813 3143 271 1069 166 651 2590 2154 411 1631 2413 1448 1681 2615 2253 807 3215 558 2218 667 2654 2410 1433 1621 2375 1293 1064 148 580 2305 1014 4043 3871 3183 429 1704 2708 2628 2307 1022 4076 4004 3713 2552 2004 3907 3326 1004 4003 3711 2543 1965 3751 2702 2602 2203 606 2412 1444 1665 2550 1994 3868 3171 383 1517 1958 3723 2591 2159 430 1706 2714 2651 2398 1388 1442 1660 2531 1919 3565 1958 3724 2594 2169 470 1867 3358 1130 412 1634 2425 1496 1875 3389 1255 910 3628 2212 642 2554 2012 3940 3457 1525 1989 3846 3084 35 126 492 1955 3711 2543 1966 3755 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   Writing example 0/1535
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   guid: train-9177
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   input_ids: 2 2563 2047 4078 4012 3747 2688 2547 1982 3820 2979 3712 2548 1987 3840 3060 4035 3839 3054 4012 3745 2679 2509 1832 3219 576 2292 964 3841 3064 4051 3904 3315 958 3820 2978 3706 2523 1887 3440 1460 1731 2816 3059 4029 3816 2961 3640 2259 832 3315 960 3826 3002 3803 2912 3443 1472 1778 3002 3803 2911 3440 1457 1717 2757 2824 3091 64 243 960 3826 3004 3810 2939 3551 1903 3502 1707 2720 2675 2495 1776 2995 3776 2802 3004 3811 2943 3568 1970 3771 2784 2930 3515 1759 2927 3503 1712 2739 2751 2800 2995 3775 2800 2995 3775 2800 2995 3775 2800 2995 3775 2800 2995 3775 2800 2995 3775 2800 2995 3775 2800 2995 3775 2800 2995 3775 2797 2983 3725 2600 2195 575 2287 944 3763 2750 2796 2980 3716 2563 2047 4080 4020 3777 2808 3028 3905 3320 980 3907 3328 1012 4033 3832 3027 3902 3308 932 3715 2560 2035 4030 3820 2978 3707 2527 1903 3504 1716 2755 2814 3051 3998 3691 2462 1642 2460 1635 2432 1524 1988 3844 3073 4085 4040 3859 3133 229 903 3598 2092 161 632 2516 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   guid: train-7650
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   input_ids: 2 3695 2478 1707 2720 2673 2485 1733 2821 3080 17 56 211 832 3313 952 3796 2882 3323 991 3951 3503 1711 2736 2740 2753 2808 3028 3908 3331 1024 4084 4035 3839 3054 4012 3745 2677 2502 1804 3105 117 456 1809 3126 204 801 3192 467 1856 3315 959 3822 2986 3739 2654 2411 1439 1647 2479 1709 2725 2693 2568 2065 55 205 805 3205 517 2053 8 17 55 207 813 3237 647 2574 2090 156 610 2426 1499 1885 3432 1427 1600 2291 959 3822 2986 3740 2657 2422 1483 1821 3173 392 1553 2101 200 785 3125 200 785 3125 200 785 3125 200 785 3125 200 785 3127 205 808 3219 575 2287 943 3757 2725 2695 2575 2095 175 686 2731 2719 2671 2477 1701 2693 2567 2064 51 189 744 2963 3645 2280 915 3646 2283 927 3694 2474 1691 2655 2416 1460 1732 2817 3064 4049 3894 3276 804 3201 503 2000 3892 3267 767 3053 4008 3731 2623 2288 948 3777 2808 3027 3904 3315 957 3816 2961 3640 2260 836 3332 1027 4095 4080 4020 3779 2816 3057 4024 3796 2881 3317 968 3857 3128 212 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   guid: train-10704
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   input_ids: 2 1741 2855 3215 560 2226 700 2786 2940 3556 1921 3576 2004 3905 3318 970 3867 3168 372 1475 1789 3048 3987 3646 2284 931 3710 2540 1953 3704 2516 1859 3328 1012 4035 3839 3055 4015 3757 2725 2696 2578 2108 228 897 3576 2003 3901 3304 915 3646 2282 921 3672 2387 1343 1261 936 3731 2621 2279 910 3625 2199 589 2341 1160 531 2111 239 944 3761 2744 2770 2876 3300 899 3583 2032 4020 3779 2815 3054 4010 3740 2658 2427 1503 1904 3508 1732 2819 3070 4075 4000 3698 2492 1764 2947 3583 2031 4013 3752 2708 2627 2303 1007 4013 3752 2708 2627 2303 1007 4013 3752 2708 2626 2298 988 3939 3455 1519 1967 3758 2730 2715 2653 2407 1422 1579 2207 622 2473 1688 2641 2357 1223 784 3124 195 766 3052 4003 3709 2536 1940 3651 2302 1001 3991 3663 2350 1194 668 2657 2424 1491 1855 3310 939 3743 2671 2479 1710 2730 2714 2652 2403 1407 1519 1967 3760 2738 2747 2782 2923 3487 1646 2475 1693 2664 2452 1601 2296 980 3908 3332 1028 4100 4098 4092 4066 3962 3547 1886 3436 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   guid: train-9178
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   input_ids: 2 2720 2676 2499 1792 3059 4032 3825 2999 3789 2856 3219 575 2287 943 3759 2735 2734 2731 2719 2671 2480 1715 2752 2801 3000 3795 2879 3311 941 3751 2701 2600 2193 567 2256 819 3264 755 3008 3827 3005 3815 2957 3624 2195 575 2288 947 3773 2792 2964 3650 2300 996 3969 3576 2003 3904 3316 961 3831 3022 3883 3229 616 2451 1599 2286 938 3738 2649 2390 1354 1307 1119 368 1459 1728 2803 3007 3822 2987 3744 2676 2499 1789 3048 3988 3651 2304 1012 4036 3844 3076 4098 4092 4068 3972 3588 2052 4099 4096 4084 4036 3844 3075 4096 4084 4035 3838 3051 3997 3688 2451 1597 2280 916 3652 2307 1024 4083 4031 3823 2989 3752 2707 2621 2278 907 3614 2155 415 1646 2475 1696 2675 2493 1767 2957 3622 2188 548 2179 510 2025 3992 3668 2371 1277 999 3983 3632 2227 704 2804 3011 3837 3047 3984 3634 2236 740 2945 3573 1992 3859 3133 232 915 3647 2286 940 3747 2688 2548 1988 3842 3065 4056 3921 3384 1236 835 3328 1012 4036 3843 3069 4072 3988 3650 2297 984 3922 3388 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   guid: train-10705
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   input_ids: 2 3647 2288 947 3773 2791 2959 3630 2220 673 2680 2515 1855 3312 946 3771 2784 2932 3524 1796 3075 4093 4072 3985 3639 2256 820 3268 769 3063 4045 3880 3219 573 2279 910 3627 2208 627 2495 1775 2990 3755 2720 2676 2500 1796 3073 4087 4046 3882 3227 608 2420 1475 1792 3059 4031 3824 2996 3780 2820 3075 4093 4072 3986 3642 2267 862 3434 1436 1636 2434 1531 2014 3947 3488 1650 2491 1757 2919 3469 1576 2193 566 2251 797 3175 400 1586 2235 733 2918 3467 1568 2163 445 1767 2957 3623 2191 558 2218 668 2659 2431 1520 1970 3770 2780 2914 3451 1504 1907 3517 1768 2961 3639 2256 819 3261 744 2961 3638 2251 799 3184 436 1731 2813 3048 3988 3652 2307 1022 4075 4000 3700 2500 1794 3066 4058 3931 3423 1389 1447 1677 2599 2192 562 2235 734 2923 3488 1652 2498 1787 3037 3942 3468 1572 2178 505 2007 3919 3374 1196 673 2680 2516 1859 3327 1008 4018 3770 2779 2910 3436 1442 1657 2519 1872 3379 1213 744 2964 3650 2300 993 3958 3530 1820 3172 386 1532 2020 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   guid: train-9179
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   input_ids: 2 1601 2296 979 3904 3316 962 3836 3044 3970 3580 2019 3967 3567 1967 3759 2735 2735 2735 2736 2740 2756 2819 3069 4071 3984 3636 2244 772 3075 4095 4077 4006 3724 2594 2169 471 1869 3365 1159 528 2100 196 769 3062 4043 3872 3188 452 1795 3070 4076 4003 3711 2544 1969 3767 2768 2867 3263 751 2991 3760 2740 2756 2820 3075 4093 4072 3987 3648 2292 963 3837 3047 3983 3629 2213 647 2576 2100 195 766 3049 3991 3664 2354 1211 735 2925 3496 1683 2624 2291 957 3813 2951 3599 2094 172 674 2683 2527 1903 3502 1708 2722 2683 2527 1903 3502 1708 2724 2690 2556 2019 3968 3572 1988 3844 3075 4095 4080 4019 3775 2800 2996 3780 2820 3074 4092 4065 3960 3539 1856 3316 963 3839 3054 4012 3745 2679 2510 1833 3223 589 2341 1160 532 2116 257 1016 4049 3896 3284 833 3320 980 3905 3317 967 3854 3116 163 640 2548 1987 3840 3059 4031 3822 2988 3748 2689 2552 2004 3907 3326 1004 4003 3711 2543 1966 3756 2724 2690 2556 2017 3957 3528 1811 3136 244 963 3839 3054 4009 3733 2630 2315 1055 110 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   guid: train-10706
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   input_ids: 2 1692 2658 2425 1496 1873 3381 1222 779 3104 116 451 1792 3059 4031 3824 2996 3779 2813 3047 3982 3627 2205 614 2443 1565 2151 398 1580 2209 632 2516 1858 3324 994 3962 3547 1886 3436 1443 1661 2533 1925 3592 2065 54 204 804 3202 507 2014 3946 3484 1633 2421 1480 1811 3134 235 927 3696 2484 1729 2808 3025 3895 3279 814 3243 672 2673 2488 1748 2884 3332 1026 4092 4068 3971 3583 2029 4007 3728 2610 2233 728 2899 3391 1263 941 3751 2703 2605 2215 656 2611 2239 751 2989 3751 2703 2605 2215 654 2601 2200 596 2372 1284 1027 4096 4084 4035 3840 3058 4026 3802 2907 3422 1385 1431 1613 2341 1158 522 2076 98 379 1501 1895 3471 1584 2227 703 2798 2987 3743 2669 2471 1679 2606 2219 671 2670 2475 1695 2671 2480 1714 2746 2778 2908 3428 1409 1525 1989 3846 3082 26 91 350 1388 1444 1665 2550 1996 3873 3192 465 1847 3277 807 3213 552 2196 580 2305 1014 4044 3876 3204 516 2051 4093 4070 3980 3617 2165 456 1812 3140 260 1028 4097 4087 4047 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   guid: train-10707
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   input_ids: 2 2456 1620 2369 1271 975 3886 3243 671 2670 2475 1693 2664 2452 1601 2294 970 3868 3169 376 1489 1848 3283 829 3303 909 3624 2196 577 2293 967 3855 3117 168 657 2616 2260 834 3322 986 3931 3422 1388 1441 1653 2503 1806 3116 161 629 2501 1798 3081 23 78 300 1188 644 2564 2050 4092 4068 3971 3581 2024 3987 3646 2283 927 3694 2475 1694 2666 2459 1631 2414 1451 1695 2670 2475 1695 2670 2475 1694 2668 2467 1663 2542 1963 3743 2670 2475 1695 2670 2475 1695 2670 2475 1695 2670 2475 1694 2666 2459 1631 2414 1451 1694 2666 2459 1631 2414 1451 1694 2666 2459 1631 2414 1451 1694 2666 2459 1630 2410 1435 1630 2410 1435 1630 2410 1435 1630 2410 1435 1631 2414 1451 1695 2670 2475 1695 2670 2475 1695 2670 2475 1695 2670 2475 1695 2670 2475 1695 2670 2476 1698 2682 2524 1891 3454 1514 1947 3678 2412 1443 1662 2540 1955 3710 2540 1955 3710 2540 1954 3706 2524 1891 3454 1516 1955 3710 2538 1947 3678 2412 1443 1662 2540 1955 3710 2540 1956 3716 2563 2046 4076 4003 3709 2535 1936 3633 2229 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   guid: train-10708
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   input_ids: 2 269 1061 136 532 2113 248 980 3905 3317 967 3856 3123 190 747 2974 3689 2454 1611 2336 1139 448 1777 2998 3786 2842 3161 342 1355 1310 1129 408 1620 2371 1277 998 3977 3608 2132 323 1278 1002 3993 3670 2380 1315 1151 494 1962 3739 2654 2411 1438 1642 2458 1625 2390 1354 1308 1122 380 1505 1912 3540 1857 3319 973 3879 3214 556 2211 638 2539 1951 3694 2473 1687 2637 2343 1167 559 2221 680 2707 2623 2285 934 3722 2586 2138 346 1372 1380 1411 1535 2030 4010 3739 2653 2407 1421 1574 2186 540 2148 385 1525 1990 3852 3107 125 488 1937 3638 2252 801 3192 465 1845 3270 777 3096 83 318 1257 918 3660 2338 1146 474 1881 3416 1362 1338 1242 860 3425 1398 1482 1818 3161 342 1353 1301 1096 273 1077 200 788 3138 249 981 3910 3337 1047 78 298 1179 607 2414 1450 1692 2659 2429 1511 1933 3624 2196 579 2303 1007 4015 3757 2726 2700 2596 2179 509 2023 3981 3622 2185 534 2121 278 1098 283 1118 364 1442 1657 2518 1867 3360 1138 441 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:30:55 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 20:31:00 - INFO - __main__ -   Saving features into cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_train_6-new-12w-0_300_dnaprom
06/26/2023 20:31:03 - INFO - __main__ -   ***** Running training *****
06/26/2023 20:31:03 - INFO - __main__ -     Num examples = 12238
06/26/2023 20:31:03 - INFO - __main__ -     Num Epochs = 30
06/26/2023 20:31:03 - INFO - __main__ -     Instantaneous batch size per GPU = 48
06/26/2023 20:31:03 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 48
06/26/2023 20:31:03 - INFO - __main__ -     Gradient Accumulation steps = 1
06/26/2023 20:31:03 - INFO - __main__ -     Total optimization steps = 7650
06/26/2023 20:31:03 - INFO - __main__ -     Continuing training from checkpoint, will skip to saved global_step
06/26/2023 20:31:03 - INFO - __main__ -     Continuing training from epoch 0
06/26/2023 20:31:03 - INFO - __main__ -     Continuing training from global step 0
06/26/2023 20:31:03 - INFO - __main__ -     Will skip the first 0 steps in the first epoch
06/26/2023 20:31:46 - INFO - __main__ -   Creating features from dataset file at /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   Writing example 0/1529
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   guid: dev-1
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   input_ids: 2 1598 2284 931 3711 2543 1968 3763 2749 2791 2960 3635 2239 751 2992 3764 2755 2815 3055 4016 3763 2751 2800 2995 3776 2803 3007 3823 2991 3760 2739 2752 2803 3008 3826 3004 3811 2941 3559 1935 3632 2228 708 2817 3061 4039 3853 3112 148 579 2303 1008 4019 3775 2799 2989 3752 2707 2624 2290 955 3805 2920 3476 1603 2303 1008 4019 3775 2799 2992 3763 2751 2797 2984 3732 2627 2304 1011 4029 3815 2957 3624 2193 568 2259 831 3311 944 3763 2751 2800 2995 3776 2803 3008 3827 3008 3827 3007 3821 2984 3731 2623 2285 935 3728 2611 2239 749 2984 3731 2624 2292 963 3837 3048 3987 3645 2280 915 3648 2291 959 3821 2983 3728 2609 2232 723 2877 3304 915 3648 2292 963 3838 3051 3999 3695 2480 1716 2756 2819 3070 4075 3998 3691 2463 1648 2484 1732 2820 3075 4095 4080 4019 3776 2803 3007 3821 2982 3723 2592 2164 451 1790 3051 4000 3698 2491 1758 2921 3480 1619 2368 1268 964 3843 3070 4076 4003 3712 2548 1988 3844 3073 4088 4049 3895 3277 808 3217 568 2260 836 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   guid: dev-2
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   input_ids: 2 4095 4078 4012 3748 2690 2556 2019 3965 3559 1933 3624 2194 569 2264 850 3388 1251 894 3564 1956 3714 2556 2019 3968 3572 1988 3841 3064 4052 3905 3320 980 3908 3332 1025 4088 4052 3907 3325 999 3983 3631 2223 687 2733 2728 2708 2625 2293 967 3853 3110 139 544 2164 452 1796 3075 4094 4076 4003 3712 2548 1988 3841 3061 4039 3854 3114 156 611 2429 1511 1933 3624 2196 580 2305 1016 4051 3902 3307 926 3692 2467 1661 2536 1940 3652 2308 1028 4099 4096 4083 4031 3823 2991 3760 2737 2744 2770 2874 3291 864 3442 1467 1757 2917 3463 1551 2093 167 654 2601 2199 590 2348 1187 638 2540 1955 3712 2545 1975 3789 2856 3219 575 2285 935 3727 2606 2219 670 2668 2467 1661 2533 1927 3599 2093 167 653 2597 2183 528 2098 188 738 2939 3551 1903 3502 1708 2724 2690 2556 2019 3966 3564 1956 3713 2552 2004 3908 3330 1017 4055 3920 3378 1211 735 2925 3496 1683 2622 2284 931 3711 2543 1966 3753 2712 2643 2365 1255 910 3627 2207 623 2478 1707 2719 2671 2479 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   guid: dev-3
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   input_ids: 2 2459 1631 2414 1451 1695 2670 2475 1695 2670 2475 1693 2662 2443 1568 2164 450 1788 3044 3971 3584 2036 4035 3840 3060 4035 3840 3060 4035 3840 3060 4035 3840 3058 4027 3805 2920 3476 1603 2303 1005 4008 3730 2620 2275 895 3568 1971 3776 2804 3011 3838 3050 3994 3675 2398 1387 1438 1643 2463 1648 2483 1728 2803 3007 3822 2988 3746 2684 2530 1914 3547 1888 3443 1471 1776 2996 3780 2817 3063 4048 3891 3261 742 2954 3611 2144 372 1476 1796 3075 4096 4084 4036 3843 3072 4084 4035 3840 3060 4035 3840 3060 4035 3840 3060 4035 3837 3048 3987 3648 2292 963 3840 3060 4035 3838 3052 4003 3712 2548 1987 3840 3060 4035 3840 3060 4035 3837 3048 3987 3648 2292 963 3840 3060 4035 3838 3052 4003 3712 2548 1987 3840 3060 4035 3840 3060 4035 3840 3060 4035 3840 3060 4035 3837 3048 3987 3647 2286 939 3743 2672 2484 1731 2814 3050 3994 3676 2403 1408 1522 1977 3799 2895 3375 1199 688 2740 2756 2817 3063 4047 3886 3243 670 2668 2465 1656 2515 1856 3315 957 3815 2960 3636 2244 771 3070 4075 3998 3690 2459 1631 2414 1451 1696 2674 2491 1760 2930 3515 1760 2930 3515 1759 2926 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   guid: dev-4
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   input_ids: 2 4094 4076 4004 3713 2551 1999 3886 3242 667 2655 2415 1456 1715 2749 2790 2956 3620 2179 511 2031 4013 3751 2701 2599 2191 558 2218 667 2654 2409 1430 1612 2340 1154 508 2018 3961 3544 1874 3388 1252 897 3573 1992 3857 3126 204 803 3198 492 1956 3716 2563 2046 4076 4004 3713 2551 2000 3890 3259 735 2925 3496 1684 2628 2306 1019 4061 3944 3476 1603 2302 1003 3999 3695 2479 1711 2736 2740 2756 2819 3072 4082 4026 3803 2910 3436 1443 1661 2536 1939 3645 2279 911 3630 2218 667 2654 2410 1435 1629 2408 1428 1604 2307 1023 4078 4012 3748 2692 2561 2040 4049 3893 3272 786 3131 223 879 3502 1708 2724 2691 2559 2029 4007 3726 2604 2211 637 2534 1931 3615 2157 423 1679 2605 2214 651 2592 2164 452 1793 3064 4052 3905 3317 967 3855 3118 171 670 2668 2467 1661 2535 1936 3636 2243 767 3054 4010 3740 2660 2436 1539 2048 4081 4023 3789 2856 3219 573 2279 909 3622 2187 542 2156 420 1668 2562 2042 4059 3933 3432 1427 1599 2288 947 3773 2789 2950 3595 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   guid: dev-5
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   input_ids: 2 2500 1796 3074 4089 4056 3922 3388 1252 898 3580 2017 3959 3535 1838 3241 663 2638 2347 1181 615 2447 1582 2217 663 2637 2342 1162 540 2145 373 1480 1812 3140 257 1016 4049 3896 3284 833 3320 978 3898 3292 868 3459 1535 2029 4008 3731 2621 2280 916 3652 2306 1019 4062 3946 3484 1636 2435 1533 2021 3973 3592 2067 64 244 961 3831 3024 3892 3267 766 3049 3990 3659 2336 1140 451 1789 3045 3976 3604 2114 251 992 3955 3519 1774 2987 3741 2664 2449 1592 2258 826 3291 862 3436 1444 1667 2557 2023 3981 3624 2194 572 2275 895 3565 1957 3720 2577 2102 203 800 3187 446 1769 2968 3665 2359 1230 812 3236 644 2563 2047 4079 4013 3750 2697 2584 2129 309 1224 788 3139 254 1004 4001 3702 2508 1827 3198 490 1947 3677 2408 1427 1600 2290 954 3804 2916 3460 1540 2051 4095 4078 4011 3743 2672 2481 1717 2760 2836 3140 260 1025 4086 4041 3864 3153 312 1233 821 3271 783 3118 170 667 2653 2406 1419 1565 2152 401 1591 2254 811 3229 615 2445 1576 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   Writing example 0/1529
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   guid: dev-1530
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   input_ids: 2 170 666 2649 2391 1359 1325 1189 645 2565 2053 5 7 13 37 134 521 2070 75 286 1132 417 1653 2501 1797 3079 15 45 165 648 2577 2101 197 773 3079 14 44 161 629 2504 1811 3133 229 904 3603 2109 231 910 3628 2209 629 2502 1804 3106 121 472 1874 3387 1245 870 3465 1557 2120 275 1085 229 902 3595 2078 107 414 1644 2468 1667 2558 2028 4001 3701 2501 1800 3089 55 205 806 3210 537 2134 331 1309 1128 402 1594 2265 855 3407 1326 1193 661 2632 2324 1089 248 977 3893 3269 773 3080 17 56 210 828 3297 887 3533 1832 3218 569 2263 845 3365 1158 522 2076 99 383 1518 1961 3735 2637 2344 1169 565 2246 779 3103 109 422 1673 2583 2125 296 1169 565 2248 785 3125 199 783 3117 168 660 2625 2293 968 3857 3126 201 789 3144 275 1086 235 925 3685 2440 1553 2102 204 804 3202 506 2011 3935 3439 1453 1704 2708 2625 2293 968 3859 3133 229 901 3592 2065 56 209 821 3270 778 3098 89 344 1363 1344 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   guid: dev-1531
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   input_ids: 2 3394 1276 996 3971 3584 2033 4022 3787 2846 3179 416 1649 2486 1740 2850 3195 479 1901 3496 1684 2628 2307 1023 4077 4008 3731 2622 2282 924 3681 2423 1485 1830 3210 540 2145 376 1491 1853 3304 916 3650 2299 991 3950 3500 1700 2690 2553 2007 3918 3371 1183 622 2476 1699 2685 2533 1928 3602 2108 228 899 3584 2036 4036 3843 3071 4077 4006 3723 2590 2155 416 1650 2491 1759 2926 3498 1692 2657 2424 1492 1859 3326 1003 3998 3692 2467 1663 2543 1967 3758 2731 2718 2666 2459 1631 2413 1448 1683 2623 2288 947 3776 2803 3007 3821 2984 3731 2624 2291 959 3822 2987 3743 2670 2476 1697 2678 2505 1813 3143 270 1068 164 643 2559 2032 4019 3775 2798 2987 3743 2671 2480 1715 2749 2791 2960 3634 2236 739 2943 3568 1971 3774 2795 2975 3694 2475 1695 2670 2476 1699 2686 2539 1952 3699 2496 1779 3005 3814 2955 3614 2156 419 1663 2542 1963 3742 2667 2463 1645 2472 1684 2628 2305 1015 4046 3883 3232 626 2490 1755 2910 3436 1442 1660 2532 1924 3585 2038 4044 3876 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   guid: dev-1532
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   input_ids: 2 1397 1480 1812 3139 253 1000 3985 3640 2258 826 3291 863 3438 1451 1694 2668 2468 1668 2564 2050 4092 4067 3967 3566 1964 3746 2684 2531 1919 3566 1963 3743 2671 2479 1710 2731 2717 2662 2443 1566 2156 419 1663 2542 1962 3739 2654 2412 1443 1663 2543 1967 3758 2731 2719 2669 2471 1679 2607 2224 692 2755 2815 3055 4013 3751 2703 2606 2218 665 2646 2379 1312 1137 438 1740 2850 3195 478 1898 3483 1632 2418 1468 1763 2943 3566 1963 3741 2663 2445 1576 2196 577 2293 965 3848 3089 53 200 788 3138 252 993 3957 3528 1811 3135 239 941 3752 2708 2628 2308 1027 4093 4072 3987 3646 2282 923 3678 2410 1436 1634 2428 1506 1914 3546 1883 3421 1382 1419 1566 2156 417 1654 2508 1827 3198 490 1948 3682 2427 1503 1901 3496 1684 2625 2293 968 3858 3131 224 884 3521 1784 3025 3894 3276 803 3197 487 1934 3627 2205 616 2449 1592 2257 822 3276 802 3193 472 1874 3387 1248 881 3509 1736 2833 3128 211 830 3308 932 3713 2549 1992 3857 3126 204 803 3197 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   guid: dev-1533
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   input_ids: 2 3133 232 916 3649 2296 977 3896 3284 833 3320 979 3903 3311 942 3755 2717 2663 2446 1579 2205 616 2452 1604 2308 1027 4095 4080 4019 3775 2800 2995 3775 2800 2996 3779 2815 3055 4014 3755 2719 2671 2480 1715 2751 2799 2992 3764 2756 2820 3074 4092 4067 3965 3560 1940 3652 2308 1027 4096 4083 4031 3824 2995 3776 2803 3005 3815 2959 3630 2220 674 2684 2532 1922 3579 2013 3943 3472 1585 2229 712 2836 3137 248 978 3897 3288 851 3391 1261 935 3728 2611 2238 747 2975 3694 2474 1691 2653 2406 1419 1565 2152 404 1602 2297 984 3922 3387 1248 884 3522 1788 3041 3960 3537 1846 3275 800 3187 448 1780 3011 3839 3055 4016 3763 2751 2797 2984 3732 2626 2299 991 3949 3496 1684 2627 2304 1011 4029 3814 2956 3617 2166 460 1828 3203 512 2034 4028 3811 2944 3572 1987 3837 3048 3987 3648 2291 960 3826 3001 3800 2899 3391 1263 942 3755 2717 2662 2441 1557 2117 262 1036 36 132 515 2045 4071 3984 3634 2234 732 2914 3452 1508 1924 3586 2044 4065 3959 3536 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   *** Example ***
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   guid: dev-1534
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   input_ids: 2 261 1030 9 22 74 282 1113 342 1353 1301 1093 261 1031 15 46 169 661 2632 2324 1089 247 973 3877 3205 518 2060 34 121 469 1862 3338 1050 90 348 1378 1403 1501 1896 3476 1602 2298 985 3925 3398 1292 1058 121 470 1865 3349 1093 261 1030 10 28 97 373 1477 1798 3082 28 98 378 1498 1881 3415 1358 1321 1175 590 2346 1178 602 2393 1366 1353 1303 1102 298 1177 600 2385 1334 1226 795 3167 365 1448 1683 2622 2281 919 3661 2342 1161 536 2129 311 1229 808 3220 578 2300 993 3958 3529 1813 3144 273 1079 206 812 3233 631 2510 1835 3229 616 2449 1589 2248 787 3134 233 919 3661 2341 1157 518 2057 22 74 282 1113 343 1359 1326 1195 671 2669 2472 1682 2618 2265 854 3403 1309 1125 389 1541 2053 5 5 8 17 55 207 815 3245 677 2694 2571 2077 102 393 1557 2117 261 1031 14 42 155 606 2409 1430 1609 2326 1100 290 1147 477 1895 3470 1579 2207 621 2472 1681 2613 2245 773 3080 20 66 250 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/26/2023 20:31:46 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)
06/26/2023 20:31:50 - INFO - __main__ -   Saving features into cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:31:51 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:31:51 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:31:51 - INFO - __main__ -     Batch size = 48
06/26/2023 20:32:00 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:32:00 - INFO - __main__ -     acc = 0.6285153695225638
06/26/2023 20:32:00 - INFO - __main__ -     auc = 0.6867387474169544
06/26/2023 20:32:00 - INFO - __main__ -     f1 = 0.5927698730957802
06/26/2023 20:32:00 - INFO - __main__ -     mcc = 0.31907960391232926
06/26/2023 20:32:00 - INFO - __main__ -     precision = 0.6980537308710255
06/26/2023 20:32:00 - INFO - __main__ -     recall = 0.6285153695225638
06/26/2023 20:32:00 - INFO - __main__ -   {"eval_acc": 0.6285153695225638, "eval_f1": 0.5927698730957802, "eval_mcc": 0.31907960391232926, "eval_auc": 0.6867387474169544, "eval_precision": 0.6980537308710255, "eval_recall": 0.6285153695225638, "learning_rate": 1.3071895424836602e-05, "loss": 0.6817854279279709, "step": 100}
06/26/2023 20:32:44 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:32:45 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:32:45 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:32:45 - INFO - __main__ -     Batch size = 48
06/26/2023 20:32:54 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:32:54 - INFO - __main__ -     acc = 0.6805101373446697
06/26/2023 20:32:54 - INFO - __main__ -     auc = 0.7444967386575905
06/26/2023 20:32:54 - INFO - __main__ -     f1 = 0.6645512394072852
06/26/2023 20:32:54 - INFO - __main__ -     mcc = 0.4012077161631882
06/26/2023 20:32:54 - INFO - __main__ -     precision = 0.7229343374792387
06/26/2023 20:32:54 - INFO - __main__ -     recall = 0.6805101373446697
06/26/2023 20:32:54 - INFO - __main__ -   {"eval_acc": 0.6805101373446697, "eval_f1": 0.6645512394072852, "eval_mcc": 0.4012077161631882, "eval_auc": 0.7444967386575905, "eval_precision": 0.7229343374792387, "eval_recall": 0.6805101373446697, "learning_rate": 2.6143790849673204e-05, "loss": 0.6139789396524429, "step": 200}
06/26/2023 20:33:37 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:33:38 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:33:38 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:33:38 - INFO - __main__ -     Batch size = 48
06/26/2023 20:33:47 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:33:47 - INFO - __main__ -     acc = 0.6909744931327665
06/26/2023 20:33:47 - INFO - __main__ -     auc = 0.7552992269363057
06/26/2023 20:33:47 - INFO - __main__ -     f1 = 0.6896066714249118
06/26/2023 20:33:47 - INFO - __main__ -     mcc = 0.38536045069971037
06/26/2023 20:33:47 - INFO - __main__ -     precision = 0.6944011927030538
06/26/2023 20:33:47 - INFO - __main__ -     recall = 0.6909744931327666
06/26/2023 20:33:47 - INFO - __main__ -   {"eval_acc": 0.6909744931327665, "eval_f1": 0.6896066714249118, "eval_mcc": 0.38536045069971037, "eval_auc": 0.7552992269363057, "eval_precision": 0.6944011927030538, "eval_recall": 0.6909744931327666, "learning_rate": 3.9215686274509805e-05, "loss": 0.5992262721061706, "step": 300}
06/26/2023 20:34:30 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:34:31 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:34:31 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:34:31 - INFO - __main__ -     Batch size = 48
06/26/2023 20:34:40 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:34:40 - INFO - __main__ -     acc = 0.684434270765206
06/26/2023 20:34:40 - INFO - __main__ -     auc = 0.7484704905081226
06/26/2023 20:34:40 - INFO - __main__ -     f1 = 0.6824289749109884
06/26/2023 20:34:40 - INFO - __main__ -     mcc = 0.3736171135674282
06/26/2023 20:34:40 - INFO - __main__ -     precision = 0.6892134078055391
06/26/2023 20:34:40 - INFO - __main__ -     recall = 0.684434270765206
06/26/2023 20:34:40 - INFO - __main__ -   {"eval_acc": 0.684434270765206, "eval_f1": 0.6824289749109884, "eval_mcc": 0.3736171135674282, "eval_auc": 0.7484704905081226, "eval_precision": 0.6892134078055391, "eval_recall": 0.684434270765206, "learning_rate": 5.228758169934641e-05, "loss": 0.5879590144753456, "step": 400}
06/26/2023 20:35:23 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:35:24 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:35:24 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:35:24 - INFO - __main__ -     Batch size = 48
06/26/2023 20:35:33 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:35:33 - INFO - __main__ -     acc = 0.6628515369522564
06/26/2023 20:35:33 - INFO - __main__ -     auc = 0.7603502547863605
06/26/2023 20:35:33 - INFO - __main__ -     f1 = 0.632486326927679
06/26/2023 20:35:33 - INFO - __main__ -     mcc = 0.3980562278645867
06/26/2023 20:35:33 - INFO - __main__ -     precision = 0.7432411193457705
06/26/2023 20:35:33 - INFO - __main__ -     recall = 0.6628515369522563
06/26/2023 20:35:33 - INFO - __main__ -   {"eval_acc": 0.6628515369522564, "eval_f1": 0.632486326927679, "eval_mcc": 0.3980562278645867, "eval_auc": 0.7603502547863605, "eval_precision": 0.7432411193457705, "eval_recall": 0.6628515369522563, "learning_rate": 6.535947712418301e-05, "loss": 0.5792439189553261, "step": 500}
06/26/2023 20:36:16 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:36:16 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:36:16 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:36:16 - INFO - __main__ -     Batch size = 48
06/26/2023 20:36:25 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:36:25 - INFO - __main__ -     acc = 0.7060170045781556
06/26/2023 20:36:25 - INFO - __main__ -     auc = 0.7642598448739669
06/26/2023 20:36:25 - INFO - __main__ -     f1 = 0.6981722744547152
06/26/2023 20:36:25 - INFO - __main__ -     mcc = 0.4352813863647085
06/26/2023 20:36:25 - INFO - __main__ -     precision = 0.729920202101211
06/26/2023 20:36:25 - INFO - __main__ -     recall = 0.7060170045781556
06/26/2023 20:36:25 - INFO - __main__ -   {"eval_acc": 0.7060170045781556, "eval_f1": 0.6981722744547152, "eval_mcc": 0.4352813863647085, "eval_auc": 0.7642598448739669, "eval_precision": 0.729920202101211, "eval_recall": 0.7060170045781556, "learning_rate": 7.843137254901961e-05, "loss": 0.5720755246281624, "step": 600}
06/26/2023 20:37:09 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:37:09 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:37:09 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:37:09 - INFO - __main__ -     Batch size = 48
06/26/2023 20:37:18 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:37:18 - INFO - __main__ -     acc = 0.6984957488554611
06/26/2023 20:37:18 - INFO - __main__ -     auc = 0.7760433665078164
06/26/2023 20:37:18 - INFO - __main__ -     f1 = 0.6847746950019677
06/26/2023 20:37:18 - INFO - __main__ -     mcc = 0.4368379731581935
06/26/2023 20:37:18 - INFO - __main__ -     precision = 0.7403419416955797
06/26/2023 20:37:18 - INFO - __main__ -     recall = 0.6984957488554611
06/26/2023 20:37:18 - INFO - __main__ -   {"eval_acc": 0.6984957488554611, "eval_f1": 0.6847746950019677, "eval_mcc": 0.4368379731581935, "eval_auc": 0.7760433665078164, "eval_precision": 0.7403419416955797, "eval_recall": 0.6984957488554611, "learning_rate": 9.150326797385621e-05, "loss": 0.5455953785777092, "step": 700}
06/26/2023 20:38:01 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:38:02 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:38:02 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:38:02 - INFO - __main__ -     Batch size = 48
06/26/2023 20:38:11 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:38:11 - INFO - __main__ -     acc = 0.7168083714846305
06/26/2023 20:38:11 - INFO - __main__ -     auc = 0.7807652445140625
06/26/2023 20:38:11 - INFO - __main__ -     f1 = 0.7133892825478625
06/26/2023 20:38:11 - INFO - __main__ -     mcc = 0.4443479166698714
06/26/2023 20:38:11 - INFO - __main__ -     precision = 0.7276723330570884
06/26/2023 20:38:11 - INFO - __main__ -     recall = 0.7168083714846305
06/26/2023 20:38:11 - INFO - __main__ -   {"eval_acc": 0.7168083714846305, "eval_f1": 0.7133892825478625, "eval_mcc": 0.4443479166698714, "eval_auc": 0.7807652445140625, "eval_precision": 0.7276723330570884, "eval_recall": 0.7168083714846305, "learning_rate": 9.949164851125636e-05, "loss": 0.538696259856224, "step": 800}
06/26/2023 20:38:54 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:38:54 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:38:54 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:38:54 - INFO - __main__ -     Batch size = 48
06/26/2023 20:39:04 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:39:04 - INFO - __main__ -     acc = 0.7177894048397645
06/26/2023 20:39:04 - INFO - __main__ -     auc = 0.7833762005200524
06/26/2023 20:39:04 - INFO - __main__ -     f1 = 0.7176695753201827
06/26/2023 20:39:04 - INFO - __main__ -     mcc = 0.4359490266220579
06/26/2023 20:39:04 - INFO - __main__ -     precision = 0.7181597791138503
06/26/2023 20:39:04 - INFO - __main__ -     recall = 0.7177894048397646
06/26/2023 20:39:04 - INFO - __main__ -   {"eval_acc": 0.7177894048397645, "eval_f1": 0.7176695753201827, "eval_mcc": 0.4359490266220579, "eval_auc": 0.7833762005200524, "eval_precision": 0.7181597791138503, "eval_recall": 0.7177894048397646, "learning_rate": 9.80392156862745e-05, "loss": 0.5000021910667419, "step": 900}
06/26/2023 20:39:47 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:39:47 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:39:47 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:39:47 - INFO - __main__ -     Batch size = 48
06/26/2023 20:39:57 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:39:57 - INFO - __main__ -     acc = 0.7119032047089601
06/26/2023 20:39:57 - INFO - __main__ -     auc = 0.7868435021885578
06/26/2023 20:39:57 - INFO - __main__ -     f1 = 0.7100112966619683
06/26/2023 20:39:57 - INFO - __main__ -     mcc = 0.42944694001036804
06/26/2023 20:39:57 - INFO - __main__ -     precision = 0.7175812708184004
06/26/2023 20:39:57 - INFO - __main__ -     recall = 0.7119032047089602
06/26/2023 20:39:57 - INFO - __main__ -   {"eval_acc": 0.7119032047089601, "eval_f1": 0.7100112966619683, "eval_mcc": 0.42944694001036804, "eval_auc": 0.7868435021885578, "eval_precision": 0.7175812708184004, "eval_recall": 0.7119032047089602, "learning_rate": 9.658678286129266e-05, "loss": 0.47909390449523925, "step": 1000}
06/26/2023 20:40:40 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:40:40 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:40:40 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:40:40 - INFO - __main__ -     Batch size = 48
06/26/2023 20:40:49 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:40:49 - INFO - __main__ -     acc = 0.7086330935251799
06/26/2023 20:40:49 - INFO - __main__ -     auc = 0.7833188826785056
06/26/2023 20:40:49 - INFO - __main__ -     f1 = 0.708613618666931
06/26/2023 20:40:49 - INFO - __main__ -     mcc = 0.4173219743491248
06/26/2023 20:40:49 - INFO - __main__ -     precision = 0.7086888845532462
06/26/2023 20:40:49 - INFO - __main__ -     recall = 0.7086330935251799
06/26/2023 20:40:49 - INFO - __main__ -   {"eval_acc": 0.7086330935251799, "eval_f1": 0.708613618666931, "eval_mcc": 0.4173219743491248, "eval_auc": 0.7833188826785056, "eval_precision": 0.7086888845532462, "eval_recall": 0.7086330935251799, "learning_rate": 9.513435003631082e-05, "loss": 0.3982149039208889, "step": 1100}
06/26/2023 20:41:33 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:41:34 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:41:34 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:41:34 - INFO - __main__ -     Batch size = 48
06/26/2023 20:41:43 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:41:43 - INFO - __main__ -     acc = 0.7168083714846305
06/26/2023 20:41:43 - INFO - __main__ -     auc = 0.7907171616889259
06/26/2023 20:41:43 - INFO - __main__ -     f1 = 0.7167846272637635
06/26/2023 20:41:43 - INFO - __main__ -     mcc = 0.43368946841423384
06/26/2023 20:41:43 - INFO - __main__ -     precision = 0.7168811030282959
06/26/2023 20:41:43 - INFO - __main__ -     recall = 0.7168083714846305
06/26/2023 20:41:43 - INFO - __main__ -   {"eval_acc": 0.7168083714846305, "eval_f1": 0.7167846272637635, "eval_mcc": 0.43368946841423384, "eval_auc": 0.7907171616889259, "eval_precision": 0.7168811030282959, "eval_recall": 0.7168083714846305, "learning_rate": 9.368191721132898e-05, "loss": 0.3791057245433331, "step": 1200}
06/26/2023 20:42:26 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:42:27 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:42:27 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:42:27 - INFO - __main__ -     Batch size = 48
06/26/2023 20:42:36 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:42:36 - INFO - __main__ -     acc = 0.7125572269457161
06/26/2023 20:42:36 - INFO - __main__ -     auc = 0.7972317193513161
06/26/2023 20:42:36 - INFO - __main__ -     f1 = 0.703759077811704
06/26/2023 20:42:36 - INFO - __main__ -     mcc = 0.45286414858682045
06/26/2023 20:42:36 - INFO - __main__ -     precision = 0.7412126136831396
06/26/2023 20:42:36 - INFO - __main__ -     recall = 0.7125572269457161
06/26/2023 20:42:36 - INFO - __main__ -   {"eval_acc": 0.7125572269457161, "eval_f1": 0.703759077811704, "eval_mcc": 0.45286414858682045, "eval_auc": 0.7972317193513161, "eval_precision": 0.7412126136831396, "eval_recall": 0.7125572269457161, "learning_rate": 9.222948438634713e-05, "loss": 0.34124991722404957, "step": 1300}
06/26/2023 20:43:19 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:43:20 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:43:20 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:43:20 - INFO - __main__ -     Batch size = 48
06/26/2023 20:43:29 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:43:29 - INFO - __main__ -     acc = 0.7135382603008502
06/26/2023 20:43:29 - INFO - __main__ -     auc = 0.7911286524618228
06/26/2023 20:43:29 - INFO - __main__ -     f1 = 0.7074823068163801
06/26/2023 20:43:29 - INFO - __main__ -     mcc = 0.4459399525744176
06/26/2023 20:43:29 - INFO - __main__ -     precision = 0.7328182792885688
06/26/2023 20:43:29 - INFO - __main__ -     recall = 0.7135382603008502
06/26/2023 20:43:29 - INFO - __main__ -   {"eval_acc": 0.7135382603008502, "eval_f1": 0.7074823068163801, "eval_mcc": 0.4459399525744176, "eval_auc": 0.7911286524618228, "eval_precision": 0.7328182792885688, "eval_recall": 0.7135382603008502, "learning_rate": 9.077705156136529e-05, "loss": 0.2577903255820274, "step": 1400}
06/26/2023 20:44:12 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:44:13 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:44:13 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:44:13 - INFO - __main__ -     Batch size = 48
06/26/2023 20:44:22 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:44:22 - INFO - __main__ -     acc = 0.724002616088947
06/26/2023 20:44:22 - INFO - __main__ -     auc = 0.7827382187240279
06/26/2023 20:44:22 - INFO - __main__ -     f1 = 0.723896324297447
06/26/2023 20:44:22 - INFO - __main__ -     mcc = 0.44835056872830464
06/26/2023 20:44:22 - INFO - __main__ -     precision = 0.7243480857375053
06/26/2023 20:44:22 - INFO - __main__ -     recall = 0.724002616088947
06/26/2023 20:44:22 - INFO - __main__ -   {"eval_acc": 0.724002616088947, "eval_f1": 0.723896324297447, "eval_mcc": 0.44835056872830464, "eval_auc": 0.7827382187240279, "eval_precision": 0.7243480857375053, "eval_recall": 0.724002616088947, "learning_rate": 8.932461873638345e-05, "loss": 0.2442212425172329, "step": 1500}
06/26/2023 20:45:06 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:45:06 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:45:06 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:45:06 - INFO - __main__ -     Batch size = 48
06/26/2023 20:45:15 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:45:15 - INFO - __main__ -     acc = 0.7190974493132767
06/26/2023 20:45:15 - INFO - __main__ -     auc = 0.7803471236923298
06/26/2023 20:45:15 - INFO - __main__ -     f1 = 0.7190959774106636
06/26/2023 20:45:15 - INFO - __main__ -     mcc = 0.4381994908737513
06/26/2023 20:45:15 - INFO - __main__ -     precision = 0.7191020415845379
06/26/2023 20:45:15 - INFO - __main__ -     recall = 0.7190974493132767
06/26/2023 20:45:15 - INFO - __main__ -   {"eval_acc": 0.7190974493132767, "eval_f1": 0.7190959774106636, "eval_mcc": 0.4381994908737513, "eval_auc": 0.7803471236923298, "eval_precision": 0.7191020415845379, "eval_recall": 0.7190974493132767, "learning_rate": 8.78721859114016e-05, "loss": 0.21165343314409257, "step": 1600}
06/26/2023 20:45:58 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:45:59 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:45:59 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:45:59 - INFO - __main__ -     Batch size = 48
06/26/2023 20:46:08 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:46:08 - INFO - __main__ -     acc = 0.7253106605624591
06/26/2023 20:46:08 - INFO - __main__ -     auc = 0.7927136618786307
06/26/2023 20:46:08 - INFO - __main__ -     f1 = 0.724223522464974
06/26/2023 20:46:08 - INFO - __main__ -     mcc = 0.45421668473826615
06/26/2023 20:46:08 - INFO - __main__ -     precision = 0.7289203673048449
06/26/2023 20:46:08 - INFO - __main__ -     recall = 0.7253106605624591
06/26/2023 20:46:08 - INFO - __main__ -   {"eval_acc": 0.7253106605624591, "eval_f1": 0.724223522464974, "eval_mcc": 0.45421668473826615, "eval_auc": 0.7927136618786307, "eval_precision": 0.7289203673048449, "eval_recall": 0.7253106605624591, "learning_rate": 8.641975308641975e-05, "loss": 0.19140702206641436, "step": 1700}
06/26/2023 20:46:51 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:46:52 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:46:52 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:46:52 - INFO - __main__ -     Batch size = 48
06/26/2023 20:47:01 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:47:01 - INFO - __main__ -     acc = 0.7347939829954219
06/26/2023 20:47:01 - INFO - __main__ -     auc = 0.79999195839238
06/26/2023 20:47:01 - INFO - __main__ -     f1 = 0.734759237269093
06/26/2023 20:47:01 - INFO - __main__ -     mcc = 0.4697110435275945
06/26/2023 20:47:01 - INFO - __main__ -     precision = 0.7349170766612914
06/26/2023 20:47:01 - INFO - __main__ -     recall = 0.7347939829954219
06/26/2023 20:47:01 - INFO - __main__ -   {"eval_acc": 0.7347939829954219, "eval_f1": 0.734759237269093, "eval_mcc": 0.4697110435275945, "eval_auc": 0.79999195839238, "eval_precision": 0.7349170766612914, "eval_recall": 0.7347939829954219, "learning_rate": 8.496732026143791e-05, "loss": 0.18054866142570972, "step": 1800}
06/26/2023 20:47:44 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:47:44 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:47:44 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:47:44 - INFO - __main__ -     Batch size = 48
06/26/2023 20:47:54 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:47:54 - INFO - __main__ -     acc = 0.7158273381294964
06/26/2023 20:47:54 - INFO - __main__ -     auc = 0.7835378881626253
06/26/2023 20:47:54 - INFO - __main__ -     f1 = 0.7157285720169253
06/26/2023 20:47:54 - INFO - __main__ -     mcc = 0.4319549339580082
06/26/2023 20:47:54 - INFO - __main__ -     precision = 0.7161277002576896
06/26/2023 20:47:54 - INFO - __main__ -     recall = 0.7158273381294964
06/26/2023 20:47:54 - INFO - __main__ -   {"eval_acc": 0.7158273381294964, "eval_f1": 0.7157285720169253, "eval_mcc": 0.4319549339580082, "eval_auc": 0.7835378881626253, "eval_precision": 0.7161277002576896, "eval_recall": 0.7158273381294964, "learning_rate": 8.351488743645607e-05, "loss": 0.13545853398740293, "step": 1900}
06/26/2023 20:48:37 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:48:37 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:48:37 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:48:37 - INFO - __main__ -     Batch size = 48
06/26/2023 20:48:46 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:48:46 - INFO - __main__ -     acc = 0.7377370830608241
06/26/2023 20:48:46 - INFO - __main__ -     auc = 0.7987065844084349
06/26/2023 20:48:46 - INFO - __main__ -     f1 = 0.7373848087874058
06/26/2023 20:48:46 - INFO - __main__ -     mcc = 0.47675493278839975
06/26/2023 20:48:46 - INFO - __main__ -     precision = 0.7390195747037905
06/26/2023 20:48:46 - INFO - __main__ -     recall = 0.7377370830608241
06/26/2023 20:48:46 - INFO - __main__ -   {"eval_acc": 0.7377370830608241, "eval_f1": 0.7373848087874058, "eval_mcc": 0.47675493278839975, "eval_auc": 0.7987065844084349, "eval_precision": 0.7390195747037905, "eval_recall": 0.7377370830608241, "learning_rate": 8.206245461147423e-05, "loss": 0.14059190925210716, "step": 2000}
06/26/2023 20:49:29 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:49:30 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:49:30 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:49:30 - INFO - __main__ -     Batch size = 48
06/26/2023 20:49:39 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:49:39 - INFO - __main__ -     acc = 0.7393721386527142
06/26/2023 20:49:39 - INFO - __main__ -     auc = 0.8060599501848074
06/26/2023 20:49:39 - INFO - __main__ -     f1 = 0.7380774215194421
06/26/2023 20:49:39 - INFO - __main__ -     mcc = 0.48354863108336527
06/26/2023 20:49:39 - INFO - __main__ -     precision = 0.7442005990532445
06/26/2023 20:49:39 - INFO - __main__ -     recall = 0.7393721386527141
06/26/2023 20:49:39 - INFO - __main__ -   {"eval_acc": 0.7393721386527142, "eval_f1": 0.7380774215194421, "eval_mcc": 0.48354863108336527, "eval_auc": 0.8060599501848074, "eval_precision": 0.7442005990532445, "eval_recall": 0.7393721386527141, "learning_rate": 8.061002178649237e-05, "loss": 0.12531585058197378, "step": 2100}
06/26/2023 20:50:22 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:50:23 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:50:23 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:50:23 - INFO - __main__ -     Batch size = 48
06/26/2023 20:50:32 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:50:32 - INFO - __main__ -     acc = 0.7289077828646174
06/26/2023 20:50:32 - INFO - __main__ -     auc = 0.7929063610399509
06/26/2023 20:50:32 - INFO - __main__ -     f1 = 0.7288263266355068
06/26/2023 20:50:32 - INFO - __main__ -     mcc = 0.4580908547610124
06/26/2023 20:50:32 - INFO - __main__ -     precision = 0.7291831546634051
06/26/2023 20:50:32 - INFO - __main__ -     recall = 0.7289077828646174
06/26/2023 20:50:32 - INFO - __main__ -   {"eval_acc": 0.7289077828646174, "eval_f1": 0.7288263266355068, "eval_mcc": 0.4580908547610124, "eval_auc": 0.7929063610399509, "eval_precision": 0.7291831546634051, "eval_recall": 0.7289077828646174, "learning_rate": 7.915758896151053e-05, "loss": 0.11384958429960534, "step": 2200}
06/26/2023 20:51:15 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:51:16 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:51:16 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:51:16 - INFO - __main__ -     Batch size = 48
06/26/2023 20:51:25 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:51:25 - INFO - __main__ -     acc = 0.7354480052321779
06/26/2023 20:51:25 - INFO - __main__ -     auc = 0.792414454190854
06/26/2023 20:51:25 - INFO - __main__ -     f1 = 0.7353494903605449
06/26/2023 20:51:25 - INFO - __main__ -     mcc = 0.47124697997581755
06/26/2023 20:51:25 - INFO - __main__ -     precision = 0.7357991055364211
06/26/2023 20:51:25 - INFO - __main__ -     recall = 0.7354480052321779
06/26/2023 20:51:25 - INFO - __main__ -   {"eval_acc": 0.7354480052321779, "eval_f1": 0.7353494903605449, "eval_mcc": 0.47124697997581755, "eval_auc": 0.792414454190854, "eval_precision": 0.7357991055364211, "eval_recall": 0.7354480052321779, "learning_rate": 7.770515613652869e-05, "loss": 0.13183380984701215, "step": 2300}
06/26/2023 20:52:08 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:52:09 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:52:09 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:52:09 - INFO - __main__ -     Batch size = 48
06/26/2023 20:52:18 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:52:18 - INFO - __main__ -     acc = 0.7383911052975801
06/26/2023 20:52:18 - INFO - __main__ -     auc = 0.7998247100636869
06/26/2023 20:52:18 - INFO - __main__ -     f1 = 0.7372897372897373
06/26/2023 20:52:18 - INFO - __main__ -     mcc = 0.4808308584933029
06/26/2023 20:52:18 - INFO - __main__ -     precision = 0.7424569429622859
06/26/2023 20:52:18 - INFO - __main__ -     recall = 0.7383911052975801
06/26/2023 20:52:18 - INFO - __main__ -   {"eval_acc": 0.7383911052975801, "eval_f1": 0.7372897372897373, "eval_mcc": 0.4808308584933029, "eval_auc": 0.7998247100636869, "eval_precision": 0.7424569429622859, "eval_recall": 0.7383911052975801, "learning_rate": 7.625272331154685e-05, "loss": 0.09060580110177398, "step": 2400}
06/26/2023 20:53:01 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:53:01 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:53:01 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:53:01 - INFO - __main__ -     Batch size = 48
06/26/2023 20:53:10 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:53:10 - INFO - __main__ -     acc = 0.7396991497710922
06/26/2023 20:53:10 - INFO - __main__ -     auc = 0.794388925508621
06/26/2023 20:53:10 - INFO - __main__ -     f1 = 0.7384657832849697
06/26/2023 20:53:10 - INFO - __main__ -     mcc = 0.48398487069478485
06/26/2023 20:53:10 - INFO - __main__ -     precision = 0.744307661588645
06/26/2023 20:53:10 - INFO - __main__ -     recall = 0.7396991497710923
06/26/2023 20:53:10 - INFO - __main__ -   {"eval_acc": 0.7396991497710922, "eval_f1": 0.7384657832849697, "eval_mcc": 0.48398487069478485, "eval_auc": 0.794388925508621, "eval_precision": 0.744307661588645, "eval_recall": 0.7396991497710923, "learning_rate": 7.4800290486565e-05, "loss": 0.10423955619102344, "step": 2500}
06/26/2023 20:53:53 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:53:53 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:53:53 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:53:53 - INFO - __main__ -     Batch size = 48
06/26/2023 20:54:03 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:54:03 - INFO - __main__ -     acc = 0.7253106605624591
06/26/2023 20:54:03 - INFO - __main__ -     auc = 0.7734736879026418
06/26/2023 20:54:03 - INFO - __main__ -     f1 = 0.7238815500092228
06/26/2023 20:54:03 - INFO - __main__ -     mcc = 0.45535959683812127
06/26/2023 20:54:03 - INFO - __main__ -     precision = 0.7300738477209066
06/26/2023 20:54:03 - INFO - __main__ -     recall = 0.7253106605624591
06/26/2023 20:54:03 - INFO - __main__ -   {"eval_acc": 0.7253106605624591, "eval_f1": 0.7238815500092228, "eval_mcc": 0.45535959683812127, "eval_auc": 0.7734736879026418, "eval_precision": 0.7300738477209066, "eval_recall": 0.7253106605624591, "learning_rate": 7.334785766158315e-05, "loss": 0.09119579500053078, "step": 2600}
06/26/2023 20:54:46 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:54:46 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:54:46 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:54:46 - INFO - __main__ -     Batch size = 48
06/26/2023 20:54:55 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:54:55 - INFO - __main__ -     acc = 0.7331589274035317
06/26/2023 20:54:55 - INFO - __main__ -     auc = 0.7938805504737063
06/26/2023 20:54:55 - INFO - __main__ -     f1 = 0.7307709404623444
06/26/2023 20:54:55 - INFO - __main__ -     mcc = 0.47481690786282155
06/26/2023 20:54:55 - INFO - __main__ -     precision = 0.7417354318179501
06/26/2023 20:54:55 - INFO - __main__ -     recall = 0.7331589274035317
06/26/2023 20:54:55 - INFO - __main__ -   {"eval_acc": 0.7331589274035317, "eval_f1": 0.7307709404623444, "eval_mcc": 0.47481690786282155, "eval_auc": 0.7938805504737063, "eval_precision": 0.7417354318179501, "eval_recall": 0.7331589274035317, "learning_rate": 7.189542483660131e-05, "loss": 0.08873825852759182, "step": 2700}
06/26/2023 20:55:38 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:55:38 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:55:38 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:55:38 - INFO - __main__ -     Batch size = 48
06/26/2023 20:55:47 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:55:47 - INFO - __main__ -     acc = 0.7341399607586658
06/26/2023 20:55:47 - INFO - __main__ -     auc = 0.7754049569667056
06/26/2023 20:55:47 - INFO - __main__ -     f1 = 0.7339965674201501
06/26/2023 20:55:47 - INFO - __main__ -     mcc = 0.4687856067866371
06/26/2023 20:55:47 - INFO - __main__ -     precision = 0.7346459190672154
06/26/2023 20:55:47 - INFO - __main__ -     recall = 0.7341399607586658
06/26/2023 20:55:47 - INFO - __main__ -   {"eval_acc": 0.7341399607586658, "eval_f1": 0.7339965674201501, "eval_mcc": 0.4687856067866371, "eval_auc": 0.7754049569667056, "eval_precision": 0.7346459190672154, "eval_recall": 0.7341399607586658, "learning_rate": 7.044299201161947e-05, "loss": 0.09236738344538026, "step": 2800}
06/26/2023 20:56:30 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:56:31 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:56:31 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:56:31 - INFO - __main__ -     Batch size = 48
06/26/2023 20:56:40 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:56:40 - INFO - __main__ -     acc = 0.7410071942446043
06/26/2023 20:56:40 - INFO - __main__ -     auc = 0.7882548471003803
06/26/2023 20:56:40 - INFO - __main__ -     f1 = 0.7402962373913815
06/26/2023 20:56:40 - INFO - __main__ -     mcc = 0.4846753571562076
06/26/2023 20:56:40 - INFO - __main__ -     precision = 0.7436755078730981
06/26/2023 20:56:40 - INFO - __main__ -     recall = 0.7410071942446044
06/26/2023 20:56:40 - INFO - __main__ -   {"eval_acc": 0.7410071942446043, "eval_f1": 0.7402962373913815, "eval_mcc": 0.4846753571562076, "eval_auc": 0.7882548471003803, "eval_precision": 0.7436755078730981, "eval_recall": 0.7410071942446044, "learning_rate": 6.899055918663763e-05, "loss": 0.06956887546693906, "step": 2900}
06/26/2023 20:57:22 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:57:23 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:57:23 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:57:23 - INFO - __main__ -     Batch size = 48
06/26/2023 20:57:32 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:57:32 - INFO - __main__ -     acc = 0.7334859385219098
06/26/2023 20:57:32 - INFO - __main__ -     auc = 0.7805278459912373
06/26/2023 20:57:32 - INFO - __main__ -     f1 = 0.732901864393792
06/26/2023 20:57:32 - INFO - __main__ -     mcc = 0.4690276653335013
06/26/2023 20:57:32 - INFO - __main__ -     precision = 0.7355462519936204
06/26/2023 20:57:32 - INFO - __main__ -     recall = 0.7334859385219097
06/26/2023 20:57:32 - INFO - __main__ -   {"eval_acc": 0.7334859385219098, "eval_f1": 0.732901864393792, "eval_mcc": 0.4690276653335013, "eval_auc": 0.7805278459912373, "eval_precision": 0.7355462519936204, "eval_recall": 0.7334859385219097, "learning_rate": 6.753812636165577e-05, "loss": 0.08057757241535, "step": 3000}
06/26/2023 20:58:15 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:58:15 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:58:15 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:58:15 - INFO - __main__ -     Batch size = 48
06/26/2023 20:58:24 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:58:24 - INFO - __main__ -     acc = 0.7289077828646174
06/26/2023 20:58:24 - INFO - __main__ -     auc = 0.7978290653641544
06/26/2023 20:58:24 - INFO - __main__ -     f1 = 0.7250764365809812
06/26/2023 20:58:24 - INFO - __main__ -     mcc = 0.4711353774514838
06/26/2023 20:58:24 - INFO - __main__ -     precision = 0.7424213597158803
06/26/2023 20:58:24 - INFO - __main__ -     recall = 0.7289077828646173
06/26/2023 20:58:24 - INFO - __main__ -   {"eval_acc": 0.7289077828646174, "eval_f1": 0.7250764365809812, "eval_mcc": 0.4711353774514838, "eval_auc": 0.7978290653641544, "eval_precision": 0.7424213597158803, "eval_recall": 0.7289077828646173, "learning_rate": 6.608569353667393e-05, "loss": 0.06634643842699006, "step": 3100}
06/26/2023 20:59:07 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 20:59:08 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 20:59:08 - INFO - __main__ -     Num examples = 3058
06/26/2023 20:59:08 - INFO - __main__ -     Batch size = 48
06/26/2023 20:59:17 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 20:59:17 - INFO - __main__ -     acc = 0.7298888162197514
06/26/2023 20:59:17 - INFO - __main__ -     auc = 0.7762262275321546
06/26/2023 20:59:17 - INFO - __main__ -     f1 = 0.7294860261484947
06/26/2023 20:59:17 - INFO - __main__ -     mcc = 0.4611529790828224
06/26/2023 20:59:17 - INFO - __main__ -     precision = 0.7312662199209352
06/26/2023 20:59:17 - INFO - __main__ -     recall = 0.7298888162197514
06/26/2023 20:59:17 - INFO - __main__ -   {"eval_acc": 0.7298888162197514, "eval_f1": 0.7294860261484947, "eval_mcc": 0.4611529790828224, "eval_auc": 0.7762262275321546, "eval_precision": 0.7312662199209352, "eval_recall": 0.7298888162197514, "learning_rate": 6.463326071169209e-05, "loss": 0.07003714297898114, "step": 3200}
06/26/2023 20:59:59 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 21:00:00 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 21:00:00 - INFO - __main__ -     Num examples = 3058
06/26/2023 21:00:00 - INFO - __main__ -     Batch size = 48
06/26/2023 21:00:09 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 21:00:09 - INFO - __main__ -     acc = 0.724002616088947
06/26/2023 21:00:09 - INFO - __main__ -     auc = 0.799927155011825
06/26/2023 21:00:09 - INFO - __main__ -     f1 = 0.7177259994829074
06/26/2023 21:00:09 - INFO - __main__ -     mcc = 0.4693647334024858
06/26/2023 21:00:09 - INFO - __main__ -     precision = 0.7458712947291076
06/26/2023 21:00:09 - INFO - __main__ -     recall = 0.724002616088947
06/26/2023 21:00:09 - INFO - __main__ -   {"eval_acc": 0.724002616088947, "eval_f1": 0.7177259994829074, "eval_mcc": 0.4693647334024858, "eval_auc": 0.799927155011825, "eval_precision": 0.7458712947291076, "eval_recall": 0.724002616088947, "learning_rate": 6.318082788671025e-05, "loss": 0.0664183401747141, "step": 3300}
06/26/2023 21:00:52 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 21:00:53 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 21:00:53 - INFO - __main__ -     Num examples = 3058
06/26/2023 21:00:53 - INFO - __main__ -     Batch size = 48
06/26/2023 21:01:02 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 21:01:02 - INFO - __main__ -     acc = 0.737083060824068
06/26/2023 21:01:02 - INFO - __main__ -     auc = 0.7976081350271468
06/26/2023 21:01:02 - INFO - __main__ -     f1 = 0.7368448768583631
06/26/2023 21:01:02 - INFO - __main__ -     mcc = 0.4750268030562257
06/26/2023 21:01:02 - INFO - __main__ -     precision = 0.7379445233639724
06/26/2023 21:01:02 - INFO - __main__ -     recall = 0.737083060824068
06/26/2023 21:01:02 - INFO - __main__ -   {"eval_acc": 0.737083060824068, "eval_f1": 0.7368448768583631, "eval_mcc": 0.4750268030562257, "eval_auc": 0.7976081350271468, "eval_precision": 0.7379445233639724, "eval_recall": 0.737083060824068, "learning_rate": 6.17283950617284e-05, "loss": 0.05529885512951296, "step": 3400}
06/26/2023 21:01:45 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 21:01:45 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 21:01:45 - INFO - __main__ -     Num examples = 3058
06/26/2023 21:01:45 - INFO - __main__ -     Batch size = 48
06/26/2023 21:01:54 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 21:01:54 - INFO - __main__ -     acc = 0.7393721386527142
06/26/2023 21:01:54 - INFO - __main__ -     auc = 0.8079800978766305
06/26/2023 21:01:54 - INFO - __main__ -     f1 = 0.739354718381082
06/26/2023 21:01:54 - INFO - __main__ -     mcc = 0.47880828404946607
06/26/2023 21:01:54 - INFO - __main__ -     precision = 0.7394361496755113
06/26/2023 21:01:54 - INFO - __main__ -     recall = 0.7393721386527142
06/26/2023 21:01:54 - INFO - __main__ -   {"eval_acc": 0.7393721386527142, "eval_f1": 0.739354718381082, "eval_mcc": 0.47880828404946607, "eval_auc": 0.8079800978766305, "eval_precision": 0.7394361496755113, "eval_recall": 0.7393721386527142, "learning_rate": 6.0275962236746555e-05, "loss": 0.0650934447342297, "step": 3500}
06/26/2023 21:02:37 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 21:02:38 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 21:02:38 - INFO - __main__ -     Num examples = 3058
06/26/2023 21:02:38 - INFO - __main__ -     Batch size = 48
06/26/2023 21:02:47 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 21:02:47 - INFO - __main__ -     acc = 0.7432962720732504
06/26/2023 21:02:47 - INFO - __main__ -     auc = 0.7837697259993301
06/26/2023 21:02:47 - INFO - __main__ -     f1 = 0.7432960250145566
06/26/2023 21:02:47 - INFO - __main__ -     mcc = 0.4865934807682691
06/26/2023 21:02:47 - INFO - __main__ -     precision = 0.74329720869592
06/26/2023 21:02:47 - INFO - __main__ -     recall = 0.7432962720732506
06/26/2023 21:02:47 - INFO - __main__ -   {"eval_acc": 0.7432962720732504, "eval_f1": 0.7432960250145566, "eval_mcc": 0.4865934807682691, "eval_auc": 0.7837697259993301, "eval_precision": 0.74329720869592, "eval_recall": 0.7432962720732506, "learning_rate": 5.882352941176471e-05, "loss": 0.05278549016627949, "step": 3600}
06/26/2023 21:03:30 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 21:03:30 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 21:03:30 - INFO - __main__ -     Num examples = 3058
06/26/2023 21:03:30 - INFO - __main__ -     Batch size = 48
06/26/2023 21:03:39 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 21:03:39 - INFO - __main__ -     acc = 0.7311968606932636
06/26/2023 21:03:39 - INFO - __main__ -     auc = 0.7690533701821467
06/26/2023 21:03:39 - INFO - __main__ -     f1 = 0.7304589736562066
06/26/2023 21:03:39 - INFO - __main__ -     mcc = 0.46494637382556137
06/26/2023 21:03:39 - INFO - __main__ -     precision = 0.7337565591129991
06/26/2023 21:03:39 - INFO - __main__ -     recall = 0.7311968606932635
06/26/2023 21:03:39 - INFO - __main__ -   {"eval_acc": 0.7311968606932636, "eval_f1": 0.7304589736562066, "eval_mcc": 0.46494637382556137, "eval_auc": 0.7690533701821467, "eval_precision": 0.7337565591129991, "eval_recall": 0.7311968606932635, "learning_rate": 5.7371096586782866e-05, "loss": 0.04150411514914595, "step": 3700}
06/26/2023 21:04:22 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 21:04:23 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 21:04:23 - INFO - __main__ -     Num examples = 3058
06/26/2023 21:04:23 - INFO - __main__ -     Batch size = 48
06/26/2023 21:04:32 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 21:04:32 - INFO - __main__ -     acc = 0.7357750163505559
06/26/2023 21:04:32 - INFO - __main__ -     auc = 0.7975480368425398
06/26/2023 21:04:32 - INFO - __main__ -     f1 = 0.7350128715118117
06/26/2023 21:04:32 - INFO - __main__ -     mcc = 0.4742861689057533
06/26/2023 21:04:32 - INFO - __main__ -     precision = 0.7385190906750269
06/26/2023 21:04:32 - INFO - __main__ -     recall = 0.7357750163505559
06/26/2023 21:04:32 - INFO - __main__ -   {"eval_acc": 0.7357750163505559, "eval_f1": 0.7350128715118117, "eval_mcc": 0.4742861689057533, "eval_auc": 0.7975480368425398, "eval_precision": 0.7385190906750269, "eval_recall": 0.7357750163505559, "learning_rate": 5.591866376180102e-05, "loss": 0.0498916099476628, "step": 3800}
06/26/2023 21:05:15 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 21:05:15 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 21:05:15 - INFO - __main__ -     Num examples = 3058
06/26/2023 21:05:15 - INFO - __main__ -     Batch size = 48
06/26/2023 21:05:24 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 21:05:24 - INFO - __main__ -     acc = 0.738064094179202
06/26/2023 21:05:24 - INFO - __main__ -     auc = 0.7950418783826616
06/26/2023 21:05:24 - INFO - __main__ -     f1 = 0.7379968238188557
06/26/2023 21:05:24 - INFO - __main__ -     mcc = 0.4763728724677013
06/26/2023 21:05:24 - INFO - __main__ -     precision = 0.7383088411605523
06/26/2023 21:05:24 - INFO - __main__ -     recall = 0.738064094179202
06/26/2023 21:05:24 - INFO - __main__ -   {"eval_acc": 0.738064094179202, "eval_f1": 0.7379968238188557, "eval_mcc": 0.4763728724677013, "eval_auc": 0.7950418783826616, "eval_precision": 0.7383088411605523, "eval_recall": 0.738064094179202, "learning_rate": 5.446623093681917e-05, "loss": 0.032607152294222036, "step": 3900}
06/26/2023 21:06:07 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 21:06:08 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 21:06:08 - INFO - __main__ -     Num examples = 3058
06/26/2023 21:06:08 - INFO - __main__ -     Batch size = 48
06/26/2023 21:06:17 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 21:06:17 - INFO - __main__ -     acc = 0.7396991497710922
06/26/2023 21:06:17 - INFO - __main__ -     auc = 0.8080930225793798
06/26/2023 21:06:17 - INFO - __main__ -     f1 = 0.7357892885906623
06/26/2023 21:06:17 - INFO - __main__ -     mcc = 0.49424949783089195
06/26/2023 21:06:17 - INFO - __main__ -     precision = 0.7547803844312482
06/26/2023 21:06:17 - INFO - __main__ -     recall = 0.7396991497710923
06/26/2023 21:06:17 - INFO - __main__ -   {"eval_acc": 0.7396991497710922, "eval_f1": 0.7357892885906623, "eval_mcc": 0.49424949783089195, "eval_auc": 0.8080930225793798, "eval_precision": 0.7547803844312482, "eval_recall": 0.7396991497710923, "learning_rate": 5.301379811183733e-05, "loss": 0.047934959466656435, "step": 4000}
06/26/2023 21:06:17 - INFO - transformers.configuration_utils -   Configuration saved in /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold4/checkpoint-4000/config.json
06/26/2023 21:06:18 - INFO - transformers.modeling_utils -   Model weights saved in /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold4/checkpoint-4000/pytorch_model.bin
06/26/2023 21:06:18 - INFO - __main__ -   Saving model checkpoint to /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold4/checkpoint-4000
06/26/2023 21:06:18 - INFO - __main__ -   Saving optimizer and scheduler states to /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold4/checkpoint-4000
06/26/2023 21:07:01 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 21:07:02 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 21:07:02 - INFO - __main__ -     Num examples = 3058
06/26/2023 21:07:02 - INFO - __main__ -     Batch size = 48
06/26/2023 21:07:11 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 21:07:11 - INFO - __main__ -     acc = 0.7331589274035317
06/26/2023 21:07:11 - INFO - __main__ -     auc = 0.7804166322688326
06/26/2023 21:07:11 - INFO - __main__ -     f1 = 0.7328956895138035
06/26/2023 21:07:11 - INFO - __main__ -     mcc = 0.4672397167652405
06/26/2023 21:07:11 - INFO - __main__ -     precision = 0.7340817005743733
06/26/2023 21:07:11 - INFO - __main__ -     recall = 0.7331589274035317
06/26/2023 21:07:11 - INFO - __main__ -   {"eval_acc": 0.7331589274035317, "eval_f1": 0.7328956895138035, "eval_mcc": 0.4672397167652405, "eval_auc": 0.7804166322688326, "eval_precision": 0.7340817005743733, "eval_recall": 0.7331589274035317, "learning_rate": 5.156136528685549e-05, "loss": 0.038527113784221, "step": 4100}
06/26/2023 21:07:54 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 21:07:55 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 21:07:55 - INFO - __main__ -     Num examples = 3058
06/26/2023 21:07:55 - INFO - __main__ -     Batch size = 48
06/26/2023 21:08:04 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 21:08:04 - INFO - __main__ -     acc = 0.7321778940483976
06/26/2023 21:08:04 - INFO - __main__ -     auc = 0.8005493102396612
06/26/2023 21:08:04 - INFO - __main__ -     f1 = 0.7282206371362627
06/26/2023 21:08:04 - INFO - __main__ -     mcc = 0.4784992375057603
06/26/2023 21:08:04 - INFO - __main__ -     precision = 0.746536735583736
06/26/2023 21:08:04 - INFO - __main__ -     recall = 0.7321778940483976
06/26/2023 21:08:04 - INFO - __main__ -   {"eval_acc": 0.7321778940483976, "eval_f1": 0.7282206371362627, "eval_mcc": 0.4784992375057603, "eval_auc": 0.8005493102396612, "eval_precision": 0.746536735583736, "eval_recall": 0.7321778940483976, "learning_rate": 5.0108932461873634e-05, "loss": 0.03381887564435601, "step": 4200}
06/26/2023 21:08:47 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 21:08:48 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 21:08:48 - INFO - __main__ -     Num examples = 3058
06/26/2023 21:08:48 - INFO - __main__ -     Batch size = 48
06/26/2023 21:08:57 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 21:08:57 - INFO - __main__ -     acc = 0.7298888162197514
06/26/2023 21:08:57 - INFO - __main__ -     auc = 0.802295579553956
06/26/2023 21:08:57 - INFO - __main__ -     f1 = 0.7277665786061142
06/26/2023 21:08:57 - INFO - __main__ -     mcc = 0.4671182963324224
06/26/2023 21:08:57 - INFO - __main__ -     precision = 0.7372880794687366
06/26/2023 21:08:57 - INFO - __main__ -     recall = 0.7298888162197514
06/26/2023 21:08:57 - INFO - __main__ -   {"eval_acc": 0.7298888162197514, "eval_f1": 0.7277665786061142, "eval_mcc": 0.4671182963324224, "eval_auc": 0.802295579553956, "eval_precision": 0.7372880794687366, "eval_recall": 0.7298888162197514, "learning_rate": 4.865649963689179e-05, "loss": 0.04773356713936664, "step": 4300}
06/26/2023 21:09:40 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 21:09:41 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 21:09:41 - INFO - __main__ -     Num examples = 3058
06/26/2023 21:09:41 - INFO - __main__ -     Batch size = 48
06/26/2023 21:09:50 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 21:09:50 - INFO - __main__ -     acc = 0.7429692609548725
06/26/2023 21:09:50 - INFO - __main__ -     auc = 0.8027581858646503
06/26/2023 21:09:50 - INFO - __main__ -     f1 = 0.7428702735755844
06/26/2023 21:09:50 - INFO - __main__ -     mcc = 0.4863130986352268
06/26/2023 21:09:50 - INFO - __main__ -     precision = 0.7433439820481261
06/26/2023 21:09:50 - INFO - __main__ -     recall = 0.7429692609548725
06/26/2023 21:09:50 - INFO - __main__ -   {"eval_acc": 0.7429692609548725, "eval_f1": 0.7428702735755844, "eval_mcc": 0.4863130986352268, "eval_auc": 0.8027581858646503, "eval_precision": 0.7433439820481261, "eval_recall": 0.7429692609548725, "learning_rate": 4.720406681190995e-05, "loss": 0.03833272155330633, "step": 4400}
06/26/2023 21:10:33 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 21:10:33 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 21:10:33 - INFO - __main__ -     Num examples = 3058
06/26/2023 21:10:33 - INFO - __main__ -     Batch size = 48
06/26/2023 21:10:42 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 21:10:42 - INFO - __main__ -     acc = 0.7449313276651406
06/26/2023 21:10:42 - INFO - __main__ -     auc = 0.8052425293251338
06/26/2023 21:10:42 - INFO - __main__ -     f1 = 0.7441218308091373
06/26/2023 21:10:42 - INFO - __main__ -     mcc = 0.4929918470016773
06/26/2023 21:10:42 - INFO - __main__ -     precision = 0.7480705138119369
06/26/2023 21:10:42 - INFO - __main__ -     recall = 0.7449313276651406
06/26/2023 21:10:42 - INFO - __main__ -   {"eval_acc": 0.7449313276651406, "eval_f1": 0.7441218308091373, "eval_mcc": 0.4929918470016773, "eval_auc": 0.8052425293251338, "eval_precision": 0.7480705138119369, "eval_recall": 0.7449313276651406, "learning_rate": 4.5751633986928104e-05, "loss": 0.036004628794034946, "step": 4500}
06/26/2023 21:11:26 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 21:11:27 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 21:11:27 - INFO - __main__ -     Num examples = 3058
06/26/2023 21:11:27 - INFO - __main__ -     Batch size = 48
06/26/2023 21:11:36 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 21:11:36 - INFO - __main__ -     acc = 0.7413342053629823
06/26/2023 21:11:36 - INFO - __main__ -     auc = 0.7988252836698475
06/26/2023 21:11:36 - INFO - __main__ -     f1 = 0.7413262111575407
06/26/2023 21:11:36 - INFO - __main__ -     mcc = 0.4826982468236252
06/26/2023 21:11:36 - INFO - __main__ -     precision = 0.7413640423828005
06/26/2023 21:11:36 - INFO - __main__ -     recall = 0.7413342053629823
06/26/2023 21:11:36 - INFO - __main__ -   {"eval_acc": 0.7413342053629823, "eval_f1": 0.7413262111575407, "eval_mcc": 0.4826982468236252, "eval_auc": 0.7988252836698475, "eval_precision": 0.7413640423828005, "eval_recall": 0.7413342053629823, "learning_rate": 4.429920116194626e-05, "loss": 0.027078874897269997, "step": 4600}
06/26/2023 21:12:19 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 21:12:19 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 21:12:19 - INFO - __main__ -     Num examples = 3058
06/26/2023 21:12:19 - INFO - __main__ -     Batch size = 48
06/26/2023 21:12:28 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 21:12:28 - INFO - __main__ -     acc = 0.7275997383911053
06/26/2023 21:12:28 - INFO - __main__ -     auc = 0.8048676107571046
06/26/2023 21:12:28 - INFO - __main__ -     f1 = 0.7206302865462283
06/26/2023 21:12:28 - INFO - __main__ -     mcc = 0.47976593588365835
06/26/2023 21:12:28 - INFO - __main__ -     precision = 0.752829105671896
06/26/2023 21:12:28 - INFO - __main__ -     recall = 0.7275997383911053
06/26/2023 21:12:28 - INFO - __main__ -   {"eval_acc": 0.7275997383911053, "eval_f1": 0.7206302865462283, "eval_mcc": 0.47976593588365835, "eval_auc": 0.8048676107571046, "eval_precision": 0.752829105671896, "eval_recall": 0.7275997383911053, "learning_rate": 4.2846768336964415e-05, "loss": 0.01858557841027505, "step": 4700}
06/26/2023 21:13:12 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 21:13:12 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 21:13:12 - INFO - __main__ -     Num examples = 3058
06/26/2023 21:13:12 - INFO - __main__ -     Batch size = 48
06/26/2023 21:13:21 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 21:13:21 - INFO - __main__ -     acc = 0.7410071942446043
06/26/2023 21:13:21 - INFO - __main__ -     auc = 0.8053197373131877
06/26/2023 21:13:21 - INFO - __main__ -     f1 = 0.73703157919424
06/26/2023 21:13:21 - INFO - __main__ -     mcc = 0.49728498253053194
06/26/2023 21:13:21 - INFO - __main__ -     precision = 0.7565196804866001
06/26/2023 21:13:21 - INFO - __main__ -     recall = 0.7410071942446044
06/26/2023 21:13:21 - INFO - __main__ -   {"eval_acc": 0.7410071942446043, "eval_f1": 0.73703157919424, "eval_mcc": 0.49728498253053194, "eval_auc": 0.8053197373131877, "eval_precision": 0.7565196804866001, "eval_recall": 0.7410071942446044, "learning_rate": 4.1394335511982573e-05, "loss": 0.022722823561925908, "step": 4800}
06/26/2023 21:14:04 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 21:14:05 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 21:14:05 - INFO - __main__ -     Num examples = 3058
06/26/2023 21:14:05 - INFO - __main__ -     Batch size = 48
06/26/2023 21:14:14 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 21:14:14 - INFO - __main__ -     acc = 0.7442773054283846
06/26/2023 21:14:14 - INFO - __main__ -     auc = 0.7973705226317787
06/26/2023 21:14:14 - INFO - __main__ -     f1 = 0.7427711268454043
06/26/2023 21:14:14 - INFO - __main__ -     mcc = 0.4943784840347016
06/26/2023 21:14:14 - INFO - __main__ -     precision = 0.7501358906917613
06/26/2023 21:14:14 - INFO - __main__ -     recall = 0.7442773054283846
06/26/2023 21:14:14 - INFO - __main__ -   {"eval_acc": 0.7442773054283846, "eval_f1": 0.7427711268454043, "eval_mcc": 0.4943784840347016, "eval_auc": 0.7973705226317787, "eval_precision": 0.7501358906917613, "eval_recall": 0.7442773054283846, "learning_rate": 3.9941902687000726e-05, "loss": 0.028991588105272966, "step": 4900}
06/26/2023 21:14:57 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 21:14:57 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 21:14:57 - INFO - __main__ -     Num examples = 3058
06/26/2023 21:14:57 - INFO - __main__ -     Batch size = 48
06/26/2023 21:15:06 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 21:15:06 - INFO - __main__ -     acc = 0.7449313276651406
06/26/2023 21:15:06 - INFO - __main__ -     auc = 0.8090646455426181
06/26/2023 21:15:06 - INFO - __main__ -     f1 = 0.7444695271201431
06/26/2023 21:15:06 - INFO - __main__ -     mcc = 0.49164289514109344
06/26/2023 21:15:06 - INFO - __main__ -     precision = 0.7467148023150955
06/26/2023 21:15:06 - INFO - __main__ -     recall = 0.7449313276651406
06/26/2023 21:15:06 - INFO - __main__ -   {"eval_acc": 0.7449313276651406, "eval_f1": 0.7444695271201431, "eval_mcc": 0.49164289514109344, "eval_auc": 0.8090646455426181, "eval_precision": 0.7467148023150955, "eval_recall": 0.7449313276651406, "learning_rate": 3.8489469862018884e-05, "loss": 0.021003267854539445, "step": 5000}
06/26/2023 21:15:49 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 21:15:49 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 21:15:49 - INFO - __main__ -     Num examples = 3058
06/26/2023 21:15:49 - INFO - __main__ -     Batch size = 48
06/26/2023 21:15:59 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 21:15:59 - INFO - __main__ -     acc = 0.7347939829954219
06/26/2023 21:15:59 - INFO - __main__ -     auc = 0.8069618506989996
06/26/2023 21:15:59 - INFO - __main__ -     f1 = 0.7324039692946892
06/26/2023 21:15:59 - INFO - __main__ -     mcc = 0.47820780731850815
06/26/2023 21:15:59 - INFO - __main__ -     precision = 0.7434929380034778
06/26/2023 21:15:59 - INFO - __main__ -     recall = 0.7347939829954219
06/26/2023 21:15:59 - INFO - __main__ -   {"eval_acc": 0.7347939829954219, "eval_f1": 0.7324039692946892, "eval_mcc": 0.47820780731850815, "eval_auc": 0.8069618506989996, "eval_precision": 0.7434929380034778, "eval_recall": 0.7347939829954219, "learning_rate": 3.7037037037037037e-05, "loss": 0.024762524160396423, "step": 5100}
06/26/2023 21:16:41 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 21:16:42 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 21:16:42 - INFO - __main__ -     Num examples = 3058
06/26/2023 21:16:42 - INFO - __main__ -     Batch size = 48
06/26/2023 21:16:51 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 21:16:51 - INFO - __main__ -     acc = 0.7383911052975801
06/26/2023 21:16:51 - INFO - __main__ -     auc = 0.8088013684420798
06/26/2023 21:16:51 - INFO - __main__ -     f1 = 0.7338833194096352
06/26/2023 21:16:51 - INFO - __main__ -     mcc = 0.493804869787999
06/26/2023 21:16:51 - INFO - __main__ -     precision = 0.7557176463462811
06/26/2023 21:16:51 - INFO - __main__ -     recall = 0.7383911052975801
06/26/2023 21:16:51 - INFO - __main__ -   {"eval_acc": 0.7383911052975801, "eval_f1": 0.7338833194096352, "eval_mcc": 0.493804869787999, "eval_auc": 0.8088013684420798, "eval_precision": 0.7557176463462811, "eval_recall": 0.7383911052975801, "learning_rate": 3.5584604212055195e-05, "loss": 0.023236345000332222, "step": 5200}
06/26/2023 21:17:34 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 21:17:34 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 21:17:34 - INFO - __main__ -     Num examples = 3058
06/26/2023 21:17:34 - INFO - __main__ -     Batch size = 48
06/26/2023 21:17:44 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 21:17:44 - INFO - __main__ -     acc = 0.7377370830608241
06/26/2023 21:17:44 - INFO - __main__ -     auc = 0.8096651996436027
06/26/2023 21:17:44 - INFO - __main__ -     f1 = 0.7335353634564795
06/26/2023 21:17:44 - INFO - __main__ -     mcc = 0.49121789816496697
06/26/2023 21:17:44 - INFO - __main__ -     precision = 0.7537414655414458
06/26/2023 21:17:44 - INFO - __main__ -     recall = 0.7377370830608241
06/26/2023 21:17:44 - INFO - __main__ -   {"eval_acc": 0.7377370830608241, "eval_f1": 0.7335353634564795, "eval_mcc": 0.49121789816496697, "eval_auc": 0.8096651996436027, "eval_precision": 0.7537414655414458, "eval_recall": 0.7377370830608241, "learning_rate": 3.413217138707335e-05, "loss": 0.018169458391930675, "step": 5300}
06/26/2023 21:18:26 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 21:18:27 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 21:18:27 - INFO - __main__ -     Num examples = 3058
06/26/2023 21:18:27 - INFO - __main__ -     Batch size = 48
06/26/2023 21:18:36 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 21:18:36 - INFO - __main__ -     acc = 0.7393721386527142
06/26/2023 21:18:36 - INFO - __main__ -     auc = 0.8024799376860958
06/26/2023 21:18:36 - INFO - __main__ -     f1 = 0.7376043550408182
06/26/2023 21:18:36 - INFO - __main__ -     mcc = 0.48532834109567075
06/26/2023 21:18:36 - INFO - __main__ -     precision = 0.7460014770269557
06/26/2023 21:18:36 - INFO - __main__ -     recall = 0.7393721386527141
06/26/2023 21:18:36 - INFO - __main__ -   {"eval_acc": 0.7393721386527142, "eval_f1": 0.7376043550408182, "eval_mcc": 0.48532834109567075, "eval_auc": 0.8024799376860958, "eval_precision": 0.7460014770269557, "eval_recall": 0.7393721386527141, "learning_rate": 3.2679738562091506e-05, "loss": 0.016049457725021057, "step": 5400}
06/26/2023 21:19:18 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 21:19:19 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 21:19:19 - INFO - __main__ -     Num examples = 3058
06/26/2023 21:19:19 - INFO - __main__ -     Batch size = 48
06/26/2023 21:19:28 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 21:19:28 - INFO - __main__ -     acc = 0.7390451275343362
06/26/2023 21:19:28 - INFO - __main__ -     auc = 0.808298126348199
06/26/2023 21:19:28 - INFO - __main__ -     f1 = 0.7356213151092169
06/26/2023 21:19:28 - INFO - __main__ -     mcc = 0.4909760321968249
06/26/2023 21:19:28 - INFO - __main__ -     precision = 0.752104557283972
06/26/2023 21:19:28 - INFO - __main__ -     recall = 0.7390451275343362
06/26/2023 21:19:28 - INFO - __main__ -   {"eval_acc": 0.7390451275343362, "eval_f1": 0.7356213151092169, "eval_mcc": 0.4909760321968249, "eval_auc": 0.808298126348199, "eval_precision": 0.752104557283972, "eval_recall": 0.7390451275343362, "learning_rate": 3.122730573710966e-05, "loss": 0.014265359417258879, "step": 5500}
06/26/2023 21:20:11 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 21:20:12 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 21:20:12 - INFO - __main__ -     Num examples = 3058
06/26/2023 21:20:12 - INFO - __main__ -     Batch size = 48
06/26/2023 21:20:21 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 21:20:21 - INFO - __main__ -     acc = 0.7442773054283846
06/26/2023 21:20:21 - INFO - __main__ -     auc = 0.8098448525797949
06/26/2023 21:20:21 - INFO - __main__ -     f1 = 0.7434466877686382
06/26/2023 21:20:21 - INFO - __main__ -     mcc = 0.49174916395565654
06/26/2023 21:20:21 - INFO - __main__ -     precision = 0.747482302773703
06/26/2023 21:20:21 - INFO - __main__ -     recall = 0.7442773054283846
06/26/2023 21:20:21 - INFO - __main__ -   {"eval_acc": 0.7442773054283846, "eval_f1": 0.7434466877686382, "eval_mcc": 0.49174916395565654, "eval_auc": 0.8098448525797949, "eval_precision": 0.747482302773703, "eval_recall": 0.7442773054283846, "learning_rate": 2.9774872912127817e-05, "loss": 0.018080395238357597, "step": 5600}
06/26/2023 21:21:04 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 21:21:05 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 21:21:05 - INFO - __main__ -     Num examples = 3058
06/26/2023 21:21:05 - INFO - __main__ -     Batch size = 48
06/26/2023 21:21:14 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 21:21:14 - INFO - __main__ -     acc = 0.7383911052975801
06/26/2023 21:21:14 - INFO - __main__ -     auc = 0.8081674502243736
06/26/2023 21:21:14 - INFO - __main__ -     f1 = 0.7383587616446607
06/26/2023 21:21:14 - INFO - __main__ -     mcc = 0.4769001323700443
06/26/2023 21:21:14 - INFO - __main__ -     precision = 0.7385090416551654
06/26/2023 21:21:14 - INFO - __main__ -     recall = 0.7383911052975801
06/26/2023 21:21:14 - INFO - __main__ -   {"eval_acc": 0.7383911052975801, "eval_f1": 0.7383587616446607, "eval_mcc": 0.4769001323700443, "eval_auc": 0.8081674502243736, "eval_precision": 0.7385090416551654, "eval_recall": 0.7383911052975801, "learning_rate": 2.832244008714597e-05, "loss": 0.018839076590084006, "step": 5700}
06/26/2023 21:21:57 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 21:21:57 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 21:21:57 - INFO - __main__ -     Num examples = 3058
06/26/2023 21:21:57 - INFO - __main__ -     Batch size = 48
06/26/2023 21:22:06 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 21:22:06 - INFO - __main__ -     acc = 0.7361020274689339
06/26/2023 21:22:06 - INFO - __main__ -     auc = 0.8095347373923205
06/26/2023 21:22:06 - INFO - __main__ -     f1 = 0.7361013219604166
06/26/2023 21:22:06 - INFO - __main__ -     mcc = 0.47220657974516955
06/26/2023 21:22:06 - INFO - __main__ -     precision = 0.7361045522829854
06/26/2023 21:22:06 - INFO - __main__ -     recall = 0.7361020274689339
06/26/2023 21:22:06 - INFO - __main__ -   {"eval_acc": 0.7361020274689339, "eval_f1": 0.7361013219604166, "eval_mcc": 0.47220657974516955, "eval_auc": 0.8095347373923205, "eval_precision": 0.7361045522829854, "eval_recall": 0.7361020274689339, "learning_rate": 2.6870007262164125e-05, "loss": 0.015897271221037953, "step": 5800}
06/26/2023 21:22:50 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 21:22:50 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 21:22:50 - INFO - __main__ -     Num examples = 3058
06/26/2023 21:22:50 - INFO - __main__ -     Batch size = 48
06/26/2023 21:22:59 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 21:22:59 - INFO - __main__ -     acc = 0.7406801831262263
06/26/2023 21:22:59 - INFO - __main__ -     auc = 0.8116770986564099
06/26/2023 21:22:59 - INFO - __main__ -     f1 = 0.7406701719590936
06/26/2023 21:22:59 - INFO - __main__ -     mcc = 0.4813975354225505
06/26/2023 21:22:59 - INFO - __main__ -     precision = 0.7407173537313688
06/26/2023 21:22:59 - INFO - __main__ -     recall = 0.7406801831262263
06/26/2023 21:22:59 - INFO - __main__ -   {"eval_acc": 0.7406801831262263, "eval_f1": 0.7406701719590936, "eval_mcc": 0.4813975354225505, "eval_auc": 0.8116770986564099, "eval_precision": 0.7407173537313688, "eval_recall": 0.7406801831262263, "learning_rate": 2.5417574437182277e-05, "loss": 0.017650929238079698, "step": 5900}
06/26/2023 21:23:42 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 21:23:43 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 21:23:43 - INFO - __main__ -     Num examples = 3058
06/26/2023 21:23:43 - INFO - __main__ -     Batch size = 48
06/26/2023 21:23:52 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 21:23:52 - INFO - __main__ -     acc = 0.7449313276651406
06/26/2023 21:23:52 - INFO - __main__ -     auc = 0.8113751106255729
06/26/2023 21:23:52 - INFO - __main__ -     f1 = 0.7438574938574939
06/26/2023 21:23:52 - INFO - __main__ -     mcc = 0.49402237724483383
06/26/2023 21:23:52 - INFO - __main__ -     precision = 0.7491087109447904
06/26/2023 21:23:52 - INFO - __main__ -     recall = 0.7449313276651406
06/26/2023 21:23:52 - INFO - __main__ -   {"eval_acc": 0.7449313276651406, "eval_f1": 0.7438574938574939, "eval_mcc": 0.49402237724483383, "eval_auc": 0.8113751106255729, "eval_precision": 0.7491087109447904, "eval_recall": 0.7449313276651406, "learning_rate": 2.3965141612200436e-05, "loss": 0.008190675823934726, "step": 6000}
06/26/2023 21:24:35 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 21:24:35 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 21:24:35 - INFO - __main__ -     Num examples = 3058
06/26/2023 21:24:35 - INFO - __main__ -     Batch size = 48
06/26/2023 21:24:44 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 21:24:44 - INFO - __main__ -     acc = 0.7465663832570307
06/26/2023 21:24:44 - INFO - __main__ -     auc = 0.8104246610441002
06/26/2023 21:24:44 - INFO - __main__ -     f1 = 0.7446195208551656
06/26/2023 21:24:44 - INFO - __main__ -     mcc = 0.5008278859326086
06/26/2023 21:24:44 - INFO - __main__ -     precision = 0.7543215421486028
06/26/2023 21:24:44 - INFO - __main__ -     recall = 0.7465663832570308
06/26/2023 21:24:44 - INFO - __main__ -   {"eval_acc": 0.7465663832570307, "eval_f1": 0.7446195208551656, "eval_mcc": 0.5008278859326086, "eval_auc": 0.8104246610441002, "eval_precision": 0.7543215421486028, "eval_recall": 0.7465663832570308, "learning_rate": 2.251270878721859e-05, "loss": 0.006268744022017927, "step": 6100}
06/26/2023 21:25:27 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 21:25:28 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 21:25:28 - INFO - __main__ -     Num examples = 3058
06/26/2023 21:25:28 - INFO - __main__ -     Batch size = 48
06/26/2023 21:25:37 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 21:25:37 - INFO - __main__ -     acc = 0.7455853499018966
06/26/2023 21:25:37 - INFO - __main__ -     auc = 0.8133876512560093
06/26/2023 21:25:37 - INFO - __main__ -     f1 = 0.7454667846652105
06/26/2023 21:25:37 - INFO - __main__ -     mcc = 0.49162892902113076
06/26/2023 21:25:37 - INFO - __main__ -     precision = 0.7460437928677492
06/26/2023 21:25:37 - INFO - __main__ -     recall = 0.7455853499018967
06/26/2023 21:25:37 - INFO - __main__ -   {"eval_acc": 0.7455853499018966, "eval_f1": 0.7454667846652105, "eval_mcc": 0.49162892902113076, "eval_auc": 0.8133876512560093, "eval_precision": 0.7460437928677492, "eval_recall": 0.7455853499018967, "learning_rate": 2.1060275962236747e-05, "loss": 0.008683887116567347, "step": 6200}
06/26/2023 21:26:20 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 21:26:21 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 21:26:21 - INFO - __main__ -     Num examples = 3058
06/26/2023 21:26:21 - INFO - __main__ -     Batch size = 48
06/26/2023 21:26:30 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 21:26:30 - INFO - __main__ -     acc = 0.7465663832570307
06/26/2023 21:26:30 - INFO - __main__ -     auc = 0.8172822702655997
06/26/2023 21:26:30 - INFO - __main__ -     f1 = 0.7464518287360442
06/26/2023 21:26:30 - INFO - __main__ -     mcc = 0.49357897183576843
06/26/2023 21:26:30 - INFO - __main__ -     precision = 0.7470127904505283
06/26/2023 21:26:30 - INFO - __main__ -     recall = 0.7465663832570307
06/26/2023 21:26:30 - INFO - __main__ -   {"eval_acc": 0.7465663832570307, "eval_f1": 0.7464518287360442, "eval_mcc": 0.49357897183576843, "eval_auc": 0.8172822702655997, "eval_precision": 0.7470127904505283, "eval_recall": 0.7465663832570307, "learning_rate": 1.9607843137254903e-05, "loss": 0.011858639331585437, "step": 6300}
06/26/2023 21:27:13 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 21:27:13 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 21:27:13 - INFO - __main__ -     Num examples = 3058
06/26/2023 21:27:13 - INFO - __main__ -     Batch size = 48
06/26/2023 21:27:22 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 21:27:22 - INFO - __main__ -     acc = 0.7449313276651406
06/26/2023 21:27:22 - INFO - __main__ -     auc = 0.8152154060092196
06/26/2023 21:27:22 - INFO - __main__ -     f1 = 0.7441774862802837
06/26/2023 21:27:22 - INFO - __main__ -     mcc = 0.4927754219786014
06/26/2023 21:27:22 - INFO - __main__ -     precision = 0.7478527540974382
06/26/2023 21:27:22 - INFO - __main__ -     recall = 0.7449313276651406
06/26/2023 21:27:22 - INFO - __main__ -   {"eval_acc": 0.7449313276651406, "eval_f1": 0.7441774862802837, "eval_mcc": 0.4927754219786014, "eval_auc": 0.8152154060092196, "eval_precision": 0.7478527540974382, "eval_recall": 0.7449313276651406, "learning_rate": 1.8155410312273058e-05, "loss": 0.0072299928708889636, "step": 6400}
06/26/2023 21:28:06 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 21:28:06 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 21:28:06 - INFO - __main__ -     Num examples = 3058
06/26/2023 21:28:06 - INFO - __main__ -     Batch size = 48
06/26/2023 21:28:15 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 21:28:15 - INFO - __main__ -     acc = 0.7468933943754088
06/26/2023 21:28:15 - INFO - __main__ -     auc = 0.8161793295609069
06/26/2023 21:28:15 - INFO - __main__ -     f1 = 0.7456941159077468
06/26/2023 21:28:15 - INFO - __main__ -     mcc = 0.49851101961059013
06/26/2023 21:28:15 - INFO - __main__ -     precision = 0.7516402244194091
06/26/2023 21:28:15 - INFO - __main__ -     recall = 0.7468933943754088
06/26/2023 21:28:15 - INFO - __main__ -   {"eval_acc": 0.7468933943754088, "eval_f1": 0.7456941159077468, "eval_mcc": 0.49851101961059013, "eval_auc": 0.8161793295609069, "eval_precision": 0.7516402244194091, "eval_recall": 0.7468933943754088, "learning_rate": 1.6702977487291213e-05, "loss": 0.007622674414997164, "step": 6500}
06/26/2023 21:28:59 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 21:28:59 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 21:28:59 - INFO - __main__ -     Num examples = 3058
06/26/2023 21:28:59 - INFO - __main__ -     Batch size = 48
06/26/2023 21:29:08 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 21:29:08 - INFO - __main__ -     acc = 0.7446043165467626
06/26/2023 21:29:08 - INFO - __main__ -     auc = 0.8155122610990225
06/26/2023 21:29:08 - INFO - __main__ -     f1 = 0.7441490229544037
06/26/2023 21:29:08 - INFO - __main__ -     mcc = 0.4909591031280906
06/26/2023 21:29:08 - INFO - __main__ -     precision = 0.7463579183181113
06/26/2023 21:29:08 - INFO - __main__ -     recall = 0.7446043165467626
06/26/2023 21:29:08 - INFO - __main__ -   {"eval_acc": 0.7446043165467626, "eval_f1": 0.7441490229544037, "eval_mcc": 0.4909591031280906, "eval_auc": 0.8155122610990225, "eval_precision": 0.7463579183181113, "eval_recall": 0.7446043165467626, "learning_rate": 1.5250544662309369e-05, "loss": 0.005943225755763706, "step": 6600}
06/26/2023 21:29:51 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 21:29:52 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 21:29:52 - INFO - __main__ -     Num examples = 3058
06/26/2023 21:29:52 - INFO - __main__ -     Batch size = 48
06/26/2023 21:30:01 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 21:30:01 - INFO - __main__ -     acc = 0.7432962720732504
06/26/2023 21:30:01 - INFO - __main__ -     auc = 0.8139238297215251
06/26/2023 21:30:01 - INFO - __main__ -     f1 = 0.7425827384286194
06/26/2023 21:30:01 - INFO - __main__ -     mcc = 0.48931275253291967
06/26/2023 21:30:01 - INFO - __main__ -     precision = 0.7460240838783349
06/26/2023 21:30:01 - INFO - __main__ -     recall = 0.7432962720732506
06/26/2023 21:30:01 - INFO - __main__ -   {"eval_acc": 0.7432962720732504, "eval_f1": 0.7425827384286194, "eval_mcc": 0.48931275253291967, "eval_auc": 0.8139238297215251, "eval_precision": 0.7460240838783349, "eval_recall": 0.7432962720732506, "learning_rate": 1.3798111837327524e-05, "loss": 0.009195894937911363, "step": 6700}
06/26/2023 21:30:44 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 21:30:45 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 21:30:45 - INFO - __main__ -     Num examples = 3058
06/26/2023 21:30:45 - INFO - __main__ -     Batch size = 48
06/26/2023 21:30:54 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 21:30:54 - INFO - __main__ -     acc = 0.7452583387835187
06/26/2023 21:30:54 - INFO - __main__ -     auc = 0.8137373328639546
06/26/2023 21:30:54 - INFO - __main__ -     f1 = 0.7432418872198012
06/26/2023 21:30:54 - INFO - __main__ -     mcc = 0.4984076392680625
06/26/2023 21:30:54 - INFO - __main__ -     precision = 0.7532127715951246
06/26/2023 21:30:54 - INFO - __main__ -     recall = 0.7452583387835187
06/26/2023 21:30:54 - INFO - __main__ -   {"eval_acc": 0.7452583387835187, "eval_f1": 0.7432418872198012, "eval_mcc": 0.4984076392680625, "eval_auc": 0.8137373328639546, "eval_precision": 0.7532127715951246, "eval_recall": 0.7452583387835187, "learning_rate": 1.2345679012345678e-05, "loss": 0.0026236107740260197, "step": 6800}
06/26/2023 21:31:37 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 21:31:38 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 21:31:38 - INFO - __main__ -     Num examples = 3058
06/26/2023 21:31:38 - INFO - __main__ -     Batch size = 48
06/26/2023 21:31:47 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 21:31:47 - INFO - __main__ -     acc = 0.7455853499018966
06/26/2023 21:31:47 - INFO - __main__ -     auc = 0.8157006828094812
06/26/2023 21:31:47 - INFO - __main__ -     f1 = 0.744700805797726
06/26/2023 21:31:47 - INFO - __main__ -     mcc = 0.49461004344822673
06/26/2023 21:31:47 - INFO - __main__ -     precision = 0.7490367352710392
06/26/2023 21:31:47 - INFO - __main__ -     recall = 0.7455853499018967
06/26/2023 21:31:47 - INFO - __main__ -   {"eval_acc": 0.7455853499018966, "eval_f1": 0.744700805797726, "eval_mcc": 0.49461004344822673, "eval_auc": 0.8157006828094812, "eval_precision": 0.7490367352710392, "eval_recall": 0.7455853499018967, "learning_rate": 1.0893246187363835e-05, "loss": 0.004678016657908302, "step": 6900}
06/26/2023 21:32:30 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 21:32:30 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 21:32:30 - INFO - __main__ -     Num examples = 3058
06/26/2023 21:32:30 - INFO - __main__ -     Batch size = 48
06/26/2023 21:32:39 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 21:32:39 - INFO - __main__ -     acc = 0.7459123610202747
06/26/2023 21:32:39 - INFO - __main__ -     auc = 0.8164905141110965
06/26/2023 21:32:39 - INFO - __main__ -     f1 = 0.7444541585972816
06/26/2023 21:32:39 - INFO - __main__ -     mcc = 0.4975355992320064
06/26/2023 21:32:39 - INFO - __main__ -     precision = 0.7516563944530046
06/26/2023 21:32:39 - INFO - __main__ -     recall = 0.7459123610202747
06/26/2023 21:32:39 - INFO - __main__ -   {"eval_acc": 0.7459123610202747, "eval_f1": 0.7444541585972816, "eval_mcc": 0.4975355992320064, "eval_auc": 0.8164905141110965, "eval_precision": 0.7516563944530046, "eval_recall": 0.7459123610202747, "learning_rate": 9.440813362381991e-06, "loss": 0.005788318880913721, "step": 7000}
06/26/2023 21:33:23 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 21:33:23 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 21:33:23 - INFO - __main__ -     Num examples = 3058
06/26/2023 21:33:23 - INFO - __main__ -     Batch size = 48
06/26/2023 21:33:32 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 21:33:32 - INFO - __main__ -     acc = 0.7468933943754088
06/26/2023 21:33:32 - INFO - __main__ -     auc = 0.8172050622775457
06/26/2023 21:33:32 - INFO - __main__ -     f1 = 0.7455523925831642
06/26/2023 21:33:32 - INFO - __main__ -     mcc = 0.49907530953509865
06/26/2023 21:33:32 - INFO - __main__ -     precision = 0.752210235532696
06/26/2023 21:33:32 - INFO - __main__ -     recall = 0.7468933943754088
06/26/2023 21:33:32 - INFO - __main__ -   {"eval_acc": 0.7468933943754088, "eval_f1": 0.7455523925831642, "eval_mcc": 0.49907530953509865, "eval_auc": 0.8172050622775457, "eval_precision": 0.752210235532696, "eval_recall": 0.7468933943754088, "learning_rate": 7.988380537400146e-06, "loss": 0.0047631355977500785, "step": 7100}
06/26/2023 21:34:16 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 21:34:16 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 21:34:16 - INFO - __main__ -     Num examples = 3058
06/26/2023 21:34:16 - INFO - __main__ -     Batch size = 48
06/26/2023 21:34:25 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 21:34:25 - INFO - __main__ -     acc = 0.7468933943754088
06/26/2023 21:34:25 - INFO - __main__ -     auc = 0.816743953074653
06/26/2023 21:34:25 - INFO - __main__ -     f1 = 0.7461985956324866
06/26/2023 21:34:25 - INFO - __main__ -     mcc = 0.49651274715459526
06/26/2023 21:34:25 - INFO - __main__ -     precision = 0.7496268771291574
06/26/2023 21:34:25 - INFO - __main__ -     recall = 0.7468933943754088
06/26/2023 21:34:25 - INFO - __main__ -   {"eval_acc": 0.7468933943754088, "eval_f1": 0.7461985956324866, "eval_mcc": 0.49651274715459526, "eval_auc": 0.816743953074653, "eval_precision": 0.7496268771291574, "eval_recall": 0.7468933943754088, "learning_rate": 6.535947712418301e-06, "loss": 0.0017845097964527667, "step": 7200}
06/26/2023 21:35:09 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 21:35:09 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 21:35:09 - INFO - __main__ -     Num examples = 3058
06/26/2023 21:35:09 - INFO - __main__ -     Batch size = 48
06/26/2023 21:35:18 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 21:35:18 - INFO - __main__ -     acc = 0.7482014388489209
06/26/2023 21:35:18 - INFO - __main__ -     auc = 0.817724558684701
06/26/2023 21:35:18 - INFO - __main__ -     f1 = 0.7472048955928927
06/26/2023 21:35:18 - INFO - __main__ -     mcc = 0.5003635177305429
06/26/2023 21:35:18 - INFO - __main__ -     precision = 0.7521778792226085
06/26/2023 21:35:18 - INFO - __main__ -     recall = 0.7482014388489209
06/26/2023 21:35:18 - INFO - __main__ -   {"eval_acc": 0.7482014388489209, "eval_f1": 0.7472048955928927, "eval_mcc": 0.5003635177305429, "eval_auc": 0.817724558684701, "eval_precision": 0.7521778792226085, "eval_recall": 0.7482014388489209, "learning_rate": 5.083514887436457e-06, "loss": 0.005684884485708608, "step": 7300}
06/26/2023 21:36:01 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 21:36:02 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 21:36:02 - INFO - __main__ -     Num examples = 3058
06/26/2023 21:36:02 - INFO - __main__ -     Batch size = 48
06/26/2023 21:36:11 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 21:36:11 - INFO - __main__ -     acc = 0.7468933943754088
06/26/2023 21:36:11 - INFO - __main__ -     auc = 0.8179007896602036
06/26/2023 21:36:11 - INFO - __main__ -     f1 = 0.746553418954429
06/26/2023 21:36:11 - INFO - __main__ -     mcc = 0.49511688343224464
06/26/2023 21:36:11 - INFO - __main__ -     precision = 0.7482252804695486
06/26/2023 21:36:11 - INFO - __main__ -     recall = 0.7468933943754088
06/26/2023 21:36:11 - INFO - __main__ -   {"eval_acc": 0.7468933943754088, "eval_f1": 0.746553418954429, "eval_mcc": 0.49511688343224464, "eval_auc": 0.8179007896602036, "eval_precision": 0.7482252804695486, "eval_recall": 0.7468933943754088, "learning_rate": 3.6310820624546117e-06, "loss": 0.004673893575163675, "step": 7400}
06/26/2023 21:36:54 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 21:36:55 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 21:36:55 - INFO - __main__ -     Num examples = 3058
06/26/2023 21:36:55 - INFO - __main__ -     Batch size = 48
06/26/2023 21:37:04 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 21:37:04 - INFO - __main__ -     acc = 0.7462393721386528
06/26/2023 21:37:04 - INFO - __main__ -     auc = 0.8174403220749401
06/26/2023 21:37:04 - INFO - __main__ -     f1 = 0.7453571019267806
06/26/2023 21:37:04 - INFO - __main__ -     mcc = 0.4959272472922966
06/26/2023 21:37:04 - INFO - __main__ -     precision = 0.749699948946861
06/26/2023 21:37:04 - INFO - __main__ -     recall = 0.7462393721386527
06/26/2023 21:37:04 - INFO - __main__ -   {"eval_acc": 0.7462393721386528, "eval_f1": 0.7453571019267806, "eval_mcc": 0.4959272472922966, "eval_auc": 0.8174403220749401, "eval_precision": 0.749699948946861, "eval_recall": 0.7462393721386527, "learning_rate": 2.178649237472767e-06, "loss": 0.0022508360333631573, "step": 7500}
06/26/2023 21:37:46 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 21:37:47 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 21:37:47 - INFO - __main__ -     Num examples = 3058
06/26/2023 21:37:47 - INFO - __main__ -     Batch size = 48
06/26/2023 21:37:56 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 21:37:56 - INFO - __main__ -     acc = 0.7468933943754088
06/26/2023 21:37:56 - INFO - __main__ -     auc = 0.8172576749231449
06/26/2023 21:37:56 - INFO - __main__ -     f1 = 0.7460712740830254
06/26/2023 21:37:56 - INFO - __main__ -     mcc = 0.49701555393108526
06/26/2023 21:37:56 - INFO - __main__ -     precision = 0.7501327156548137
06/26/2023 21:37:56 - INFO - __main__ -     recall = 0.7468933943754088
06/26/2023 21:37:56 - INFO - __main__ -   {"eval_acc": 0.7468933943754088, "eval_f1": 0.7460712740830254, "eval_mcc": 0.49701555393108526, "eval_auc": 0.8172576749231449, "eval_precision": 0.7501327156548137, "eval_recall": 0.7468933943754088, "learning_rate": 7.262164124909224e-07, "loss": 0.0019228719956299756, "step": 7600}
06/26/2023 21:38:18 - INFO - __main__ -    global_step = 7650, average loss = 0.1345740040059586
06/26/2023 21:38:18 - INFO - __main__ -   Saving model checkpoint to /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold4
06/26/2023 21:38:18 - INFO - transformers.configuration_utils -   Configuration saved in /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold4/config.json
06/26/2023 21:38:18 - INFO - transformers.modeling_utils -   Model weights saved in /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold4/pytorch_model.bin
06/26/2023 21:38:18 - INFO - transformers.configuration_utils -   loading configuration file /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold4/config.json
06/26/2023 21:38:18 - INFO - transformers.configuration_utils -   Model config BertConfig {
  "architectures": [
    "BertForSequenceClassification"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "do_sample": false,
  "eos_token_ids": 0,
  "filter_num": 128,
  "filter_size": [
    2,
    3,
    4,
    5,
    6
  ],
  "finetuning_task": "dnaprom",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "num_return_sequences": 1,
  "num_rnn_layer": 2,
  "output_attentions": false,
  "output_hidden_states": true,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "rnn": "lstm",
  "rnn_dropout": 0.0,
  "rnn_hidden": 768,
  "split": 0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 4101
}

06/26/2023 21:38:18 - INFO - transformers.modeling_utils -   loading weights file /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold4/pytorch_model.bin
06/26/2023 21:38:20 - INFO - transformers.tokenization_utils -   Model name '/data3/linming/DNABERT/examples/output/fold5_100_15296/_fold4' not found in model shortcut name list (dna3, dna4, dna5, dna6). Assuming '/data3/linming/DNABERT/examples/output/fold5_100_15296/_fold4' is a path, a model identifier, or url to a directory containing tokenizer files.
06/26/2023 21:38:20 - INFO - transformers.tokenization_utils -   Didn't find file /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold4/added_tokens.json. We won't load it.
06/26/2023 21:38:20 - INFO - transformers.tokenization_utils -   loading file /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold4/vocab.txt
06/26/2023 21:38:20 - INFO - transformers.tokenization_utils -   loading file None
06/26/2023 21:38:20 - INFO - transformers.tokenization_utils -   loading file /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold4/special_tokens_map.json
06/26/2023 21:38:20 - INFO - transformers.tokenization_utils -   loading file /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold4/tokenizer_config.json
06/26/2023 21:38:20 - INFO - transformers.tokenization_utils -   Model name '/data3/linming/DNABERT/examples/output/fold5_100_15296/_fold4' not found in model shortcut name list (dna3, dna4, dna5, dna6). Assuming '/data3/linming/DNABERT/examples/output/fold5_100_15296/_fold4' is a path, a model identifier, or url to a directory containing tokenizer files.
06/26/2023 21:38:20 - INFO - transformers.tokenization_utils -   Didn't find file /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold4/added_tokens.json. We won't load it.
06/26/2023 21:38:20 - INFO - transformers.tokenization_utils -   loading file /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold4/vocab.txt
06/26/2023 21:38:20 - INFO - transformers.tokenization_utils -   loading file None
06/26/2023 21:38:20 - INFO - transformers.tokenization_utils -   loading file /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold4/special_tokens_map.json
06/26/2023 21:38:20 - INFO - transformers.tokenization_utils -   loading file /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold4/tokenizer_config.json
06/26/2023 21:38:20 - INFO - __main__ -   Evaluate the following checkpoints: ['/data3/linming/DNABERT/examples/output/fold5_100_15296/_fold4']
06/26/2023 21:38:20 - INFO - transformers.configuration_utils -   loading configuration file /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold4/config.json
06/26/2023 21:38:20 - INFO - transformers.configuration_utils -   Model config BertConfig {
  "architectures": [
    "BertForSequenceClassification"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "do_sample": false,
  "eos_token_ids": 0,
  "filter_num": 128,
  "filter_size": [
    2,
    3,
    4,
    5,
    6
  ],
  "finetuning_task": "dnaprom",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "num_return_sequences": 1,
  "num_rnn_layer": 2,
  "output_attentions": false,
  "output_hidden_states": true,
  "output_past": true,
  "pad_token_id": 0,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "rnn": "lstm",
  "rnn_dropout": 0.0,
  "rnn_hidden": 768,
  "split": 0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 4101
}

06/26/2023 21:38:20 - INFO - transformers.modeling_utils -   loading weights file /data3/linming/DNABERT/examples/output/fold5_100_15296/_fold4/pytorch_model.bin
06/26/2023 21:38:22 - INFO - __main__ -   Loading features from cached file /data3/linming/DNABERT/examples/data/fold5_100_15296/4/after/cached_dev_6-new-12w-0_300_dnaprom
06/26/2023 21:38:23 - INFO - __main__ -   ***** Running evaluation  *****
06/26/2023 21:38:23 - INFO - __main__ -     Num examples = 3058
06/26/2023 21:38:23 - INFO - __main__ -     Batch size = 48
06/26/2023 21:38:32 - INFO - __main__ -   ***** Eval results  *****
06/26/2023 21:38:32 - INFO - __main__ -     acc = 0.7462393721386528
06/26/2023 21:38:32 - INFO - __main__ -     auc = 0.8174082411934772
06/26/2023 21:38:32 - INFO - __main__ -     f1 = 0.745452704349408
06/26/2023 21:38:32 - INFO - __main__ -     mcc = 0.4955512299654349
06/26/2023 21:38:32 - INFO - __main__ -     precision = 0.7493214421676431
06/26/2023 21:38:32 - INFO - __main__ -     recall = 0.7462393721386527
